[2023-01-31 12:57:36 QFormer_transformer_base_patch4_window7_224] (main.py 442): INFO Full config saved to output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/config.json
[2023-01-31 12:57:36 QFormer_transformer_base_patch4_window7_224] (main.py 445): INFO AMP_OPT_LEVEL: O1
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
  SCALE: null
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /imagenet
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  NUM_WORKERS: 8
  PIN_MEMORY: true
  ZIP_MODE: false
EMA:
  EMA_DECAY: 0.9999200015999999
  EMA_FORCE_CPU: false
  ENABLE_EMA: true
ENABLE_WANDB: true
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.55
  DROP_RATE: 0.0
  EMSWIN:
    EM_FACTOR: 0.9
    EM_ITERS: 3
    INSTANCE_TOKENS:
    - 10
    - 10
    - 10
    - 0
  LABEL_SMOOTHING: 0.1
  NAME: QFormer_transformer_base_patch4_window7_224
  NUM_CLASSES: 1000
  PRETRAINED: ''
  QuadrangleAttention:
    context_size: null
    pyramid_size:
    - 1
    rpe: v1
  RESUME: ''
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 18
    - 2
    EMBED_DIM: 128
    IN_CHANS: 3
    LAYER_RATIO:
    - 1
    - 2
    - 3
    - 4
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 4
    - 8
    - 16
    - 32
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    RELATIVE_POS_EMBEDDING: true
    SHIFT: true
    WINDOW_SIZE: 7
  TYPE: qformer
OUTPUT: output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1
PRINT_FREQ: 50
RESUME_OPTIMIZER: true
SAVE_FREQ: 1
SEED: 0
TAG: 1024-dpr55-coords_lambda5e-1
TEST:
  CROP: true
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 0.001
  CLIP_GRAD: 5.0
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 1.0e-05
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 20
  WARMUP_LR: 1.0e-06
  WEIGHT_DECAY: 0.05
  coords_lambda: 0.5

[2023-01-31 12:57:40 QFormer_transformer_base_patch4_window7_224] (main.py 99): INFO Creating model:qformer/QFormer_transformer_base_patch4_window7_224
[2023-01-31 12:57:42 QFormer_transformer_base_patch4_window7_224] (main.py 102): INFO QFormer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(128, 36, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=128, input_resolution=(56, 56), num_heads=4, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(128, 36, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(256, 72, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=256, input_resolution=(28, 28), num_heads=8, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(256, 72, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): SwinTransformerBlock(
          dim=512, input_resolution=(14, 14), num_heads=16, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(1024, 288, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=1024, input_resolution=(7, 7), num_heads=32, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (pos): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (attn): QuadrangleAttention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (transform): Sequential(
              (0): AvgPool2d(kernel_size=7, stride=7, padding=0)
              (1): LeakyReLU(negative_slope=0.01)
              (2): Conv2d(1024, 288, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2023-01-31 12:57:42 QFormer_transformer_base_patch4_window7_224] (main.py 115): INFO enable EMA model
[2023-01-31 12:57:43 QFormer_transformer_base_patch4_window7_224] (main.py 129): INFO number of params: 90336216
[2023-01-31 12:57:43 QFormer_transformer_base_patch4_window7_224] (main.py 132): INFO number of GFLOPs: 0.020893696
[2023-01-31 12:57:49 QFormer_transformer_base_patch4_window7_224] (main.py 175): INFO no checkpoint found in output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1, ignoring auto resume
[2023-01-31 12:57:49 QFormer_transformer_base_patch4_window7_224] (main.py 201): INFO Start training
[2023-01-31 12:57:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][0/1251]	eta 2:26:04 lr 0.000001	time 7.0060 (7.0060)	loss 6.9892 (6.9892)	grad_norm 1.2953 (1.2953)	mem 16239MB
[2023-01-31 12:58:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][50/1251]	eta 0:14:35 lr 0.000003	time 0.5629 (0.7290)	loss 6.9700 (6.9520)	grad_norm 0.9723 (1.1264)	mem 17299MB
[2023-01-31 12:58:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][100/1251]	eta 0:12:25 lr 0.000005	time 0.6384 (0.6473)	loss 6.9397 (6.9454)	grad_norm 0.8986 (1.0539)	mem 17299MB
[2023-01-31 12:59:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][150/1251]	eta 0:11:21 lr 0.000007	time 0.5520 (0.6192)	loss 6.9149 (6.9390)	grad_norm 0.8155 (0.9824)	mem 17299MB
[2023-01-31 12:59:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][200/1251]	eta 0:10:36 lr 0.000009	time 0.5600 (0.6057)	loss 6.9312 (6.9333)	grad_norm 0.7016 (0.9181)	mem 17299MB
[2023-01-31 13:00:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][250/1251]	eta 0:09:57 lr 0.000011	time 0.5578 (0.5968)	loss 6.9116 (6.9288)	grad_norm 0.6325 (0.8663)	mem 17299MB
[2023-01-31 13:00:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][300/1251]	eta 0:09:22 lr 0.000013	time 0.5540 (0.5915)	loss 6.9358 (6.9255)	grad_norm 0.5914 (0.8291)	mem 17299MB
[2023-01-31 13:01:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][350/1251]	eta 0:08:49 lr 0.000015	time 0.5493 (0.5878)	loss 6.9116 (6.9219)	grad_norm 0.6106 (0.8009)	mem 17299MB
[2023-01-31 13:01:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][400/1251]	eta 0:08:17 lr 0.000017	time 0.5511 (0.5842)	loss 6.9076 (6.9182)	grad_norm 0.7135 (0.7827)	mem 17299MB
[2023-01-31 13:02:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][450/1251]	eta 0:07:46 lr 0.000019	time 0.5546 (0.5820)	loss 6.8817 (6.9150)	grad_norm 0.7139 (0.7743)	mem 17299MB
[2023-01-31 13:02:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][500/1251]	eta 0:07:15 lr 0.000021	time 0.5577 (0.5804)	loss 6.8786 (6.9104)	grad_norm 0.6571 (0.7679)	mem 17299MB
[2023-01-31 13:03:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][550/1251]	eta 0:06:45 lr 0.000023	time 0.5498 (0.5788)	loss 6.8680 (6.9064)	grad_norm 1.0020 (0.7677)	mem 17299MB
[2023-01-31 13:03:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][600/1251]	eta 0:06:15 lr 0.000025	time 0.5509 (0.5769)	loss 6.7855 (6.9011)	grad_norm 1.1346 (0.7709)	mem 17299MB
[2023-01-31 13:04:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][650/1251]	eta 0:05:45 lr 0.000027	time 0.5784 (0.5755)	loss 6.8071 (6.8970)	grad_norm 0.7669 (0.7739)	mem 17299MB
[2023-01-31 13:04:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][700/1251]	eta 0:05:16 lr 0.000029	time 0.5467 (0.5745)	loss 6.8909 (6.8930)	grad_norm 0.7529 (0.7805)	mem 17299MB
[2023-01-31 13:05:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][750/1251]	eta 0:04:47 lr 0.000031	time 0.5521 (0.5734)	loss 6.9414 (6.8890)	grad_norm 0.8087 (0.7856)	mem 17300MB
[2023-01-31 13:05:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][800/1251]	eta 0:04:18 lr 0.000033	time 0.5513 (0.5725)	loss 6.8648 (6.8856)	grad_norm 1.0268 (0.7946)	mem 17300MB
[2023-01-31 13:05:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][850/1251]	eta 0:03:49 lr 0.000035	time 0.5521 (0.5716)	loss 6.9563 (6.8814)	grad_norm 1.0034 (0.8037)	mem 17300MB
[2023-01-31 13:06:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][900/1251]	eta 0:03:20 lr 0.000037	time 0.5588 (0.5708)	loss 6.8985 (6.8774)	grad_norm 1.0856 (0.8139)	mem 17300MB
[2023-01-31 13:06:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][950/1251]	eta 0:02:51 lr 0.000039	time 0.5509 (0.5699)	loss 6.7870 (6.8724)	grad_norm 1.2022 (0.8280)	mem 17300MB
[2023-01-31 13:07:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][1000/1251]	eta 0:02:22 lr 0.000041	time 0.5491 (0.5692)	loss 6.7943 (6.8683)	grad_norm 1.3288 (0.8414)	mem 17300MB
[2023-01-31 13:07:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][1050/1251]	eta 0:01:54 lr 0.000043	time 0.5511 (0.5686)	loss 6.6792 (6.8638)	grad_norm 1.1264 (0.8625)	mem 17300MB
[2023-01-31 13:08:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][1100/1251]	eta 0:01:25 lr 0.000045	time 0.5523 (0.5680)	loss 6.7905 (6.8581)	grad_norm 1.4386 (0.8795)	mem 17300MB
[2023-01-31 13:08:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][1150/1251]	eta 0:00:57 lr 0.000047	time 0.5449 (0.5675)	loss 6.8798 (6.8529)	grad_norm 1.2118 (0.8972)	mem 17300MB
[2023-01-31 13:09:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][1200/1251]	eta 0:00:28 lr 0.000049	time 0.5622 (0.5671)	loss 6.6773 (6.8477)	grad_norm 1.0345 (0.9138)	mem 17300MB
[2023-01-31 13:09:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [0/300][1250/1251]	eta 0:00:00 lr 0.000051	time 0.5470 (0.5666)	loss 6.6713 (6.8423)	grad_norm 0.8954 (0.9290)	mem 17300MB
[2023-01-31 13:09:38 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 0 training takes 0:11:48
[2023-01-31 13:09:38 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_0.pth saving......
[2023-01-31 13:09:40 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_0.pth saved !!!
[2023-01-31 13:09:41 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.905 (0.905)	Loss 6.2723 (6.2723)	Acc@1 1.953 (1.953)	Acc@5 6.348 (6.348)	Mem 17300MB
[2023-01-31 13:09:51 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 1.974 Acc@5 6.614
[2023-01-31 13:09:51 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 2.0%
[2023-01-31 13:09:53 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.307 (1.307)	Loss 6.9494 (6.9494)	Acc@1 0.000 (0.000)	Acc@5 0.195 (0.195)	Mem 17300MB
[2023-01-31 13:10:01 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 0.078 Acc@5 0.520
[2023-01-31 13:10:01 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 0.1%
[2023-01-31 13:10:01 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 1.97% at 0 epoch
[2023-01-31 13:10:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][0/1251]	eta 1:02:44 lr 0.000051	time 3.0088 (3.0088)	loss 6.6402 (6.6402)	grad_norm 1.2780 (1.2780)	mem 17413MB
[2023-01-31 13:10:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][50/1251]	eta 0:12:10 lr 0.000053	time 0.5542 (0.6083)	loss 6.6173 (6.7071)	grad_norm 1.5189 (1.3602)	mem 17413MB
[2023-01-31 13:11:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][100/1251]	eta 0:11:12 lr 0.000055	time 0.5617 (0.5840)	loss 6.6803 (6.6941)	grad_norm 1.5658 (1.3510)	mem 17413MB
[2023-01-31 13:11:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][150/1251]	eta 0:10:33 lr 0.000057	time 0.5454 (0.5757)	loss 6.7008 (6.6911)	grad_norm 1.2256 (1.4263)	mem 17413MB
[2023-01-31 13:11:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][200/1251]	eta 0:09:59 lr 0.000059	time 0.5554 (0.5705)	loss 6.6650 (6.6838)	grad_norm 1.6174 (1.4302)	mem 17413MB
[2023-01-31 13:12:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][250/1251]	eta 0:09:28 lr 0.000061	time 0.5546 (0.5680)	loss 6.6644 (6.6741)	grad_norm 1.1886 (1.4552)	mem 17413MB
[2023-01-31 13:12:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][300/1251]	eta 0:08:58 lr 0.000063	time 0.5511 (0.5664)	loss 6.5823 (6.6674)	grad_norm 1.1978 (1.4576)	mem 17413MB
[2023-01-31 13:13:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][350/1251]	eta 0:08:29 lr 0.000065	time 0.5511 (0.5653)	loss 6.6565 (6.6578)	grad_norm 1.6781 (1.4516)	mem 17413MB
[2023-01-31 13:13:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][400/1251]	eta 0:08:00 lr 0.000067	time 0.6415 (0.5645)	loss 6.3273 (6.6485)	grad_norm 1.4747 (1.4633)	mem 17413MB
[2023-01-31 13:14:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][450/1251]	eta 0:07:31 lr 0.000069	time 0.5578 (0.5637)	loss 6.7497 (6.6412)	grad_norm 1.5705 (1.4558)	mem 17413MB
[2023-01-31 13:14:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][500/1251]	eta 0:07:02 lr 0.000071	time 0.5609 (0.5631)	loss 6.5806 (6.6325)	grad_norm 1.5721 (1.4606)	mem 17413MB
[2023-01-31 13:15:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][550/1251]	eta 0:06:34 lr 0.000073	time 0.5496 (0.5625)	loss 6.5902 (6.6272)	grad_norm 2.5786 (1.4761)	mem 17413MB
[2023-01-31 13:15:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][600/1251]	eta 0:06:05 lr 0.000075	time 0.5587 (0.5622)	loss 6.6029 (6.6200)	grad_norm 1.1753 (1.4803)	mem 17413MB
[2023-01-31 13:16:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][650/1251]	eta 0:05:37 lr 0.000077	time 0.5529 (0.5619)	loss 6.6217 (6.6137)	grad_norm 1.5745 (1.4922)	mem 17413MB
[2023-01-31 13:16:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][700/1251]	eta 0:05:09 lr 0.000079	time 0.5622 (0.5615)	loss 6.4681 (6.6066)	grad_norm 1.4438 (1.4943)	mem 17413MB
[2023-01-31 13:17:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][750/1251]	eta 0:04:41 lr 0.000081	time 0.5517 (0.5611)	loss 6.4008 (6.5982)	grad_norm 1.7300 (1.5036)	mem 17413MB
[2023-01-31 13:17:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][800/1251]	eta 0:04:13 lr 0.000083	time 0.5551 (0.5610)	loss 6.6310 (6.5968)	grad_norm 1.3700 (1.5114)	mem 17413MB
[2023-01-31 13:17:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][850/1251]	eta 0:03:44 lr 0.000085	time 0.5540 (0.5608)	loss 6.2940 (6.5896)	grad_norm 1.5506 (1.5198)	mem 17413MB
[2023-01-31 13:18:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][900/1251]	eta 0:03:16 lr 0.000087	time 0.5659 (0.5607)	loss 6.6477 (6.5849)	grad_norm 1.3536 (1.5243)	mem 17413MB
[2023-01-31 13:18:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][950/1251]	eta 0:02:48 lr 0.000089	time 0.5567 (0.5606)	loss 6.5359 (6.5799)	grad_norm 1.5897 (nan)	mem 17413MB
[2023-01-31 13:19:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][1000/1251]	eta 0:02:20 lr 0.000091	time 0.5530 (0.5604)	loss 6.5924 (6.5721)	grad_norm 1.8770 (nan)	mem 17413MB
[2023-01-31 13:19:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][1050/1251]	eta 0:01:52 lr 0.000093	time 0.5654 (0.5605)	loss 6.3236 (6.5673)	grad_norm 1.6980 (nan)	mem 17413MB
[2023-01-31 13:20:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][1100/1251]	eta 0:01:24 lr 0.000095	time 0.5486 (0.5606)	loss 6.3278 (6.5642)	grad_norm 1.5969 (nan)	mem 17413MB
[2023-01-31 13:20:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][1150/1251]	eta 0:00:56 lr 0.000097	time 0.5575 (0.5606)	loss 6.6877 (6.5585)	grad_norm 1.4711 (nan)	mem 17413MB
[2023-01-31 13:21:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][1200/1251]	eta 0:00:28 lr 0.000099	time 0.5682 (0.5605)	loss 6.6891 (6.5542)	grad_norm 1.5194 (nan)	mem 17413MB
[2023-01-31 13:21:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [1/300][1250/1251]	eta 0:00:00 lr 0.000101	time 0.5500 (0.5605)	loss 6.2346 (6.5490)	grad_norm 1.6598 (nan)	mem 17413MB
[2023-01-31 13:21:42 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 1 training takes 0:11:41
[2023-01-31 13:21:42 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_1.pth saving......
[2023-01-31 13:21:44 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_1.pth saved !!!
[2023-01-31 13:21:45 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.876 (0.876)	Loss 5.5175 (5.5175)	Acc@1 6.641 (6.641)	Acc@5 17.969 (17.969)	Mem 17413MB
[2023-01-31 13:21:53 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 5.912 Acc@5 17.314
[2023-01-31 13:21:53 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 5.9%
[2023-01-31 13:21:54 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.248 (1.248)	Loss 6.9557 (6.9557)	Acc@1 0.195 (0.195)	Acc@5 0.293 (0.293)	Mem 17413MB
[2023-01-31 13:22:02 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 0.116 Acc@5 0.536
[2023-01-31 13:22:02 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 0.1%
[2023-01-31 13:22:02 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 5.91% at 1 epoch
[2023-01-31 13:22:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][0/1251]	eta 0:37:04 lr 0.000101	time 1.7782 (1.7782)	loss 6.2475 (6.2475)	grad_norm 1.3767 (1.3767)	mem 17413MB
[2023-01-31 13:22:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][50/1251]	eta 0:11:39 lr 0.000103	time 0.5540 (0.5822)	loss 6.5952 (6.4551)	grad_norm 1.9367 (1.6973)	mem 17413MB
[2023-01-31 13:23:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][100/1251]	eta 0:10:58 lr 0.000105	time 0.5519 (0.5719)	loss 6.5109 (6.4675)	grad_norm 2.0935 (1.6788)	mem 17413MB
[2023-01-31 13:23:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][150/1251]	eta 0:10:24 lr 0.000107	time 0.5601 (0.5673)	loss 6.0082 (6.4568)	grad_norm 1.2762 (1.7020)	mem 17413MB
[2023-01-31 13:23:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][200/1251]	eta 0:09:53 lr 0.000109	time 0.5533 (0.5649)	loss 6.5957 (6.4625)	grad_norm 1.5464 (1.6987)	mem 17413MB
[2023-01-31 13:24:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][250/1251]	eta 0:09:24 lr 0.000111	time 0.5458 (0.5636)	loss 5.9688 (6.4509)	grad_norm 1.6729 (1.6993)	mem 17413MB
[2023-01-31 13:24:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][300/1251]	eta 0:08:55 lr 0.000113	time 0.5507 (0.5632)	loss 6.3894 (6.4401)	grad_norm 1.8954 (1.7226)	mem 17413MB
[2023-01-31 13:25:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][350/1251]	eta 0:08:26 lr 0.000115	time 0.5538 (0.5621)	loss 6.3123 (6.4281)	grad_norm 1.5097 (1.7278)	mem 17413MB
[2023-01-31 13:25:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][400/1251]	eta 0:07:58 lr 0.000117	time 0.5505 (0.5620)	loss 6.0808 (6.4152)	grad_norm 1.8295 (1.7326)	mem 17413MB
[2023-01-31 13:26:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][450/1251]	eta 0:07:29 lr 0.000119	time 0.5515 (0.5613)	loss 6.3603 (6.4064)	grad_norm 1.8376 (1.7409)	mem 17413MB
[2023-01-31 13:26:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][500/1251]	eta 0:07:01 lr 0.000121	time 0.5563 (0.5612)	loss 6.5737 (6.4032)	grad_norm 2.0162 (1.7476)	mem 17413MB
[2023-01-31 13:27:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][550/1251]	eta 0:06:33 lr 0.000123	time 0.5587 (0.5610)	loss 6.2735 (6.3975)	grad_norm 2.0975 (1.7551)	mem 17413MB
[2023-01-31 13:27:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][600/1251]	eta 0:06:05 lr 0.000125	time 0.5565 (0.5610)	loss 6.2103 (6.3948)	grad_norm 1.5074 (1.7533)	mem 17413MB
[2023-01-31 13:28:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][650/1251]	eta 0:05:37 lr 0.000127	time 0.6396 (0.5610)	loss 6.4760 (6.3889)	grad_norm 1.8024 (1.7506)	mem 17413MB
[2023-01-31 13:28:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][700/1251]	eta 0:05:09 lr 0.000129	time 0.5574 (0.5609)	loss 6.4266 (6.3865)	grad_norm 1.4610 (1.7551)	mem 17413MB
[2023-01-31 13:29:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][750/1251]	eta 0:04:40 lr 0.000131	time 0.6479 (0.5607)	loss 6.1145 (6.3849)	grad_norm 1.9369 (1.7563)	mem 17413MB
[2023-01-31 13:29:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][800/1251]	eta 0:04:12 lr 0.000133	time 0.5531 (0.5609)	loss 6.4447 (6.3787)	grad_norm 1.7081 (1.7532)	mem 17413MB
[2023-01-31 13:29:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][850/1251]	eta 0:03:44 lr 0.000135	time 0.5537 (0.5606)	loss 6.3572 (6.3738)	grad_norm 1.7257 (1.7654)	mem 17413MB
[2023-01-31 13:30:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][900/1251]	eta 0:03:16 lr 0.000137	time 0.5582 (0.5606)	loss 6.4401 (6.3693)	grad_norm 1.6831 (1.7658)	mem 17413MB
[2023-01-31 13:30:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][950/1251]	eta 0:02:48 lr 0.000139	time 0.5537 (0.5606)	loss 6.4778 (6.3660)	grad_norm 1.9315 (1.7707)	mem 17413MB
[2023-01-31 13:31:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][1000/1251]	eta 0:02:20 lr 0.000141	time 0.5495 (0.5606)	loss 6.3789 (6.3597)	grad_norm 1.9006 (1.7753)	mem 17413MB
[2023-01-31 13:31:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][1050/1251]	eta 0:01:52 lr 0.000143	time 0.5580 (0.5605)	loss 6.2446 (6.3535)	grad_norm 1.6202 (1.7715)	mem 17413MB
[2023-01-31 13:32:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][1100/1251]	eta 0:01:24 lr 0.000145	time 0.6384 (0.5605)	loss 5.6092 (6.3496)	grad_norm 1.6642 (1.7773)	mem 17413MB
[2023-01-31 13:32:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][1150/1251]	eta 0:00:56 lr 0.000147	time 0.5586 (0.5605)	loss 6.4078 (6.3474)	grad_norm 1.6678 (1.7824)	mem 17413MB
[2023-01-31 13:33:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][1200/1251]	eta 0:00:28 lr 0.000149	time 0.5571 (0.5608)	loss 6.1746 (6.3429)	grad_norm 1.8147 (inf)	mem 17413MB
[2023-01-31 13:33:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [2/300][1250/1251]	eta 0:00:00 lr 0.000151	time 0.5622 (0.5607)	loss 6.4586 (6.3391)	grad_norm 1.9722 (inf)	mem 17413MB
[2023-01-31 13:33:43 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 2 training takes 0:11:41
[2023-01-31 13:33:44 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_2.pth saving......
[2023-01-31 13:33:45 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_2.pth saved !!!
[2023-01-31 13:33:46 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.844 (0.844)	Loss 4.9254 (4.9254)	Acc@1 10.645 (10.645)	Acc@5 26.562 (26.562)	Mem 17413MB
[2023-01-31 13:33:54 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 10.908 Acc@5 27.106
[2023-01-31 13:33:54 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 10.9%
[2023-01-31 13:33:56 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.403 (1.403)	Loss 6.9303 (6.9303)	Acc@1 0.098 (0.098)	Acc@5 0.488 (0.488)	Mem 17413MB
[2023-01-31 13:34:03 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 0.140 Acc@5 0.576
[2023-01-31 13:34:03 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 0.1%
[2023-01-31 13:34:03 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 10.91% at 2 epoch
[2023-01-31 13:34:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][0/1251]	eta 0:33:54 lr 0.000151	time 1.6260 (1.6260)	loss 5.9237 (5.9237)	grad_norm 1.9651 (1.9651)	mem 17413MB
[2023-01-31 13:34:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][50/1251]	eta 0:11:36 lr 0.000153	time 0.5551 (0.5800)	loss 6.2209 (6.2291)	grad_norm 1.8530 (1.8637)	mem 17413MB
[2023-01-31 13:35:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][100/1251]	eta 0:10:59 lr 0.000155	time 0.5573 (0.5730)	loss 5.9973 (6.2210)	grad_norm 2.0078 (1.8710)	mem 17413MB
[2023-01-31 13:35:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][150/1251]	eta 0:10:27 lr 0.000157	time 0.5492 (0.5698)	loss 6.1538 (6.1871)	grad_norm 1.7122 (1.9020)	mem 17413MB
[2023-01-31 13:35:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][200/1251]	eta 0:09:55 lr 0.000159	time 0.5577 (0.5667)	loss 6.6388 (6.1845)	grad_norm 2.4992 (1.9062)	mem 17413MB
[2023-01-31 13:36:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][250/1251]	eta 0:09:25 lr 0.000161	time 0.5533 (0.5653)	loss 6.5625 (6.1903)	grad_norm 1.6337 (1.9070)	mem 17413MB
[2023-01-31 13:36:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][300/1251]	eta 0:08:57 lr 0.000163	time 0.5818 (0.5647)	loss 5.8302 (6.1972)	grad_norm 2.1839 (1.9074)	mem 17413MB
[2023-01-31 13:37:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][350/1251]	eta 0:08:28 lr 0.000165	time 0.5515 (0.5641)	loss 6.2608 (6.1822)	grad_norm 1.5771 (1.9062)	mem 17413MB
[2023-01-31 13:37:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][400/1251]	eta 0:07:59 lr 0.000167	time 0.5517 (0.5637)	loss 5.7402 (6.1766)	grad_norm 2.6916 (1.9003)	mem 17413MB
[2023-01-31 13:38:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][450/1251]	eta 0:07:31 lr 0.000169	time 0.5562 (0.5632)	loss 6.0006 (6.1764)	grad_norm 1.8504 (1.9031)	mem 17413MB
[2023-01-31 13:38:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][500/1251]	eta 0:07:02 lr 0.000171	time 0.5526 (0.5627)	loss 6.4470 (6.1743)	grad_norm 2.5863 (1.9083)	mem 17413MB
[2023-01-31 13:39:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][550/1251]	eta 0:06:34 lr 0.000173	time 0.5794 (0.5625)	loss 6.4904 (6.1679)	grad_norm 2.0098 (1.9042)	mem 17413MB
[2023-01-31 13:39:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][600/1251]	eta 0:06:06 lr 0.000175	time 0.5502 (0.5623)	loss 6.0485 (6.1648)	grad_norm 2.2737 (1.9109)	mem 17413MB
[2023-01-31 13:40:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][650/1251]	eta 0:05:37 lr 0.000177	time 0.5561 (0.5622)	loss 6.3873 (6.1634)	grad_norm 1.7755 (1.9078)	mem 17413MB
[2023-01-31 13:40:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][700/1251]	eta 0:05:09 lr 0.000179	time 0.5506 (0.5622)	loss 5.8636 (6.1598)	grad_norm 1.7913 (1.9091)	mem 17413MB
[2023-01-31 13:41:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][750/1251]	eta 0:04:41 lr 0.000181	time 0.5555 (0.5620)	loss 5.4526 (6.1578)	grad_norm 2.4350 (1.9082)	mem 17413MB
[2023-01-31 13:41:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][800/1251]	eta 0:04:13 lr 0.000183	time 0.5542 (0.5618)	loss 6.4249 (6.1573)	grad_norm 2.4948 (1.9060)	mem 17413MB
[2023-01-31 13:42:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][850/1251]	eta 0:03:45 lr 0.000185	time 0.5545 (0.5617)	loss 6.0862 (6.1548)	grad_norm 1.6915 (1.9076)	mem 17413MB
[2023-01-31 13:42:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][900/1251]	eta 0:03:17 lr 0.000187	time 0.5478 (0.5617)	loss 6.2278 (6.1498)	grad_norm 1.6830 (1.9052)	mem 17413MB
[2023-01-31 13:42:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][950/1251]	eta 0:02:49 lr 0.000189	time 0.5565 (0.5617)	loss 6.0857 (6.1511)	grad_norm 2.0529 (1.9061)	mem 17413MB
[2023-01-31 13:43:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][1000/1251]	eta 0:02:20 lr 0.000191	time 0.6056 (0.5616)	loss 6.1183 (6.1468)	grad_norm 1.4961 (1.9137)	mem 17413MB
[2023-01-31 13:43:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][1050/1251]	eta 0:01:52 lr 0.000193	time 0.5566 (0.5615)	loss 6.4436 (6.1436)	grad_norm 1.9495 (1.9201)	mem 17413MB
[2023-01-31 13:44:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][1100/1251]	eta 0:01:24 lr 0.000195	time 0.5560 (0.5616)	loss 6.3624 (6.1370)	grad_norm 2.3519 (1.9219)	mem 17413MB
[2023-01-31 13:44:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][1150/1251]	eta 0:00:56 lr 0.000197	time 0.5548 (0.5616)	loss 5.7128 (6.1276)	grad_norm 1.9271 (1.9264)	mem 17413MB
[2023-01-31 13:45:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][1200/1251]	eta 0:00:28 lr 0.000199	time 0.5604 (0.5616)	loss 6.3234 (6.1251)	grad_norm 2.2094 (1.9261)	mem 17413MB
[2023-01-31 13:45:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [3/300][1250/1251]	eta 0:00:00 lr 0.000201	time 0.5485 (0.5616)	loss 6.5100 (6.1228)	grad_norm 1.8472 (1.9272)	mem 17413MB
[2023-01-31 13:45:46 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 3 training takes 0:11:42
[2023-01-31 13:45:46 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_3.pth saving......
[2023-01-31 13:45:48 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_3.pth saved !!!
[2023-01-31 13:45:49 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.842 (0.842)	Loss 4.2896 (4.2896)	Acc@1 17.578 (17.578)	Acc@5 41.211 (41.211)	Mem 17413MB
[2023-01-31 13:45:57 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 17.870 Acc@5 38.848
[2023-01-31 13:45:57 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 17.9%
[2023-01-31 13:45:58 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.307 (1.307)	Loss 6.9230 (6.9230)	Acc@1 0.195 (0.195)	Acc@5 0.488 (0.488)	Mem 17413MB
[2023-01-31 13:46:06 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 0.136 Acc@5 0.696
[2023-01-31 13:46:06 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 0.1%
[2023-01-31 13:46:06 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 17.87% at 3 epoch
[2023-01-31 13:46:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][0/1251]	eta 0:35:12 lr 0.000201	time 1.6884 (1.6884)	loss 6.4773 (6.4773)	grad_norm 1.5488 (1.5488)	mem 17413MB
[2023-01-31 13:46:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][50/1251]	eta 0:11:41 lr 0.000203	time 0.5602 (0.5837)	loss 6.0228 (5.9330)	grad_norm 1.7995 (1.8729)	mem 17413MB
[2023-01-31 13:47:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][100/1251]	eta 0:10:59 lr 0.000205	time 0.5507 (0.5734)	loss 6.1998 (5.9595)	grad_norm 1.8876 (1.9102)	mem 17413MB
[2023-01-31 13:47:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][150/1251]	eta 0:10:26 lr 0.000207	time 0.5510 (0.5693)	loss 5.7809 (5.9630)	grad_norm 1.8663 (1.9045)	mem 17413MB
[2023-01-31 13:48:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][200/1251]	eta 0:09:56 lr 0.000209	time 0.5649 (0.5674)	loss 6.2813 (5.9665)	grad_norm 1.6819 (1.9236)	mem 17413MB
[2023-01-31 13:48:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][250/1251]	eta 0:09:26 lr 0.000211	time 0.5514 (0.5663)	loss 6.3508 (5.9772)	grad_norm 2.2082 (1.9199)	mem 17413MB
[2023-01-31 13:48:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][300/1251]	eta 0:08:58 lr 0.000213	time 0.5571 (0.5662)	loss 5.8051 (5.9785)	grad_norm 1.9691 (1.9270)	mem 17413MB
[2023-01-31 13:49:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][350/1251]	eta 0:08:29 lr 0.000215	time 0.5536 (0.5651)	loss 6.5558 (5.9755)	grad_norm 1.9344 (1.9381)	mem 17413MB
[2023-01-31 13:49:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][400/1251]	eta 0:08:00 lr 0.000217	time 0.5521 (0.5649)	loss 6.3907 (5.9660)	grad_norm 1.8197 (1.9434)	mem 17413MB
[2023-01-31 13:50:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][450/1251]	eta 0:07:32 lr 0.000219	time 0.5567 (0.5644)	loss 5.8808 (5.9662)	grad_norm 1.9464 (1.9414)	mem 17413MB
[2023-01-31 13:50:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][500/1251]	eta 0:07:03 lr 0.000221	time 0.5538 (0.5639)	loss 6.1739 (5.9654)	grad_norm 4.4388 (1.9494)	mem 17413MB
[2023-01-31 13:51:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][550/1251]	eta 0:06:35 lr 0.000223	time 0.5575 (0.5638)	loss 6.3357 (5.9569)	grad_norm 1.8169 (1.9521)	mem 17413MB
[2023-01-31 13:51:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][600/1251]	eta 0:06:06 lr 0.000225	time 0.5556 (0.5634)	loss 5.7211 (5.9526)	grad_norm 1.7057 (1.9609)	mem 17413MB
[2023-01-31 13:52:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][650/1251]	eta 0:05:38 lr 0.000227	time 0.5547 (0.5634)	loss 5.8770 (5.9500)	grad_norm 2.4202 (1.9623)	mem 17413MB
[2023-01-31 13:52:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][700/1251]	eta 0:05:10 lr 0.000229	time 0.5540 (0.5634)	loss 5.7094 (5.9455)	grad_norm 1.9591 (1.9629)	mem 17413MB
[2023-01-31 13:53:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][750/1251]	eta 0:04:42 lr 0.000231	time 0.5613 (0.5631)	loss 5.6079 (5.9362)	grad_norm 1.8630 (1.9615)	mem 17413MB
[2023-01-31 13:53:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][800/1251]	eta 0:04:13 lr 0.000233	time 0.5612 (0.5632)	loss 6.3270 (5.9306)	grad_norm 1.8676 (1.9615)	mem 17413MB
[2023-01-31 13:54:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][850/1251]	eta 0:03:45 lr 0.000235	time 0.5589 (0.5630)	loss 6.1094 (5.9269)	grad_norm 1.7217 (1.9634)	mem 17413MB
[2023-01-31 13:54:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][900/1251]	eta 0:03:17 lr 0.000237	time 0.5553 (0.5630)	loss 6.0555 (5.9274)	grad_norm 1.8884 (inf)	mem 17413MB
[2023-01-31 13:55:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][950/1251]	eta 0:02:49 lr 0.000239	time 0.5604 (0.5629)	loss 5.6340 (5.9261)	grad_norm 1.8238 (inf)	mem 17413MB
[2023-01-31 13:55:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][1000/1251]	eta 0:02:21 lr 0.000241	time 0.5533 (0.5629)	loss 6.1803 (5.9216)	grad_norm 2.0814 (inf)	mem 17413MB
[2023-01-31 13:55:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][1050/1251]	eta 0:01:53 lr 0.000243	time 0.5579 (0.5629)	loss 5.9651 (5.9146)	grad_norm 1.9690 (inf)	mem 17413MB
[2023-01-31 13:56:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][1100/1251]	eta 0:01:24 lr 0.000245	time 0.5542 (0.5628)	loss 5.3462 (5.9126)	grad_norm 1.6695 (inf)	mem 17413MB
[2023-01-31 13:56:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][1150/1251]	eta 0:00:56 lr 0.000247	time 0.5576 (0.5628)	loss 6.1065 (5.9047)	grad_norm 1.9199 (inf)	mem 17413MB
[2023-01-31 13:57:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][1200/1251]	eta 0:00:28 lr 0.000249	time 0.5513 (0.5628)	loss 5.3670 (5.9030)	grad_norm 1.9411 (inf)	mem 17413MB
[2023-01-31 13:57:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [4/300][1250/1251]	eta 0:00:00 lr 0.000251	time 0.5532 (0.5629)	loss 5.3142 (5.8972)	grad_norm 1.8265 (inf)	mem 17413MB
[2023-01-31 13:57:50 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 4 training takes 0:11:44
[2023-01-31 13:57:50 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_4.pth saving......
[2023-01-31 13:57:52 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_4.pth saved !!!
[2023-01-31 13:57:53 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.829 (0.829)	Loss 3.7689 (3.7689)	Acc@1 23.828 (23.828)	Acc@5 50.098 (50.098)	Mem 17413MB
[2023-01-31 13:58:01 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 25.446 Acc@5 49.826
[2023-01-31 13:58:01 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 25.4%
[2023-01-31 13:58:02 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.237 (1.237)	Loss 6.9347 (6.9347)	Acc@1 0.098 (0.098)	Acc@5 0.781 (0.781)	Mem 17413MB
[2023-01-31 13:58:10 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 0.168 Acc@5 0.770
[2023-01-31 13:58:10 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 0.2%
[2023-01-31 13:58:10 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 25.45% at 4 epoch
[2023-01-31 13:58:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][0/1251]	eta 0:34:01 lr 0.000251	time 1.6317 (1.6317)	loss 5.7195 (5.7195)	grad_norm 1.6954 (1.6954)	mem 17413MB
[2023-01-31 13:58:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][50/1251]	eta 0:11:41 lr 0.000253	time 0.5651 (0.5845)	loss 5.6738 (5.8776)	grad_norm 1.6133 (2.0455)	mem 17413MB
[2023-01-31 13:59:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][100/1251]	eta 0:11:01 lr 0.000255	time 0.5550 (0.5747)	loss 5.4657 (5.8164)	grad_norm 1.9452 (2.0689)	mem 17413MB
[2023-01-31 13:59:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][150/1251]	eta 0:10:28 lr 0.000257	time 0.5563 (0.5704)	loss 6.2944 (5.8179)	grad_norm 1.8400 (2.0493)	mem 17413MB
[2023-01-31 14:00:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][200/1251]	eta 0:09:57 lr 0.000259	time 0.5591 (0.5688)	loss 4.8632 (5.7868)	grad_norm 2.0695 (2.0420)	mem 17413MB
[2023-01-31 14:00:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][250/1251]	eta 0:09:27 lr 0.000261	time 0.5607 (0.5673)	loss 5.9680 (5.7628)	grad_norm 1.5855 (2.0348)	mem 17413MB
[2023-01-31 14:01:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][300/1251]	eta 0:08:58 lr 0.000263	time 0.5657 (0.5668)	loss 5.5506 (5.7678)	grad_norm 1.8983 (2.0136)	mem 17413MB
[2023-01-31 14:01:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][350/1251]	eta 0:08:29 lr 0.000265	time 0.5535 (0.5660)	loss 5.2088 (5.7586)	grad_norm 2.0720 (2.0006)	mem 17413MB
[2023-01-31 14:01:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][400/1251]	eta 0:08:01 lr 0.000267	time 0.6215 (0.5657)	loss 5.7888 (5.7478)	grad_norm 2.0692 (2.0100)	mem 17413MB
[2023-01-31 14:02:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][450/1251]	eta 0:07:32 lr 0.000269	time 0.5623 (0.5654)	loss 6.0545 (5.7392)	grad_norm 2.1255 (2.0143)	mem 17413MB
[2023-01-31 14:02:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][500/1251]	eta 0:07:04 lr 0.000271	time 0.5564 (0.5648)	loss 6.2546 (5.7369)	grad_norm 1.8535 (2.0042)	mem 17413MB
[2023-01-31 14:03:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][550/1251]	eta 0:06:35 lr 0.000273	time 0.5626 (0.5648)	loss 4.7693 (5.7298)	grad_norm 1.7014 (1.9934)	mem 17413MB
[2023-01-31 14:03:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][600/1251]	eta 0:06:07 lr 0.000275	time 0.5554 (0.5645)	loss 5.3495 (5.7194)	grad_norm 2.0547 (1.9870)	mem 17413MB
[2023-01-31 14:04:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][650/1251]	eta 0:05:39 lr 0.000277	time 0.5541 (0.5644)	loss 4.4408 (5.7086)	grad_norm 2.2082 (1.9863)	mem 17413MB
[2023-01-31 14:04:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][700/1251]	eta 0:05:10 lr 0.000279	time 0.5592 (0.5643)	loss 5.5625 (5.6975)	grad_norm 2.1044 (1.9852)	mem 17413MB
[2023-01-31 14:05:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][750/1251]	eta 0:04:42 lr 0.000281	time 0.5592 (0.5640)	loss 4.9068 (5.6850)	grad_norm 1.8119 (1.9892)	mem 17413MB
[2023-01-31 14:05:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][800/1251]	eta 0:04:14 lr 0.000283	time 0.6479 (0.5640)	loss 5.9079 (5.6807)	grad_norm 2.5312 (1.9904)	mem 17413MB
[2023-01-31 14:06:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][850/1251]	eta 0:03:46 lr 0.000285	time 0.5623 (0.5639)	loss 5.3232 (5.6799)	grad_norm 1.9045 (1.9895)	mem 17413MB
[2023-01-31 14:06:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][900/1251]	eta 0:03:17 lr 0.000287	time 0.5561 (0.5639)	loss 5.9935 (5.6821)	grad_norm 2.2551 (1.9856)	mem 17413MB
[2023-01-31 14:07:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][950/1251]	eta 0:02:49 lr 0.000289	time 0.5596 (0.5639)	loss 5.0690 (5.6779)	grad_norm 1.8787 (1.9873)	mem 17413MB
[2023-01-31 14:07:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][1000/1251]	eta 0:02:21 lr 0.000291	time 0.5843 (0.5637)	loss 5.5724 (5.6749)	grad_norm 1.9000 (1.9843)	mem 17413MB
[2023-01-31 14:08:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][1050/1251]	eta 0:01:53 lr 0.000293	time 0.5569 (0.5637)	loss 5.5150 (5.6714)	grad_norm 2.1222 (1.9832)	mem 17413MB
[2023-01-31 14:08:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][1100/1251]	eta 0:01:25 lr 0.000295	time 0.5562 (0.5636)	loss 6.0722 (5.6687)	grad_norm 1.8367 (1.9805)	mem 17413MB
[2023-01-31 14:08:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][1150/1251]	eta 0:00:56 lr 0.000297	time 0.5579 (0.5637)	loss 5.4333 (5.6628)	grad_norm 1.7119 (1.9773)	mem 17413MB
[2023-01-31 14:09:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][1200/1251]	eta 0:00:28 lr 0.000299	time 0.5586 (0.5636)	loss 6.0598 (5.6591)	grad_norm 1.9710 (1.9750)	mem 17413MB
[2023-01-31 14:09:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [5/300][1250/1251]	eta 0:00:00 lr 0.000301	time 0.5538 (0.5636)	loss 5.4257 (5.6547)	grad_norm 2.3256 (1.9722)	mem 17413MB
[2023-01-31 14:09:55 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 5 training takes 0:11:45
[2023-01-31 14:09:55 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_5.pth saving......
[2023-01-31 14:09:57 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_5.pth saved !!!
[2023-01-31 14:09:58 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.831 (0.831)	Loss 3.3141 (3.3141)	Acc@1 32.715 (32.715)	Acc@5 58.105 (58.105)	Mem 17413MB
[2023-01-31 14:10:06 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 32.654 Acc@5 58.144
[2023-01-31 14:10:06 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 32.7%
[2023-01-31 14:10:07 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.221 (1.221)	Loss 6.9144 (6.9144)	Acc@1 0.000 (0.000)	Acc@5 0.977 (0.977)	Mem 17413MB
[2023-01-31 14:10:15 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 0.210 Acc@5 0.940
[2023-01-31 14:10:15 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 0.2%
[2023-01-31 14:10:15 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 32.65% at 5 epoch
[2023-01-31 14:10:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][0/1251]	eta 0:36:44 lr 0.000301	time 1.7621 (1.7621)	loss 5.1216 (5.1216)	grad_norm 1.9810 (1.9810)	mem 17413MB
[2023-01-31 14:10:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][50/1251]	eta 0:11:45 lr 0.000303	time 0.5563 (0.5876)	loss 4.5255 (5.4859)	grad_norm 1.8029 (1.9934)	mem 17413MB
[2023-01-31 14:11:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][100/1251]	eta 0:11:04 lr 0.000305	time 0.5534 (0.5774)	loss 6.0633 (5.5021)	grad_norm 1.7122 (1.9918)	mem 17413MB
[2023-01-31 14:11:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][150/1251]	eta 0:10:30 lr 0.000307	time 0.5583 (0.5727)	loss 6.0074 (5.5106)	grad_norm 2.3192 (2.0380)	mem 17413MB
[2023-01-31 14:12:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][200/1251]	eta 0:09:59 lr 0.000309	time 0.5570 (0.5703)	loss 5.2964 (5.5262)	grad_norm 1.7892 (1.9959)	mem 17413MB
[2023-01-31 14:12:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][250/1251]	eta 0:09:29 lr 0.000311	time 0.5522 (0.5690)	loss 5.7135 (5.5027)	grad_norm 2.4653 (1.9863)	mem 17413MB
[2023-01-31 14:13:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][300/1251]	eta 0:09:00 lr 0.000313	time 0.5568 (0.5684)	loss 5.6021 (5.5018)	grad_norm 2.7318 (1.9756)	mem 17413MB
[2023-01-31 14:13:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][350/1251]	eta 0:08:31 lr 0.000315	time 0.5640 (0.5677)	loss 5.4969 (5.4922)	grad_norm 2.1943 (1.9569)	mem 17413MB
[2023-01-31 14:14:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][400/1251]	eta 0:08:02 lr 0.000317	time 0.5576 (0.5670)	loss 5.8709 (5.5020)	grad_norm 1.9728 (1.9594)	mem 17413MB
[2023-01-31 14:14:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][450/1251]	eta 0:07:33 lr 0.000319	time 0.5248 (0.5665)	loss 5.6261 (5.4959)	grad_norm inf (inf)	mem 17413MB
[2023-01-31 14:14:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][500/1251]	eta 0:07:05 lr 0.000321	time 0.5550 (0.5662)	loss 5.7338 (5.4899)	grad_norm 1.7346 (inf)	mem 17413MB
[2023-01-31 14:15:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][550/1251]	eta 0:06:36 lr 0.000323	time 0.5524 (0.5661)	loss 4.4483 (5.4712)	grad_norm 1.9574 (inf)	mem 17413MB
[2023-01-31 14:15:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][600/1251]	eta 0:06:08 lr 0.000325	time 0.5555 (0.5658)	loss 5.6963 (5.4771)	grad_norm 1.5957 (inf)	mem 17413MB
[2023-01-31 14:16:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][650/1251]	eta 0:05:40 lr 0.000327	time 0.5577 (0.5658)	loss 5.2279 (5.4723)	grad_norm 1.6191 (inf)	mem 17413MB
[2023-01-31 14:16:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][700/1251]	eta 0:05:11 lr 0.000329	time 0.5546 (0.5655)	loss 6.1149 (5.4674)	grad_norm 1.8717 (inf)	mem 17413MB
[2023-01-31 14:17:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][750/1251]	eta 0:04:43 lr 0.000331	time 0.5580 (0.5653)	loss 5.7920 (5.4608)	grad_norm 1.7944 (inf)	mem 17413MB
[2023-01-31 14:17:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][800/1251]	eta 0:04:14 lr 0.000333	time 0.5628 (0.5653)	loss 4.8364 (5.4618)	grad_norm 1.7900 (inf)	mem 17413MB
[2023-01-31 14:18:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][850/1251]	eta 0:03:46 lr 0.000335	time 0.6371 (0.5651)	loss 6.1038 (5.4573)	grad_norm 1.4263 (inf)	mem 17413MB
[2023-01-31 14:18:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][900/1251]	eta 0:03:18 lr 0.000337	time 0.5590 (0.5650)	loss 5.0952 (5.4576)	grad_norm 1.7673 (inf)	mem 17413MB
[2023-01-31 14:19:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][950/1251]	eta 0:02:50 lr 0.000339	time 0.5511 (0.5651)	loss 5.5929 (5.4574)	grad_norm 1.7697 (inf)	mem 17413MB
[2023-01-31 14:19:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][1000/1251]	eta 0:02:21 lr 0.000341	time 0.5601 (0.5649)	loss 6.0333 (5.4566)	grad_norm 1.9613 (inf)	mem 17413MB
[2023-01-31 14:20:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][1050/1251]	eta 0:01:53 lr 0.000343	time 0.5649 (0.5648)	loss 5.2871 (5.4558)	grad_norm 2.0765 (inf)	mem 17413MB
[2023-01-31 14:20:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][1100/1251]	eta 0:01:25 lr 0.000345	time 0.5628 (0.5647)	loss 5.8106 (5.4537)	grad_norm 1.9880 (inf)	mem 17413MB
[2023-01-31 14:21:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][1150/1251]	eta 0:00:57 lr 0.000347	time 0.5639 (0.5647)	loss 4.9659 (5.4511)	grad_norm 1.6265 (inf)	mem 17413MB
[2023-01-31 14:21:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][1200/1251]	eta 0:00:28 lr 0.000349	time 0.5528 (0.5647)	loss 5.2391 (5.4449)	grad_norm 1.7730 (inf)	mem 17413MB
[2023-01-31 14:22:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [6/300][1250/1251]	eta 0:00:00 lr 0.000351	time 0.5505 (0.5646)	loss 5.5246 (5.4465)	grad_norm 1.7643 (inf)	mem 17413MB
[2023-01-31 14:22:01 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 6 training takes 0:11:46
[2023-01-31 14:22:01 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_6.pth saving......
[2023-01-31 14:22:03 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_6.pth saved !!!
[2023-01-31 14:22:04 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.860 (0.860)	Loss 2.9363 (2.9363)	Acc@1 37.891 (37.891)	Acc@5 63.379 (63.379)	Mem 17413MB
[2023-01-31 14:22:12 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 38.488 Acc@5 64.480
[2023-01-31 14:22:12 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 38.5%
[2023-01-31 14:22:13 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.342 (1.342)	Loss 6.8843 (6.8843)	Acc@1 0.488 (0.488)	Acc@5 1.758 (1.758)	Mem 17413MB
[2023-01-31 14:22:21 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 0.358 Acc@5 1.456
[2023-01-31 14:22:21 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 0.4%
[2023-01-31 14:22:21 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 38.49% at 6 epoch
[2023-01-31 14:22:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][0/1251]	eta 0:36:58 lr 0.000351	time 1.7735 (1.7735)	loss 5.7212 (5.7212)	grad_norm 1.9154 (1.9154)	mem 17413MB
[2023-01-31 14:22:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][50/1251]	eta 0:11:46 lr 0.000353	time 0.5578 (0.5885)	loss 5.0534 (5.3485)	grad_norm 1.5646 (1.8504)	mem 17413MB
[2023-01-31 14:23:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][100/1251]	eta 0:11:05 lr 0.000355	time 0.5571 (0.5778)	loss 4.7497 (5.3348)	grad_norm 2.6031 (1.8358)	mem 17413MB
[2023-01-31 14:23:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][150/1251]	eta 0:10:30 lr 0.000357	time 0.5562 (0.5729)	loss 5.7348 (5.3065)	grad_norm 1.5647 (1.8411)	mem 17413MB
[2023-01-31 14:24:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][200/1251]	eta 0:09:59 lr 0.000359	time 0.5646 (0.5707)	loss 5.4266 (5.3263)	grad_norm 1.9597 (1.8488)	mem 17413MB
[2023-01-31 14:24:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][250/1251]	eta 0:09:29 lr 0.000361	time 0.5581 (0.5694)	loss 4.4117 (5.3228)	grad_norm 1.9935 (1.8582)	mem 17413MB
[2023-01-31 14:25:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][300/1251]	eta 0:09:00 lr 0.000363	time 0.5561 (0.5687)	loss 5.0377 (5.3118)	grad_norm 3.3154 (1.8697)	mem 17413MB
[2023-01-31 14:25:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][350/1251]	eta 0:08:31 lr 0.000365	time 0.5758 (0.5678)	loss 6.1093 (5.3156)	grad_norm 2.0521 (1.8560)	mem 17413MB
[2023-01-31 14:26:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][400/1251]	eta 0:08:02 lr 0.000367	time 0.5605 (0.5674)	loss 5.2369 (5.3008)	grad_norm 1.5384 (1.8505)	mem 17413MB
[2023-01-31 14:26:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][450/1251]	eta 0:07:34 lr 0.000369	time 0.5567 (0.5668)	loss 5.7039 (5.2950)	grad_norm 2.9905 (1.8486)	mem 17413MB
[2023-01-31 14:27:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][500/1251]	eta 0:07:05 lr 0.000371	time 0.5622 (0.5664)	loss 4.9990 (5.2924)	grad_norm 1.7200 (1.8517)	mem 17413MB
[2023-01-31 14:27:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][550/1251]	eta 0:06:37 lr 0.000373	time 0.5599 (0.5664)	loss 5.3287 (5.2932)	grad_norm 1.6904 (1.8494)	mem 17413MB
[2023-01-31 14:28:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][600/1251]	eta 0:06:08 lr 0.000375	time 0.5627 (0.5661)	loss 4.8822 (5.2827)	grad_norm 3.2614 (1.8532)	mem 17413MB
[2023-01-31 14:28:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][650/1251]	eta 0:05:40 lr 0.000377	time 0.5608 (0.5663)	loss 5.7945 (5.2886)	grad_norm 2.4934 (1.8513)	mem 17413MB
[2023-01-31 14:28:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][700/1251]	eta 0:05:11 lr 0.000379	time 0.5611 (0.5659)	loss 4.9665 (5.2932)	grad_norm 1.6206 (1.8477)	mem 17413MB
[2023-01-31 14:29:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][750/1251]	eta 0:04:43 lr 0.000381	time 0.5525 (0.5657)	loss 4.8905 (5.2891)	grad_norm 1.8802 (1.8476)	mem 17413MB
[2023-01-31 14:29:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][800/1251]	eta 0:04:15 lr 0.000383	time 0.5588 (0.5656)	loss 5.8494 (5.2875)	grad_norm 1.5469 (1.8420)	mem 17413MB
[2023-01-31 14:30:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][850/1251]	eta 0:03:46 lr 0.000385	time 0.5564 (0.5655)	loss 5.2721 (5.2798)	grad_norm 2.0265 (1.8401)	mem 17413MB
[2023-01-31 14:30:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][900/1251]	eta 0:03:18 lr 0.000387	time 0.5570 (0.5653)	loss 4.7267 (5.2751)	grad_norm 1.7844 (1.8387)	mem 17413MB
[2023-01-31 14:31:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][950/1251]	eta 0:02:50 lr 0.000389	time 0.5631 (0.5652)	loss 5.2477 (5.2839)	grad_norm 1.7715 (1.8331)	mem 17413MB
[2023-01-31 14:31:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][1000/1251]	eta 0:02:21 lr 0.000391	time 0.6362 (0.5652)	loss 5.9704 (5.2789)	grad_norm 1.4315 (1.8282)	mem 17413MB
[2023-01-31 14:32:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][1050/1251]	eta 0:01:53 lr 0.000393	time 0.5672 (0.5651)	loss 5.1257 (5.2739)	grad_norm 1.5538 (1.8293)	mem 17413MB
[2023-01-31 14:32:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][1100/1251]	eta 0:01:25 lr 0.000395	time 0.5623 (0.5652)	loss 5.1970 (5.2664)	grad_norm 1.7183 (1.8284)	mem 17413MB
[2023-01-31 14:33:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][1150/1251]	eta 0:00:57 lr 0.000397	time 0.5621 (0.5654)	loss 4.8435 (5.2619)	grad_norm 1.8110 (1.8249)	mem 17413MB
[2023-01-31 14:33:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][1200/1251]	eta 0:00:28 lr 0.000399	time 0.5567 (0.5655)	loss 4.0114 (5.2590)	grad_norm 2.1400 (1.8215)	mem 17413MB
[2023-01-31 14:34:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [7/300][1250/1251]	eta 0:00:00 lr 0.000401	time 0.6080 (0.5654)	loss 4.8717 (5.2549)	grad_norm 1.4965 (inf)	mem 17413MB
[2023-01-31 14:34:08 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 7 training takes 0:11:47
[2023-01-31 14:34:09 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_7.pth saving......
[2023-01-31 14:34:10 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_7.pth saved !!!
[2023-01-31 14:34:11 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.961 (0.961)	Loss 2.6068 (2.6068)	Acc@1 44.434 (44.434)	Acc@5 67.773 (67.773)	Mem 17413MB
[2023-01-31 14:34:19 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 43.222 Acc@5 69.310
[2023-01-31 14:34:19 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 43.2%
[2023-01-31 14:34:20 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.226 (1.226)	Loss 6.7846 (6.7846)	Acc@1 0.586 (0.586)	Acc@5 2.148 (2.148)	Mem 17413MB
[2023-01-31 14:34:28 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 0.554 Acc@5 2.244
[2023-01-31 14:34:28 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 0.6%
[2023-01-31 14:34:28 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 43.22% at 7 epoch
[2023-01-31 14:34:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][0/1251]	eta 0:35:02 lr 0.000401	time 1.6807 (1.6807)	loss 5.6766 (5.6766)	grad_norm 2.2664 (2.2664)	mem 17413MB
[2023-01-31 14:34:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][50/1251]	eta 0:11:43 lr 0.000403	time 0.5595 (0.5860)	loss 5.8413 (5.3358)	grad_norm 1.6854 (1.8590)	mem 17413MB
[2023-01-31 14:35:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][100/1251]	eta 0:11:04 lr 0.000405	time 0.5621 (0.5772)	loss 4.7510 (5.2754)	grad_norm 4.2202 (1.8140)	mem 17413MB
[2023-01-31 14:35:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][150/1251]	eta 0:10:31 lr 0.000407	time 0.5564 (0.5738)	loss 4.7976 (5.2380)	grad_norm 1.7849 (1.7777)	mem 17413MB
[2023-01-31 14:36:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][200/1251]	eta 0:10:00 lr 0.000409	time 0.5594 (0.5711)	loss 4.3925 (5.2384)	grad_norm 1.6003 (1.7935)	mem 17413MB
[2023-01-31 14:36:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][250/1251]	eta 0:09:31 lr 0.000411	time 0.5644 (0.5709)	loss 5.6417 (5.2211)	grad_norm 1.6618 (1.7841)	mem 17413MB
[2023-01-31 14:37:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][300/1251]	eta 0:09:01 lr 0.000413	time 0.5572 (0.5698)	loss 4.6165 (5.2127)	grad_norm 1.8390 (1.7711)	mem 17413MB
[2023-01-31 14:37:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][350/1251]	eta 0:08:33 lr 0.000415	time 0.5660 (0.5694)	loss 5.3362 (5.1971)	grad_norm 1.7272 (1.7872)	mem 17413MB
[2023-01-31 14:38:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][400/1251]	eta 0:08:04 lr 0.000417	time 0.5558 (0.5690)	loss 5.2113 (5.1727)	grad_norm 1.6505 (1.7848)	mem 17413MB
[2023-01-31 14:38:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][450/1251]	eta 0:07:35 lr 0.000419	time 0.5567 (0.5683)	loss 4.7954 (5.1652)	grad_norm 1.6811 (1.7867)	mem 17413MB
[2023-01-31 14:39:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][500/1251]	eta 0:07:06 lr 0.000421	time 0.5599 (0.5682)	loss 5.1530 (5.1649)	grad_norm 1.5875 (1.7783)	mem 17413MB
[2023-01-31 14:39:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][550/1251]	eta 0:06:38 lr 0.000423	time 0.5594 (0.5682)	loss 4.2415 (5.1593)	grad_norm 1.7073 (1.7721)	mem 17413MB
[2023-01-31 14:40:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][600/1251]	eta 0:06:09 lr 0.000425	time 0.5643 (0.5678)	loss 5.4460 (5.1440)	grad_norm 1.5543 (1.7684)	mem 17413MB
[2023-01-31 14:40:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][650/1251]	eta 0:05:41 lr 0.000427	time 0.5590 (0.5679)	loss 5.0412 (5.1375)	grad_norm 1.6642 (1.7691)	mem 17413MB
[2023-01-31 14:41:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][700/1251]	eta 0:05:12 lr 0.000429	time 0.5619 (0.5677)	loss 4.6166 (5.1409)	grad_norm 1.7396 (1.7687)	mem 17413MB
[2023-01-31 14:41:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][750/1251]	eta 0:04:44 lr 0.000431	time 0.5514 (0.5676)	loss 4.2557 (5.1386)	grad_norm 1.9381 (1.7684)	mem 17413MB
[2023-01-31 14:42:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][800/1251]	eta 0:04:16 lr 0.000433	time 0.5612 (0.5677)	loss 5.7691 (5.1340)	grad_norm 1.4431 (1.7693)	mem 17413MB
[2023-01-31 14:42:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][850/1251]	eta 0:03:47 lr 0.000435	time 0.5554 (0.5675)	loss 5.2597 (5.1313)	grad_norm 1.7564 (1.7685)	mem 17413MB
[2023-01-31 14:43:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][900/1251]	eta 0:03:19 lr 0.000437	time 0.5605 (0.5676)	loss 4.7700 (5.1315)	grad_norm 1.6666 (1.7644)	mem 17413MB
[2023-01-31 14:43:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][950/1251]	eta 0:02:50 lr 0.000439	time 0.5579 (0.5677)	loss 3.9760 (5.1259)	grad_norm 1.5971 (1.7604)	mem 17413MB
[2023-01-31 14:43:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][1000/1251]	eta 0:02:22 lr 0.000441	time 0.5558 (0.5676)	loss 5.1095 (5.1283)	grad_norm 1.9736 (1.7598)	mem 17413MB
[2023-01-31 14:44:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][1050/1251]	eta 0:01:54 lr 0.000443	time 0.5790 (0.5677)	loss 5.7164 (5.1295)	grad_norm 1.7032 (1.7561)	mem 17413MB
[2023-01-31 14:44:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][1100/1251]	eta 0:01:25 lr 0.000445	time 0.5617 (0.5676)	loss 5.5263 (5.1260)	grad_norm 1.6761 (1.7533)	mem 17413MB
[2023-01-31 14:45:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][1150/1251]	eta 0:00:57 lr 0.000447	time 0.5589 (0.5675)	loss 4.7219 (5.1253)	grad_norm 1.8149 (1.7545)	mem 17413MB
[2023-01-31 14:45:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][1200/1251]	eta 0:00:28 lr 0.000449	time 0.6265 (0.5676)	loss 4.5119 (5.1193)	grad_norm 2.0211 (1.7540)	mem 17413MB
[2023-01-31 14:46:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [8/300][1250/1251]	eta 0:00:00 lr 0.000451	time 0.5510 (0.5673)	loss 5.3952 (5.1154)	grad_norm 1.9702 (1.7501)	mem 17413MB
[2023-01-31 14:46:18 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 8 training takes 0:11:49
[2023-01-31 14:46:18 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_8.pth saving......
[2023-01-31 14:46:20 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_8.pth saved !!!
[2023-01-31 14:46:21 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.886 (0.886)	Loss 2.4776 (2.4776)	Acc@1 47.852 (47.852)	Acc@5 71.777 (71.777)	Mem 17413MB
[2023-01-31 14:46:29 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 47.670 Acc@5 73.536
[2023-01-31 14:46:29 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 47.7%
[2023-01-31 14:46:30 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.228 (1.228)	Loss 6.6565 (6.6565)	Acc@1 0.391 (0.391)	Acc@5 3.027 (3.027)	Mem 17413MB
[2023-01-31 14:46:38 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 0.892 Acc@5 3.298
[2023-01-31 14:46:38 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 0.9%
[2023-01-31 14:46:38 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 47.67% at 8 epoch
[2023-01-31 14:46:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][0/1251]	eta 0:36:56 lr 0.000451	time 1.7716 (1.7716)	loss 4.2312 (4.2312)	grad_norm 1.6863 (1.6863)	mem 17413MB
[2023-01-31 14:47:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][50/1251]	eta 0:11:42 lr 0.000453	time 0.5575 (0.5852)	loss 4.1091 (5.0158)	grad_norm 2.0899 (1.7450)	mem 17413MB
[2023-01-31 14:47:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][100/1251]	eta 0:11:04 lr 0.000455	time 0.5544 (0.5773)	loss 5.2602 (5.0889)	grad_norm 1.7036 (1.7550)	mem 17413MB
[2023-01-31 14:48:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][150/1251]	eta 0:10:30 lr 0.000457	time 0.5588 (0.5726)	loss 4.2916 (5.0535)	grad_norm 1.7119 (1.7376)	mem 17413MB
[2023-01-31 14:48:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][200/1251]	eta 0:10:00 lr 0.000459	time 0.5612 (0.5715)	loss 4.9562 (5.0655)	grad_norm 1.7079 (1.7475)	mem 17413MB
[2023-01-31 14:49:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][250/1251]	eta 0:09:30 lr 0.000461	time 0.5578 (0.5703)	loss 5.2861 (5.1005)	grad_norm 1.7532 (1.7125)	mem 17413MB
[2023-01-31 14:49:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][300/1251]	eta 0:09:01 lr 0.000463	time 0.5558 (0.5694)	loss 4.2838 (5.0747)	grad_norm 1.4360 (1.7149)	mem 17413MB
[2023-01-31 14:49:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][350/1251]	eta 0:08:32 lr 0.000465	time 0.5559 (0.5689)	loss 5.0987 (5.0566)	grad_norm 2.0994 (1.7189)	mem 17413MB
[2023-01-31 14:50:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][400/1251]	eta 0:08:03 lr 0.000467	time 0.5555 (0.5682)	loss 4.2471 (5.0443)	grad_norm 1.4881 (1.7150)	mem 17413MB
[2023-01-31 14:50:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][450/1251]	eta 0:07:34 lr 0.000469	time 0.5532 (0.5679)	loss 4.9139 (5.0475)	grad_norm 1.6398 (1.7107)	mem 17413MB
[2023-01-31 14:51:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][500/1251]	eta 0:07:06 lr 0.000471	time 0.5557 (0.5676)	loss 5.2235 (5.0262)	grad_norm 1.6584 (1.7084)	mem 17413MB
[2023-01-31 14:51:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][550/1251]	eta 0:06:37 lr 0.000473	time 0.5539 (0.5674)	loss 5.5673 (5.0236)	grad_norm 1.5885 (1.7097)	mem 17413MB
[2023-01-31 14:52:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][600/1251]	eta 0:06:09 lr 0.000475	time 0.5549 (0.5670)	loss 4.5595 (5.0203)	grad_norm 1.3184 (1.7088)	mem 17413MB
[2023-01-31 14:52:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][650/1251]	eta 0:05:40 lr 0.000477	time 0.5614 (0.5672)	loss 4.8790 (5.0176)	grad_norm 1.9710 (1.7027)	mem 17413MB
[2023-01-31 14:53:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][700/1251]	eta 0:05:12 lr 0.000478	time 0.5618 (0.5667)	loss 5.5425 (5.0161)	grad_norm 1.5746 (1.7051)	mem 17413MB
[2023-01-31 14:53:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][750/1251]	eta 0:04:43 lr 0.000480	time 0.5593 (0.5666)	loss 4.9844 (5.0165)	grad_norm 1.5324 (1.7044)	mem 17413MB
[2023-01-31 14:54:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][800/1251]	eta 0:04:15 lr 0.000482	time 0.5592 (0.5665)	loss 3.9119 (5.0136)	grad_norm 1.8324 (1.7029)	mem 17413MB
[2023-01-31 14:54:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][850/1251]	eta 0:03:47 lr 0.000484	time 0.5569 (0.5665)	loss 5.1954 (5.0106)	grad_norm 1.4601 (1.7033)	mem 17413MB
[2023-01-31 14:55:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][900/1251]	eta 0:03:18 lr 0.000486	time 0.5650 (0.5663)	loss 5.6081 (5.0004)	grad_norm 3.0063 (1.7016)	mem 17413MB
[2023-01-31 14:55:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][950/1251]	eta 0:02:50 lr 0.000488	time 0.5611 (0.5663)	loss 5.3519 (4.9889)	grad_norm 1.5037 (1.7018)	mem 17413MB
[2023-01-31 14:56:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][1000/1251]	eta 0:02:22 lr 0.000490	time 0.5595 (0.5663)	loss 5.4447 (4.9882)	grad_norm 1.5543 (inf)	mem 17413MB
[2023-01-31 14:56:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][1050/1251]	eta 0:01:53 lr 0.000492	time 0.5713 (0.5663)	loss 4.5260 (4.9871)	grad_norm 1.4352 (inf)	mem 17413MB
[2023-01-31 14:57:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][1100/1251]	eta 0:01:25 lr 0.000494	time 0.5667 (0.5661)	loss 4.6488 (4.9841)	grad_norm 1.8928 (inf)	mem 17413MB
[2023-01-31 14:57:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][1150/1251]	eta 0:00:57 lr 0.000496	time 0.5675 (0.5662)	loss 5.5831 (4.9770)	grad_norm 1.7594 (inf)	mem 17413MB
[2023-01-31 14:57:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][1200/1251]	eta 0:00:28 lr 0.000498	time 0.5528 (0.5661)	loss 4.0648 (4.9706)	grad_norm 1.3034 (inf)	mem 17413MB
[2023-01-31 14:58:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [9/300][1250/1251]	eta 0:00:00 lr 0.000500	time 0.6294 (0.5661)	loss 5.2362 (4.9692)	grad_norm 2.1276 (inf)	mem 17413MB
[2023-01-31 14:58:27 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 9 training takes 0:11:48
[2023-01-31 14:58:27 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_9.pth saving......
[2023-01-31 14:58:29 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_9.pth saved !!!
[2023-01-31 14:58:29 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.886 (0.886)	Loss 2.1391 (2.1391)	Acc@1 52.832 (52.832)	Acc@5 77.539 (77.539)	Mem 17413MB
[2023-01-31 14:58:37 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 50.888 Acc@5 76.212
[2023-01-31 14:58:37 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 50.9%
[2023-01-31 14:58:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.212 (1.212)	Loss 6.5556 (6.5556)	Acc@1 1.562 (1.562)	Acc@5 3.516 (3.516)	Mem 17413MB
[2023-01-31 14:58:46 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 1.314 Acc@5 4.774
[2023-01-31 14:58:46 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 1.3%
[2023-01-31 14:58:46 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 50.89% at 9 epoch
[2023-01-31 14:58:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][0/1251]	eta 0:36:18 lr 0.000501	time 1.7415 (1.7415)	loss 5.3713 (5.3713)	grad_norm 2.1501 (2.1501)	mem 17413MB
[2023-01-31 14:59:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][50/1251]	eta 0:11:52 lr 0.000502	time 0.5674 (0.5934)	loss 3.9784 (5.0332)	grad_norm 1.8907 (1.6442)	mem 17413MB
[2023-01-31 14:59:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][100/1251]	eta 0:11:05 lr 0.000504	time 0.5705 (0.5783)	loss 4.7607 (4.9966)	grad_norm 2.2393 (1.6788)	mem 17413MB
[2023-01-31 15:00:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][150/1251]	eta 0:10:32 lr 0.000506	time 0.5614 (0.5744)	loss 5.3460 (4.9822)	grad_norm 1.8106 (1.6587)	mem 17413MB
[2023-01-31 15:00:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][200/1251]	eta 0:10:00 lr 0.000508	time 0.5597 (0.5717)	loss 4.5461 (4.9848)	grad_norm 1.7355 (1.6616)	mem 17413MB
[2023-01-31 15:01:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][250/1251]	eta 0:09:31 lr 0.000510	time 0.5621 (0.5707)	loss 3.9501 (4.9782)	grad_norm 1.5162 (1.6464)	mem 17413MB
[2023-01-31 15:01:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][300/1251]	eta 0:09:01 lr 0.000512	time 0.5542 (0.5695)	loss 5.3977 (4.9505)	grad_norm 1.4380 (1.6410)	mem 17413MB
[2023-01-31 15:02:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][350/1251]	eta 0:08:32 lr 0.000514	time 0.5578 (0.5691)	loss 4.3185 (4.9493)	grad_norm 1.7631 (1.6351)	mem 17413MB
[2023-01-31 15:02:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][400/1251]	eta 0:08:03 lr 0.000516	time 0.5620 (0.5682)	loss 3.7309 (4.9597)	grad_norm 1.7881 (1.6228)	mem 17413MB
[2023-01-31 15:03:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][450/1251]	eta 0:07:34 lr 0.000518	time 0.5558 (0.5679)	loss 4.8822 (4.9587)	grad_norm 1.4934 (1.6253)	mem 17413MB
[2023-01-31 15:03:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][500/1251]	eta 0:07:06 lr 0.000520	time 0.5614 (0.5677)	loss 5.3708 (4.9432)	grad_norm 1.5211 (1.6221)	mem 17413MB
[2023-01-31 15:03:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][550/1251]	eta 0:06:37 lr 0.000522	time 0.5518 (0.5675)	loss 3.8645 (4.9446)	grad_norm 1.5411 (1.6211)	mem 17413MB
[2023-01-31 15:04:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][600/1251]	eta 0:06:09 lr 0.000524	time 0.5516 (0.5674)	loss 5.0619 (4.9367)	grad_norm 1.8430 (1.6181)	mem 17413MB
[2023-01-31 15:04:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][650/1251]	eta 0:05:40 lr 0.000526	time 0.5597 (0.5671)	loss 4.7905 (4.9318)	grad_norm 1.8061 (1.6196)	mem 17413MB
[2023-01-31 15:05:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][700/1251]	eta 0:05:12 lr 0.000528	time 0.5583 (0.5670)	loss 5.3563 (4.9294)	grad_norm 1.3485 (1.6127)	mem 17413MB
[2023-01-31 15:05:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][750/1251]	eta 0:04:44 lr 0.000530	time 0.5653 (0.5670)	loss 4.3648 (4.9233)	grad_norm 1.3894 (1.6113)	mem 17413MB
[2023-01-31 15:06:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][800/1251]	eta 0:04:15 lr 0.000532	time 0.5620 (0.5668)	loss 3.3993 (4.9121)	grad_norm 1.6099 (1.6191)	mem 17413MB
[2023-01-31 15:06:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][850/1251]	eta 0:03:47 lr 0.000534	time 0.5656 (0.5668)	loss 3.7005 (4.9086)	grad_norm 1.5015 (1.6174)	mem 17413MB
[2023-01-31 15:07:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][900/1251]	eta 0:03:18 lr 0.000536	time 0.5650 (0.5666)	loss 4.1376 (4.9028)	grad_norm 1.3699 (1.6154)	mem 17413MB
[2023-01-31 15:07:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][950/1251]	eta 0:02:50 lr 0.000538	time 0.5541 (0.5666)	loss 4.3934 (4.9061)	grad_norm 1.3430 (1.6081)	mem 17413MB
[2023-01-31 15:08:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][1000/1251]	eta 0:02:22 lr 0.000540	time 0.5631 (0.5666)	loss 5.4915 (4.9047)	grad_norm 1.5054 (1.6101)	mem 17413MB
[2023-01-31 15:08:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][1050/1251]	eta 0:01:53 lr 0.000542	time 0.5549 (0.5666)	loss 5.0125 (4.8940)	grad_norm 1.6888 (1.6115)	mem 17413MB
[2023-01-31 15:09:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][1100/1251]	eta 0:01:25 lr 0.000544	time 0.5640 (0.5667)	loss 4.9556 (4.8823)	grad_norm 1.5596 (1.6102)	mem 17413MB
[2023-01-31 15:09:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][1150/1251]	eta 0:00:57 lr 0.000546	time 0.5617 (0.5666)	loss 3.9896 (4.8739)	grad_norm 2.2361 (1.6091)	mem 17413MB
[2023-01-31 15:10:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][1200/1251]	eta 0:00:28 lr 0.000548	time 0.6234 (0.5665)	loss 5.5908 (4.8741)	grad_norm 1.5833 (1.6092)	mem 17413MB
[2023-01-31 15:10:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [10/300][1250/1251]	eta 0:00:00 lr 0.000550	time 0.5529 (0.5665)	loss 4.8229 (4.8743)	grad_norm 1.5319 (1.6062)	mem 17413MB
[2023-01-31 15:10:35 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 10 training takes 0:11:48
[2023-01-31 15:10:35 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_10.pth saving......
[2023-01-31 15:10:37 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_10.pth saved !!!
[2023-01-31 15:10:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.850 (0.850)	Loss 2.1332 (2.1332)	Acc@1 51.953 (51.953)	Acc@5 78.906 (78.906)	Mem 17413MB
[2023-01-31 15:10:46 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 53.246 Acc@5 78.368
[2023-01-31 15:10:46 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 53.2%
[2023-01-31 15:10:47 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.166 (1.166)	Loss 6.2502 (6.2502)	Acc@1 2.344 (2.344)	Acc@5 8.008 (8.008)	Mem 17413MB
[2023-01-31 15:10:55 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 1.966 Acc@5 6.836
[2023-01-31 15:10:55 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 2.0%
[2023-01-31 15:10:55 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 53.25% at 10 epoch
[2023-01-31 15:10:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][0/1251]	eta 0:35:35 lr 0.000550	time 1.7074 (1.7074)	loss 5.1764 (5.1764)	grad_norm 1.7475 (1.7475)	mem 17413MB
[2023-01-31 15:11:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][50/1251]	eta 0:11:46 lr 0.000552	time 0.6294 (0.5883)	loss 4.7608 (4.7774)	grad_norm 1.7453 (1.5550)	mem 17413MB
[2023-01-31 15:11:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][100/1251]	eta 0:11:03 lr 0.000554	time 0.6166 (0.5768)	loss 4.7760 (4.7951)	grad_norm 1.3395 (1.5910)	mem 17413MB
[2023-01-31 15:12:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][150/1251]	eta 0:10:29 lr 0.000556	time 0.5574 (0.5717)	loss 5.0366 (4.8000)	grad_norm 1.5592 (1.6101)	mem 17413MB
[2023-01-31 15:12:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][200/1251]	eta 0:09:59 lr 0.000558	time 0.5533 (0.5704)	loss 4.2197 (4.7513)	grad_norm 1.5449 (1.5937)	mem 17413MB
[2023-01-31 15:13:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][250/1251]	eta 0:09:30 lr 0.000560	time 0.5584 (0.5695)	loss 4.7830 (4.7844)	grad_norm 1.4826 (1.5948)	mem 17413MB
[2023-01-31 15:13:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][300/1251]	eta 0:09:00 lr 0.000562	time 0.5574 (0.5682)	loss 5.2285 (4.7784)	grad_norm 1.5697 (1.5769)	mem 17413MB
[2023-01-31 15:14:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][350/1251]	eta 0:08:31 lr 0.000564	time 0.5569 (0.5679)	loss 3.4686 (4.7938)	grad_norm 1.3784 (1.5846)	mem 17413MB
[2023-01-31 15:14:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][400/1251]	eta 0:08:02 lr 0.000566	time 0.5672 (0.5671)	loss 5.4228 (4.8108)	grad_norm 1.5960 (1.5865)	mem 17413MB
[2023-01-31 15:15:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][450/1251]	eta 0:07:34 lr 0.000568	time 0.5526 (0.5668)	loss 4.3814 (4.8032)	grad_norm 1.4352 (1.5820)	mem 17413MB
[2023-01-31 15:15:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][500/1251]	eta 0:07:05 lr 0.000570	time 0.6208 (0.5667)	loss 5.0602 (4.7968)	grad_norm 1.5516 (1.5908)	mem 17413MB
[2023-01-31 15:16:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][550/1251]	eta 0:06:36 lr 0.000572	time 0.5607 (0.5663)	loss 4.9545 (4.7883)	grad_norm 1.4122 (1.5855)	mem 17413MB
[2023-01-31 15:16:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][600/1251]	eta 0:06:08 lr 0.000574	time 0.5582 (0.5662)	loss 5.2581 (4.7897)	grad_norm 1.6219 (1.5847)	mem 17413MB
[2023-01-31 15:17:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][650/1251]	eta 0:05:40 lr 0.000576	time 0.5570 (0.5662)	loss 5.4115 (4.8027)	grad_norm 1.4601 (1.5797)	mem 17413MB
[2023-01-31 15:17:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][700/1251]	eta 0:05:11 lr 0.000578	time 0.5556 (0.5662)	loss 5.1351 (4.8048)	grad_norm 1.2450 (inf)	mem 17413MB
[2023-01-31 15:18:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][750/1251]	eta 0:04:43 lr 0.000580	time 0.5622 (0.5660)	loss 5.3224 (4.8097)	grad_norm 1.5092 (inf)	mem 17413MB
[2023-01-31 15:18:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][800/1251]	eta 0:04:15 lr 0.000582	time 0.5574 (0.5660)	loss 4.7457 (4.8126)	grad_norm 1.3628 (inf)	mem 17413MB
[2023-01-31 15:18:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][850/1251]	eta 0:03:46 lr 0.000584	time 0.5559 (0.5658)	loss 4.9320 (4.8143)	grad_norm 1.7713 (inf)	mem 17413MB
[2023-01-31 15:19:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][900/1251]	eta 0:03:18 lr 0.000586	time 0.6180 (0.5659)	loss 3.6592 (4.8111)	grad_norm 1.4548 (inf)	mem 17413MB
[2023-01-31 15:19:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][950/1251]	eta 0:02:50 lr 0.000588	time 0.5623 (0.5657)	loss 4.5123 (4.7986)	grad_norm 1.5760 (inf)	mem 17413MB
[2023-01-31 15:20:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][1000/1251]	eta 0:02:22 lr 0.000590	time 0.5591 (0.5658)	loss 5.0977 (4.7936)	grad_norm 1.3818 (inf)	mem 17413MB
[2023-01-31 15:20:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][1050/1251]	eta 0:01:53 lr 0.000592	time 0.5746 (0.5658)	loss 4.3603 (4.7910)	grad_norm 2.1842 (inf)	mem 17413MB
[2023-01-31 15:21:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][1100/1251]	eta 0:01:25 lr 0.000594	time 0.5687 (0.5657)	loss 5.5414 (4.7886)	grad_norm 2.5893 (inf)	mem 17413MB
[2023-01-31 15:21:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][1150/1251]	eta 0:00:57 lr 0.000596	time 0.5590 (0.5657)	loss 5.2519 (4.7879)	grad_norm 1.7068 (inf)	mem 17413MB
[2023-01-31 15:22:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][1200/1251]	eta 0:00:28 lr 0.000598	time 0.5589 (0.5657)	loss 5.0543 (4.7859)	grad_norm 1.3409 (inf)	mem 17413MB
[2023-01-31 15:22:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [11/300][1250/1251]	eta 0:00:00 lr 0.000600	time 0.5516 (0.5656)	loss 5.0312 (4.7830)	grad_norm 1.3899 (inf)	mem 17413MB
[2023-01-31 15:22:43 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 11 training takes 0:11:47
[2023-01-31 15:22:43 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_11.pth saving......
[2023-01-31 15:22:45 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_11.pth saved !!!
[2023-01-31 15:22:46 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.855 (0.855)	Loss 1.9486 (1.9486)	Acc@1 57.520 (57.520)	Acc@5 80.859 (80.859)	Mem 17413MB
[2023-01-31 15:22:53 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 55.144 Acc@5 79.750
[2023-01-31 15:22:53 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 55.1%
[2023-01-31 15:22:55 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.251 (1.251)	Loss 6.0756 (6.0756)	Acc@1 3.516 (3.516)	Acc@5 9.473 (9.473)	Mem 17413MB
[2023-01-31 15:23:03 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 3.000 Acc@5 9.900
[2023-01-31 15:23:03 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 3.0%
[2023-01-31 15:23:03 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 55.14% at 11 epoch
[2023-01-31 15:23:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][0/1251]	eta 0:33:49 lr 0.000600	time 1.6222 (1.6222)	loss 5.1687 (5.1687)	grad_norm 1.4705 (1.4705)	mem 17413MB
[2023-01-31 15:23:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][50/1251]	eta 0:11:51 lr 0.000602	time 0.5627 (0.5928)	loss 4.8650 (4.5847)	grad_norm 1.6873 (1.5726)	mem 17413MB
[2023-01-31 15:24:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][100/1251]	eta 0:11:06 lr 0.000604	time 0.5672 (0.5787)	loss 4.4143 (4.6253)	grad_norm 1.7883 (1.5504)	mem 17413MB
[2023-01-31 15:24:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][150/1251]	eta 0:10:33 lr 0.000606	time 0.5596 (0.5753)	loss 4.5559 (4.6768)	grad_norm 1.8100 (1.5321)	mem 17413MB
[2023-01-31 15:24:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][200/1251]	eta 0:10:01 lr 0.000608	time 0.5565 (0.5725)	loss 4.9882 (4.6937)	grad_norm 1.5842 (1.5246)	mem 17413MB
[2023-01-31 15:25:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][250/1251]	eta 0:09:31 lr 0.000610	time 0.5543 (0.5710)	loss 5.2113 (4.6955)	grad_norm 1.4593 (1.5115)	mem 17413MB
[2023-01-31 15:25:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][300/1251]	eta 0:09:02 lr 0.000612	time 0.5525 (0.5700)	loss 5.3408 (4.7112)	grad_norm 1.6023 (1.5137)	mem 17413MB
[2023-01-31 15:26:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][350/1251]	eta 0:08:32 lr 0.000614	time 0.5522 (0.5692)	loss 4.6166 (4.6995)	grad_norm 1.4820 (1.5215)	mem 17413MB
[2023-01-31 15:26:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][400/1251]	eta 0:08:03 lr 0.000616	time 0.5851 (0.5685)	loss 4.6353 (4.6932)	grad_norm 1.4774 (1.5180)	mem 17413MB
[2023-01-31 15:27:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][450/1251]	eta 0:07:34 lr 0.000618	time 0.6167 (0.5679)	loss 4.8793 (4.6909)	grad_norm 1.3041 (1.5185)	mem 17413MB
[2023-01-31 15:27:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][500/1251]	eta 0:07:06 lr 0.000620	time 0.5607 (0.5673)	loss 5.4710 (4.6868)	grad_norm 1.5588 (1.5162)	mem 17413MB
[2023-01-31 15:28:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][550/1251]	eta 0:06:37 lr 0.000622	time 0.5518 (0.5670)	loss 4.8555 (4.6928)	grad_norm 1.2320 (1.5119)	mem 17413MB
[2023-01-31 15:28:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][600/1251]	eta 0:06:08 lr 0.000624	time 0.5611 (0.5668)	loss 5.1528 (4.6914)	grad_norm 1.5973 (1.5162)	mem 17413MB
[2023-01-31 15:29:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][650/1251]	eta 0:05:40 lr 0.000626	time 0.5493 (0.5667)	loss 3.7998 (4.6949)	grad_norm 1.4119 (1.5151)	mem 17413MB
[2023-01-31 15:29:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][700/1251]	eta 0:05:12 lr 0.000628	time 0.5708 (0.5667)	loss 5.0414 (4.6915)	grad_norm 1.7318 (1.5138)	mem 17413MB
[2023-01-31 15:30:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][750/1251]	eta 0:04:43 lr 0.000630	time 0.5552 (0.5666)	loss 4.4338 (4.6933)	grad_norm 1.2810 (1.5129)	mem 17413MB
[2023-01-31 15:30:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][800/1251]	eta 0:04:15 lr 0.000632	time 0.6144 (0.5664)	loss 4.2941 (4.6892)	grad_norm 1.4204 (1.5106)	mem 17413MB
[2023-01-31 15:31:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][850/1251]	eta 0:03:47 lr 0.000634	time 0.5572 (0.5663)	loss 4.3516 (4.6968)	grad_norm 1.4841 (1.5115)	mem 17413MB
[2023-01-31 15:31:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][900/1251]	eta 0:03:18 lr 0.000636	time 0.5574 (0.5661)	loss 5.0658 (4.7021)	grad_norm 1.4801 (1.5119)	mem 17413MB
[2023-01-31 15:32:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][950/1251]	eta 0:02:50 lr 0.000638	time 0.5641 (0.5662)	loss 5.4859 (4.6908)	grad_norm 1.5082 (1.5120)	mem 17413MB
[2023-01-31 15:32:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][1000/1251]	eta 0:02:22 lr 0.000640	time 0.5583 (0.5661)	loss 4.3119 (4.6890)	grad_norm 1.3286 (1.5126)	mem 17413MB
[2023-01-31 15:32:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][1050/1251]	eta 0:01:53 lr 0.000642	time 0.5568 (0.5660)	loss 5.1858 (4.6841)	grad_norm 1.3236 (1.5100)	mem 17413MB
[2023-01-31 15:33:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][1100/1251]	eta 0:01:25 lr 0.000644	time 0.5539 (0.5659)	loss 4.0383 (4.6832)	grad_norm 1.6077 (1.5126)	mem 17413MB
[2023-01-31 15:33:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][1150/1251]	eta 0:00:57 lr 0.000646	time 0.6194 (0.5659)	loss 3.7792 (4.6861)	grad_norm 1.3369 (1.5093)	mem 17413MB
[2023-01-31 15:34:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][1200/1251]	eta 0:00:28 lr 0.000648	time 0.5534 (0.5658)	loss 4.0560 (4.6844)	grad_norm 1.4825 (1.5102)	mem 17413MB
[2023-01-31 15:34:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [12/300][1250/1251]	eta 0:00:00 lr 0.000650	time 0.5538 (0.5657)	loss 5.2974 (4.6809)	grad_norm 1.4744 (1.5118)	mem 17413MB
[2023-01-31 15:34:50 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 12 training takes 0:11:47
[2023-01-31 15:34:51 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_12.pth saving......
[2023-01-31 15:34:52 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_12.pth saved !!!
[2023-01-31 15:34:53 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.920 (0.920)	Loss 1.9376 (1.9376)	Acc@1 56.836 (56.836)	Acc@5 81.348 (81.348)	Mem 17413MB
[2023-01-31 15:35:01 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 57.376 Acc@5 81.686
[2023-01-31 15:35:01 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 57.4%
[2023-01-31 15:35:02 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.305 (1.305)	Loss 5.8272 (5.8272)	Acc@1 4.395 (4.395)	Acc@5 13.965 (13.965)	Mem 17413MB
[2023-01-31 15:35:10 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 4.606 Acc@5 14.192
[2023-01-31 15:35:10 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 4.6%
[2023-01-31 15:35:10 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 57.38% at 12 epoch
[2023-01-31 15:35:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][0/1251]	eta 0:37:29 lr 0.000650	time 1.7979 (1.7979)	loss 3.4858 (3.4858)	grad_norm 1.3989 (1.3989)	mem 17413MB
[2023-01-31 15:35:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][50/1251]	eta 0:11:48 lr 0.000652	time 0.5588 (0.5899)	loss 5.2444 (4.5357)	grad_norm 1.4170 (1.4469)	mem 17413MB
[2023-01-31 15:36:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][100/1251]	eta 0:11:04 lr 0.000654	time 0.5569 (0.5769)	loss 4.1843 (4.5681)	grad_norm 1.3373 (1.4813)	mem 17413MB
[2023-01-31 15:36:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][150/1251]	eta 0:10:31 lr 0.000656	time 0.5559 (0.5731)	loss 4.8580 (4.5673)	grad_norm 1.6346 (1.5044)	mem 17413MB
[2023-01-31 15:37:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][200/1251]	eta 0:10:00 lr 0.000658	time 0.5560 (0.5716)	loss 3.8488 (4.5714)	grad_norm 1.6278 (1.5043)	mem 17413MB
[2023-01-31 15:37:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][250/1251]	eta 0:09:30 lr 0.000660	time 0.5612 (0.5704)	loss 4.8390 (4.5959)	grad_norm 1.4510 (1.5058)	mem 17413MB
[2023-01-31 15:38:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][300/1251]	eta 0:09:01 lr 0.000662	time 0.5558 (0.5698)	loss 4.8053 (4.5647)	grad_norm 1.3041 (1.5026)	mem 17413MB
[2023-01-31 15:38:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][350/1251]	eta 0:08:32 lr 0.000664	time 0.5496 (0.5688)	loss 4.0788 (4.5688)	grad_norm 2.0892 (1.4955)	mem 17413MB
[2023-01-31 15:38:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][400/1251]	eta 0:08:03 lr 0.000666	time 0.5674 (0.5681)	loss 5.0338 (4.5785)	grad_norm 1.5547 (nan)	mem 17413MB
[2023-01-31 15:39:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][450/1251]	eta 0:07:34 lr 0.000668	time 0.5466 (0.5680)	loss 5.1413 (4.5910)	grad_norm 1.4842 (nan)	mem 17413MB
[2023-01-31 15:39:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][500/1251]	eta 0:07:06 lr 0.000670	time 0.5554 (0.5673)	loss 5.5801 (4.5968)	grad_norm 1.5139 (nan)	mem 17413MB
[2023-01-31 15:40:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][550/1251]	eta 0:06:37 lr 0.000672	time 0.5529 (0.5672)	loss 4.8991 (4.5895)	grad_norm 1.3803 (nan)	mem 17413MB
[2023-01-31 15:40:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][600/1251]	eta 0:06:09 lr 0.000674	time 0.5638 (0.5670)	loss 5.3408 (4.5916)	grad_norm 1.3198 (nan)	mem 17413MB
[2023-01-31 15:41:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][650/1251]	eta 0:05:40 lr 0.000676	time 0.5588 (0.5666)	loss 4.9134 (4.5906)	grad_norm 1.5211 (nan)	mem 17413MB
[2023-01-31 15:41:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][700/1251]	eta 0:05:12 lr 0.000678	time 0.5568 (0.5667)	loss 5.3583 (4.5924)	grad_norm 1.3005 (nan)	mem 17413MB
[2023-01-31 15:42:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][750/1251]	eta 0:04:43 lr 0.000680	time 0.5562 (0.5664)	loss 4.2999 (4.5894)	grad_norm 1.6039 (nan)	mem 17413MB
[2023-01-31 15:42:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][800/1251]	eta 0:04:15 lr 0.000682	time 0.6217 (0.5665)	loss 4.2832 (4.5811)	grad_norm 1.2172 (nan)	mem 17413MB
[2023-01-31 15:43:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][850/1251]	eta 0:03:47 lr 0.000684	time 0.6267 (0.5664)	loss 4.5061 (4.5804)	grad_norm 1.3737 (nan)	mem 17413MB
[2023-01-31 15:43:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][900/1251]	eta 0:03:18 lr 0.000686	time 0.5581 (0.5661)	loss 3.7954 (4.5848)	grad_norm 1.3749 (nan)	mem 17413MB
[2023-01-31 15:44:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][950/1251]	eta 0:02:50 lr 0.000688	time 0.5616 (0.5663)	loss 4.8099 (4.5796)	grad_norm 1.3657 (nan)	mem 17413MB
[2023-01-31 15:44:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][1000/1251]	eta 0:02:22 lr 0.000690	time 0.5587 (0.5662)	loss 4.6446 (4.5825)	grad_norm 1.4045 (nan)	mem 17413MB
[2023-01-31 15:45:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][1050/1251]	eta 0:01:53 lr 0.000692	time 0.5515 (0.5662)	loss 4.3171 (4.5836)	grad_norm 1.3578 (nan)	mem 17413MB
[2023-01-31 15:45:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][1100/1251]	eta 0:01:25 lr 0.000694	time 0.5569 (0.5662)	loss 5.2948 (4.5812)	grad_norm 1.5626 (nan)	mem 17413MB
[2023-01-31 15:46:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][1150/1251]	eta 0:00:57 lr 0.000696	time 0.5677 (0.5661)	loss 4.7637 (4.5781)	grad_norm 1.5250 (nan)	mem 17413MB
[2023-01-31 15:46:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][1200/1251]	eta 0:00:28 lr 0.000698	time 0.5694 (0.5661)	loss 4.4896 (4.5755)	grad_norm 1.4288 (nan)	mem 17413MB
[2023-01-31 15:46:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [13/300][1250/1251]	eta 0:00:00 lr 0.000700	time 0.5513 (0.5661)	loss 4.6883 (4.5724)	grad_norm 1.7629 (nan)	mem 17413MB
[2023-01-31 15:46:59 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 13 training takes 0:11:48
[2023-01-31 15:46:59 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_13.pth saving......
[2023-01-31 15:47:01 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_13.pth saved !!!
[2023-01-31 15:47:02 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.969 (0.969)	Loss 1.8174 (1.8174)	Acc@1 59.375 (59.375)	Acc@5 82.422 (82.422)	Mem 17413MB
[2023-01-31 15:47:09 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 58.852 Acc@5 82.900
[2023-01-31 15:47:09 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 58.9%
[2023-01-31 15:47:11 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.415 (1.415)	Loss 5.4124 (5.4124)	Acc@1 6.152 (6.152)	Acc@5 21.680 (21.680)	Mem 17413MB
[2023-01-31 15:47:19 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 7.046 Acc@5 20.120
[2023-01-31 15:47:19 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 7.0%
[2023-01-31 15:47:19 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 58.85% at 13 epoch
[2023-01-31 15:47:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][0/1251]	eta 0:34:01 lr 0.000700	time 1.6318 (1.6318)	loss 5.0335 (5.0335)	grad_norm 1.5957 (1.5957)	mem 17413MB
[2023-01-31 15:47:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][50/1251]	eta 0:11:44 lr 0.000702	time 0.5641 (0.5862)	loss 5.0791 (4.5508)	grad_norm 1.8832 (1.4293)	mem 17413MB
[2023-01-31 15:48:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][100/1251]	eta 0:11:04 lr 0.000704	time 0.6256 (0.5769)	loss 4.2610 (4.5911)	grad_norm 1.6663 (1.4831)	mem 17413MB
[2023-01-31 15:48:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][150/1251]	eta 0:10:28 lr 0.000706	time 0.5565 (0.5711)	loss 4.4333 (4.5569)	grad_norm 1.5860 (1.4861)	mem 17413MB
[2023-01-31 15:49:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][200/1251]	eta 0:09:59 lr 0.000708	time 0.5627 (0.5700)	loss 5.2105 (4.5360)	grad_norm 1.6394 (1.4716)	mem 17413MB
[2023-01-31 15:49:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][250/1251]	eta 0:09:28 lr 0.000710	time 0.5625 (0.5678)	loss 5.2084 (4.5356)	grad_norm 1.8049 (1.4770)	mem 17413MB
[2023-01-31 15:50:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][300/1251]	eta 0:08:59 lr 0.000712	time 0.5585 (0.5676)	loss 4.4098 (4.5385)	grad_norm 1.3739 (1.4811)	mem 17413MB
[2023-01-31 15:50:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][350/1251]	eta 0:08:30 lr 0.000714	time 0.5561 (0.5664)	loss 3.4109 (4.5269)	grad_norm 1.4161 (1.4746)	mem 17413MB
[2023-01-31 15:51:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][400/1251]	eta 0:08:01 lr 0.000716	time 0.5648 (0.5664)	loss 4.6059 (4.5317)	grad_norm 1.2983 (1.4699)	mem 17413MB
[2023-01-31 15:51:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][450/1251]	eta 0:07:33 lr 0.000718	time 0.5549 (0.5657)	loss 4.4020 (4.5261)	grad_norm 1.7015 (1.4693)	mem 17413MB
[2023-01-31 15:52:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][500/1251]	eta 0:07:04 lr 0.000720	time 0.6281 (0.5658)	loss 5.4685 (4.5224)	grad_norm 1.2932 (1.4651)	mem 17413MB
[2023-01-31 15:52:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][550/1251]	eta 0:06:36 lr 0.000722	time 0.5539 (0.5654)	loss 3.3050 (4.5135)	grad_norm 1.3144 (1.4642)	mem 17413MB
[2023-01-31 15:52:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][600/1251]	eta 0:06:08 lr 0.000724	time 0.5587 (0.5653)	loss 4.9975 (4.5291)	grad_norm 1.3166 (1.4568)	mem 17413MB
[2023-01-31 15:53:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][650/1251]	eta 0:05:39 lr 0.000726	time 0.5610 (0.5649)	loss 3.3121 (4.5217)	grad_norm 1.4312 (1.4509)	mem 17413MB
[2023-01-31 15:53:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][700/1251]	eta 0:05:11 lr 0.000728	time 0.5621 (0.5650)	loss 4.5879 (4.5281)	grad_norm 1.2791 (1.4522)	mem 17413MB
[2023-01-31 15:54:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][750/1251]	eta 0:04:42 lr 0.000730	time 0.5568 (0.5648)	loss 4.5804 (4.5437)	grad_norm 1.2458 (1.4476)	mem 17413MB
[2023-01-31 15:54:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][800/1251]	eta 0:04:14 lr 0.000732	time 0.5622 (0.5649)	loss 3.9597 (4.5482)	grad_norm 1.5385 (1.4464)	mem 17413MB
[2023-01-31 15:55:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][850/1251]	eta 0:03:46 lr 0.000734	time 0.5564 (0.5647)	loss 4.4447 (4.5457)	grad_norm 1.3826 (1.4426)	mem 17413MB
[2023-01-31 15:55:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][900/1251]	eta 0:03:18 lr 0.000736	time 0.6275 (0.5647)	loss 4.1571 (4.5488)	grad_norm 1.7169 (1.4431)	mem 17413MB
[2023-01-31 15:56:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][950/1251]	eta 0:02:49 lr 0.000738	time 0.5634 (0.5645)	loss 4.1293 (4.5375)	grad_norm 1.2570 (1.4443)	mem 17413MB
[2023-01-31 15:56:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][1000/1251]	eta 0:02:21 lr 0.000740	time 0.5597 (0.5646)	loss 4.2289 (4.5418)	grad_norm 1.4457 (1.4461)	mem 17413MB
[2023-01-31 15:57:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][1050/1251]	eta 0:01:53 lr 0.000742	time 0.5585 (0.5644)	loss 3.5851 (4.5385)	grad_norm 1.2777 (1.4441)	mem 17413MB
[2023-01-31 15:57:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][1100/1251]	eta 0:01:25 lr 0.000744	time 0.6633 (0.5646)	loss 4.7269 (4.5365)	grad_norm 1.3914 (1.4434)	mem 17413MB
[2023-01-31 15:58:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][1150/1251]	eta 0:00:57 lr 0.000746	time 0.5596 (0.5645)	loss 4.7294 (4.5316)	grad_norm 1.3774 (1.4438)	mem 17413MB
[2023-01-31 15:58:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][1200/1251]	eta 0:00:28 lr 0.000748	time 0.6167 (0.5644)	loss 4.2932 (4.5287)	grad_norm 1.9216 (nan)	mem 17413MB
[2023-01-31 15:59:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [14/300][1250/1251]	eta 0:00:00 lr 0.000750	time 0.5601 (0.5645)	loss 4.5502 (4.5227)	grad_norm 1.4874 (nan)	mem 17413MB
[2023-01-31 15:59:05 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 14 training takes 0:11:46
[2023-01-31 15:59:05 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_14.pth saving......
[2023-01-31 15:59:07 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_14.pth saved !!!
[2023-01-31 15:59:08 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.848 (0.848)	Loss 1.9314 (1.9314)	Acc@1 58.203 (58.203)	Acc@5 82.422 (82.422)	Mem 17413MB
[2023-01-31 15:59:16 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 60.006 Acc@5 83.632
[2023-01-31 15:59:16 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 60.0%
[2023-01-31 15:59:17 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.288 (1.288)	Loss 5.0635 (5.0635)	Acc@1 11.523 (11.523)	Acc@5 26.172 (26.172)	Mem 17413MB
[2023-01-31 15:59:25 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 11.136 Acc@5 28.238
[2023-01-31 15:59:25 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 11.1%
[2023-01-31 15:59:25 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 60.01% at 14 epoch
[2023-01-31 15:59:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][0/1251]	eta 0:34:18 lr 0.000750	time 1.6452 (1.6452)	loss 4.5490 (4.5490)	grad_norm 1.3694 (1.3694)	mem 17413MB
[2023-01-31 15:59:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][50/1251]	eta 0:11:45 lr 0.000752	time 0.5861 (0.5877)	loss 4.4990 (4.6175)	grad_norm 1.5590 (1.4158)	mem 17413MB
[2023-01-31 16:00:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][100/1251]	eta 0:11:03 lr 0.000754	time 0.5598 (0.5763)	loss 4.8433 (4.4848)	grad_norm 1.4217 (1.4513)	mem 17413MB
[2023-01-31 16:00:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][150/1251]	eta 0:10:30 lr 0.000756	time 0.5590 (0.5727)	loss 4.7954 (4.5009)	grad_norm 1.2016 (1.4290)	mem 17413MB
[2023-01-31 16:01:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][200/1251]	eta 0:09:58 lr 0.000758	time 0.5545 (0.5699)	loss 5.2943 (4.4701)	grad_norm 1.6602 (1.4354)	mem 17413MB
[2023-01-31 16:01:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][250/1251]	eta 0:09:29 lr 0.000760	time 0.5563 (0.5693)	loss 4.5419 (4.4909)	grad_norm 1.4402 (1.4335)	mem 17413MB
[2023-01-31 16:02:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][300/1251]	eta 0:09:00 lr 0.000762	time 0.5610 (0.5686)	loss 5.2337 (4.4858)	grad_norm 1.6306 (1.4365)	mem 17413MB
[2023-01-31 16:02:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][350/1251]	eta 0:08:31 lr 0.000764	time 0.5669 (0.5679)	loss 3.0132 (4.5043)	grad_norm 1.3440 (1.4315)	mem 17413MB
[2023-01-31 16:03:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][400/1251]	eta 0:08:02 lr 0.000766	time 0.5550 (0.5675)	loss 4.2408 (4.4838)	grad_norm 1.7105 (1.4347)	mem 17413MB
[2023-01-31 16:03:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][450/1251]	eta 0:07:34 lr 0.000768	time 0.6275 (0.5672)	loss 4.9258 (4.5070)	grad_norm 1.3391 (1.4373)	mem 17413MB
[2023-01-31 16:04:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][500/1251]	eta 0:07:05 lr 0.000770	time 0.5576 (0.5668)	loss 4.3486 (4.5073)	grad_norm 1.7938 (1.4330)	mem 17413MB
[2023-01-31 16:04:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][550/1251]	eta 0:06:36 lr 0.000772	time 0.5651 (0.5663)	loss 3.3383 (4.4930)	grad_norm 1.5086 (1.4322)	mem 17413MB
[2023-01-31 16:05:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][600/1251]	eta 0:06:08 lr 0.000774	time 0.5581 (0.5662)	loss 3.9858 (4.4944)	grad_norm 1.4232 (1.4309)	mem 17413MB
[2023-01-31 16:05:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][650/1251]	eta 0:05:40 lr 0.000776	time 0.5579 (0.5660)	loss 5.3979 (4.4909)	grad_norm 1.3358 (1.4261)	mem 17413MB
[2023-01-31 16:06:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][700/1251]	eta 0:05:11 lr 0.000778	time 0.5538 (0.5659)	loss 4.9149 (4.4999)	grad_norm 1.4434 (1.4272)	mem 17413MB
[2023-01-31 16:06:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][750/1251]	eta 0:04:43 lr 0.000780	time 0.5584 (0.5657)	loss 4.5229 (4.4946)	grad_norm 1.3635 (1.4257)	mem 17413MB
[2023-01-31 16:06:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][800/1251]	eta 0:04:15 lr 0.000782	time 0.5596 (0.5656)	loss 4.3389 (4.4979)	grad_norm 1.4877 (1.4235)	mem 17413MB
[2023-01-31 16:07:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][850/1251]	eta 0:03:46 lr 0.000784	time 0.5552 (0.5656)	loss 3.7823 (4.5013)	grad_norm 1.4544 (1.4221)	mem 17413MB
[2023-01-31 16:07:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][900/1251]	eta 0:03:18 lr 0.000786	time 0.5777 (0.5657)	loss 4.4063 (4.4970)	grad_norm 1.3832 (1.4219)	mem 17413MB
[2023-01-31 16:08:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][950/1251]	eta 0:02:50 lr 0.000788	time 0.5610 (0.5656)	loss 3.5305 (4.4911)	grad_norm 1.8061 (1.4211)	mem 17413MB
[2023-01-31 16:08:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][1000/1251]	eta 0:02:21 lr 0.000790	time 0.5556 (0.5655)	loss 5.4673 (4.4954)	grad_norm 1.5800 (1.4221)	mem 17413MB
[2023-01-31 16:09:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][1050/1251]	eta 0:01:53 lr 0.000792	time 0.5578 (0.5654)	loss 3.4240 (4.4890)	grad_norm 1.5003 (1.4209)	mem 17413MB
[2023-01-31 16:09:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][1100/1251]	eta 0:01:25 lr 0.000794	time 0.5601 (0.5654)	loss 5.1450 (4.4882)	grad_norm 1.4712 (1.4189)	mem 17413MB
[2023-01-31 16:10:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][1150/1251]	eta 0:00:57 lr 0.000796	time 0.5595 (0.5653)	loss 5.3605 (4.4906)	grad_norm 1.2588 (1.4184)	mem 17413MB
[2023-01-31 16:10:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][1200/1251]	eta 0:00:28 lr 0.000798	time 0.5486 (0.5653)	loss 5.2755 (4.4899)	grad_norm 1.3658 (1.4170)	mem 17413MB
[2023-01-31 16:11:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [15/300][1250/1251]	eta 0:00:00 lr 0.000800	time 0.5513 (0.5652)	loss 4.8987 (4.4855)	grad_norm 1.3020 (1.4173)	mem 17413MB
[2023-01-31 16:11:12 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 15 training takes 0:11:47
[2023-01-31 16:11:12 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_15.pth saving......
[2023-01-31 16:11:14 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_15.pth saved !!!
[2023-01-31 16:11:15 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.864 (0.864)	Loss 1.6623 (1.6623)	Acc@1 62.500 (62.500)	Acc@5 85.352 (85.352)	Mem 17413MB
[2023-01-31 16:11:23 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 61.128 Acc@5 84.326
[2023-01-31 16:11:23 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 61.1%
[2023-01-31 16:11:24 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.237 (1.237)	Loss 4.4366 (4.4366)	Acc@1 16.504 (16.504)	Acc@5 36.621 (36.621)	Mem 17413MB
[2023-01-31 16:11:32 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 16.904 Acc@5 37.876
[2023-01-31 16:11:32 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 16.9%
[2023-01-31 16:11:32 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 61.13% at 15 epoch
[2023-01-31 16:11:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][0/1251]	eta 0:36:24 lr 0.000800	time 1.7463 (1.7463)	loss 4.4423 (4.4423)	grad_norm 1.5849 (1.5849)	mem 17413MB
[2023-01-31 16:12:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][50/1251]	eta 0:11:46 lr 0.000802	time 0.5618 (0.5882)	loss 3.2669 (4.5457)	grad_norm 1.2851 (1.4300)	mem 17413MB
[2023-01-31 16:12:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][100/1251]	eta 0:11:04 lr 0.000804	time 0.6382 (0.5773)	loss 4.5216 (4.5158)	grad_norm 1.2324 (1.4033)	mem 17413MB
[2023-01-31 16:12:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][150/1251]	eta 0:10:30 lr 0.000806	time 0.5557 (0.5726)	loss 4.8748 (4.4727)	grad_norm 1.3448 (1.3940)	mem 17413MB
[2023-01-31 16:13:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][200/1251]	eta 0:09:58 lr 0.000808	time 0.5573 (0.5699)	loss 4.9243 (4.4411)	grad_norm 1.3961 (1.3926)	mem 17413MB
[2023-01-31 16:13:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][250/1251]	eta 0:09:29 lr 0.000810	time 0.6266 (0.5692)	loss 4.5661 (4.4308)	grad_norm 1.2004 (1.3840)	mem 17413MB
[2023-01-31 16:14:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][300/1251]	eta 0:09:00 lr 0.000812	time 0.5559 (0.5680)	loss 4.2725 (4.4386)	grad_norm 1.2063 (1.3860)	mem 17413MB
[2023-01-31 16:14:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][350/1251]	eta 0:08:31 lr 0.000814	time 0.5462 (0.5677)	loss 4.7513 (4.4266)	grad_norm 1.4344 (1.3834)	mem 17413MB
[2023-01-31 16:15:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][400/1251]	eta 0:08:02 lr 0.000816	time 0.5850 (0.5674)	loss 4.6275 (4.4346)	grad_norm 1.4104 (1.3839)	mem 17413MB
[2023-01-31 16:15:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][450/1251]	eta 0:07:34 lr 0.000818	time 0.5543 (0.5669)	loss 4.0950 (4.4405)	grad_norm 1.2867 (1.3855)	mem 17413MB
[2023-01-31 16:16:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][500/1251]	eta 0:07:05 lr 0.000820	time 0.5580 (0.5668)	loss 4.4323 (4.4464)	grad_norm 1.2467 (1.3874)	mem 17413MB
[2023-01-31 16:16:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][550/1251]	eta 0:06:37 lr 0.000822	time 0.5551 (0.5665)	loss 4.8901 (4.4508)	grad_norm 1.4001 (1.3842)	mem 17413MB
[2023-01-31 16:17:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][600/1251]	eta 0:06:08 lr 0.000824	time 0.5638 (0.5664)	loss 4.8981 (4.4619)	grad_norm 1.5938 (1.3854)	mem 17413MB
[2023-01-31 16:17:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][650/1251]	eta 0:05:40 lr 0.000826	time 0.5599 (0.5663)	loss 3.2132 (4.4566)	grad_norm 1.2959 (1.3892)	mem 17413MB
[2023-01-31 16:18:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][700/1251]	eta 0:05:11 lr 0.000828	time 0.5547 (0.5662)	loss 4.9214 (4.4567)	grad_norm 1.6685 (1.3893)	mem 17413MB
[2023-01-31 16:18:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][750/1251]	eta 0:04:43 lr 0.000830	time 0.5710 (0.5662)	loss 4.4555 (4.4587)	grad_norm 1.7709 (1.3901)	mem 17413MB
[2023-01-31 16:19:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][800/1251]	eta 0:04:15 lr 0.000832	time 0.7156 (0.5660)	loss 4.3866 (4.4581)	grad_norm 1.7201 (nan)	mem 17413MB
[2023-01-31 16:19:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][850/1251]	eta 0:03:46 lr 0.000834	time 0.5562 (0.5659)	loss 3.3443 (4.4573)	grad_norm 1.2899 (nan)	mem 17413MB
[2023-01-31 16:20:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][900/1251]	eta 0:03:18 lr 0.000836	time 0.5642 (0.5658)	loss 4.7111 (4.4553)	grad_norm 1.3753 (nan)	mem 17413MB
[2023-01-31 16:20:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][950/1251]	eta 0:02:50 lr 0.000838	time 0.5611 (0.5657)	loss 5.0319 (4.4506)	grad_norm 1.2826 (nan)	mem 17413MB
[2023-01-31 16:20:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][1000/1251]	eta 0:02:22 lr 0.000840	time 0.6259 (0.5658)	loss 4.0899 (4.4465)	grad_norm 1.1245 (nan)	mem 17413MB
[2023-01-31 16:21:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][1050/1251]	eta 0:01:53 lr 0.000842	time 0.5565 (0.5656)	loss 4.7462 (4.4424)	grad_norm 1.3808 (nan)	mem 17413MB
[2023-01-31 16:21:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][1100/1251]	eta 0:01:25 lr 0.000844	time 0.5558 (0.5655)	loss 4.5371 (4.4351)	grad_norm 1.5126 (nan)	mem 17413MB
[2023-01-31 16:22:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][1150/1251]	eta 0:00:57 lr 0.000846	time 0.5590 (0.5654)	loss 4.3558 (4.4329)	grad_norm 1.3648 (nan)	mem 17413MB
[2023-01-31 16:22:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][1200/1251]	eta 0:00:28 lr 0.000848	time 0.5551 (0.5654)	loss 4.6114 (4.4360)	grad_norm 1.2268 (nan)	mem 17413MB
[2023-01-31 16:23:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [16/300][1250/1251]	eta 0:00:00 lr 0.000850	time 0.5581 (0.5653)	loss 4.7007 (4.4349)	grad_norm 1.5670 (nan)	mem 17413MB
[2023-01-31 16:23:19 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 16 training takes 0:11:47
[2023-01-31 16:23:19 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_16.pth saving......
[2023-01-31 16:23:21 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_16.pth saved !!!
[2023-01-31 16:23:22 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.950 (0.950)	Loss 1.5913 (1.5913)	Acc@1 63.379 (63.379)	Acc@5 85.547 (85.547)	Mem 17413MB
[2023-01-31 16:23:30 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 62.316 Acc@5 85.278
[2023-01-31 16:23:30 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 62.3%
[2023-01-31 16:23:31 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.175 (1.175)	Loss 3.8750 (3.8750)	Acc@1 23.828 (23.828)	Acc@5 48.633 (48.633)	Mem 17413MB
[2023-01-31 16:23:39 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 24.220 Acc@5 48.104
[2023-01-31 16:23:39 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 24.2%
[2023-01-31 16:23:39 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 62.32% at 16 epoch
[2023-01-31 16:23:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][0/1251]	eta 0:34:15 lr 0.000850	time 1.6428 (1.6428)	loss 4.0457 (4.0457)	grad_norm 1.2619 (1.2619)	mem 17413MB
[2023-01-31 16:24:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][50/1251]	eta 0:11:44 lr 0.000852	time 0.5592 (0.5866)	loss 4.2865 (4.2189)	grad_norm 1.2629 (1.4075)	mem 17413MB
[2023-01-31 16:24:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][100/1251]	eta 0:11:02 lr 0.000854	time 0.5656 (0.5754)	loss 4.5450 (4.3696)	grad_norm 1.3524 (1.3866)	mem 17413MB
[2023-01-31 16:25:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][150/1251]	eta 0:10:29 lr 0.000856	time 0.5578 (0.5713)	loss 3.8448 (4.3241)	grad_norm 1.4034 (1.3885)	mem 17413MB
[2023-01-31 16:25:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][200/1251]	eta 0:09:58 lr 0.000858	time 0.5564 (0.5693)	loss 5.0823 (4.3065)	grad_norm 1.2051 (1.4033)	mem 17413MB
[2023-01-31 16:26:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][250/1251]	eta 0:09:28 lr 0.000860	time 0.5631 (0.5681)	loss 3.3330 (4.2955)	grad_norm 1.4750 (1.3913)	mem 17413MB
[2023-01-31 16:26:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][300/1251]	eta 0:08:59 lr 0.000862	time 0.6256 (0.5678)	loss 4.5168 (4.3096)	grad_norm 1.4022 (1.3857)	mem 17413MB
[2023-01-31 16:26:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][350/1251]	eta 0:08:30 lr 0.000864	time 0.5597 (0.5668)	loss 4.6408 (4.2994)	grad_norm 1.3765 (1.3824)	mem 17413MB
[2023-01-31 16:27:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][400/1251]	eta 0:08:01 lr 0.000866	time 0.5658 (0.5664)	loss 4.7750 (4.3138)	grad_norm 1.2591 (1.3819)	mem 17413MB
[2023-01-31 16:27:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][450/1251]	eta 0:07:33 lr 0.000868	time 0.5559 (0.5662)	loss 4.4782 (4.3331)	grad_norm 1.2476 (1.3769)	mem 17413MB
[2023-01-31 16:28:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][500/1251]	eta 0:07:04 lr 0.000870	time 0.5497 (0.5659)	loss 3.7161 (4.3426)	grad_norm 1.4909 (1.3798)	mem 17413MB
[2023-01-31 16:28:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][550/1251]	eta 0:06:36 lr 0.000872	time 0.5564 (0.5660)	loss 4.4154 (4.3468)	grad_norm 1.2480 (1.3771)	mem 17413MB
[2023-01-31 16:29:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][600/1251]	eta 0:06:08 lr 0.000874	time 0.5538 (0.5657)	loss 5.2278 (4.3511)	grad_norm 1.5180 (1.3769)	mem 17413MB
[2023-01-31 16:29:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][650/1251]	eta 0:05:39 lr 0.000876	time 0.5549 (0.5656)	loss 3.9298 (4.3564)	grad_norm 1.2725 (1.3777)	mem 17413MB
[2023-01-31 16:30:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][700/1251]	eta 0:05:11 lr 0.000878	time 0.5757 (0.5657)	loss 5.1180 (4.3546)	grad_norm 1.1902 (1.3742)	mem 17413MB
[2023-01-31 16:30:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][750/1251]	eta 0:04:43 lr 0.000880	time 0.5573 (0.5655)	loss 3.2645 (4.3622)	grad_norm 1.2750 (1.3755)	mem 17413MB
[2023-01-31 16:31:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][800/1251]	eta 0:04:15 lr 0.000882	time 0.5517 (0.5655)	loss 4.5392 (4.3584)	grad_norm 1.6005 (1.3751)	mem 17413MB
[2023-01-31 16:31:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][850/1251]	eta 0:03:46 lr 0.000884	time 0.5518 (0.5652)	loss 4.7922 (4.3565)	grad_norm 1.2478 (1.3740)	mem 17413MB
[2023-01-31 16:32:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][900/1251]	eta 0:03:18 lr 0.000886	time 0.6216 (0.5652)	loss 4.5052 (4.3558)	grad_norm 1.7065 (1.3734)	mem 17413MB
[2023-01-31 16:32:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][950/1251]	eta 0:02:50 lr 0.000888	time 0.5496 (0.5652)	loss 4.5552 (4.3588)	grad_norm 1.3116 (1.3718)	mem 17413MB
[2023-01-31 16:33:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][1000/1251]	eta 0:02:21 lr 0.000890	time 0.5514 (0.5651)	loss 4.7661 (4.3649)	grad_norm 1.3352 (1.3705)	mem 17413MB
[2023-01-31 16:33:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][1050/1251]	eta 0:01:53 lr 0.000892	time 0.5547 (0.5651)	loss 4.2418 (4.3664)	grad_norm 1.2178 (1.3704)	mem 17413MB
[2023-01-31 16:34:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][1100/1251]	eta 0:01:25 lr 0.000894	time 0.5575 (0.5652)	loss 4.6888 (4.3717)	grad_norm 1.2546 (1.3682)	mem 17413MB
[2023-01-31 16:34:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][1150/1251]	eta 0:00:57 lr 0.000896	time 0.5560 (0.5651)	loss 4.7019 (4.3716)	grad_norm 1.3215 (1.3692)	mem 17413MB
[2023-01-31 16:34:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][1200/1251]	eta 0:00:28 lr 0.000898	time 0.5618 (0.5650)	loss 4.9844 (4.3774)	grad_norm 1.2764 (1.3703)	mem 17413MB
[2023-01-31 16:35:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [17/300][1250/1251]	eta 0:00:00 lr 0.000900	time 0.5810 (0.5650)	loss 4.9097 (4.3810)	grad_norm 1.9379 (1.3700)	mem 17413MB
[2023-01-31 16:35:26 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 17 training takes 0:11:46
[2023-01-31 16:35:26 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_17.pth saving......
[2023-01-31 16:35:28 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_17.pth saved !!!
[2023-01-31 16:35:29 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.857 (0.857)	Loss 1.6761 (1.6761)	Acc@1 64.062 (64.062)	Acc@5 85.645 (85.645)	Mem 17413MB
[2023-01-31 16:35:37 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 62.546 Acc@5 85.336
[2023-01-31 16:35:37 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 62.5%
[2023-01-31 16:35:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.218 (1.218)	Loss 3.3255 (3.3255)	Acc@1 34.375 (34.375)	Acc@5 59.082 (59.082)	Mem 17413MB
[2023-01-31 16:35:46 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 32.110 Acc@5 57.592
[2023-01-31 16:35:46 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 32.1%
[2023-01-31 16:35:46 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 62.55% at 17 epoch
[2023-01-31 16:35:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][0/1251]	eta 0:38:12 lr 0.000900	time 1.8326 (1.8326)	loss 4.1914 (4.1914)	grad_norm 1.5521 (1.5521)	mem 17413MB
[2023-01-31 16:36:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][50/1251]	eta 0:11:47 lr 0.000902	time 0.5745 (0.5889)	loss 4.2496 (4.2093)	grad_norm 1.4279 (1.3739)	mem 17413MB
[2023-01-31 16:36:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][100/1251]	eta 0:11:05 lr 0.000904	time 0.5561 (0.5782)	loss 3.5513 (4.2623)	grad_norm 1.4960 (1.3892)	mem 17413MB
[2023-01-31 16:37:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][150/1251]	eta 0:10:31 lr 0.000906	time 0.5595 (0.5732)	loss 4.6613 (4.3356)	grad_norm 1.2174 (1.3678)	mem 17413MB
[2023-01-31 16:37:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][200/1251]	eta 0:10:00 lr 0.000908	time 0.5604 (0.5709)	loss 5.2207 (4.2906)	grad_norm 1.4750 (1.3661)	mem 17413MB
[2023-01-31 16:38:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][250/1251]	eta 0:09:29 lr 0.000910	time 0.5625 (0.5693)	loss 3.9403 (4.3073)	grad_norm 1.3386 (1.3551)	mem 17413MB
[2023-01-31 16:38:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][300/1251]	eta 0:09:01 lr 0.000912	time 0.5614 (0.5689)	loss 4.4247 (4.3165)	grad_norm 1.1496 (1.3488)	mem 17413MB
[2023-01-31 16:39:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][350/1251]	eta 0:08:31 lr 0.000914	time 0.5547 (0.5679)	loss 5.5494 (4.3175)	grad_norm 1.4688 (1.3451)	mem 17413MB
[2023-01-31 16:39:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][400/1251]	eta 0:08:02 lr 0.000916	time 0.5663 (0.5675)	loss 4.5641 (4.3058)	grad_norm 1.2543 (1.3379)	mem 17413MB
[2023-01-31 16:40:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][450/1251]	eta 0:07:34 lr 0.000918	time 0.5619 (0.5668)	loss 4.5182 (4.3133)	grad_norm 1.1689 (1.3363)	mem 17413MB
[2023-01-31 16:40:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][500/1251]	eta 0:07:05 lr 0.000920	time 0.5613 (0.5668)	loss 4.3427 (4.3187)	grad_norm 1.2250 (1.3427)	mem 17413MB
[2023-01-31 16:40:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][550/1251]	eta 0:06:37 lr 0.000922	time 0.5661 (0.5666)	loss 4.4945 (4.3078)	grad_norm 1.3121 (1.3436)	mem 17413MB
[2023-01-31 16:41:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][600/1251]	eta 0:06:08 lr 0.000924	time 0.5509 (0.5662)	loss 5.6296 (4.3038)	grad_norm 1.1979 (nan)	mem 17413MB
[2023-01-31 16:41:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][650/1251]	eta 0:05:40 lr 0.000926	time 0.5539 (0.5660)	loss 3.4253 (4.3045)	grad_norm 1.6072 (nan)	mem 17413MB
[2023-01-31 16:42:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][700/1251]	eta 0:05:11 lr 0.000928	time 0.5541 (0.5660)	loss 4.8385 (4.3020)	grad_norm 1.2191 (nan)	mem 17413MB
[2023-01-31 16:42:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][750/1251]	eta 0:04:43 lr 0.000930	time 0.5560 (0.5657)	loss 3.5957 (4.3090)	grad_norm 1.1350 (nan)	mem 17413MB
[2023-01-31 16:43:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][800/1251]	eta 0:04:15 lr 0.000932	time 0.5537 (0.5655)	loss 4.3990 (4.3079)	grad_norm 1.3243 (nan)	mem 17413MB
[2023-01-31 16:43:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][850/1251]	eta 0:03:46 lr 0.000934	time 0.5552 (0.5654)	loss 4.6622 (4.3084)	grad_norm 1.2586 (nan)	mem 17413MB
[2023-01-31 16:44:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][900/1251]	eta 0:03:18 lr 0.000936	time 0.5530 (0.5654)	loss 4.9796 (4.2993)	grad_norm 1.4514 (nan)	mem 17413MB
[2023-01-31 16:44:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][950/1251]	eta 0:02:50 lr 0.000938	time 0.5582 (0.5652)	loss 4.6110 (4.3021)	grad_norm 1.4051 (nan)	mem 17413MB
[2023-01-31 16:45:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][1000/1251]	eta 0:02:21 lr 0.000940	time 0.5578 (0.5652)	loss 4.4686 (4.3002)	grad_norm 1.3403 (nan)	mem 17413MB
[2023-01-31 16:45:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][1050/1251]	eta 0:01:53 lr 0.000942	time 0.5588 (0.5651)	loss 4.1241 (4.3023)	grad_norm 1.4669 (nan)	mem 17413MB
[2023-01-31 16:46:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][1100/1251]	eta 0:01:25 lr 0.000944	time 0.5527 (0.5650)	loss 4.8861 (4.3115)	grad_norm 1.1631 (nan)	mem 17413MB
[2023-01-31 16:46:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][1150/1251]	eta 0:00:57 lr 0.000946	time 0.5580 (0.5650)	loss 4.2179 (4.3114)	grad_norm 1.3623 (nan)	mem 17413MB
[2023-01-31 16:47:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][1200/1251]	eta 0:00:28 lr 0.000948	time 0.5596 (0.5648)	loss 5.1564 (4.3158)	grad_norm 1.2464 (nan)	mem 17413MB
[2023-01-31 16:47:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [18/300][1250/1251]	eta 0:00:00 lr 0.000950	time 0.5490 (0.5647)	loss 3.9291 (4.3134)	grad_norm 1.1809 (nan)	mem 17413MB
[2023-01-31 16:47:32 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 18 training takes 0:11:46
[2023-01-31 16:47:33 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_18.pth saving......
[2023-01-31 16:47:34 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_18.pth saved !!!
[2023-01-31 16:47:35 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.878 (0.878)	Loss 1.5672 (1.5672)	Acc@1 63.965 (63.965)	Acc@5 86.133 (86.133)	Mem 17413MB
[2023-01-31 16:47:43 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 63.392 Acc@5 85.928
[2023-01-31 16:47:43 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 63.4%
[2023-01-31 16:47:44 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.259 (1.259)	Loss 3.0203 (3.0203)	Acc@1 35.840 (35.840)	Acc@5 63.965 (63.965)	Mem 17413MB
[2023-01-31 16:47:52 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 38.894 Acc@5 64.862
[2023-01-31 16:47:52 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 38.9%
[2023-01-31 16:47:52 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 63.39% at 18 epoch
[2023-01-31 16:47:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][0/1251]	eta 0:34:20 lr 0.000950	time 1.6467 (1.6467)	loss 4.5459 (4.5459)	grad_norm 1.6130 (1.6130)	mem 17413MB
[2023-01-31 16:48:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][50/1251]	eta 0:11:46 lr 0.000952	time 0.5652 (0.5879)	loss 4.1694 (4.1825)	grad_norm 1.2290 (1.3503)	mem 17413MB
[2023-01-31 16:48:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][100/1251]	eta 0:11:03 lr 0.000954	time 0.5571 (0.5764)	loss 4.3332 (4.2769)	grad_norm 1.2420 (1.3389)	mem 17413MB
[2023-01-31 16:49:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][150/1251]	eta 0:10:28 lr 0.000956	time 0.5536 (0.5713)	loss 4.1495 (4.2897)	grad_norm 1.3436 (1.3200)	mem 17413MB
[2023-01-31 16:49:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][200/1251]	eta 0:09:58 lr 0.000958	time 0.5623 (0.5691)	loss 3.2454 (4.3128)	grad_norm 1.4056 (1.3182)	mem 17413MB
[2023-01-31 16:50:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][250/1251]	eta 0:09:28 lr 0.000960	time 0.5498 (0.5682)	loss 3.8906 (4.3203)	grad_norm 1.2001 (1.3157)	mem 17413MB
[2023-01-31 16:50:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][300/1251]	eta 0:08:59 lr 0.000962	time 0.6473 (0.5676)	loss 3.5443 (4.3099)	grad_norm 1.5826 (1.3183)	mem 17413MB
[2023-01-31 16:51:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][350/1251]	eta 0:08:30 lr 0.000964	time 0.5556 (0.5670)	loss 4.3598 (4.3165)	grad_norm 1.2128 (1.3185)	mem 17413MB
[2023-01-31 16:51:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][400/1251]	eta 0:08:02 lr 0.000966	time 0.6411 (0.5665)	loss 3.4525 (4.3205)	grad_norm 1.2781 (1.3188)	mem 17413MB
[2023-01-31 16:52:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][450/1251]	eta 0:07:33 lr 0.000968	time 0.5659 (0.5660)	loss 4.4894 (4.3160)	grad_norm 1.4110 (1.3194)	mem 17413MB
[2023-01-31 16:52:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][500/1251]	eta 0:07:04 lr 0.000970	time 0.5567 (0.5657)	loss 4.6424 (4.3159)	grad_norm 1.1760 (1.3162)	mem 17413MB
[2023-01-31 16:53:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][550/1251]	eta 0:06:36 lr 0.000972	time 0.5588 (0.5655)	loss 3.7598 (4.3142)	grad_norm 1.3363 (1.3210)	mem 17413MB
[2023-01-31 16:53:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][600/1251]	eta 0:06:07 lr 0.000974	time 0.5525 (0.5653)	loss 4.1048 (4.3128)	grad_norm 1.4668 (1.3224)	mem 17413MB
[2023-01-31 16:54:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][650/1251]	eta 0:05:39 lr 0.000976	time 0.5555 (0.5652)	loss 4.9110 (4.3108)	grad_norm 1.2700 (1.3229)	mem 17413MB
[2023-01-31 16:54:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][700/1251]	eta 0:05:11 lr 0.000978	time 0.5588 (0.5649)	loss 4.6779 (4.2961)	grad_norm 1.1674 (1.3204)	mem 17413MB
[2023-01-31 16:54:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][750/1251]	eta 0:04:42 lr 0.000980	time 0.5527 (0.5648)	loss 4.1481 (4.2999)	grad_norm 1.2019 (1.3188)	mem 17413MB
[2023-01-31 16:55:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][800/1251]	eta 0:04:14 lr 0.000982	time 0.5582 (0.5647)	loss 4.3559 (4.3041)	grad_norm 1.3546 (1.3206)	mem 17413MB
[2023-01-31 16:55:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][850/1251]	eta 0:03:46 lr 0.000984	time 0.5558 (0.5647)	loss 5.3232 (4.3060)	grad_norm 1.1275 (1.3185)	mem 17413MB
[2023-01-31 16:56:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][900/1251]	eta 0:03:18 lr 0.000986	time 0.5521 (0.5646)	loss 4.1217 (4.3142)	grad_norm 1.3393 (1.3176)	mem 17413MB
[2023-01-31 16:56:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][950/1251]	eta 0:02:49 lr 0.000988	time 0.5497 (0.5645)	loss 5.2471 (4.3146)	grad_norm 1.1524 (1.3170)	mem 17413MB
[2023-01-31 16:57:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][1000/1251]	eta 0:02:21 lr 0.000990	time 0.6082 (0.5646)	loss 4.4160 (4.3242)	grad_norm 1.2763 (1.3134)	mem 17413MB
[2023-01-31 16:57:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][1050/1251]	eta 0:01:53 lr 0.000992	time 0.5626 (0.5645)	loss 4.8821 (4.3175)	grad_norm 1.2843 (1.3152)	mem 17413MB
[2023-01-31 16:58:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][1100/1251]	eta 0:01:25 lr 0.000994	time 0.5517 (0.5646)	loss 4.5748 (4.3163)	grad_norm 1.6664 (1.3152)	mem 17413MB
[2023-01-31 16:58:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][1150/1251]	eta 0:00:57 lr 0.000996	time 0.5611 (0.5646)	loss 4.4026 (4.3122)	grad_norm 1.4444 (1.3172)	mem 17413MB
[2023-01-31 16:59:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][1200/1251]	eta 0:00:28 lr 0.000998	time 0.6157 (0.5646)	loss 5.0528 (4.3135)	grad_norm 1.6000 (1.3157)	mem 17413MB
[2023-01-31 16:59:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [19/300][1250/1251]	eta 0:00:00 lr 0.001000	time 0.5513 (0.5645)	loss 4.6078 (4.3153)	grad_norm 1.7210 (1.3137)	mem 17413MB
[2023-01-31 16:59:39 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 19 training takes 0:11:46
[2023-01-31 16:59:39 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_19.pth saving......
[2023-01-31 16:59:41 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_19.pth saved !!!
[2023-01-31 16:59:41 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.886 (0.886)	Loss 1.5154 (1.5154)	Acc@1 64.941 (64.941)	Acc@5 86.035 (86.035)	Mem 17413MB
[2023-01-31 16:59:49 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 64.198 Acc@5 86.792
[2023-01-31 16:59:49 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 64.2%
[2023-01-31 16:59:51 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.342 (1.342)	Loss 2.5561 (2.5561)	Acc@1 45.215 (45.215)	Acc@5 71.777 (71.777)	Mem 17413MB
[2023-01-31 16:59:59 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 44.676 Acc@5 70.678
[2023-01-31 16:59:59 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 44.7%
[2023-01-31 16:59:59 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 64.20% at 19 epoch
[2023-01-31 17:00:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][0/1251]	eta 0:34:47 lr 0.000989	time 1.6684 (1.6684)	loss 4.1895 (4.1895)	grad_norm 1.2645 (1.2645)	mem 17413MB
[2023-01-31 17:00:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][50/1251]	eta 0:11:41 lr 0.000989	time 0.5606 (0.5841)	loss 3.3084 (4.2168)	grad_norm 1.2652 (1.3015)	mem 17413MB
[2023-01-31 17:00:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][100/1251]	eta 0:11:03 lr 0.000989	time 0.5578 (0.5764)	loss 4.2138 (4.2188)	grad_norm 1.4424 (1.3094)	mem 17413MB
[2023-01-31 17:01:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][150/1251]	eta 0:10:29 lr 0.000989	time 0.5835 (0.5715)	loss 4.1031 (4.2244)	grad_norm 1.1232 (1.3103)	mem 17413MB
[2023-01-31 17:01:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][200/1251]	eta 0:09:58 lr 0.000989	time 0.5574 (0.5696)	loss 4.1595 (4.2512)	grad_norm 1.3380 (1.3026)	mem 17413MB
[2023-01-31 17:02:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][250/1251]	eta 0:09:29 lr 0.000989	time 0.6281 (0.5689)	loss 4.2304 (4.2584)	grad_norm 1.1250 (1.2929)	mem 17413MB
[2023-01-31 17:02:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][300/1251]	eta 0:09:00 lr 0.000989	time 0.5622 (0.5681)	loss 3.0274 (4.2575)	grad_norm 1.2998 (1.2911)	mem 17413MB
[2023-01-31 17:03:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][350/1251]	eta 0:08:31 lr 0.000989	time 0.5555 (0.5675)	loss 4.7017 (4.2597)	grad_norm 1.2986 (1.2987)	mem 17413MB
[2023-01-31 17:03:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][400/1251]	eta 0:08:02 lr 0.000989	time 0.5538 (0.5670)	loss 4.6478 (4.2508)	grad_norm 1.3342 (1.2999)	mem 17413MB
[2023-01-31 17:04:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][450/1251]	eta 0:07:33 lr 0.000989	time 0.5615 (0.5664)	loss 4.9953 (4.2516)	grad_norm 1.2445 (1.2978)	mem 17413MB
[2023-01-31 17:04:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][500/1251]	eta 0:07:05 lr 0.000989	time 0.5627 (0.5664)	loss 4.4878 (4.2395)	grad_norm 1.3401 (1.2929)	mem 17413MB
[2023-01-31 17:05:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][550/1251]	eta 0:06:36 lr 0.000989	time 0.5549 (0.5661)	loss 3.8351 (4.2322)	grad_norm 1.2666 (1.2914)	mem 17413MB
[2023-01-31 17:05:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][600/1251]	eta 0:06:08 lr 0.000989	time 0.5555 (0.5660)	loss 4.1927 (4.2387)	grad_norm 1.3619 (nan)	mem 17413MB
[2023-01-31 17:06:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][650/1251]	eta 0:05:40 lr 0.000989	time 0.6295 (0.5661)	loss 4.8263 (4.2321)	grad_norm 1.2204 (nan)	mem 17413MB
[2023-01-31 17:06:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][700/1251]	eta 0:05:11 lr 0.000989	time 0.5573 (0.5657)	loss 4.9064 (4.2329)	grad_norm 1.2238 (nan)	mem 17413MB
[2023-01-31 17:07:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][750/1251]	eta 0:04:43 lr 0.000989	time 0.5603 (0.5657)	loss 4.9751 (4.2334)	grad_norm 1.3617 (nan)	mem 17413MB
[2023-01-31 17:07:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][800/1251]	eta 0:04:15 lr 0.000988	time 0.5586 (0.5656)	loss 4.2385 (4.2341)	grad_norm 1.2158 (nan)	mem 17413MB
[2023-01-31 17:08:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][850/1251]	eta 0:03:46 lr 0.000988	time 0.5508 (0.5655)	loss 4.5440 (4.2433)	grad_norm 1.4662 (nan)	mem 17413MB
[2023-01-31 17:08:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][900/1251]	eta 0:03:18 lr 0.000988	time 0.5572 (0.5655)	loss 4.5575 (4.2290)	grad_norm 1.3505 (nan)	mem 17413MB
[2023-01-31 17:08:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][950/1251]	eta 0:02:50 lr 0.000988	time 0.5587 (0.5653)	loss 4.2373 (4.2268)	grad_norm 1.2923 (nan)	mem 17413MB
[2023-01-31 17:09:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][1000/1251]	eta 0:02:21 lr 0.000988	time 0.5584 (0.5654)	loss 4.6211 (4.2177)	grad_norm 1.2796 (nan)	mem 17413MB
[2023-01-31 17:09:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][1050/1251]	eta 0:01:53 lr 0.000988	time 0.6221 (0.5654)	loss 4.6903 (4.2148)	grad_norm 1.1866 (nan)	mem 17413MB
[2023-01-31 17:10:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][1100/1251]	eta 0:01:25 lr 0.000988	time 0.5601 (0.5653)	loss 4.2366 (4.2149)	grad_norm 1.2021 (nan)	mem 17413MB
[2023-01-31 17:10:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][1150/1251]	eta 0:00:57 lr 0.000988	time 0.5539 (0.5653)	loss 5.2706 (4.2137)	grad_norm 1.1980 (nan)	mem 17413MB
[2023-01-31 17:11:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][1200/1251]	eta 0:00:28 lr 0.000988	time 0.5629 (0.5652)	loss 4.0233 (4.2148)	grad_norm 1.2570 (nan)	mem 17413MB
[2023-01-31 17:11:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [20/300][1250/1251]	eta 0:00:00 lr 0.000988	time 0.5520 (0.5651)	loss 4.5492 (4.2174)	grad_norm 1.2212 (nan)	mem 17413MB
[2023-01-31 17:11:46 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 20 training takes 0:11:47
[2023-01-31 17:11:46 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_20.pth saving......
[2023-01-31 17:11:48 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_20.pth saved !!!
[2023-01-31 17:11:49 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.849 (0.849)	Loss 1.5197 (1.5197)	Acc@1 65.723 (65.723)	Acc@5 86.914 (86.914)	Mem 17413MB
[2023-01-31 17:11:56 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 64.832 Acc@5 87.144
[2023-01-31 17:11:56 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 64.8%
[2023-01-31 17:11:58 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.301 (1.301)	Loss 2.2861 (2.2861)	Acc@1 48.926 (48.926)	Acc@5 76.270 (76.270)	Mem 17413MB
[2023-01-31 17:12:06 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 49.758 Acc@5 75.266
[2023-01-31 17:12:06 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 49.8%
[2023-01-31 17:12:06 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 64.83% at 20 epoch
[2023-01-31 17:12:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][0/1251]	eta 0:36:29 lr 0.000988	time 1.7499 (1.7499)	loss 3.8356 (3.8356)	grad_norm 1.2513 (1.2513)	mem 17413MB
[2023-01-31 17:12:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][50/1251]	eta 0:11:47 lr 0.000988	time 0.5582 (0.5887)	loss 4.5966 (4.2990)	grad_norm 1.2702 (1.2845)	mem 17413MB
[2023-01-31 17:13:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][100/1251]	eta 0:11:02 lr 0.000988	time 0.5559 (0.5754)	loss 4.3117 (4.2969)	grad_norm 1.2211 (1.2697)	mem 17413MB
[2023-01-31 17:13:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][150/1251]	eta 0:10:29 lr 0.000988	time 0.5596 (0.5715)	loss 4.4780 (4.2931)	grad_norm 1.1550 (1.2746)	mem 17413MB
[2023-01-31 17:14:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][200/1251]	eta 0:09:58 lr 0.000988	time 0.5671 (0.5696)	loss 4.4838 (4.2808)	grad_norm 1.1977 (1.2795)	mem 17413MB
[2023-01-31 17:14:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][250/1251]	eta 0:09:28 lr 0.000988	time 0.5585 (0.5679)	loss 4.4417 (4.2504)	grad_norm 1.5650 (1.2844)	mem 17413MB
[2023-01-31 17:14:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][300/1251]	eta 0:08:59 lr 0.000988	time 0.5541 (0.5669)	loss 4.1454 (4.2691)	grad_norm 1.3974 (1.2871)	mem 17413MB
[2023-01-31 17:15:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][350/1251]	eta 0:08:30 lr 0.000988	time 0.5472 (0.5668)	loss 3.8982 (4.2424)	grad_norm 1.1317 (1.2865)	mem 17413MB
[2023-01-31 17:15:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][400/1251]	eta 0:08:01 lr 0.000988	time 0.5663 (0.5662)	loss 3.5184 (4.2380)	grad_norm 1.1700 (1.2845)	mem 17413MB
[2023-01-31 17:16:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][450/1251]	eta 0:07:33 lr 0.000988	time 0.5522 (0.5661)	loss 4.5532 (4.2482)	grad_norm 1.1367 (1.2876)	mem 17413MB
[2023-01-31 17:16:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][500/1251]	eta 0:07:04 lr 0.000988	time 0.5561 (0.5654)	loss 4.6035 (4.2369)	grad_norm 1.2714 (1.2813)	mem 17413MB
[2023-01-31 17:17:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][550/1251]	eta 0:06:36 lr 0.000988	time 0.5521 (0.5654)	loss 3.7653 (4.2390)	grad_norm 1.1811 (1.2815)	mem 17413MB
[2023-01-31 17:17:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][600/1251]	eta 0:06:07 lr 0.000988	time 0.5587 (0.5652)	loss 4.7978 (4.2374)	grad_norm 1.2100 (1.2800)	mem 17413MB
[2023-01-31 17:18:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][650/1251]	eta 0:05:39 lr 0.000987	time 0.5535 (0.5651)	loss 4.6370 (4.2337)	grad_norm 1.3744 (1.2799)	mem 17413MB
[2023-01-31 17:18:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][700/1251]	eta 0:05:11 lr 0.000987	time 0.5550 (0.5648)	loss 3.6545 (4.2344)	grad_norm 1.1505 (1.2763)	mem 17413MB
[2023-01-31 17:19:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][750/1251]	eta 0:04:43 lr 0.000987	time 0.5599 (0.5650)	loss 4.6142 (4.2279)	grad_norm 1.0584 (1.2766)	mem 17413MB
[2023-01-31 17:19:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][800/1251]	eta 0:04:14 lr 0.000987	time 0.5577 (0.5647)	loss 3.1280 (4.2266)	grad_norm 1.2293 (1.2768)	mem 17413MB
[2023-01-31 17:20:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][850/1251]	eta 0:03:46 lr 0.000987	time 0.5626 (0.5648)	loss 4.0993 (4.2343)	grad_norm 1.2887 (1.2742)	mem 17413MB
[2023-01-31 17:20:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][900/1251]	eta 0:03:18 lr 0.000987	time 0.5613 (0.5645)	loss 3.6441 (4.2338)	grad_norm 1.3258 (1.2742)	mem 17413MB
[2023-01-31 17:21:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][950/1251]	eta 0:02:49 lr 0.000987	time 0.5534 (0.5645)	loss 2.9352 (4.2288)	grad_norm 1.1777 (1.2720)	mem 17413MB
[2023-01-31 17:21:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][1000/1251]	eta 0:02:21 lr 0.000987	time 0.5531 (0.5644)	loss 4.5459 (4.2274)	grad_norm 1.0818 (1.2722)	mem 17413MB
[2023-01-31 17:21:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][1050/1251]	eta 0:01:53 lr 0.000987	time 0.5578 (0.5645)	loss 5.0306 (4.2243)	grad_norm 1.1198 (1.2708)	mem 17413MB
[2023-01-31 17:22:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][1100/1251]	eta 0:01:25 lr 0.000987	time 0.5531 (0.5644)	loss 5.0340 (4.2208)	grad_norm 1.3866 (1.2701)	mem 17413MB
[2023-01-31 17:22:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][1150/1251]	eta 0:00:57 lr 0.000987	time 0.6214 (0.5645)	loss 3.7419 (4.2213)	grad_norm 1.4173 (1.2727)	mem 17413MB
[2023-01-31 17:23:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][1200/1251]	eta 0:00:28 lr 0.000987	time 0.5593 (0.5644)	loss 3.8360 (4.2159)	grad_norm 1.3323 (1.2706)	mem 17413MB
[2023-01-31 17:23:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [21/300][1250/1251]	eta 0:00:00 lr 0.000987	time 0.6114 (0.5643)	loss 3.4131 (4.2142)	grad_norm 1.1395 (1.2702)	mem 17413MB
[2023-01-31 17:23:52 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 21 training takes 0:11:46
[2023-01-31 17:23:52 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_21.pth saving......
[2023-01-31 17:23:54 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_21.pth saved !!!
[2023-01-31 17:23:55 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.873 (0.873)	Loss 1.4556 (1.4556)	Acc@1 66.699 (66.699)	Acc@5 88.379 (88.379)	Mem 17413MB
[2023-01-31 17:24:02 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 66.068 Acc@5 87.760
[2023-01-31 17:24:02 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 66.1%
[2023-01-31 17:24:04 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.165 (1.165)	Loss 2.1201 (2.1201)	Acc@1 52.930 (52.930)	Acc@5 79.883 (79.883)	Mem 17413MB
[2023-01-31 17:24:12 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 53.682 Acc@5 78.554
[2023-01-31 17:24:12 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 53.7%
[2023-01-31 17:24:12 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 66.07% at 21 epoch
[2023-01-31 17:24:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][0/1251]	eta 0:35:45 lr 0.000987	time 1.7152 (1.7152)	loss 5.0476 (5.0476)	grad_norm 1.2611 (1.2611)	mem 17413MB
[2023-01-31 17:24:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][50/1251]	eta 0:11:45 lr 0.000987	time 0.5610 (0.5873)	loss 3.4622 (4.2581)	grad_norm 1.4071 (1.2842)	mem 17413MB
[2023-01-31 17:25:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][100/1251]	eta 0:11:02 lr 0.000987	time 0.5514 (0.5753)	loss 4.7009 (4.1779)	grad_norm 1.3074 (1.2706)	mem 17413MB
[2023-01-31 17:25:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][150/1251]	eta 0:10:29 lr 0.000987	time 0.5539 (0.5720)	loss 3.2372 (4.2016)	grad_norm 1.1669 (1.2642)	mem 17413MB
[2023-01-31 17:26:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][200/1251]	eta 0:09:58 lr 0.000987	time 0.6385 (0.5696)	loss 4.3403 (4.1879)	grad_norm 1.1611 (nan)	mem 17413MB
[2023-01-31 17:26:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][250/1251]	eta 0:09:28 lr 0.000987	time 0.5534 (0.5684)	loss 4.3672 (4.1781)	grad_norm 1.3185 (nan)	mem 17413MB
[2023-01-31 17:27:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][300/1251]	eta 0:08:59 lr 0.000987	time 0.5493 (0.5677)	loss 4.1580 (4.1922)	grad_norm 1.2063 (nan)	mem 17413MB
[2023-01-31 17:27:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][350/1251]	eta 0:08:30 lr 0.000987	time 0.5787 (0.5669)	loss 3.7923 (4.1990)	grad_norm 1.2800 (nan)	mem 17413MB
[2023-01-31 17:27:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][400/1251]	eta 0:08:02 lr 0.000987	time 0.5619 (0.5664)	loss 4.8155 (4.1945)	grad_norm 1.2088 (nan)	mem 17413MB
[2023-01-31 17:28:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][450/1251]	eta 0:07:33 lr 0.000986	time 0.5580 (0.5663)	loss 4.3720 (4.1973)	grad_norm 1.1338 (nan)	mem 17413MB
[2023-01-31 17:28:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][500/1251]	eta 0:07:05 lr 0.000986	time 0.5542 (0.5660)	loss 4.6161 (4.1894)	grad_norm 1.2060 (nan)	mem 17413MB
[2023-01-31 17:29:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][550/1251]	eta 0:06:36 lr 0.000986	time 0.5609 (0.5660)	loss 3.1973 (4.1747)	grad_norm 1.2077 (nan)	mem 17413MB
[2023-01-31 17:29:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][600/1251]	eta 0:06:08 lr 0.000986	time 0.6236 (0.5657)	loss 4.1896 (4.1782)	grad_norm 1.1860 (nan)	mem 17413MB
[2023-01-31 17:30:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][650/1251]	eta 0:05:39 lr 0.000986	time 0.5582 (0.5656)	loss 4.6682 (4.1753)	grad_norm 1.2025 (nan)	mem 17413MB
[2023-01-31 17:30:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][700/1251]	eta 0:05:11 lr 0.000986	time 0.5579 (0.5654)	loss 4.3246 (4.1666)	grad_norm 1.1811 (nan)	mem 17413MB
[2023-01-31 17:31:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][750/1251]	eta 0:04:43 lr 0.000986	time 0.5582 (0.5654)	loss 2.6029 (4.1707)	grad_norm 1.1593 (nan)	mem 17413MB
[2023-01-31 17:31:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][800/1251]	eta 0:04:14 lr 0.000986	time 0.5663 (0.5653)	loss 4.3697 (4.1714)	grad_norm 1.3331 (nan)	mem 17413MB
[2023-01-31 17:32:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][850/1251]	eta 0:03:46 lr 0.000986	time 0.6085 (0.5654)	loss 4.1987 (4.1673)	grad_norm 1.1461 (nan)	mem 17413MB
[2023-01-31 17:32:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][900/1251]	eta 0:03:18 lr 0.000986	time 0.5613 (0.5652)	loss 4.8169 (4.1625)	grad_norm 1.3938 (nan)	mem 17413MB
[2023-01-31 17:33:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][950/1251]	eta 0:02:50 lr 0.000986	time 0.5568 (0.5651)	loss 4.1741 (4.1591)	grad_norm 1.1502 (nan)	mem 17413MB
[2023-01-31 17:33:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][1000/1251]	eta 0:02:21 lr 0.000986	time 0.6283 (0.5651)	loss 4.4419 (4.1601)	grad_norm 1.3345 (nan)	mem 17413MB
[2023-01-31 17:34:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][1050/1251]	eta 0:01:53 lr 0.000986	time 0.5611 (0.5650)	loss 4.6844 (4.1591)	grad_norm 1.4076 (nan)	mem 17413MB
[2023-01-31 17:34:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][1100/1251]	eta 0:01:25 lr 0.000986	time 0.5533 (0.5651)	loss 4.9665 (4.1651)	grad_norm 1.5030 (nan)	mem 17413MB
[2023-01-31 17:35:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][1150/1251]	eta 0:00:57 lr 0.000986	time 0.5625 (0.5649)	loss 4.3515 (4.1637)	grad_norm 1.3250 (nan)	mem 17413MB
[2023-01-31 17:35:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][1200/1251]	eta 0:00:28 lr 0.000986	time 0.6207 (0.5650)	loss 3.9644 (4.1651)	grad_norm 1.4386 (nan)	mem 17413MB
[2023-01-31 17:35:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [22/300][1250/1251]	eta 0:00:00 lr 0.000986	time 0.5521 (0.5650)	loss 4.3949 (4.1619)	grad_norm 1.2155 (nan)	mem 17413MB
[2023-01-31 17:35:59 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 22 training takes 0:11:46
[2023-01-31 17:35:59 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_22.pth saving......
[2023-01-31 17:36:00 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_22.pth saved !!!
[2023-01-31 17:36:01 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.860 (0.860)	Loss 1.4759 (1.4759)	Acc@1 66.113 (66.113)	Acc@5 87.793 (87.793)	Mem 17413MB
[2023-01-31 17:36:09 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 66.810 Acc@5 88.378
[2023-01-31 17:36:09 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 66.8%
[2023-01-31 17:36:10 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.211 (1.211)	Loss 2.0240 (2.0240)	Acc@1 55.371 (55.371)	Acc@5 80.469 (80.469)	Mem 17413MB
[2023-01-31 17:36:18 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 56.800 Acc@5 81.014
[2023-01-31 17:36:18 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 56.8%
[2023-01-31 17:36:18 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 66.81% at 22 epoch
[2023-01-31 17:36:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][0/1251]	eta 0:35:42 lr 0.000986	time 1.7128 (1.7128)	loss 3.3282 (3.3282)	grad_norm 1.2369 (1.2369)	mem 17413MB
[2023-01-31 17:36:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][50/1251]	eta 0:11:45 lr 0.000986	time 0.6199 (0.5870)	loss 4.5190 (4.0657)	grad_norm 1.2723 (1.2463)	mem 17413MB
[2023-01-31 17:37:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][100/1251]	eta 0:11:02 lr 0.000986	time 0.6151 (0.5756)	loss 3.9112 (4.1399)	grad_norm 1.2674 (1.2607)	mem 17413MB
[2023-01-31 17:37:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][150/1251]	eta 0:10:27 lr 0.000986	time 0.5572 (0.5704)	loss 3.3313 (4.0579)	grad_norm 1.7293 (1.2605)	mem 17413MB
[2023-01-31 17:38:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][200/1251]	eta 0:09:58 lr 0.000986	time 0.5469 (0.5690)	loss 3.8589 (4.0676)	grad_norm 1.1824 (1.2574)	mem 17413MB
[2023-01-31 17:38:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][250/1251]	eta 0:09:28 lr 0.000985	time 0.5568 (0.5680)	loss 4.3126 (4.0699)	grad_norm 1.1983 (1.2579)	mem 17413MB
[2023-01-31 17:39:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][300/1251]	eta 0:08:59 lr 0.000985	time 0.5511 (0.5673)	loss 3.6651 (4.0747)	grad_norm 1.3179 (1.2614)	mem 17413MB
[2023-01-31 17:39:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][350/1251]	eta 0:08:30 lr 0.000985	time 0.5574 (0.5667)	loss 3.0474 (4.0899)	grad_norm 1.1275 (1.2619)	mem 17413MB
[2023-01-31 17:40:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][400/1251]	eta 0:08:01 lr 0.000985	time 0.5606 (0.5661)	loss 4.6245 (4.1039)	grad_norm 1.1405 (1.2573)	mem 17413MB
[2023-01-31 17:40:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][450/1251]	eta 0:07:33 lr 0.000985	time 0.5550 (0.5656)	loss 3.3887 (4.0964)	grad_norm 1.2187 (1.2560)	mem 17413MB
[2023-01-31 17:41:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][500/1251]	eta 0:07:04 lr 0.000985	time 0.6186 (0.5655)	loss 4.2544 (4.0975)	grad_norm 1.1020 (1.2523)	mem 17413MB
[2023-01-31 17:41:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][550/1251]	eta 0:06:35 lr 0.000985	time 0.5589 (0.5649)	loss 3.3648 (4.1110)	grad_norm 1.2206 (1.2536)	mem 17413MB
[2023-01-31 17:41:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][600/1251]	eta 0:06:07 lr 0.000985	time 0.5614 (0.5650)	loss 4.9461 (4.1243)	grad_norm 1.3376 (1.2542)	mem 17413MB
[2023-01-31 17:42:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][650/1251]	eta 0:05:39 lr 0.000985	time 0.5632 (0.5648)	loss 4.8730 (4.1220)	grad_norm 1.3208 (1.2522)	mem 17413MB
[2023-01-31 17:42:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][700/1251]	eta 0:05:11 lr 0.000985	time 0.5545 (0.5647)	loss 4.4755 (4.1197)	grad_norm 1.2533 (1.2539)	mem 17413MB
[2023-01-31 17:43:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][750/1251]	eta 0:04:42 lr 0.000985	time 0.5600 (0.5646)	loss 4.1762 (4.1250)	grad_norm 1.2379 (1.2534)	mem 17413MB
[2023-01-31 17:43:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][800/1251]	eta 0:04:14 lr 0.000985	time 0.5574 (0.5645)	loss 4.4812 (4.1210)	grad_norm 1.2409 (1.2549)	mem 17413MB
[2023-01-31 17:44:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][850/1251]	eta 0:03:46 lr 0.000985	time 0.5608 (0.5644)	loss 3.2929 (4.1116)	grad_norm 1.3908 (1.2517)	mem 17413MB
[2023-01-31 17:44:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][900/1251]	eta 0:03:18 lr 0.000985	time 0.6226 (0.5645)	loss 4.3328 (4.1173)	grad_norm 1.1090 (1.2498)	mem 17413MB
[2023-01-31 17:45:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][950/1251]	eta 0:02:49 lr 0.000985	time 0.5530 (0.5642)	loss 4.6849 (4.1209)	grad_norm 1.2946 (1.2478)	mem 17413MB
[2023-01-31 17:45:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][1000/1251]	eta 0:02:21 lr 0.000985	time 0.5533 (0.5644)	loss 3.1545 (4.1145)	grad_norm 1.1352 (1.2469)	mem 17413MB
[2023-01-31 17:46:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][1050/1251]	eta 0:01:53 lr 0.000985	time 0.5627 (0.5643)	loss 4.7501 (4.1151)	grad_norm 1.2196 (1.2470)	mem 17413MB
[2023-01-31 17:46:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][1100/1251]	eta 0:01:25 lr 0.000985	time 0.5703 (0.5642)	loss 5.3351 (4.1187)	grad_norm 1.2359 (nan)	mem 17413MB
[2023-01-31 17:47:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][1150/1251]	eta 0:00:56 lr 0.000985	time 0.5547 (0.5642)	loss 3.7867 (4.1111)	grad_norm 1.1115 (nan)	mem 17413MB
[2023-01-31 17:47:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][1200/1251]	eta 0:00:28 lr 0.000985	time 0.5568 (0.5642)	loss 3.0269 (4.1148)	grad_norm 1.3525 (nan)	mem 17413MB
[2023-01-31 17:48:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [23/300][1250/1251]	eta 0:00:00 lr 0.000984	time 0.5501 (0.5642)	loss 3.4296 (4.1153)	grad_norm 1.2330 (nan)	mem 17413MB
[2023-01-31 17:48:04 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 23 training takes 0:11:45
[2023-01-31 17:48:04 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_23.pth saving......
[2023-01-31 17:48:06 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_23.pth saved !!!
[2023-01-31 17:48:07 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.878 (0.878)	Loss 1.3530 (1.3530)	Acc@1 67.871 (67.871)	Acc@5 89.355 (89.355)	Mem 17413MB
[2023-01-31 17:48:15 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 67.302 Acc@5 88.494
[2023-01-31 17:48:15 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 67.3%
[2023-01-31 17:48:16 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.262 (1.262)	Loss 1.7633 (1.7633)	Acc@1 59.277 (59.277)	Acc@5 83.008 (83.008)	Mem 17413MB
[2023-01-31 17:48:24 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 59.478 Acc@5 82.976
[2023-01-31 17:48:24 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 59.5%
[2023-01-31 17:48:24 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 67.30% at 23 epoch
[2023-01-31 17:48:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][0/1251]	eta 0:35:14 lr 0.000984	time 1.6899 (1.6899)	loss 4.5085 (4.5085)	grad_norm 1.3458 (1.3458)	mem 17413MB
[2023-01-31 17:48:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][50/1251]	eta 0:11:49 lr 0.000984	time 0.5591 (0.5907)	loss 4.7409 (4.1456)	grad_norm 1.1630 (1.2494)	mem 17413MB
[2023-01-31 17:49:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][100/1251]	eta 0:11:02 lr 0.000984	time 0.5640 (0.5755)	loss 4.7784 (4.1422)	grad_norm 1.2085 (1.2721)	mem 17413MB
[2023-01-31 17:49:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][150/1251]	eta 0:10:30 lr 0.000984	time 0.5626 (0.5729)	loss 4.4797 (4.1606)	grad_norm 1.0579 (1.2568)	mem 17413MB
[2023-01-31 17:50:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][200/1251]	eta 0:09:59 lr 0.000984	time 0.5566 (0.5705)	loss 2.6654 (4.1317)	grad_norm 1.2615 (1.2462)	mem 17413MB
[2023-01-31 17:50:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][250/1251]	eta 0:09:29 lr 0.000984	time 0.5609 (0.5689)	loss 3.6124 (4.1353)	grad_norm 1.2210 (1.2407)	mem 17413MB
[2023-01-31 17:51:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][300/1251]	eta 0:09:00 lr 0.000984	time 0.5563 (0.5685)	loss 4.1498 (4.1330)	grad_norm 1.2254 (1.2411)	mem 17413MB
[2023-01-31 17:51:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][350/1251]	eta 0:08:31 lr 0.000984	time 0.5735 (0.5677)	loss 3.2236 (4.1278)	grad_norm 1.2433 (1.2418)	mem 17413MB
[2023-01-31 17:52:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][400/1251]	eta 0:08:02 lr 0.000984	time 0.5566 (0.5669)	loss 4.0526 (4.1169)	grad_norm 1.3785 (1.2455)	mem 17413MB
[2023-01-31 17:52:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][450/1251]	eta 0:07:33 lr 0.000984	time 0.6265 (0.5667)	loss 4.3824 (4.1209)	grad_norm 1.3378 (1.2452)	mem 17413MB
[2023-01-31 17:53:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][500/1251]	eta 0:07:04 lr 0.000984	time 0.5577 (0.5659)	loss 2.7491 (4.1098)	grad_norm 1.2316 (1.2428)	mem 17413MB
[2023-01-31 17:53:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][550/1251]	eta 0:06:36 lr 0.000984	time 0.5590 (0.5657)	loss 4.1738 (4.0920)	grad_norm 1.3863 (1.2401)	mem 17413MB
[2023-01-31 17:54:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][600/1251]	eta 0:06:08 lr 0.000984	time 0.5551 (0.5655)	loss 3.8145 (4.0947)	grad_norm 1.2449 (1.2405)	mem 17413MB
[2023-01-31 17:54:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][650/1251]	eta 0:05:39 lr 0.000984	time 0.5581 (0.5653)	loss 5.1423 (4.0948)	grad_norm 1.1210 (1.2386)	mem 17413MB
[2023-01-31 17:55:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][700/1251]	eta 0:05:11 lr 0.000984	time 0.5526 (0.5652)	loss 4.5753 (4.0869)	grad_norm 1.1430 (1.2368)	mem 17413MB
[2023-01-31 17:55:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][750/1251]	eta 0:04:43 lr 0.000984	time 0.5589 (0.5653)	loss 4.0658 (4.0931)	grad_norm 1.2444 (1.2357)	mem 17413MB
[2023-01-31 17:55:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][800/1251]	eta 0:04:14 lr 0.000984	time 0.5558 (0.5650)	loss 4.6881 (4.1079)	grad_norm 1.0448 (1.2356)	mem 17413MB
[2023-01-31 17:56:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][850/1251]	eta 0:03:46 lr 0.000984	time 0.5628 (0.5650)	loss 4.0474 (4.1153)	grad_norm 1.3518 (1.2340)	mem 17413MB
[2023-01-31 17:56:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][900/1251]	eta 0:03:18 lr 0.000984	time 0.5570 (0.5648)	loss 2.5884 (4.1133)	grad_norm 1.1376 (1.2345)	mem 17413MB
[2023-01-31 17:57:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][950/1251]	eta 0:02:50 lr 0.000983	time 0.5606 (0.5648)	loss 3.8487 (4.1104)	grad_norm 1.1396 (1.2343)	mem 17413MB
[2023-01-31 17:57:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][1000/1251]	eta 0:02:21 lr 0.000983	time 0.5686 (0.5649)	loss 4.7295 (4.1048)	grad_norm 1.2724 (1.2345)	mem 17413MB
[2023-01-31 17:58:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][1050/1251]	eta 0:01:53 lr 0.000983	time 0.5523 (0.5647)	loss 3.0815 (4.1106)	grad_norm 1.2310 (1.2339)	mem 17413MB
[2023-01-31 17:58:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][1100/1251]	eta 0:01:25 lr 0.000983	time 0.5568 (0.5648)	loss 4.3194 (4.1159)	grad_norm 1.1771 (1.2343)	mem 17413MB
[2023-01-31 17:59:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][1150/1251]	eta 0:00:57 lr 0.000983	time 0.6282 (0.5648)	loss 5.0951 (4.1200)	grad_norm 1.0298 (1.2339)	mem 17413MB
[2023-01-31 17:59:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][1200/1251]	eta 0:00:28 lr 0.000983	time 0.5574 (0.5647)	loss 4.0030 (4.1105)	grad_norm 1.1486 (1.2340)	mem 17413MB
[2023-01-31 18:00:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [24/300][1250/1251]	eta 0:00:00 lr 0.000983	time 0.5523 (0.5646)	loss 3.6338 (4.1104)	grad_norm 1.4798 (1.2348)	mem 17413MB
[2023-01-31 18:00:11 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 24 training takes 0:11:46
[2023-01-31 18:00:11 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_24.pth saving......
[2023-01-31 18:00:12 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_24.pth saved !!!
[2023-01-31 18:00:13 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.881 (0.881)	Loss 1.3638 (1.3638)	Acc@1 69.336 (69.336)	Acc@5 88.574 (88.574)	Mem 17413MB
[2023-01-31 18:00:21 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 67.918 Acc@5 89.140
[2023-01-31 18:00:21 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 67.9%
[2023-01-31 18:00:22 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.217 (1.217)	Loss 1.7352 (1.7352)	Acc@1 62.207 (62.207)	Acc@5 83.984 (83.984)	Mem 17413MB
[2023-01-31 18:00:30 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 61.576 Acc@5 84.420
[2023-01-31 18:00:30 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 61.6%
[2023-01-31 18:00:30 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 67.92% at 24 epoch
[2023-01-31 18:00:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][0/1251]	eta 0:35:34 lr 0.000983	time 1.7062 (1.7062)	loss 5.0453 (5.0453)	grad_norm 1.2524 (1.2524)	mem 17413MB
[2023-01-31 18:01:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][50/1251]	eta 0:11:46 lr 0.000983	time 0.5603 (0.5882)	loss 3.4015 (3.9621)	grad_norm 1.2812 (1.2211)	mem 17413MB
[2023-01-31 18:01:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][100/1251]	eta 0:11:01 lr 0.000983	time 0.5527 (0.5748)	loss 4.9637 (4.0591)	grad_norm 1.1010 (1.2288)	mem 17413MB
[2023-01-31 18:01:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][150/1251]	eta 0:10:29 lr 0.000983	time 0.5559 (0.5721)	loss 4.3456 (4.0597)	grad_norm 1.1914 (1.2321)	mem 17413MB
[2023-01-31 18:02:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][200/1251]	eta 0:09:59 lr 0.000983	time 0.5601 (0.5701)	loss 4.1983 (4.0787)	grad_norm 1.0996 (1.2315)	mem 17413MB
[2023-01-31 18:02:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][250/1251]	eta 0:09:29 lr 0.000983	time 0.5591 (0.5688)	loss 3.9788 (4.0830)	grad_norm 1.1057 (1.2315)	mem 17413MB
[2023-01-31 18:03:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][300/1251]	eta 0:09:00 lr 0.000983	time 0.5828 (0.5683)	loss 4.8607 (4.0632)	grad_norm 1.1254 (1.2336)	mem 17413MB
[2023-01-31 18:03:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][350/1251]	eta 0:08:30 lr 0.000983	time 0.5623 (0.5670)	loss 4.6282 (4.0678)	grad_norm 1.2185 (1.2335)	mem 17413MB
[2023-01-31 18:04:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][400/1251]	eta 0:08:02 lr 0.000983	time 0.5543 (0.5669)	loss 4.7239 (4.0675)	grad_norm 1.5449 (1.2337)	mem 17413MB
[2023-01-31 18:04:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][450/1251]	eta 0:07:33 lr 0.000983	time 0.5599 (0.5667)	loss 4.2816 (4.0759)	grad_norm 1.0812 (1.2321)	mem 17413MB
[2023-01-31 18:05:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][500/1251]	eta 0:07:05 lr 0.000983	time 0.5616 (0.5666)	loss 4.8236 (4.0806)	grad_norm 1.1063 (1.2333)	mem 17413MB
[2023-01-31 18:05:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][550/1251]	eta 0:06:37 lr 0.000983	time 0.6333 (0.5665)	loss 3.6279 (4.0854)	grad_norm 1.2128 (1.2346)	mem 17413MB
[2023-01-31 18:06:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][600/1251]	eta 0:06:08 lr 0.000982	time 0.5551 (0.5663)	loss 4.2322 (4.0806)	grad_norm 1.3051 (1.2338)	mem 17413MB
[2023-01-31 18:06:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][650/1251]	eta 0:05:40 lr 0.000982	time 0.5482 (0.5660)	loss 3.9865 (4.0810)	grad_norm 1.2007 (1.2373)	mem 17413MB
[2023-01-31 18:07:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][700/1251]	eta 0:05:11 lr 0.000982	time 0.5529 (0.5659)	loss 2.8325 (4.0763)	grad_norm 1.4791 (nan)	mem 17413MB
[2023-01-31 18:07:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][750/1251]	eta 0:04:43 lr 0.000982	time 0.5537 (0.5658)	loss 3.8588 (4.0707)	grad_norm 1.3662 (nan)	mem 17413MB
[2023-01-31 18:08:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][800/1251]	eta 0:04:15 lr 0.000982	time 0.6289 (0.5659)	loss 4.0460 (4.0675)	grad_norm 1.3107 (nan)	mem 17413MB
[2023-01-31 18:08:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][850/1251]	eta 0:03:46 lr 0.000982	time 0.6285 (0.5659)	loss 3.5656 (4.0724)	grad_norm 1.2585 (nan)	mem 17413MB
[2023-01-31 18:09:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][900/1251]	eta 0:03:18 lr 0.000982	time 0.5540 (0.5657)	loss 3.9337 (4.0779)	grad_norm 1.1826 (nan)	mem 17413MB
[2023-01-31 18:09:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][950/1251]	eta 0:02:50 lr 0.000982	time 0.5561 (0.5657)	loss 4.0336 (4.0788)	grad_norm 1.2962 (nan)	mem 17413MB
[2023-01-31 18:09:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][1000/1251]	eta 0:02:22 lr 0.000982	time 0.5566 (0.5658)	loss 3.4224 (4.0777)	grad_norm 1.2301 (nan)	mem 17413MB
[2023-01-31 18:10:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][1050/1251]	eta 0:01:53 lr 0.000982	time 0.5574 (0.5657)	loss 2.8058 (4.0764)	grad_norm 1.3681 (nan)	mem 17413MB
[2023-01-31 18:10:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][1100/1251]	eta 0:01:25 lr 0.000982	time 0.5525 (0.5657)	loss 3.4236 (4.0746)	grad_norm 1.2953 (nan)	mem 17413MB
[2023-01-31 18:11:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][1150/1251]	eta 0:00:57 lr 0.000982	time 0.5603 (0.5654)	loss 3.5389 (4.0740)	grad_norm 1.3342 (nan)	mem 17413MB
[2023-01-31 18:11:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][1200/1251]	eta 0:00:28 lr 0.000982	time 0.5634 (0.5655)	loss 5.1359 (4.0741)	grad_norm 1.3028 (nan)	mem 17413MB
[2023-01-31 18:12:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [25/300][1250/1251]	eta 0:00:00 lr 0.000982	time 0.5510 (0.5655)	loss 4.7119 (4.0691)	grad_norm 1.2043 (nan)	mem 17413MB
[2023-01-31 18:12:18 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 25 training takes 0:11:47
[2023-01-31 18:12:18 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_25.pth saving......
[2023-01-31 18:12:20 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_25.pth saved !!!
[2023-01-31 18:12:21 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.852 (0.852)	Loss 1.4458 (1.4458)	Acc@1 67.773 (67.773)	Acc@5 87.402 (87.402)	Mem 17413MB
[2023-01-31 18:12:29 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 68.408 Acc@5 89.376
[2023-01-31 18:12:29 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 68.4%
[2023-01-31 18:12:30 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.204 (1.204)	Loss 1.7588 (1.7588)	Acc@1 62.598 (62.598)	Acc@5 84.180 (84.180)	Mem 17413MB
[2023-01-31 18:12:38 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 63.290 Acc@5 85.596
[2023-01-31 18:12:38 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 63.3%
[2023-01-31 18:12:38 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 68.41% at 25 epoch
[2023-01-31 18:12:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][0/1251]	eta 0:34:32 lr 0.000982	time 1.6565 (1.6565)	loss 3.8559 (3.8559)	grad_norm 1.1450 (1.1450)	mem 17413MB
[2023-01-31 18:13:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][50/1251]	eta 0:11:45 lr 0.000982	time 0.6324 (0.5873)	loss 4.3749 (4.0127)	grad_norm 1.0370 (1.2303)	mem 17413MB
[2023-01-31 18:13:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][100/1251]	eta 0:11:04 lr 0.000982	time 0.6301 (0.5770)	loss 4.8228 (3.9863)	grad_norm 1.3008 (1.2165)	mem 17413MB
[2023-01-31 18:14:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][150/1251]	eta 0:10:29 lr 0.000982	time 0.5531 (0.5714)	loss 2.9359 (3.9894)	grad_norm 1.0880 (1.2093)	mem 17413MB
[2023-01-31 18:14:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][200/1251]	eta 0:09:59 lr 0.000982	time 0.5540 (0.5703)	loss 4.6506 (3.9886)	grad_norm 1.2196 (1.2088)	mem 17413MB
[2023-01-31 18:15:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][250/1251]	eta 0:09:28 lr 0.000981	time 0.5572 (0.5680)	loss 4.6221 (3.9968)	grad_norm 1.1568 (1.2070)	mem 17413MB
[2023-01-31 18:15:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][300/1251]	eta 0:09:00 lr 0.000981	time 0.5562 (0.5679)	loss 5.3323 (4.0193)	grad_norm 1.2220 (1.2082)	mem 17413MB
[2023-01-31 18:15:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][350/1251]	eta 0:08:30 lr 0.000981	time 0.6464 (0.5670)	loss 3.4969 (4.0331)	grad_norm 1.1799 (1.2085)	mem 17413MB
[2023-01-31 18:16:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][400/1251]	eta 0:08:02 lr 0.000981	time 0.5617 (0.5665)	loss 4.2048 (4.0204)	grad_norm 1.3271 (nan)	mem 17413MB
[2023-01-31 18:16:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][450/1251]	eta 0:07:33 lr 0.000981	time 0.5573 (0.5662)	loss 4.1624 (4.0152)	grad_norm 1.3518 (nan)	mem 17413MB
[2023-01-31 18:17:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][500/1251]	eta 0:07:05 lr 0.000981	time 0.6264 (0.5660)	loss 4.5803 (4.0156)	grad_norm 1.1386 (nan)	mem 17413MB
[2023-01-31 18:17:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][550/1251]	eta 0:06:36 lr 0.000981	time 0.5610 (0.5655)	loss 4.2709 (4.0244)	grad_norm 1.2925 (nan)	mem 17413MB
[2023-01-31 18:18:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][600/1251]	eta 0:06:08 lr 0.000981	time 0.5474 (0.5657)	loss 4.4602 (4.0340)	grad_norm 1.3992 (nan)	mem 17413MB
[2023-01-31 18:18:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][650/1251]	eta 0:05:39 lr 0.000981	time 0.5652 (0.5652)	loss 3.8144 (4.0236)	grad_norm 1.4634 (nan)	mem 17413MB
[2023-01-31 18:19:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][700/1251]	eta 0:05:11 lr 0.000981	time 0.5548 (0.5653)	loss 5.2183 (4.0208)	grad_norm 1.1809 (nan)	mem 17413MB
[2023-01-31 18:19:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][750/1251]	eta 0:04:43 lr 0.000981	time 0.5590 (0.5651)	loss 3.0224 (4.0219)	grad_norm 1.2830 (nan)	mem 17413MB
[2023-01-31 18:20:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][800/1251]	eta 0:04:14 lr 0.000981	time 0.5495 (0.5651)	loss 4.8894 (4.0307)	grad_norm 1.3356 (nan)	mem 17413MB
[2023-01-31 18:20:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][850/1251]	eta 0:03:46 lr 0.000981	time 0.5562 (0.5650)	loss 4.4858 (4.0322)	grad_norm 1.3199 (nan)	mem 17413MB
[2023-01-31 18:21:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][900/1251]	eta 0:03:18 lr 0.000981	time 0.6335 (0.5650)	loss 4.3796 (4.0267)	grad_norm 1.1402 (nan)	mem 17413MB
[2023-01-31 18:21:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][950/1251]	eta 0:02:50 lr 0.000981	time 0.5682 (0.5650)	loss 4.5180 (4.0297)	grad_norm 1.1412 (nan)	mem 17413MB
[2023-01-31 18:22:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][1000/1251]	eta 0:02:21 lr 0.000981	time 0.5574 (0.5650)	loss 4.2674 (4.0344)	grad_norm 1.1993 (nan)	mem 17413MB
[2023-01-31 18:22:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][1050/1251]	eta 0:01:53 lr 0.000981	time 0.5548 (0.5648)	loss 3.0868 (4.0361)	grad_norm 1.1710 (nan)	mem 17413MB
[2023-01-31 18:23:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][1100/1251]	eta 0:01:25 lr 0.000981	time 0.6532 (0.5649)	loss 4.2774 (4.0413)	grad_norm 1.2426 (nan)	mem 17413MB
[2023-01-31 18:23:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][1150/1251]	eta 0:00:57 lr 0.000980	time 0.5546 (0.5649)	loss 3.0556 (4.0320)	grad_norm 1.3751 (nan)	mem 17413MB
[2023-01-31 18:23:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][1200/1251]	eta 0:00:28 lr 0.000980	time 0.5553 (0.5648)	loss 4.2346 (4.0257)	grad_norm 1.3594 (nan)	mem 17413MB
[2023-01-31 18:24:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [26/300][1250/1251]	eta 0:00:00 lr 0.000980	time 0.5517 (0.5648)	loss 4.6974 (4.0245)	grad_norm 1.2252 (nan)	mem 17413MB
[2023-01-31 18:24:24 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 26 training takes 0:11:46
[2023-01-31 18:24:24 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_26.pth saving......
[2023-01-31 18:24:26 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_26.pth saved !!!
[2023-01-31 18:24:27 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.844 (0.844)	Loss 1.3080 (1.3080)	Acc@1 70.117 (70.117)	Acc@5 89.355 (89.355)	Mem 17413MB
[2023-01-31 18:24:35 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 69.024 Acc@5 89.838
[2023-01-31 18:24:35 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 69.0%
[2023-01-31 18:24:36 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.134 (1.134)	Loss 1.6783 (1.6783)	Acc@1 63.379 (63.379)	Acc@5 86.035 (86.035)	Mem 17413MB
[2023-01-31 18:24:44 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 64.730 Acc@5 86.694
[2023-01-31 18:24:44 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 64.7%
[2023-01-31 18:24:44 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 69.02% at 26 epoch
[2023-01-31 18:24:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][0/1251]	eta 0:36:36 lr 0.000980	time 1.7557 (1.7557)	loss 4.2744 (4.2744)	grad_norm 1.1317 (1.1317)	mem 17413MB
[2023-01-31 18:25:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][50/1251]	eta 0:11:46 lr 0.000980	time 0.5589 (0.5886)	loss 3.6732 (3.9591)	grad_norm 1.2436 (1.2149)	mem 17413MB
[2023-01-31 18:25:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][100/1251]	eta 0:11:03 lr 0.000980	time 0.5533 (0.5768)	loss 4.2928 (4.0488)	grad_norm 1.3467 (1.2183)	mem 17413MB
[2023-01-31 18:26:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][150/1251]	eta 0:10:30 lr 0.000980	time 0.5618 (0.5722)	loss 4.4584 (4.0025)	grad_norm 1.3446 (1.2269)	mem 17413MB
[2023-01-31 18:26:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][200/1251]	eta 0:09:59 lr 0.000980	time 0.5526 (0.5700)	loss 4.0841 (3.9715)	grad_norm 1.1733 (1.2223)	mem 17413MB
[2023-01-31 18:27:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][250/1251]	eta 0:09:28 lr 0.000980	time 0.5543 (0.5684)	loss 3.2893 (3.9569)	grad_norm 1.2515 (1.2204)	mem 17413MB
[2023-01-31 18:27:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][300/1251]	eta 0:09:00 lr 0.000980	time 0.5584 (0.5679)	loss 3.5554 (3.9697)	grad_norm 1.3521 (1.2173)	mem 17413MB
[2023-01-31 18:28:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][350/1251]	eta 0:08:30 lr 0.000980	time 0.5542 (0.5670)	loss 2.8034 (3.9635)	grad_norm 1.3156 (1.2216)	mem 17413MB
[2023-01-31 18:28:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][400/1251]	eta 0:08:02 lr 0.000980	time 0.5550 (0.5667)	loss 3.5596 (3.9617)	grad_norm 1.3299 (1.2209)	mem 17413MB
[2023-01-31 18:29:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][450/1251]	eta 0:07:34 lr 0.000980	time 0.6392 (0.5668)	loss 4.0740 (3.9488)	grad_norm 1.2353 (1.2234)	mem 17413MB
[2023-01-31 18:29:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][500/1251]	eta 0:07:05 lr 0.000980	time 0.5547 (0.5663)	loss 3.9366 (3.9568)	grad_norm 1.2847 (1.2221)	mem 17413MB
[2023-01-31 18:29:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][550/1251]	eta 0:06:36 lr 0.000980	time 0.5587 (0.5659)	loss 4.0194 (3.9699)	grad_norm 1.2131 (1.2212)	mem 17413MB
[2023-01-31 18:30:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][600/1251]	eta 0:06:08 lr 0.000980	time 0.5584 (0.5660)	loss 4.2609 (3.9720)	grad_norm 1.2489 (1.2226)	mem 17413MB
[2023-01-31 18:30:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][650/1251]	eta 0:05:40 lr 0.000980	time 0.5544 (0.5658)	loss 3.3256 (3.9706)	grad_norm 1.1952 (1.2247)	mem 17413MB
[2023-01-31 18:31:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][700/1251]	eta 0:05:11 lr 0.000980	time 0.5572 (0.5657)	loss 3.6047 (3.9717)	grad_norm 1.2164 (1.2234)	mem 17413MB
[2023-01-31 18:31:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][750/1251]	eta 0:04:43 lr 0.000979	time 0.5510 (0.5654)	loss 3.9939 (3.9782)	grad_norm 1.1313 (1.2276)	mem 17413MB
[2023-01-31 18:32:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][800/1251]	eta 0:04:14 lr 0.000979	time 0.5485 (0.5652)	loss 3.8028 (3.9764)	grad_norm 1.4020 (1.2277)	mem 17413MB
[2023-01-31 18:32:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][850/1251]	eta 0:03:46 lr 0.000979	time 0.5572 (0.5652)	loss 4.9010 (3.9696)	grad_norm 1.2885 (1.2312)	mem 17413MB
[2023-01-31 18:33:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][900/1251]	eta 0:03:18 lr 0.000979	time 0.5520 (0.5652)	loss 3.4620 (3.9642)	grad_norm 1.1663 (1.2312)	mem 17413MB
[2023-01-31 18:33:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][950/1251]	eta 0:02:50 lr 0.000979	time 0.5497 (0.5651)	loss 4.0624 (3.9779)	grad_norm 1.1375 (1.2306)	mem 17413MB
[2023-01-31 18:34:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][1000/1251]	eta 0:02:21 lr 0.000979	time 0.5541 (0.5651)	loss 4.7587 (3.9808)	grad_norm 1.2389 (1.2300)	mem 17413MB
[2023-01-31 18:34:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][1050/1251]	eta 0:01:53 lr 0.000979	time 0.5551 (0.5650)	loss 4.5011 (3.9775)	grad_norm 1.1565 (1.2288)	mem 17413MB
[2023-01-31 18:35:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][1100/1251]	eta 0:01:25 lr 0.000979	time 0.5601 (0.5650)	loss 3.6784 (3.9835)	grad_norm 1.2853 (1.2286)	mem 17413MB
[2023-01-31 18:35:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][1150/1251]	eta 0:00:57 lr 0.000979	time 0.5595 (0.5649)	loss 3.8924 (3.9830)	grad_norm 1.2667 (1.2272)	mem 17413MB
[2023-01-31 18:36:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][1200/1251]	eta 0:00:28 lr 0.000979	time 0.5577 (0.5648)	loss 3.4034 (3.9884)	grad_norm 1.1504 (1.2263)	mem 17413MB
[2023-01-31 18:36:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [27/300][1250/1251]	eta 0:00:00 lr 0.000979	time 0.5529 (0.5648)	loss 2.7927 (3.9844)	grad_norm 1.1740 (1.2273)	mem 17413MB
[2023-01-31 18:36:31 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 27 training takes 0:11:46
[2023-01-31 18:36:31 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_27.pth saving......
[2023-01-31 18:36:33 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_27.pth saved !!!
[2023-01-31 18:36:33 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.856 (0.856)	Loss 1.3522 (1.3522)	Acc@1 67.285 (67.285)	Acc@5 89.355 (89.355)	Mem 17413MB
[2023-01-31 18:36:41 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 69.200 Acc@5 89.760
[2023-01-31 18:36:41 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 69.2%
[2023-01-31 18:36:43 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.242 (1.242)	Loss 1.5917 (1.5917)	Acc@1 65.625 (65.625)	Acc@5 87.305 (87.305)	Mem 17413MB
[2023-01-31 18:36:50 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 65.968 Acc@5 87.492
[2023-01-31 18:36:50 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 66.0%
[2023-01-31 18:36:50 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 69.20% at 27 epoch
[2023-01-31 18:36:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][0/1251]	eta 0:35:53 lr 0.000979	time 1.7215 (1.7215)	loss 4.0808 (4.0808)	grad_norm 1.1652 (1.1652)	mem 17413MB
[2023-01-31 18:37:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][50/1251]	eta 0:11:47 lr 0.000979	time 0.5542 (0.5888)	loss 3.0235 (3.8661)	grad_norm 1.3126 (1.2209)	mem 17413MB
[2023-01-31 18:37:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][100/1251]	eta 0:11:03 lr 0.000979	time 0.5558 (0.5763)	loss 4.6298 (3.9777)	grad_norm 1.4050 (1.2195)	mem 17413MB
[2023-01-31 18:38:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][150/1251]	eta 0:10:30 lr 0.000979	time 0.5554 (0.5724)	loss 4.1035 (4.0216)	grad_norm 1.4744 (1.2327)	mem 17413MB
[2023-01-31 18:38:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][200/1251]	eta 0:09:59 lr 0.000979	time 0.5603 (0.5703)	loss 3.5510 (4.0401)	grad_norm 1.1389 (1.2373)	mem 17413MB
[2023-01-31 18:39:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][250/1251]	eta 0:09:29 lr 0.000979	time 0.5592 (0.5689)	loss 3.8605 (4.0332)	grad_norm 1.1077 (1.2343)	mem 17413MB
[2023-01-31 18:39:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][300/1251]	eta 0:09:00 lr 0.000979	time 0.5552 (0.5684)	loss 3.2728 (4.0069)	grad_norm 1.1204 (1.2294)	mem 17413MB
[2023-01-31 18:40:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][350/1251]	eta 0:08:31 lr 0.000978	time 0.5547 (0.5673)	loss 2.8203 (3.9797)	grad_norm 1.2312 (1.2283)	mem 17413MB
[2023-01-31 18:40:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][400/1251]	eta 0:08:02 lr 0.000978	time 0.5560 (0.5673)	loss 3.6317 (3.9689)	grad_norm 1.2336 (1.2311)	mem 17413MB
[2023-01-31 18:41:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][450/1251]	eta 0:07:34 lr 0.000978	time 0.5605 (0.5669)	loss 4.1185 (3.9733)	grad_norm 1.1111 (1.2303)	mem 17413MB
[2023-01-31 18:41:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][500/1251]	eta 0:07:05 lr 0.000978	time 0.5582 (0.5664)	loss 3.5438 (3.9750)	grad_norm 1.2515 (1.2306)	mem 17413MB
[2023-01-31 18:42:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][550/1251]	eta 0:06:36 lr 0.000978	time 0.5623 (0.5662)	loss 3.8116 (3.9737)	grad_norm 1.2042 (1.2318)	mem 17413MB
[2023-01-31 18:42:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][600/1251]	eta 0:06:08 lr 0.000978	time 0.5551 (0.5659)	loss 4.4326 (3.9871)	grad_norm 1.4566 (nan)	mem 17413MB
[2023-01-31 18:42:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][650/1251]	eta 0:05:40 lr 0.000978	time 0.5593 (0.5658)	loss 3.3705 (3.9738)	grad_norm 1.2321 (nan)	mem 17413MB
[2023-01-31 18:43:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][700/1251]	eta 0:05:11 lr 0.000978	time 0.5602 (0.5657)	loss 3.7003 (3.9643)	grad_norm 1.2857 (nan)	mem 17413MB
[2023-01-31 18:43:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][750/1251]	eta 0:04:43 lr 0.000978	time 0.5576 (0.5655)	loss 3.9415 (3.9593)	grad_norm 1.1896 (nan)	mem 17413MB
[2023-01-31 18:44:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][800/1251]	eta 0:04:15 lr 0.000978	time 0.6172 (0.5656)	loss 4.1131 (3.9618)	grad_norm 1.0846 (nan)	mem 17413MB
[2023-01-31 18:44:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][850/1251]	eta 0:03:46 lr 0.000978	time 0.5543 (0.5654)	loss 2.8874 (3.9568)	grad_norm 1.0762 (nan)	mem 17413MB
[2023-01-31 18:45:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][900/1251]	eta 0:03:18 lr 0.000978	time 0.5548 (0.5654)	loss 4.2856 (3.9524)	grad_norm 1.2551 (nan)	mem 17413MB
[2023-01-31 18:45:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][950/1251]	eta 0:02:50 lr 0.000978	time 0.5529 (0.5652)	loss 3.2566 (3.9499)	grad_norm 1.1940 (nan)	mem 17413MB
[2023-01-31 18:46:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][1000/1251]	eta 0:02:21 lr 0.000978	time 0.6321 (0.5652)	loss 3.4653 (3.9450)	grad_norm 1.1584 (nan)	mem 17413MB
[2023-01-31 18:46:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][1050/1251]	eta 0:01:53 lr 0.000978	time 0.5571 (0.5650)	loss 3.9272 (3.9453)	grad_norm 1.1670 (nan)	mem 17413MB
[2023-01-31 18:47:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][1100/1251]	eta 0:01:25 lr 0.000978	time 0.5638 (0.5649)	loss 4.1348 (3.9431)	grad_norm 1.1473 (nan)	mem 17413MB
[2023-01-31 18:47:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][1150/1251]	eta 0:00:57 lr 0.000977	time 0.5595 (0.5649)	loss 3.7826 (3.9444)	grad_norm 1.1387 (nan)	mem 17413MB
[2023-01-31 18:48:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][1200/1251]	eta 0:00:28 lr 0.000977	time 0.5622 (0.5648)	loss 4.1837 (3.9408)	grad_norm 1.2981 (nan)	mem 17413MB
[2023-01-31 18:48:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [28/300][1250/1251]	eta 0:00:00 lr 0.000977	time 0.6088 (0.5648)	loss 3.8202 (3.9466)	grad_norm 1.2506 (nan)	mem 17413MB
[2023-01-31 18:48:37 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 28 training takes 0:11:46
[2023-01-31 18:48:37 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_28.pth saving......
[2023-01-31 18:48:39 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_28.pth saved !!!
[2023-01-31 18:48:40 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.881 (0.881)	Loss 1.2531 (1.2531)	Acc@1 70.898 (70.898)	Acc@5 91.602 (91.602)	Mem 17413MB
[2023-01-31 18:48:48 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 69.622 Acc@5 90.088
[2023-01-31 18:48:48 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 69.6%
[2023-01-31 18:48:49 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.155 (1.155)	Loss 1.5297 (1.5297)	Acc@1 66.992 (66.992)	Acc@5 87.207 (87.207)	Mem 17413MB
[2023-01-31 18:48:57 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 67.162 Acc@5 88.240
[2023-01-31 18:48:57 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 67.2%
[2023-01-31 18:48:57 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 69.62% at 28 epoch
[2023-01-31 18:48:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][0/1251]	eta 0:36:14 lr 0.000977	time 1.7385 (1.7385)	loss 4.1733 (4.1733)	grad_norm 1.2173 (1.2173)	mem 17413MB
[2023-01-31 18:49:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][50/1251]	eta 0:11:48 lr 0.000977	time 0.5572 (0.5902)	loss 3.1265 (3.8460)	grad_norm 1.2732 (1.1695)	mem 17413MB
[2023-01-31 18:49:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][100/1251]	eta 0:11:05 lr 0.000977	time 0.5601 (0.5778)	loss 4.6436 (3.8757)	grad_norm 1.3073 (1.2125)	mem 17413MB
[2023-01-31 18:50:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][150/1251]	eta 0:10:31 lr 0.000977	time 0.5546 (0.5736)	loss 3.8681 (3.8769)	grad_norm 1.0008 (1.2065)	mem 17413MB
[2023-01-31 18:50:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][200/1251]	eta 0:10:00 lr 0.000977	time 0.5634 (0.5710)	loss 2.9111 (3.8819)	grad_norm 1.3976 (1.2187)	mem 17413MB
[2023-01-31 18:51:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][250/1251]	eta 0:09:29 lr 0.000977	time 0.5597 (0.5694)	loss 4.1890 (3.9139)	grad_norm 1.3568 (1.2217)	mem 17413MB
[2023-01-31 18:51:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][300/1251]	eta 0:09:01 lr 0.000977	time 0.6118 (0.5689)	loss 4.1111 (3.9010)	grad_norm 1.2729 (1.2201)	mem 17413MB
[2023-01-31 18:52:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][350/1251]	eta 0:08:31 lr 0.000977	time 0.5536 (0.5678)	loss 3.8677 (3.9050)	grad_norm 1.1080 (1.2209)	mem 17413MB
[2023-01-31 18:52:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][400/1251]	eta 0:08:03 lr 0.000977	time 0.5568 (0.5678)	loss 3.7142 (3.9200)	grad_norm 1.2231 (1.2209)	mem 17413MB
[2023-01-31 18:53:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][450/1251]	eta 0:07:34 lr 0.000977	time 0.6285 (0.5674)	loss 2.7848 (3.9107)	grad_norm 1.1825 (1.2220)	mem 17413MB
[2023-01-31 18:53:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][500/1251]	eta 0:07:05 lr 0.000977	time 0.5493 (0.5670)	loss 3.4454 (3.9225)	grad_norm 1.3560 (1.2228)	mem 17413MB
[2023-01-31 18:54:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][550/1251]	eta 0:06:37 lr 0.000977	time 0.5545 (0.5668)	loss 2.7516 (3.9133)	grad_norm 1.0653 (1.2248)	mem 17413MB
[2023-01-31 18:54:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][600/1251]	eta 0:06:08 lr 0.000977	time 0.5521 (0.5665)	loss 3.8783 (3.9114)	grad_norm 1.2395 (1.2234)	mem 17413MB
[2023-01-31 18:55:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][650/1251]	eta 0:05:40 lr 0.000977	time 0.5621 (0.5664)	loss 4.8599 (3.9194)	grad_norm 1.2226 (1.2236)	mem 17413MB
[2023-01-31 18:55:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][700/1251]	eta 0:05:12 lr 0.000976	time 0.5515 (0.5664)	loss 4.7057 (3.9223)	grad_norm 1.1695 (1.2256)	mem 17413MB
[2023-01-31 18:56:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][750/1251]	eta 0:04:43 lr 0.000976	time 0.5511 (0.5660)	loss 4.0724 (3.9199)	grad_norm 1.1680 (1.2270)	mem 17413MB
[2023-01-31 18:56:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][800/1251]	eta 0:04:15 lr 0.000976	time 0.5663 (0.5659)	loss 4.0329 (3.9203)	grad_norm 1.2521 (1.2272)	mem 17413MB
[2023-01-31 18:56:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][850/1251]	eta 0:03:46 lr 0.000976	time 0.5606 (0.5657)	loss 4.2502 (3.9186)	grad_norm 1.1233 (1.2284)	mem 17413MB
[2023-01-31 18:57:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][900/1251]	eta 0:03:18 lr 0.000976	time 0.5597 (0.5655)	loss 4.4975 (3.9261)	grad_norm 1.1648 (1.2294)	mem 17413MB
[2023-01-31 18:57:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][950/1251]	eta 0:02:50 lr 0.000976	time 0.5567 (0.5655)	loss 3.3492 (3.9180)	grad_norm 1.1916 (1.2288)	mem 17413MB
[2023-01-31 18:58:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][1000/1251]	eta 0:02:21 lr 0.000976	time 0.5646 (0.5653)	loss 4.4900 (3.9207)	grad_norm 1.4185 (1.2271)	mem 17413MB
[2023-01-31 18:58:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][1050/1251]	eta 0:01:53 lr 0.000976	time 0.5566 (0.5652)	loss 4.4210 (3.9267)	grad_norm 1.3477 (1.2270)	mem 17413MB
[2023-01-31 18:59:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][1100/1251]	eta 0:01:25 lr 0.000976	time 0.5551 (0.5653)	loss 3.5500 (3.9233)	grad_norm 1.0805 (1.2276)	mem 17413MB
[2023-01-31 18:59:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][1150/1251]	eta 0:00:57 lr 0.000976	time 0.5538 (0.5652)	loss 3.6100 (3.9252)	grad_norm 1.0456 (1.2274)	mem 17413MB
[2023-01-31 19:00:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][1200/1251]	eta 0:00:28 lr 0.000976	time 0.5505 (0.5653)	loss 4.4775 (3.9254)	grad_norm 1.3538 (1.2286)	mem 17413MB
[2023-01-31 19:00:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [29/300][1250/1251]	eta 0:00:00 lr 0.000976	time 0.5522 (0.5652)	loss 4.2875 (3.9213)	grad_norm 1.2150 (1.2291)	mem 17413MB
[2023-01-31 19:00:44 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 29 training takes 0:11:47
[2023-01-31 19:00:44 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_29.pth saving......
[2023-01-31 19:00:46 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_29.pth saved !!!
[2023-01-31 19:00:47 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.870 (0.870)	Loss 1.2942 (1.2942)	Acc@1 68.848 (68.848)	Acc@5 89.258 (89.258)	Mem 17413MB
[2023-01-31 19:00:55 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 70.088 Acc@5 90.316
[2023-01-31 19:00:55 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 70.1%
[2023-01-31 19:00:56 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.472 (1.472)	Loss 1.4510 (1.4510)	Acc@1 70.117 (70.117)	Acc@5 89.551 (89.551)	Mem 17413MB
[2023-01-31 19:01:04 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 68.206 Acc@5 88.860
[2023-01-31 19:01:04 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 68.2%
[2023-01-31 19:01:04 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 70.09% at 29 epoch
[2023-01-31 19:01:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][0/1251]	eta 0:34:34 lr 0.000976	time 1.6579 (1.6579)	loss 4.4672 (4.4672)	grad_norm 1.3661 (1.3661)	mem 17413MB
[2023-01-31 19:01:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][50/1251]	eta 0:11:44 lr 0.000976	time 0.5560 (0.5863)	loss 3.7081 (3.9295)	grad_norm 1.1414 (1.2479)	mem 17413MB
[2023-01-31 19:02:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][100/1251]	eta 0:11:04 lr 0.000976	time 0.5610 (0.5769)	loss 2.8104 (3.8757)	grad_norm 1.2170 (1.2344)	mem 17413MB
[2023-01-31 19:02:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][150/1251]	eta 0:10:30 lr 0.000976	time 0.5628 (0.5731)	loss 3.3769 (3.9193)	grad_norm 1.2154 (1.2268)	mem 17413MB
[2023-01-31 19:02:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][200/1251]	eta 0:09:59 lr 0.000976	time 0.5576 (0.5703)	loss 4.5493 (3.9602)	grad_norm 1.1076 (1.2252)	mem 17413MB
[2023-01-31 19:03:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][250/1251]	eta 0:09:29 lr 0.000975	time 0.5619 (0.5694)	loss 3.2677 (3.9186)	grad_norm 1.2001 (1.2252)	mem 17413MB
[2023-01-31 19:03:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][300/1251]	eta 0:09:00 lr 0.000975	time 0.5584 (0.5688)	loss 3.7737 (3.9051)	grad_norm 1.2842 (1.2197)	mem 17413MB
[2023-01-31 19:04:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][350/1251]	eta 0:08:31 lr 0.000975	time 0.5549 (0.5678)	loss 3.6941 (3.9102)	grad_norm 1.2161 (1.2265)	mem 17413MB
[2023-01-31 19:04:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][400/1251]	eta 0:08:03 lr 0.000975	time 0.5538 (0.5676)	loss 4.4096 (3.9170)	grad_norm 1.1489 (1.2242)	mem 17413MB
[2023-01-31 19:05:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][450/1251]	eta 0:07:34 lr 0.000975	time 0.5570 (0.5669)	loss 2.7108 (3.9010)	grad_norm 1.2690 (1.2187)	mem 17413MB
[2023-01-31 19:05:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][500/1251]	eta 0:07:05 lr 0.000975	time 0.5577 (0.5669)	loss 2.6561 (3.8901)	grad_norm 1.4487 (nan)	mem 17413MB
[2023-01-31 19:06:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][550/1251]	eta 0:06:37 lr 0.000975	time 0.5541 (0.5665)	loss 2.8672 (3.8861)	grad_norm 1.0845 (nan)	mem 17413MB
[2023-01-31 19:06:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][600/1251]	eta 0:06:08 lr 0.000975	time 0.5777 (0.5663)	loss 3.1698 (3.9021)	grad_norm 1.2203 (nan)	mem 17413MB
[2023-01-31 19:07:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][650/1251]	eta 0:05:40 lr 0.000975	time 0.5591 (0.5660)	loss 3.0148 (3.9051)	grad_norm 1.4758 (nan)	mem 17413MB
[2023-01-31 19:07:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][700/1251]	eta 0:05:11 lr 0.000975	time 0.5542 (0.5659)	loss 3.6687 (3.9094)	grad_norm 1.1843 (nan)	mem 17413MB
[2023-01-31 19:08:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][750/1251]	eta 0:04:43 lr 0.000975	time 0.5571 (0.5657)	loss 3.6643 (3.9197)	grad_norm 1.2577 (nan)	mem 17413MB
[2023-01-31 19:08:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][800/1251]	eta 0:04:15 lr 0.000975	time 0.5553 (0.5657)	loss 4.1548 (3.9110)	grad_norm 1.0222 (nan)	mem 17413MB
[2023-01-31 19:09:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][850/1251]	eta 0:03:46 lr 0.000975	time 0.5576 (0.5654)	loss 3.0100 (3.9122)	grad_norm 1.2742 (nan)	mem 17413MB
[2023-01-31 19:09:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][900/1251]	eta 0:03:18 lr 0.000975	time 0.5514 (0.5656)	loss 3.1975 (3.9158)	grad_norm 1.0892 (nan)	mem 17413MB
[2023-01-31 19:10:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][950/1251]	eta 0:02:50 lr 0.000975	time 0.5585 (0.5654)	loss 3.4109 (3.9122)	grad_norm 1.2680 (nan)	mem 17413MB
[2023-01-31 19:10:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][1000/1251]	eta 0:02:21 lr 0.000974	time 0.5597 (0.5653)	loss 4.3499 (3.9124)	grad_norm 1.3203 (nan)	mem 17413MB
[2023-01-31 19:10:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][1050/1251]	eta 0:01:53 lr 0.000974	time 0.5607 (0.5653)	loss 4.8239 (3.9063)	grad_norm 1.3899 (nan)	mem 17413MB
[2023-01-31 19:11:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][1100/1251]	eta 0:01:25 lr 0.000974	time 0.5555 (0.5652)	loss 4.1644 (3.9024)	grad_norm 1.2823 (nan)	mem 17413MB
[2023-01-31 19:11:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][1150/1251]	eta 0:00:57 lr 0.000974	time 0.5600 (0.5651)	loss 4.2916 (3.8981)	grad_norm 1.1951 (nan)	mem 17413MB
[2023-01-31 19:12:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][1200/1251]	eta 0:00:28 lr 0.000974	time 0.5524 (0.5650)	loss 4.4934 (3.8987)	grad_norm 1.3645 (nan)	mem 17413MB
[2023-01-31 19:12:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [30/300][1250/1251]	eta 0:00:00 lr 0.000974	time 0.5517 (0.5649)	loss 3.8199 (3.8975)	grad_norm 1.4053 (nan)	mem 17413MB
[2023-01-31 19:12:51 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 30 training takes 0:11:46
[2023-01-31 19:12:51 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_30.pth saving......
[2023-01-31 19:12:53 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_30.pth saved !!!
[2023-01-31 19:12:54 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.868 (0.868)	Loss 1.1514 (1.1514)	Acc@1 73.438 (73.438)	Acc@5 91.309 (91.309)	Mem 17413MB
[2023-01-31 19:13:02 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 70.662 Acc@5 90.512
[2023-01-31 19:13:02 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 70.7%
[2023-01-31 19:13:03 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.233 (1.233)	Loss 1.4032 (1.4032)	Acc@1 71.289 (71.289)	Acc@5 89.648 (89.648)	Mem 17413MB
[2023-01-31 19:13:11 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 69.036 Acc@5 89.368
[2023-01-31 19:13:11 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 69.0%
[2023-01-31 19:13:11 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 70.66% at 30 epoch
[2023-01-31 19:13:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][0/1251]	eta 0:34:46 lr 0.000974	time 1.6682 (1.6682)	loss 3.2672 (3.2672)	grad_norm 1.2423 (1.2423)	mem 17413MB
[2023-01-31 19:13:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][50/1251]	eta 0:11:44 lr 0.000974	time 0.5524 (0.5868)	loss 4.2575 (3.7414)	grad_norm 1.1175 (1.2260)	mem 17413MB
[2023-01-31 19:14:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][100/1251]	eta 0:11:01 lr 0.000974	time 0.6471 (0.5750)	loss 4.1290 (3.8069)	grad_norm 1.2187 (1.2210)	mem 17413MB
[2023-01-31 19:14:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][150/1251]	eta 0:10:30 lr 0.000974	time 0.5604 (0.5722)	loss 3.3206 (3.8717)	grad_norm 1.0589 (1.2366)	mem 17413MB
[2023-01-31 19:15:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][200/1251]	eta 0:09:58 lr 0.000974	time 0.5594 (0.5693)	loss 4.1765 (3.8959)	grad_norm 1.2627 (1.2372)	mem 17413MB
[2023-01-31 19:15:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][250/1251]	eta 0:09:29 lr 0.000974	time 0.5789 (0.5686)	loss 4.6300 (3.8795)	grad_norm 1.1952 (1.2390)	mem 17413MB
[2023-01-31 19:16:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][300/1251]	eta 0:08:59 lr 0.000974	time 0.5605 (0.5671)	loss 3.5280 (3.9024)	grad_norm 1.1404 (1.2318)	mem 17413MB
[2023-01-31 19:16:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][350/1251]	eta 0:08:30 lr 0.000974	time 0.5595 (0.5669)	loss 3.3570 (3.9020)	grad_norm 1.1244 (1.2298)	mem 17413MB
[2023-01-31 19:16:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][400/1251]	eta 0:08:01 lr 0.000974	time 0.5561 (0.5664)	loss 4.1227 (3.9027)	grad_norm 1.1526 (1.2275)	mem 17413MB
[2023-01-31 19:17:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][450/1251]	eta 0:07:33 lr 0.000974	time 0.5580 (0.5660)	loss 4.5712 (3.9044)	grad_norm 1.1598 (1.2291)	mem 17413MB
[2023-01-31 19:17:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][500/1251]	eta 0:07:04 lr 0.000973	time 0.5580 (0.5655)	loss 3.5744 (3.9045)	grad_norm 1.1936 (1.2274)	mem 17413MB
[2023-01-31 19:18:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][550/1251]	eta 0:06:36 lr 0.000973	time 0.6367 (0.5657)	loss 3.0515 (3.8951)	grad_norm 1.1319 (1.2286)	mem 17413MB
[2023-01-31 19:18:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][600/1251]	eta 0:06:07 lr 0.000973	time 0.5608 (0.5653)	loss 4.1391 (3.8959)	grad_norm 1.1147 (1.2270)	mem 17413MB
[2023-01-31 19:19:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][650/1251]	eta 0:05:39 lr 0.000973	time 0.5644 (0.5654)	loss 2.7625 (3.9043)	grad_norm 1.1592 (1.2278)	mem 17413MB
[2023-01-31 19:19:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][700/1251]	eta 0:05:11 lr 0.000973	time 0.5674 (0.5651)	loss 4.7508 (3.9146)	grad_norm 1.2873 (1.2272)	mem 17413MB
[2023-01-31 19:20:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][750/1251]	eta 0:04:43 lr 0.000973	time 0.5587 (0.5653)	loss 4.8044 (3.9216)	grad_norm 1.1779 (1.2254)	mem 17413MB
[2023-01-31 19:20:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][800/1251]	eta 0:04:14 lr 0.000973	time 0.5575 (0.5650)	loss 3.7305 (3.9155)	grad_norm 1.3243 (1.2234)	mem 17413MB
[2023-01-31 19:21:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][850/1251]	eta 0:03:46 lr 0.000973	time 0.5550 (0.5649)	loss 3.1608 (3.9183)	grad_norm 1.4438 (1.2248)	mem 17413MB
[2023-01-31 19:21:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][900/1251]	eta 0:03:18 lr 0.000973	time 0.5561 (0.5647)	loss 4.2938 (3.9178)	grad_norm 1.1406 (1.2249)	mem 17413MB
[2023-01-31 19:22:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][950/1251]	eta 0:02:49 lr 0.000973	time 0.5609 (0.5648)	loss 3.4928 (3.9206)	grad_norm 1.1692 (1.2248)	mem 17413MB
[2023-01-31 19:22:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][1000/1251]	eta 0:02:21 lr 0.000973	time 0.6220 (0.5649)	loss 4.2993 (3.9183)	grad_norm 1.3826 (1.2257)	mem 17413MB
[2023-01-31 19:23:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][1050/1251]	eta 0:01:53 lr 0.000973	time 0.5620 (0.5648)	loss 3.6965 (3.9174)	grad_norm 1.1458 (1.2251)	mem 17413MB
[2023-01-31 19:23:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][1100/1251]	eta 0:01:25 lr 0.000973	time 0.5597 (0.5648)	loss 2.3097 (3.9124)	grad_norm 1.3376 (1.2244)	mem 17413MB
[2023-01-31 19:24:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][1150/1251]	eta 0:00:57 lr 0.000973	time 0.5561 (0.5648)	loss 4.0681 (3.9082)	grad_norm 1.2697 (1.2260)	mem 17413MB
[2023-01-31 19:24:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][1200/1251]	eta 0:00:28 lr 0.000973	time 0.5549 (0.5648)	loss 4.2413 (3.9070)	grad_norm 1.1021 (1.2253)	mem 17413MB
[2023-01-31 19:24:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [31/300][1250/1251]	eta 0:00:00 lr 0.000972	time 0.6133 (0.5648)	loss 3.8889 (3.9065)	grad_norm 1.3580 (1.2239)	mem 17413MB
[2023-01-31 19:24:57 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 31 training takes 0:11:46
[2023-01-31 19:24:58 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_31.pth saving......
[2023-01-31 19:24:59 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_31.pth saved !!!
[2023-01-31 19:25:00 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.889 (0.889)	Loss 1.2280 (1.2280)	Acc@1 72.266 (72.266)	Acc@5 91.699 (91.699)	Mem 17413MB
[2023-01-31 19:25:08 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 71.084 Acc@5 90.748
[2023-01-31 19:25:08 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 71.1%
[2023-01-31 19:25:09 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.224 (1.224)	Loss 1.3738 (1.3738)	Acc@1 70.508 (70.508)	Acc@5 89.160 (89.160)	Mem 17413MB
[2023-01-31 19:25:17 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 69.722 Acc@5 89.780
[2023-01-31 19:25:17 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 69.7%
[2023-01-31 19:25:17 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 71.08% at 31 epoch
[2023-01-31 19:25:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][0/1251]	eta 0:37:17 lr 0.000972	time 1.7884 (1.7884)	loss 3.6353 (3.6353)	grad_norm 1.4840 (1.4840)	mem 17413MB
[2023-01-31 19:25:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][50/1251]	eta 0:11:51 lr 0.000972	time 0.5566 (0.5922)	loss 3.9183 (3.8237)	grad_norm 1.1256 (1.2126)	mem 17413MB
[2023-01-31 19:26:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][100/1251]	eta 0:11:07 lr 0.000972	time 0.6206 (0.5797)	loss 3.9153 (3.8188)	grad_norm 1.0836 (1.1970)	mem 17413MB
[2023-01-31 19:26:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][150/1251]	eta 0:10:33 lr 0.000972	time 0.5555 (0.5752)	loss 4.5685 (3.8555)	grad_norm 1.1719 (1.2033)	mem 17413MB
[2023-01-31 19:27:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][200/1251]	eta 0:10:02 lr 0.000972	time 0.5559 (0.5730)	loss 3.6720 (3.8507)	grad_norm 1.1694 (1.2079)	mem 17413MB
[2023-01-31 19:27:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][250/1251]	eta 0:09:32 lr 0.000972	time 0.6197 (0.5719)	loss 3.7957 (3.8708)	grad_norm 1.0902 (1.2103)	mem 17413MB
[2023-01-31 19:28:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][300/1251]	eta 0:09:03 lr 0.000972	time 0.6374 (0.5712)	loss 3.9529 (3.8887)	grad_norm 1.3789 (1.2171)	mem 17413MB
[2023-01-31 19:28:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][350/1251]	eta 0:08:33 lr 0.000972	time 0.5602 (0.5701)	loss 4.7162 (3.8849)	grad_norm 1.2185 (1.2154)	mem 17413MB
[2023-01-31 19:29:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][400/1251]	eta 0:08:04 lr 0.000972	time 0.5620 (0.5693)	loss 3.1788 (3.8804)	grad_norm 1.3559 (1.2175)	mem 17413MB
[2023-01-31 19:29:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][450/1251]	eta 0:07:35 lr 0.000972	time 0.5538 (0.5689)	loss 4.6644 (3.8943)	grad_norm 1.3720 (1.2220)	mem 17413MB
[2023-01-31 19:30:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][500/1251]	eta 0:07:07 lr 0.000972	time 0.6094 (0.5688)	loss 4.1510 (3.9077)	grad_norm 1.2443 (1.2195)	mem 17413MB
[2023-01-31 19:30:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][550/1251]	eta 0:06:38 lr 0.000972	time 0.5507 (0.5683)	loss 2.8398 (3.8932)	grad_norm 1.4233 (1.2187)	mem 17413MB
[2023-01-31 19:30:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][600/1251]	eta 0:06:09 lr 0.000972	time 0.5589 (0.5681)	loss 2.9477 (3.8831)	grad_norm 1.1058 (1.2221)	mem 17413MB
[2023-01-31 19:31:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][650/1251]	eta 0:05:41 lr 0.000972	time 0.5622 (0.5679)	loss 2.6868 (3.8871)	grad_norm 1.1862 (1.2230)	mem 17413MB
[2023-01-31 19:31:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][700/1251]	eta 0:05:12 lr 0.000972	time 0.5608 (0.5677)	loss 3.9811 (3.8851)	grad_norm 1.1788 (1.2244)	mem 17413MB
[2023-01-31 19:32:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][750/1251]	eta 0:04:44 lr 0.000971	time 0.5564 (0.5677)	loss 4.1257 (3.8800)	grad_norm 1.1056 (1.2261)	mem 17413MB
[2023-01-31 19:32:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][800/1251]	eta 0:04:16 lr 0.000971	time 0.5550 (0.5676)	loss 3.9680 (3.8726)	grad_norm 1.1207 (1.2265)	mem 17413MB
[2023-01-31 19:33:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][850/1251]	eta 0:03:47 lr 0.000971	time 0.5515 (0.5676)	loss 4.1363 (3.8723)	grad_norm 1.1837 (1.2255)	mem 17413MB
[2023-01-31 19:33:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][900/1251]	eta 0:03:19 lr 0.000971	time 0.6208 (0.5675)	loss 4.1675 (3.8672)	grad_norm 1.2581 (1.2256)	mem 17413MB
[2023-01-31 19:34:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][950/1251]	eta 0:02:50 lr 0.000971	time 0.5633 (0.5674)	loss 4.7329 (3.8678)	grad_norm 1.5460 (1.2259)	mem 17413MB
[2023-01-31 19:34:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][1000/1251]	eta 0:02:22 lr 0.000971	time 0.5558 (0.5673)	loss 4.1387 (3.8729)	grad_norm 1.4966 (1.2239)	mem 17413MB
[2023-01-31 19:35:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][1050/1251]	eta 0:01:54 lr 0.000971	time 0.5579 (0.5672)	loss 2.8866 (3.8753)	grad_norm 1.6062 (1.2238)	mem 17413MB
[2023-01-31 19:35:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][1100/1251]	eta 0:01:25 lr 0.000971	time 0.5679 (0.5672)	loss 4.1466 (3.8826)	grad_norm 1.2829 (1.2240)	mem 17413MB
[2023-01-31 19:36:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][1150/1251]	eta 0:00:57 lr 0.000971	time 0.5544 (0.5671)	loss 3.9756 (3.8866)	grad_norm 1.1835 (1.2244)	mem 17413MB
[2023-01-31 19:36:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][1200/1251]	eta 0:00:28 lr 0.000971	time 0.5557 (0.5670)	loss 4.6230 (3.8834)	grad_norm 1.5157 (1.2256)	mem 17413MB
[2023-01-31 19:37:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [32/300][1250/1251]	eta 0:00:00 lr 0.000971	time 0.5512 (0.5669)	loss 4.7779 (3.8829)	grad_norm 1.1972 (1.2253)	mem 17413MB
[2023-01-31 19:37:06 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 32 training takes 0:11:49
[2023-01-31 19:37:07 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_32.pth saving......
[2023-01-31 19:37:08 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_32.pth saved !!!
[2023-01-31 19:37:09 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.870 (0.870)	Loss 1.2073 (1.2073)	Acc@1 70.801 (70.801)	Acc@5 92.285 (92.285)	Mem 17413MB
[2023-01-31 19:37:17 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 70.844 Acc@5 90.942
[2023-01-31 19:37:17 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 70.8%
[2023-01-31 19:37:18 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.234 (1.234)	Loss 1.3474 (1.3474)	Acc@1 70.703 (70.703)	Acc@5 89.062 (89.062)	Mem 17413MB
[2023-01-31 19:37:26 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 70.356 Acc@5 90.160
[2023-01-31 19:37:26 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 70.4%
[2023-01-31 19:37:26 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 71.08% at 31 epoch
[2023-01-31 19:37:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][0/1251]	eta 0:34:40 lr 0.000971	time 1.6628 (1.6628)	loss 4.4268 (4.4268)	grad_norm 1.1930 (1.1930)	mem 17413MB
[2023-01-31 19:37:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][50/1251]	eta 0:11:45 lr 0.000971	time 0.5586 (0.5876)	loss 3.4167 (3.8511)	grad_norm 1.1968 (1.2123)	mem 17413MB
[2023-01-31 19:38:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][100/1251]	eta 0:11:04 lr 0.000971	time 0.5548 (0.5776)	loss 4.0596 (3.8660)	grad_norm 1.1828 (1.2190)	mem 17413MB
[2023-01-31 19:38:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][150/1251]	eta 0:10:30 lr 0.000971	time 0.5528 (0.5723)	loss 3.5719 (3.8496)	grad_norm 1.2966 (1.2207)	mem 17413MB
[2023-01-31 19:39:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][200/1251]	eta 0:09:59 lr 0.000970	time 0.5545 (0.5707)	loss 3.1551 (3.8313)	grad_norm 1.1889 (1.2227)	mem 17413MB
[2023-01-31 19:39:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][250/1251]	eta 0:09:30 lr 0.000970	time 0.6400 (0.5697)	loss 4.0214 (3.8130)	grad_norm 1.2278 (1.2201)	mem 17413MB
[2023-01-31 19:40:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][300/1251]	eta 0:09:00 lr 0.000970	time 0.5710 (0.5683)	loss 4.5593 (3.8342)	grad_norm 1.0796 (1.2148)	mem 17413MB
[2023-01-31 19:40:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][350/1251]	eta 0:08:31 lr 0.000970	time 0.5543 (0.5679)	loss 3.1722 (3.8211)	grad_norm 1.1946 (1.2162)	mem 17413MB
[2023-01-31 19:41:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][400/1251]	eta 0:08:02 lr 0.000970	time 0.5533 (0.5674)	loss 3.2874 (3.8063)	grad_norm 1.3797 (1.2210)	mem 17413MB
[2023-01-31 19:41:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][450/1251]	eta 0:07:34 lr 0.000970	time 0.6108 (0.5674)	loss 4.2881 (3.8024)	grad_norm 1.1665 (1.2180)	mem 17413MB
[2023-01-31 19:42:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][500/1251]	eta 0:07:05 lr 0.000970	time 0.5565 (0.5672)	loss 3.8814 (3.7961)	grad_norm 1.1491 (1.2220)	mem 17413MB
[2023-01-31 19:42:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][550/1251]	eta 0:06:37 lr 0.000970	time 0.5589 (0.5669)	loss 4.9023 (3.8017)	grad_norm 1.1193 (1.2229)	mem 17413MB
[2023-01-31 19:43:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][600/1251]	eta 0:06:09 lr 0.000970	time 0.5618 (0.5669)	loss 3.5219 (3.7998)	grad_norm 1.1359 (1.2224)	mem 17413MB
[2023-01-31 19:43:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][650/1251]	eta 0:05:40 lr 0.000970	time 0.5588 (0.5666)	loss 3.9668 (3.8061)	grad_norm 1.2154 (1.2221)	mem 17413MB
[2023-01-31 19:44:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][700/1251]	eta 0:05:12 lr 0.000970	time 0.5557 (0.5665)	loss 4.6153 (3.8195)	grad_norm 1.2145 (1.2223)	mem 17413MB
[2023-01-31 19:44:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][750/1251]	eta 0:04:43 lr 0.000970	time 0.5581 (0.5664)	loss 4.4897 (3.8263)	grad_norm 1.3150 (nan)	mem 17413MB
[2023-01-31 19:45:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][800/1251]	eta 0:04:15 lr 0.000970	time 0.5554 (0.5664)	loss 2.9039 (3.8338)	grad_norm 1.2978 (nan)	mem 17413MB
[2023-01-31 19:45:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][850/1251]	eta 0:03:47 lr 0.000970	time 0.5581 (0.5663)	loss 3.6748 (3.8347)	grad_norm 1.1423 (nan)	mem 17413MB
[2023-01-31 19:45:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][900/1251]	eta 0:03:18 lr 0.000969	time 0.5549 (0.5663)	loss 3.1372 (3.8344)	grad_norm 1.1658 (nan)	mem 17413MB
[2023-01-31 19:46:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][950/1251]	eta 0:02:50 lr 0.000969	time 0.5610 (0.5661)	loss 4.6179 (3.8434)	grad_norm 1.1378 (nan)	mem 17413MB
[2023-01-31 19:46:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][1000/1251]	eta 0:02:22 lr 0.000969	time 0.5549 (0.5662)	loss 3.7834 (3.8420)	grad_norm 1.1335 (nan)	mem 17413MB
[2023-01-31 19:47:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][1050/1251]	eta 0:01:53 lr 0.000969	time 0.5576 (0.5662)	loss 4.1641 (3.8445)	grad_norm 1.0939 (nan)	mem 17413MB
[2023-01-31 19:47:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][1100/1251]	eta 0:01:25 lr 0.000969	time 0.5609 (0.5662)	loss 3.6489 (3.8408)	grad_norm 1.2925 (nan)	mem 17413MB
[2023-01-31 19:48:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][1150/1251]	eta 0:00:57 lr 0.000969	time 0.5607 (0.5661)	loss 2.4679 (3.8428)	grad_norm 1.1703 (nan)	mem 17413MB
[2023-01-31 19:48:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][1200/1251]	eta 0:00:28 lr 0.000969	time 0.5546 (0.5661)	loss 4.2637 (3.8404)	grad_norm 1.0928 (nan)	mem 17413MB
[2023-01-31 19:49:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [33/300][1250/1251]	eta 0:00:00 lr 0.000969	time 0.5574 (0.5661)	loss 3.8479 (3.8432)	grad_norm 1.1298 (nan)	mem 17413MB
[2023-01-31 19:49:15 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 33 training takes 0:11:48
[2023-01-31 19:49:15 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_33.pth saving......
[2023-01-31 19:49:17 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_33.pth saved !!!
[2023-01-31 19:49:18 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.857 (0.857)	Loss 1.1335 (1.1335)	Acc@1 73.730 (73.730)	Acc@5 92.188 (92.188)	Mem 17413MB
[2023-01-31 19:49:25 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 71.548 Acc@5 90.914
[2023-01-31 19:49:25 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 71.5%
[2023-01-31 19:49:27 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.192 (1.192)	Loss 1.2801 (1.2801)	Acc@1 71.582 (71.582)	Acc@5 90.625 (90.625)	Mem 17413MB
[2023-01-31 19:49:34 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 71.032 Acc@5 90.510
[2023-01-31 19:49:34 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 71.0%
[2023-01-31 19:49:34 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 71.55% at 33 epoch
[2023-01-31 19:49:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][0/1251]	eta 0:36:41 lr 0.000969	time 1.7601 (1.7601)	loss 3.9612 (3.9612)	grad_norm 1.1050 (1.1050)	mem 17413MB
[2023-01-31 19:50:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][50/1251]	eta 0:11:53 lr 0.000969	time 0.6418 (0.5941)	loss 3.7762 (3.7351)	grad_norm 1.2678 (1.2253)	mem 17413MB
[2023-01-31 19:50:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][100/1251]	eta 0:11:06 lr 0.000969	time 0.5599 (0.5788)	loss 4.1773 (3.7601)	grad_norm 1.1872 (1.2122)	mem 17413MB
[2023-01-31 19:51:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][150/1251]	eta 0:10:33 lr 0.000969	time 0.5600 (0.5750)	loss 5.0619 (3.7852)	grad_norm 1.2762 (1.2127)	mem 17413MB
[2023-01-31 19:51:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][200/1251]	eta 0:10:01 lr 0.000969	time 0.5513 (0.5720)	loss 4.4402 (3.7862)	grad_norm 1.2121 (1.2156)	mem 17413MB
[2023-01-31 19:51:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][250/1251]	eta 0:09:31 lr 0.000969	time 0.5532 (0.5710)	loss 4.4154 (3.7809)	grad_norm 1.2348 (1.2144)	mem 17413MB
[2023-01-31 19:52:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][300/1251]	eta 0:09:01 lr 0.000969	time 0.5513 (0.5695)	loss 4.2141 (3.7977)	grad_norm 1.1950 (1.2199)	mem 17413MB
[2023-01-31 19:52:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][350/1251]	eta 0:08:32 lr 0.000968	time 0.5558 (0.5692)	loss 4.0535 (3.8115)	grad_norm 1.1449 (1.2240)	mem 17413MB
[2023-01-31 19:53:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][400/1251]	eta 0:08:03 lr 0.000968	time 0.5542 (0.5683)	loss 3.4196 (3.8034)	grad_norm 1.2309 (1.2214)	mem 17413MB
[2023-01-31 19:53:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][450/1251]	eta 0:07:34 lr 0.000968	time 0.5515 (0.5680)	loss 3.0906 (3.7928)	grad_norm 1.2594 (1.2243)	mem 17413MB
[2023-01-31 19:54:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][500/1251]	eta 0:07:06 lr 0.000968	time 0.5574 (0.5677)	loss 4.1999 (3.7944)	grad_norm 1.2615 (1.2263)	mem 17413MB
[2023-01-31 19:54:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][550/1251]	eta 0:06:37 lr 0.000968	time 0.5590 (0.5674)	loss 4.4758 (3.8091)	grad_norm 1.2295 (1.2271)	mem 17413MB
[2023-01-31 19:55:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][600/1251]	eta 0:06:09 lr 0.000968	time 0.5648 (0.5673)	loss 3.1489 (3.8129)	grad_norm 1.2028 (1.2271)	mem 17413MB
[2023-01-31 19:55:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][650/1251]	eta 0:05:40 lr 0.000968	time 0.5558 (0.5671)	loss 3.6486 (3.8194)	grad_norm 1.1902 (1.2252)	mem 17413MB
[2023-01-31 19:56:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][700/1251]	eta 0:05:12 lr 0.000968	time 0.5586 (0.5669)	loss 4.1784 (3.8266)	grad_norm 1.1826 (1.2257)	mem 17413MB
[2023-01-31 19:56:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][750/1251]	eta 0:04:43 lr 0.000968	time 0.5623 (0.5668)	loss 3.4341 (3.8326)	grad_norm 1.2160 (1.2270)	mem 17413MB
[2023-01-31 19:57:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][800/1251]	eta 0:04:15 lr 0.000968	time 0.6227 (0.5667)	loss 3.9830 (3.8297)	grad_norm 1.1365 (1.2283)	mem 17413MB
[2023-01-31 19:57:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][850/1251]	eta 0:03:47 lr 0.000968	time 0.5561 (0.5663)	loss 4.7944 (3.8327)	grad_norm 1.2310 (1.2288)	mem 17413MB
[2023-01-31 19:58:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][900/1251]	eta 0:03:18 lr 0.000968	time 0.5638 (0.5664)	loss 4.1330 (3.8365)	grad_norm 1.1568 (1.2289)	mem 17413MB
[2023-01-31 19:58:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][950/1251]	eta 0:02:50 lr 0.000968	time 0.5696 (0.5663)	loss 4.0315 (3.8368)	grad_norm 1.2652 (1.2309)	mem 17413MB
[2023-01-31 19:59:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][1000/1251]	eta 0:02:22 lr 0.000967	time 0.5537 (0.5663)	loss 4.2510 (3.8283)	grad_norm 1.2064 (1.2294)	mem 17413MB
[2023-01-31 19:59:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][1050/1251]	eta 0:01:53 lr 0.000967	time 0.5532 (0.5662)	loss 2.6592 (3.8255)	grad_norm 1.2916 (1.2283)	mem 17413MB
[2023-01-31 19:59:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][1100/1251]	eta 0:01:25 lr 0.000967	time 0.5585 (0.5661)	loss 3.4711 (3.8245)	grad_norm 1.2316 (1.2278)	mem 17413MB
[2023-01-31 20:00:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][1150/1251]	eta 0:00:57 lr 0.000967	time 0.5533 (0.5660)	loss 3.4561 (3.8249)	grad_norm 1.3483 (1.2272)	mem 17413MB
[2023-01-31 20:00:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][1200/1251]	eta 0:00:28 lr 0.000967	time 0.6243 (0.5661)	loss 4.7605 (3.8248)	grad_norm 1.2789 (1.2280)	mem 17413MB
[2023-01-31 20:01:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [34/300][1250/1251]	eta 0:00:00 lr 0.000967	time 0.5507 (0.5660)	loss 4.3094 (3.8230)	grad_norm 1.0869 (1.2272)	mem 17413MB
[2023-01-31 20:01:23 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 34 training takes 0:11:48
[2023-01-31 20:01:23 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_34.pth saving......
[2023-01-31 20:01:25 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_34.pth saved !!!
[2023-01-31 20:01:26 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.840 (0.840)	Loss 1.1725 (1.1725)	Acc@1 71.777 (71.777)	Acc@5 92.188 (92.188)	Mem 17413MB
[2023-01-31 20:01:33 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 71.834 Acc@5 91.130
[2023-01-31 20:01:33 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 71.8%
[2023-01-31 20:01:35 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.164 (1.164)	Loss 1.2402 (1.2402)	Acc@1 71.777 (71.777)	Acc@5 90.820 (90.820)	Mem 17413MB
[2023-01-31 20:01:42 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 71.538 Acc@5 90.862
[2023-01-31 20:01:42 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 71.5%
[2023-01-31 20:01:42 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 71.83% at 34 epoch
[2023-01-31 20:01:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][0/1251]	eta 0:35:37 lr 0.000967	time 1.7090 (1.7090)	loss 4.3683 (4.3683)	grad_norm 1.2613 (1.2613)	mem 17413MB
[2023-01-31 20:02:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][50/1251]	eta 0:11:51 lr 0.000967	time 0.5590 (0.5922)	loss 2.9258 (3.8029)	grad_norm 1.5160 (1.2285)	mem 17413MB
[2023-01-31 20:02:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][100/1251]	eta 0:11:08 lr 0.000967	time 0.6187 (0.5810)	loss 2.5805 (3.7926)	grad_norm 1.1330 (1.2263)	mem 17413MB
[2023-01-31 20:03:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][150/1251]	eta 0:10:33 lr 0.000967	time 0.5533 (0.5752)	loss 4.0318 (3.8117)	grad_norm 1.2000 (nan)	mem 17413MB
[2023-01-31 20:03:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][200/1251]	eta 0:10:02 lr 0.000967	time 0.5562 (0.5737)	loss 2.9500 (3.8047)	grad_norm 1.1678 (nan)	mem 17413MB
[2023-01-31 20:04:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][250/1251]	eta 0:09:32 lr 0.000967	time 0.6184 (0.5721)	loss 3.5937 (3.8127)	grad_norm 1.3749 (nan)	mem 17413MB
[2023-01-31 20:04:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][300/1251]	eta 0:09:02 lr 0.000967	time 0.5592 (0.5707)	loss 4.4093 (3.8142)	grad_norm 1.2632 (nan)	mem 17413MB
[2023-01-31 20:05:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][350/1251]	eta 0:08:33 lr 0.000967	time 0.5617 (0.5702)	loss 3.2372 (3.8247)	grad_norm 1.1344 (nan)	mem 17413MB
[2023-01-31 20:05:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][400/1251]	eta 0:08:04 lr 0.000967	time 0.5517 (0.5694)	loss 4.3148 (3.8379)	grad_norm 1.3077 (nan)	mem 17413MB
[2023-01-31 20:05:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][450/1251]	eta 0:07:35 lr 0.000966	time 0.5547 (0.5690)	loss 3.5882 (3.8417)	grad_norm 1.1244 (nan)	mem 17413MB
[2023-01-31 20:06:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][500/1251]	eta 0:07:06 lr 0.000966	time 0.6206 (0.5685)	loss 3.8865 (3.8439)	grad_norm 1.2613 (nan)	mem 17413MB
[2023-01-31 20:06:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][550/1251]	eta 0:06:38 lr 0.000966	time 0.5552 (0.5680)	loss 3.2137 (3.8412)	grad_norm 1.1636 (nan)	mem 17413MB
[2023-01-31 20:07:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][600/1251]	eta 0:06:09 lr 0.000966	time 0.5529 (0.5678)	loss 3.6627 (3.8524)	grad_norm 1.1821 (nan)	mem 17413MB
[2023-01-31 20:07:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][650/1251]	eta 0:05:41 lr 0.000966	time 0.5603 (0.5676)	loss 3.9846 (3.8431)	grad_norm 1.2156 (nan)	mem 17413MB
[2023-01-31 20:08:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][700/1251]	eta 0:05:12 lr 0.000966	time 0.5566 (0.5674)	loss 4.0926 (3.8319)	grad_norm 1.1755 (nan)	mem 17413MB
[2023-01-31 20:08:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][750/1251]	eta 0:04:44 lr 0.000966	time 0.5593 (0.5673)	loss 2.6452 (3.8232)	grad_norm 1.3592 (nan)	mem 17413MB
[2023-01-31 20:09:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][800/1251]	eta 0:04:15 lr 0.000966	time 0.5572 (0.5671)	loss 4.1974 (3.8271)	grad_norm 1.2498 (nan)	mem 17413MB
[2023-01-31 20:09:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][850/1251]	eta 0:03:47 lr 0.000966	time 0.5543 (0.5668)	loss 3.8841 (3.8278)	grad_norm 1.0445 (nan)	mem 17413MB
[2023-01-31 20:10:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][900/1251]	eta 0:03:18 lr 0.000966	time 0.6185 (0.5668)	loss 3.3370 (3.8303)	grad_norm 1.1715 (nan)	mem 17413MB
[2023-01-31 20:10:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][950/1251]	eta 0:02:50 lr 0.000966	time 0.5549 (0.5667)	loss 4.4583 (3.8364)	grad_norm 1.1227 (nan)	mem 17413MB
[2023-01-31 20:11:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][1000/1251]	eta 0:02:22 lr 0.000966	time 0.5560 (0.5666)	loss 3.9164 (3.8362)	grad_norm 1.2241 (nan)	mem 17413MB
[2023-01-31 20:11:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][1050/1251]	eta 0:01:53 lr 0.000966	time 0.5587 (0.5665)	loss 3.3992 (3.8336)	grad_norm 1.1813 (nan)	mem 17413MB
[2023-01-31 20:12:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][1100/1251]	eta 0:01:25 lr 0.000965	time 0.5567 (0.5663)	loss 4.8885 (3.8279)	grad_norm 1.1110 (nan)	mem 17413MB
[2023-01-31 20:12:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][1150/1251]	eta 0:00:57 lr 0.000965	time 0.5566 (0.5664)	loss 4.0155 (3.8260)	grad_norm 1.2438 (nan)	mem 17413MB
[2023-01-31 20:13:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][1200/1251]	eta 0:00:28 lr 0.000965	time 0.5578 (0.5664)	loss 2.9735 (3.8260)	grad_norm 1.5262 (nan)	mem 17413MB
[2023-01-31 20:13:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [35/300][1250/1251]	eta 0:00:00 lr 0.000965	time 0.5520 (0.5662)	loss 4.0241 (3.8302)	grad_norm 1.2207 (nan)	mem 17413MB
[2023-01-31 20:13:31 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 35 training takes 0:11:48
[2023-01-31 20:13:31 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_35.pth saving......
[2023-01-31 20:13:33 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_35.pth saved !!!
[2023-01-31 20:13:34 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.938 (0.938)	Loss 1.2074 (1.2074)	Acc@1 72.168 (72.168)	Acc@5 91.211 (91.211)	Mem 17413MB
[2023-01-31 20:13:42 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 71.986 Acc@5 91.232
[2023-01-31 20:13:42 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 72.0%
[2023-01-31 20:13:43 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.328 (1.328)	Loss 1.2387 (1.2387)	Acc@1 71.484 (71.484)	Acc@5 90.723 (90.723)	Mem 17413MB
[2023-01-31 20:13:51 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 72.060 Acc@5 91.150
[2023-01-31 20:13:51 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 72.1%
[2023-01-31 20:13:51 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 72.06% at 35 epoch
[2023-01-31 20:13:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][0/1251]	eta 0:37:55 lr 0.000965	time 1.8191 (1.8191)	loss 4.1339 (4.1339)	grad_norm 1.1615 (1.1615)	mem 17413MB
[2023-01-31 20:14:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][50/1251]	eta 0:11:50 lr 0.000965	time 0.5570 (0.5918)	loss 4.4249 (3.9167)	grad_norm 1.2794 (1.2206)	mem 17413MB
[2023-01-31 20:14:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][100/1251]	eta 0:11:04 lr 0.000965	time 0.6248 (0.5777)	loss 3.9900 (3.8874)	grad_norm 1.2058 (1.2205)	mem 17413MB
[2023-01-31 20:15:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][150/1251]	eta 0:10:32 lr 0.000965	time 0.5470 (0.5743)	loss 3.5248 (3.8769)	grad_norm 1.1233 (1.2107)	mem 17413MB
[2023-01-31 20:15:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][200/1251]	eta 0:10:00 lr 0.000965	time 0.5523 (0.5716)	loss 4.4488 (3.8524)	grad_norm 1.2493 (1.2157)	mem 17413MB
[2023-01-31 20:16:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][250/1251]	eta 0:09:31 lr 0.000965	time 0.5554 (0.5709)	loss 3.7562 (3.8443)	grad_norm 1.2157 (1.2208)	mem 17413MB
[2023-01-31 20:16:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][300/1251]	eta 0:09:01 lr 0.000965	time 0.5640 (0.5697)	loss 4.1331 (3.8435)	grad_norm 1.2632 (1.2203)	mem 17413MB
[2023-01-31 20:17:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][350/1251]	eta 0:08:32 lr 0.000965	time 0.5709 (0.5693)	loss 3.8199 (3.8239)	grad_norm 1.1882 (1.2260)	mem 17413MB
[2023-01-31 20:17:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][400/1251]	eta 0:08:03 lr 0.000965	time 0.5564 (0.5685)	loss 4.1634 (3.8262)	grad_norm 1.2468 (1.2262)	mem 17413MB
[2023-01-31 20:18:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][450/1251]	eta 0:07:35 lr 0.000965	time 0.6177 (0.5686)	loss 5.0291 (3.8280)	grad_norm 1.3220 (1.2313)	mem 17413MB
[2023-01-31 20:18:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][500/1251]	eta 0:07:06 lr 0.000964	time 0.5572 (0.5676)	loss 3.5650 (3.8045)	grad_norm 1.1240 (1.2343)	mem 17413MB
[2023-01-31 20:19:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][550/1251]	eta 0:06:37 lr 0.000964	time 0.5539 (0.5676)	loss 4.3580 (3.8040)	grad_norm 1.4864 (1.2332)	mem 17413MB
[2023-01-31 20:19:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][600/1251]	eta 0:06:09 lr 0.000964	time 0.5641 (0.5674)	loss 4.4243 (3.8073)	grad_norm 1.2173 (1.2326)	mem 17413MB
[2023-01-31 20:20:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][650/1251]	eta 0:05:40 lr 0.000964	time 0.5611 (0.5671)	loss 4.1348 (3.8107)	grad_norm 1.3056 (1.2342)	mem 17413MB
[2023-01-31 20:20:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][700/1251]	eta 0:05:12 lr 0.000964	time 0.5526 (0.5669)	loss 3.9644 (3.8119)	grad_norm 1.1543 (1.2324)	mem 17413MB
[2023-01-31 20:20:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][750/1251]	eta 0:04:43 lr 0.000964	time 0.6436 (0.5669)	loss 4.1281 (3.8136)	grad_norm 1.1013 (1.2302)	mem 17413MB
[2023-01-31 20:21:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][800/1251]	eta 0:04:15 lr 0.000964	time 0.5526 (0.5668)	loss 3.5364 (3.8130)	grad_norm 1.1906 (1.2314)	mem 17413MB
[2023-01-31 20:21:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][850/1251]	eta 0:03:47 lr 0.000964	time 0.5571 (0.5667)	loss 4.1338 (3.8023)	grad_norm 1.1415 (1.2317)	mem 17413MB
[2023-01-31 20:22:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][900/1251]	eta 0:03:18 lr 0.000964	time 0.5614 (0.5665)	loss 3.1225 (3.8042)	grad_norm 1.1691 (1.2320)	mem 17413MB
[2023-01-31 20:22:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][950/1251]	eta 0:02:50 lr 0.000964	time 0.5569 (0.5664)	loss 4.0844 (3.8097)	grad_norm 1.1249 (1.2320)	mem 17413MB
[2023-01-31 20:23:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][1000/1251]	eta 0:02:22 lr 0.000964	time 0.5672 (0.5665)	loss 3.1574 (3.8103)	grad_norm 1.2797 (1.2319)	mem 17413MB
[2023-01-31 20:23:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][1050/1251]	eta 0:01:53 lr 0.000964	time 0.5615 (0.5664)	loss 3.0768 (3.8091)	grad_norm 1.1363 (1.2324)	mem 17413MB
[2023-01-31 20:24:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][1100/1251]	eta 0:01:25 lr 0.000964	time 0.5565 (0.5664)	loss 3.5164 (3.8079)	grad_norm 1.1799 (1.2310)	mem 17413MB
[2023-01-31 20:24:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][1150/1251]	eta 0:00:57 lr 0.000963	time 0.6302 (0.5663)	loss 4.6301 (3.8121)	grad_norm 1.3923 (1.2293)	mem 17413MB
[2023-01-31 20:25:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][1200/1251]	eta 0:00:28 lr 0.000963	time 0.5611 (0.5662)	loss 3.9749 (3.8160)	grad_norm 1.1246 (1.2295)	mem 17413MB
[2023-01-31 20:25:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [36/300][1250/1251]	eta 0:00:00 lr 0.000963	time 0.5556 (0.5662)	loss 4.0279 (3.8140)	grad_norm 1.1731 (1.2282)	mem 17413MB
[2023-01-31 20:25:39 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 36 training takes 0:11:48
[2023-01-31 20:25:40 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_36.pth saving......
[2023-01-31 20:25:41 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_36.pth saved !!!
[2023-01-31 20:25:42 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.888 (0.888)	Loss 1.1136 (1.1136)	Acc@1 74.512 (74.512)	Acc@5 92.871 (92.871)	Mem 17413MB
[2023-01-31 20:25:50 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 72.390 Acc@5 91.594
[2023-01-31 20:25:50 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 72.4%
[2023-01-31 20:25:51 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.353 (1.353)	Loss 1.1187 (1.1187)	Acc@1 73.828 (73.828)	Acc@5 92.773 (92.773)	Mem 17413MB
[2023-01-31 20:25:59 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 72.490 Acc@5 91.420
[2023-01-31 20:25:59 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 72.5%
[2023-01-31 20:25:59 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 72.49% at 36 epoch
[2023-01-31 20:26:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][0/1251]	eta 0:36:18 lr 0.000963	time 1.7411 (1.7411)	loss 3.6738 (3.6738)	grad_norm 1.0799 (1.0799)	mem 17413MB
[2023-01-31 20:26:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][50/1251]	eta 0:11:47 lr 0.000963	time 0.5641 (0.5893)	loss 4.4821 (3.9131)	grad_norm 1.2311 (1.2344)	mem 17413MB
[2023-01-31 20:26:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][100/1251]	eta 0:11:05 lr 0.000963	time 0.5631 (0.5786)	loss 4.1154 (3.8750)	grad_norm 1.3918 (1.2253)	mem 17413MB
[2023-01-31 20:27:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][150/1251]	eta 0:10:33 lr 0.000963	time 0.5583 (0.5756)	loss 3.9150 (3.8550)	grad_norm 1.2863 (1.2245)	mem 17413MB
[2023-01-31 20:27:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][200/1251]	eta 0:10:03 lr 0.000963	time 0.5600 (0.5743)	loss 4.0650 (3.8360)	grad_norm 1.2820 (1.2324)	mem 17413MB
[2023-01-31 20:28:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][250/1251]	eta 0:09:33 lr 0.000963	time 0.5552 (0.5725)	loss 2.7663 (3.8105)	grad_norm 1.1521 (1.2330)	mem 17413MB
[2023-01-31 20:28:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][300/1251]	eta 0:09:03 lr 0.000963	time 0.5707 (0.5718)	loss 3.0800 (3.8180)	grad_norm 1.0931 (1.2327)	mem 17413MB
[2023-01-31 20:29:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][350/1251]	eta 0:08:34 lr 0.000963	time 0.5466 (0.5707)	loss 4.4976 (3.8258)	grad_norm 1.2611 (1.2291)	mem 17413MB
[2023-01-31 20:29:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][400/1251]	eta 0:08:05 lr 0.000963	time 0.5548 (0.5702)	loss 4.1021 (3.8136)	grad_norm 1.2136 (1.2300)	mem 17413MB
[2023-01-31 20:30:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][450/1251]	eta 0:07:36 lr 0.000963	time 0.5480 (0.5699)	loss 3.7464 (3.8010)	grad_norm 1.1920 (1.2341)	mem 17413MB
[2023-01-31 20:30:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][500/1251]	eta 0:07:07 lr 0.000963	time 0.5579 (0.5695)	loss 3.2341 (3.8018)	grad_norm 1.2092 (1.2313)	mem 17413MB
[2023-01-31 20:31:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][550/1251]	eta 0:06:38 lr 0.000962	time 0.5525 (0.5690)	loss 4.0456 (3.8125)	grad_norm 1.2315 (1.2292)	mem 17413MB
[2023-01-31 20:31:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][600/1251]	eta 0:06:10 lr 0.000962	time 0.5539 (0.5689)	loss 4.7444 (3.8062)	grad_norm 1.1950 (1.2309)	mem 17413MB
[2023-01-31 20:32:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][650/1251]	eta 0:05:41 lr 0.000962	time 0.5805 (0.5685)	loss 4.1434 (3.8039)	grad_norm 1.2026 (1.2296)	mem 17413MB
[2023-01-31 20:32:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][700/1251]	eta 0:05:13 lr 0.000962	time 0.5516 (0.5684)	loss 3.0029 (3.8050)	grad_norm 1.2760 (1.2302)	mem 17413MB
[2023-01-31 20:33:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][750/1251]	eta 0:04:44 lr 0.000962	time 0.5544 (0.5681)	loss 3.3875 (3.8145)	grad_norm 1.1370 (1.2317)	mem 17413MB
[2023-01-31 20:33:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][800/1251]	eta 0:04:16 lr 0.000962	time 0.6170 (0.5683)	loss 3.7467 (3.8094)	grad_norm 1.7440 (1.2325)	mem 17413MB
[2023-01-31 20:34:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][850/1251]	eta 0:03:47 lr 0.000962	time 0.6244 (0.5679)	loss 4.0801 (3.8042)	grad_norm 1.2642 (1.2340)	mem 17413MB
[2023-01-31 20:34:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][900/1251]	eta 0:03:19 lr 0.000962	time 0.6211 (0.5678)	loss 4.0455 (3.8064)	grad_norm 1.3076 (1.2321)	mem 17413MB
[2023-01-31 20:34:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][950/1251]	eta 0:02:50 lr 0.000962	time 0.5668 (0.5676)	loss 4.0523 (3.8060)	grad_norm 1.2791 (1.2319)	mem 17413MB
[2023-01-31 20:35:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][1000/1251]	eta 0:02:22 lr 0.000962	time 0.6106 (0.5677)	loss 3.8182 (3.8070)	grad_norm 1.2007 (1.2318)	mem 17413MB
[2023-01-31 20:35:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][1050/1251]	eta 0:01:54 lr 0.000962	time 0.5532 (0.5676)	loss 4.1937 (3.8062)	grad_norm 1.3223 (1.2335)	mem 17413MB
[2023-01-31 20:36:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][1100/1251]	eta 0:01:25 lr 0.000962	time 0.5603 (0.5677)	loss 4.8450 (3.8087)	grad_norm 1.3797 (1.2327)	mem 17413MB
[2023-01-31 20:36:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][1150/1251]	eta 0:00:57 lr 0.000961	time 0.5522 (0.5675)	loss 4.2513 (3.8123)	grad_norm 1.2187 (1.2341)	mem 17413MB
[2023-01-31 20:37:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][1200/1251]	eta 0:00:28 lr 0.000961	time 0.6282 (0.5674)	loss 4.0974 (3.8135)	grad_norm 1.1357 (1.2344)	mem 17413MB
[2023-01-31 20:37:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [37/300][1250/1251]	eta 0:00:00 lr 0.000961	time 0.5503 (0.5675)	loss 3.8929 (3.8130)	grad_norm 1.0600 (1.2345)	mem 17413MB
[2023-01-31 20:37:49 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 37 training takes 0:11:50
[2023-01-31 20:37:50 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_37.pth saving......
[2023-01-31 20:37:51 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_37.pth saved !!!
[2023-01-31 20:37:52 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.816 (0.816)	Loss 1.2162 (1.2162)	Acc@1 72.656 (72.656)	Acc@5 91.602 (91.602)	Mem 17413MB
[2023-01-31 20:38:00 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 72.372 Acc@5 91.534
[2023-01-31 20:38:00 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 72.4%
[2023-01-31 20:38:01 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.224 (1.224)	Loss 1.1496 (1.1496)	Acc@1 73.438 (73.438)	Acc@5 90.723 (90.723)	Mem 17413MB
[2023-01-31 20:38:09 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 72.920 Acc@5 91.616
[2023-01-31 20:38:09 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 72.9%
[2023-01-31 20:38:09 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 72.92% at 37 epoch
[2023-01-31 20:38:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][0/1251]	eta 0:34:42 lr 0.000961	time 1.6644 (1.6644)	loss 3.8264 (3.8264)	grad_norm 1.1776 (1.1776)	mem 17413MB
[2023-01-31 20:38:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][50/1251]	eta 0:11:50 lr 0.000961	time 0.5556 (0.5918)	loss 3.6193 (3.7041)	grad_norm 1.2213 (1.2460)	mem 17413MB
[2023-01-31 20:39:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][100/1251]	eta 0:11:06 lr 0.000961	time 0.6314 (0.5793)	loss 2.9215 (3.7476)	grad_norm 1.3837 (1.2317)	mem 17413MB
[2023-01-31 20:39:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][150/1251]	eta 0:10:32 lr 0.000961	time 0.5569 (0.5744)	loss 3.7312 (3.7735)	grad_norm 1.1345 (1.2299)	mem 17413MB
[2023-01-31 20:40:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][200/1251]	eta 0:10:01 lr 0.000961	time 0.6384 (0.5723)	loss 3.4137 (3.7856)	grad_norm 1.1947 (1.2309)	mem 17413MB
[2023-01-31 20:40:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][250/1251]	eta 0:09:31 lr 0.000961	time 0.5582 (0.5709)	loss 4.9933 (3.8159)	grad_norm 1.2171 (1.2324)	mem 17413MB
[2023-01-31 20:41:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][300/1251]	eta 0:09:02 lr 0.000961	time 0.5594 (0.5702)	loss 3.5219 (3.8121)	grad_norm 1.3404 (1.2351)	mem 17413MB
[2023-01-31 20:41:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][350/1251]	eta 0:08:32 lr 0.000961	time 0.5571 (0.5692)	loss 3.3456 (3.8189)	grad_norm 1.1244 (1.2385)	mem 17413MB
[2023-01-31 20:41:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][400/1251]	eta 0:08:03 lr 0.000961	time 0.5505 (0.5684)	loss 4.9896 (3.8202)	grad_norm 1.3164 (nan)	mem 17413MB
[2023-01-31 20:42:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][450/1251]	eta 0:07:35 lr 0.000961	time 0.5633 (0.5682)	loss 4.0703 (3.8147)	grad_norm 1.0799 (nan)	mem 17413MB
[2023-01-31 20:42:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][500/1251]	eta 0:07:06 lr 0.000961	time 0.6254 (0.5681)	loss 4.0585 (3.8222)	grad_norm 1.2009 (nan)	mem 17413MB
[2023-01-31 20:43:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][550/1251]	eta 0:06:38 lr 0.000960	time 0.5571 (0.5679)	loss 2.7176 (3.8146)	grad_norm 1.2132 (nan)	mem 17413MB
[2023-01-31 20:43:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][600/1251]	eta 0:06:09 lr 0.000960	time 0.5587 (0.5677)	loss 4.3311 (3.8087)	grad_norm 1.0504 (nan)	mem 17413MB
[2023-01-31 20:44:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][650/1251]	eta 0:05:41 lr 0.000960	time 0.5616 (0.5676)	loss 4.6561 (3.8106)	grad_norm 1.1420 (nan)	mem 17413MB
[2023-01-31 20:44:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][700/1251]	eta 0:05:12 lr 0.000960	time 0.5490 (0.5675)	loss 4.6307 (3.8161)	grad_norm 1.2613 (nan)	mem 17413MB
[2023-01-31 20:45:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][750/1251]	eta 0:04:44 lr 0.000960	time 0.5655 (0.5672)	loss 4.6202 (3.8192)	grad_norm 1.2889 (nan)	mem 17413MB
[2023-01-31 20:45:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][800/1251]	eta 0:04:15 lr 0.000960	time 0.5552 (0.5672)	loss 3.5080 (3.8092)	grad_norm 1.1794 (nan)	mem 17413MB
[2023-01-31 20:46:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][850/1251]	eta 0:03:47 lr 0.000960	time 0.5551 (0.5671)	loss 3.9320 (3.8109)	grad_norm 1.2870 (nan)	mem 17413MB
[2023-01-31 20:46:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][900/1251]	eta 0:03:19 lr 0.000960	time 0.6259 (0.5673)	loss 4.2584 (3.8175)	grad_norm 1.1123 (nan)	mem 17413MB
[2023-01-31 20:47:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][950/1251]	eta 0:02:50 lr 0.000960	time 0.5592 (0.5671)	loss 4.7809 (3.8165)	grad_norm 1.2695 (nan)	mem 17413MB
[2023-01-31 20:47:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][1000/1251]	eta 0:02:22 lr 0.000960	time 0.5602 (0.5671)	loss 4.5297 (3.8133)	grad_norm 1.1949 (nan)	mem 17413MB
[2023-01-31 20:48:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][1050/1251]	eta 0:01:53 lr 0.000960	time 0.5571 (0.5669)	loss 4.2341 (3.8126)	grad_norm 1.2623 (nan)	mem 17413MB
[2023-01-31 20:48:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][1100/1251]	eta 0:01:25 lr 0.000960	time 0.6497 (0.5669)	loss 2.6047 (3.8100)	grad_norm 1.3020 (nan)	mem 17413MB
[2023-01-31 20:49:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][1150/1251]	eta 0:00:57 lr 0.000959	time 0.5530 (0.5668)	loss 4.6254 (3.8083)	grad_norm 1.1494 (nan)	mem 17413MB
[2023-01-31 20:49:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][1200/1251]	eta 0:00:28 lr 0.000959	time 0.5512 (0.5668)	loss 3.4064 (3.8026)	grad_norm 1.2376 (nan)	mem 17413MB
[2023-01-31 20:49:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [38/300][1250/1251]	eta 0:00:00 lr 0.000959	time 0.5504 (0.5668)	loss 4.7301 (3.8029)	grad_norm 1.1737 (nan)	mem 17413MB
[2023-01-31 20:49:58 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 38 training takes 0:11:49
[2023-01-31 20:49:58 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_38.pth saving......
[2023-01-31 20:50:00 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_38.pth saved !!!
[2023-01-31 20:50:01 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.848 (0.848)	Loss 1.2088 (1.2088)	Acc@1 72.949 (72.949)	Acc@5 90.234 (90.234)	Mem 17413MB
[2023-01-31 20:50:09 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 72.446 Acc@5 91.448
[2023-01-31 20:50:09 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 72.4%
[2023-01-31 20:50:10 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.254 (1.254)	Loss 1.2535 (1.2535)	Acc@1 70.508 (70.508)	Acc@5 88.965 (88.965)	Mem 17413MB
[2023-01-31 20:50:18 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 73.296 Acc@5 91.868
[2023-01-31 20:50:18 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 73.3%
[2023-01-31 20:50:18 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 73.30% at 38 epoch
[2023-01-31 20:50:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][0/1251]	eta 0:34:35 lr 0.000959	time 1.6587 (1.6587)	loss 3.4990 (3.4990)	grad_norm 1.1929 (1.1929)	mem 17413MB
[2023-01-31 20:50:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][50/1251]	eta 0:11:45 lr 0.000959	time 0.5509 (0.5878)	loss 3.9736 (3.7342)	grad_norm 1.3296 (1.2281)	mem 17413MB
[2023-01-31 20:51:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][100/1251]	eta 0:11:04 lr 0.000959	time 0.5523 (0.5773)	loss 3.5220 (3.7733)	grad_norm 1.3642 (1.2323)	mem 17413MB
[2023-01-31 20:51:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][150/1251]	eta 0:10:31 lr 0.000959	time 0.5555 (0.5738)	loss 4.4545 (3.8346)	grad_norm 1.2357 (1.2235)	mem 17413MB
[2023-01-31 20:52:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][200/1251]	eta 0:10:00 lr 0.000959	time 0.6336 (0.5715)	loss 2.8966 (3.8222)	grad_norm 1.1201 (1.2313)	mem 17413MB
[2023-01-31 20:52:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][250/1251]	eta 0:09:31 lr 0.000959	time 0.5614 (0.5705)	loss 3.9486 (3.8087)	grad_norm 1.1062 (1.2226)	mem 17413MB
[2023-01-31 20:53:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][300/1251]	eta 0:09:01 lr 0.000959	time 0.5711 (0.5697)	loss 4.6795 (3.8074)	grad_norm 1.3292 (1.2271)	mem 17413MB
[2023-01-31 20:53:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][350/1251]	eta 0:08:32 lr 0.000959	time 0.5832 (0.5692)	loss 3.8917 (3.8095)	grad_norm 1.1241 (1.2262)	mem 17413MB
[2023-01-31 20:54:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][400/1251]	eta 0:08:04 lr 0.000959	time 0.5603 (0.5689)	loss 4.4113 (3.8111)	grad_norm 1.1274 (1.2253)	mem 17413MB
[2023-01-31 20:54:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][450/1251]	eta 0:07:35 lr 0.000959	time 0.6289 (0.5687)	loss 3.2229 (3.8082)	grad_norm 1.2660 (1.2221)	mem 17413MB
[2023-01-31 20:55:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][500/1251]	eta 0:07:06 lr 0.000958	time 0.5620 (0.5683)	loss 4.2891 (3.8028)	grad_norm 1.1914 (1.2215)	mem 17413MB
[2023-01-31 20:55:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][550/1251]	eta 0:06:38 lr 0.000958	time 0.5536 (0.5682)	loss 3.7388 (3.7966)	grad_norm 1.3477 (1.2217)	mem 17413MB
[2023-01-31 20:55:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][600/1251]	eta 0:06:09 lr 0.000958	time 0.5616 (0.5678)	loss 4.0797 (3.8077)	grad_norm 1.2395 (1.2237)	mem 17413MB
[2023-01-31 20:56:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][650/1251]	eta 0:05:41 lr 0.000958	time 0.5463 (0.5677)	loss 3.4484 (3.8107)	grad_norm 1.3142 (1.2244)	mem 17413MB
[2023-01-31 20:56:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][700/1251]	eta 0:05:12 lr 0.000958	time 0.5588 (0.5675)	loss 3.2106 (3.8000)	grad_norm 1.2606 (1.2249)	mem 17413MB
[2023-01-31 20:57:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][750/1251]	eta 0:04:44 lr 0.000958	time 0.5574 (0.5672)	loss 4.4257 (3.7987)	grad_norm 1.2080 (nan)	mem 17413MB
[2023-01-31 20:57:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][800/1251]	eta 0:04:15 lr 0.000958	time 0.5592 (0.5672)	loss 4.2521 (3.7948)	grad_norm 1.1788 (nan)	mem 17413MB
[2023-01-31 20:58:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][850/1251]	eta 0:03:47 lr 0.000958	time 0.5550 (0.5671)	loss 2.9153 (3.7906)	grad_norm 1.2369 (nan)	mem 17413MB
[2023-01-31 20:58:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][900/1251]	eta 0:03:19 lr 0.000958	time 0.5556 (0.5671)	loss 3.9729 (3.7914)	grad_norm 1.2419 (nan)	mem 17413MB
[2023-01-31 20:59:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][950/1251]	eta 0:02:50 lr 0.000958	time 0.5541 (0.5668)	loss 3.9384 (3.7877)	grad_norm 1.3559 (nan)	mem 17413MB
[2023-01-31 20:59:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][1000/1251]	eta 0:02:22 lr 0.000958	time 0.5612 (0.5668)	loss 3.3896 (3.7862)	grad_norm 1.1390 (nan)	mem 17413MB
[2023-01-31 21:00:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][1050/1251]	eta 0:01:53 lr 0.000958	time 0.5594 (0.5668)	loss 2.8277 (3.7871)	grad_norm 1.2421 (nan)	mem 17413MB
[2023-01-31 21:00:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][1100/1251]	eta 0:01:25 lr 0.000957	time 0.5569 (0.5668)	loss 3.6390 (3.7900)	grad_norm 1.1411 (nan)	mem 17413MB
[2023-01-31 21:01:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][1150/1251]	eta 0:00:57 lr 0.000957	time 0.5547 (0.5666)	loss 3.9979 (3.7941)	grad_norm 1.2328 (nan)	mem 17413MB
[2023-01-31 21:01:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][1200/1251]	eta 0:00:28 lr 0.000957	time 0.5561 (0.5667)	loss 3.9358 (3.7958)	grad_norm 1.1485 (nan)	mem 17413MB
[2023-01-31 21:02:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [39/300][1250/1251]	eta 0:00:00 lr 0.000957	time 0.5522 (0.5665)	loss 3.0618 (3.7865)	grad_norm 1.2297 (nan)	mem 17413MB
[2023-01-31 21:02:07 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 39 training takes 0:11:48
[2023-01-31 21:02:07 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_39.pth saving......
[2023-01-31 21:02:09 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_39.pth saved !!!
[2023-01-31 21:02:10 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.837 (0.837)	Loss 1.1229 (1.1229)	Acc@1 73.047 (73.047)	Acc@5 91.699 (91.699)	Mem 17413MB
[2023-01-31 21:02:18 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 72.750 Acc@5 91.772
[2023-01-31 21:02:18 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 72.7%
[2023-01-31 21:02:19 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.139 (1.139)	Loss 1.1103 (1.1103)	Acc@1 74.121 (74.121)	Acc@5 92.871 (92.871)	Mem 17413MB
[2023-01-31 21:02:27 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 73.620 Acc@5 92.084
[2023-01-31 21:02:27 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 73.6%
[2023-01-31 21:02:27 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 73.62% at 39 epoch
[2023-01-31 21:02:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][0/1251]	eta 0:34:27 lr 0.000957	time 1.6528 (1.6528)	loss 2.7035 (2.7035)	grad_norm 1.2992 (1.2992)	mem 17413MB
[2023-01-31 21:02:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][50/1251]	eta 0:11:43 lr 0.000957	time 0.5645 (0.5854)	loss 2.7037 (3.8136)	grad_norm 1.3586 (1.2240)	mem 17413MB
[2023-01-31 21:03:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][100/1251]	eta 0:11:05 lr 0.000957	time 0.5546 (0.5782)	loss 4.5396 (3.6994)	grad_norm 1.1949 (1.2357)	mem 17413MB
[2023-01-31 21:03:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][150/1251]	eta 0:10:32 lr 0.000957	time 0.6401 (0.5744)	loss 3.9551 (3.7302)	grad_norm 1.2734 (1.2353)	mem 17413MB
[2023-01-31 21:04:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][200/1251]	eta 0:10:02 lr 0.000957	time 0.5545 (0.5731)	loss 3.2542 (3.7237)	grad_norm 1.2040 (1.2370)	mem 17413MB
[2023-01-31 21:04:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][250/1251]	eta 0:09:32 lr 0.000957	time 0.5563 (0.5717)	loss 4.1221 (3.7375)	grad_norm 1.2519 (1.2331)	mem 17413MB
[2023-01-31 21:05:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][300/1251]	eta 0:09:02 lr 0.000957	time 0.6299 (0.5709)	loss 4.4400 (3.7296)	grad_norm 1.2063 (1.2341)	mem 17413MB
[2023-01-31 21:05:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][350/1251]	eta 0:08:33 lr 0.000957	time 0.5572 (0.5701)	loss 3.0926 (3.7361)	grad_norm 1.2603 (1.2317)	mem 17413MB
[2023-01-31 21:06:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][400/1251]	eta 0:08:04 lr 0.000957	time 0.6091 (0.5695)	loss 4.5555 (3.7778)	grad_norm 1.2487 (1.2319)	mem 17413MB
[2023-01-31 21:06:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][450/1251]	eta 0:07:35 lr 0.000956	time 0.5598 (0.5691)	loss 3.4385 (3.7814)	grad_norm 1.2101 (1.2334)	mem 17413MB
[2023-01-31 21:07:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][500/1251]	eta 0:07:07 lr 0.000956	time 0.5575 (0.5687)	loss 4.4186 (3.7858)	grad_norm 1.4356 (1.2357)	mem 17413MB
[2023-01-31 21:07:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][550/1251]	eta 0:06:38 lr 0.000956	time 0.5547 (0.5684)	loss 4.2988 (3.7921)	grad_norm 1.2145 (1.2348)	mem 17413MB
[2023-01-31 21:08:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][600/1251]	eta 0:06:09 lr 0.000956	time 0.5520 (0.5683)	loss 3.8627 (3.7740)	grad_norm 1.1429 (1.2347)	mem 17413MB
[2023-01-31 21:08:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][650/1251]	eta 0:05:41 lr 0.000956	time 0.5514 (0.5682)	loss 4.2273 (3.7767)	grad_norm 1.2265 (1.2350)	mem 17413MB
[2023-01-31 21:09:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][700/1251]	eta 0:05:12 lr 0.000956	time 0.5521 (0.5679)	loss 3.6801 (3.7833)	grad_norm 1.2316 (1.2344)	mem 17413MB
[2023-01-31 21:09:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][750/1251]	eta 0:04:44 lr 0.000956	time 0.5498 (0.5678)	loss 3.9075 (3.7692)	grad_norm 1.2710 (1.2354)	mem 17413MB
[2023-01-31 21:10:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][800/1251]	eta 0:04:16 lr 0.000956	time 0.6282 (0.5678)	loss 3.4521 (3.7668)	grad_norm 1.0948 (1.2350)	mem 17413MB
[2023-01-31 21:10:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][850/1251]	eta 0:03:47 lr 0.000956	time 0.5559 (0.5676)	loss 2.7790 (3.7776)	grad_norm 1.1173 (1.2358)	mem 17413MB
[2023-01-31 21:10:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][900/1251]	eta 0:03:19 lr 0.000956	time 0.5602 (0.5676)	loss 4.5013 (3.7828)	grad_norm 1.3802 (1.2352)	mem 17413MB
[2023-01-31 21:11:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][950/1251]	eta 0:02:50 lr 0.000956	time 0.5564 (0.5675)	loss 3.9969 (3.7788)	grad_norm 1.2414 (1.2349)	mem 17413MB
[2023-01-31 21:11:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][1000/1251]	eta 0:02:22 lr 0.000956	time 0.6098 (0.5676)	loss 3.7396 (3.7808)	grad_norm 1.3851 (1.2347)	mem 17413MB
[2023-01-31 21:12:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][1050/1251]	eta 0:01:54 lr 0.000955	time 0.5702 (0.5676)	loss 4.0528 (3.7808)	grad_norm 1.2815 (1.2355)	mem 17413MB
[2023-01-31 21:12:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][1100/1251]	eta 0:01:25 lr 0.000955	time 0.5734 (0.5673)	loss 3.6227 (3.7757)	grad_norm 1.2033 (1.2348)	mem 17413MB
[2023-01-31 21:13:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][1150/1251]	eta 0:00:57 lr 0.000955	time 0.5558 (0.5675)	loss 3.6495 (3.7760)	grad_norm 1.2075 (1.2348)	mem 17413MB
[2023-01-31 21:13:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][1200/1251]	eta 0:00:28 lr 0.000955	time 0.6317 (0.5674)	loss 4.4100 (3.7667)	grad_norm 1.2617 (1.2342)	mem 17413MB
[2023-01-31 21:14:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [40/300][1250/1251]	eta 0:00:00 lr 0.000955	time 0.5511 (0.5672)	loss 3.7770 (3.7628)	grad_norm 1.3469 (1.2350)	mem 17413MB
[2023-01-31 21:14:17 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 40 training takes 0:11:49
[2023-01-31 21:14:17 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_40.pth saving......
[2023-01-31 21:14:19 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_40.pth saved !!!
[2023-01-31 21:14:19 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.866 (0.866)	Loss 1.1768 (1.1768)	Acc@1 73.047 (73.047)	Acc@5 90.820 (90.820)	Mem 17413MB
[2023-01-31 21:14:27 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 72.678 Acc@5 91.714
[2023-01-31 21:14:27 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 72.7%
[2023-01-31 21:14:28 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.218 (1.218)	Loss 1.1768 (1.1768)	Acc@1 71.973 (71.973)	Acc@5 91.602 (91.602)	Mem 17413MB
[2023-01-31 21:14:37 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 74.020 Acc@5 92.248
[2023-01-31 21:14:37 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 74.0%
[2023-01-31 21:14:37 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 74.02% at 40 epoch
[2023-01-31 21:14:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][0/1251]	eta 0:36:59 lr 0.000955	time 1.7742 (1.7742)	loss 4.1445 (4.1445)	grad_norm 1.1434 (1.1434)	mem 17413MB
[2023-01-31 21:15:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][50/1251]	eta 0:11:48 lr 0.000955	time 0.5622 (0.5895)	loss 4.1365 (3.6970)	grad_norm 1.2535 (1.2526)	mem 17413MB
[2023-01-31 21:15:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][100/1251]	eta 0:11:04 lr 0.000955	time 0.5538 (0.5777)	loss 3.4969 (3.7286)	grad_norm 1.2822 (1.2394)	mem 17413MB
[2023-01-31 21:16:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][150/1251]	eta 0:10:31 lr 0.000955	time 0.5580 (0.5740)	loss 3.6177 (3.7521)	grad_norm 1.1466 (1.2283)	mem 17413MB
[2023-01-31 21:16:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][200/1251]	eta 0:10:00 lr 0.000955	time 0.5554 (0.5716)	loss 4.3937 (3.7236)	grad_norm 1.2881 (1.2319)	mem 17413MB
[2023-01-31 21:17:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][250/1251]	eta 0:09:31 lr 0.000955	time 0.5631 (0.5706)	loss 4.5159 (3.7644)	grad_norm 1.2524 (1.2309)	mem 17413MB
[2023-01-31 21:17:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][300/1251]	eta 0:09:02 lr 0.000955	time 0.5501 (0.5701)	loss 4.3774 (3.7544)	grad_norm 1.2350 (1.2310)	mem 17413MB
[2023-01-31 21:17:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][350/1251]	eta 0:08:33 lr 0.000954	time 0.5551 (0.5696)	loss 4.5939 (3.7714)	grad_norm 1.2162 (1.2312)	mem 17413MB
[2023-01-31 21:18:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][400/1251]	eta 0:08:04 lr 0.000954	time 0.5681 (0.5690)	loss 4.5384 (3.7579)	grad_norm 1.3606 (1.2326)	mem 17413MB
[2023-01-31 21:18:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][450/1251]	eta 0:07:35 lr 0.000954	time 0.5607 (0.5689)	loss 3.1615 (3.7437)	grad_norm 1.2250 (1.2354)	mem 17413MB
[2023-01-31 21:19:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][500/1251]	eta 0:07:07 lr 0.000954	time 0.5526 (0.5686)	loss 2.3375 (3.7323)	grad_norm 1.2339 (1.2353)	mem 17413MB
[2023-01-31 21:19:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][550/1251]	eta 0:06:38 lr 0.000954	time 0.5632 (0.5685)	loss 3.1745 (3.7287)	grad_norm 1.2572 (1.2366)	mem 17413MB
[2023-01-31 21:20:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][600/1251]	eta 0:06:09 lr 0.000954	time 0.5545 (0.5684)	loss 4.1680 (3.7337)	grad_norm 1.3524 (1.2359)	mem 17413MB
[2023-01-31 21:20:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][650/1251]	eta 0:05:41 lr 0.000954	time 0.5583 (0.5682)	loss 3.8145 (3.7437)	grad_norm 1.2223 (1.2395)	mem 17413MB
[2023-01-31 21:21:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][700/1251]	eta 0:05:13 lr 0.000954	time 0.5560 (0.5682)	loss 3.5300 (3.7426)	grad_norm 1.1789 (1.2401)	mem 17413MB
[2023-01-31 21:21:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][750/1251]	eta 0:04:44 lr 0.000954	time 0.5568 (0.5679)	loss 4.2595 (3.7476)	grad_norm 1.1673 (1.2397)	mem 17413MB
[2023-01-31 21:22:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][800/1251]	eta 0:04:16 lr 0.000954	time 0.5502 (0.5677)	loss 3.0828 (3.7448)	grad_norm 1.2388 (1.2385)	mem 17413MB
[2023-01-31 21:22:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][850/1251]	eta 0:03:47 lr 0.000954	time 0.5754 (0.5676)	loss 3.5919 (3.7561)	grad_norm 1.3168 (1.2381)	mem 17413MB
[2023-01-31 21:23:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][900/1251]	eta 0:03:19 lr 0.000954	time 0.5595 (0.5676)	loss 3.7529 (3.7559)	grad_norm 1.1823 (1.2375)	mem 17413MB
[2023-01-31 21:23:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][950/1251]	eta 0:02:50 lr 0.000953	time 0.5566 (0.5675)	loss 4.3316 (3.7588)	grad_norm 1.2075 (1.2381)	mem 17413MB
[2023-01-31 21:24:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][1000/1251]	eta 0:02:22 lr 0.000953	time 0.5562 (0.5673)	loss 3.7020 (3.7560)	grad_norm 1.1910 (1.2374)	mem 17413MB
[2023-01-31 21:24:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][1050/1251]	eta 0:01:54 lr 0.000953	time 0.5569 (0.5674)	loss 2.7434 (3.7573)	grad_norm 1.1956 (1.2368)	mem 17413MB
[2023-01-31 21:25:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][1100/1251]	eta 0:01:25 lr 0.000953	time 0.5651 (0.5674)	loss 3.3369 (3.7590)	grad_norm 1.1758 (1.2373)	mem 17413MB
[2023-01-31 21:25:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][1150/1251]	eta 0:00:57 lr 0.000953	time 0.5588 (0.5674)	loss 4.1735 (3.7599)	grad_norm 1.1719 (1.2358)	mem 17413MB
[2023-01-31 21:25:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][1200/1251]	eta 0:00:28 lr 0.000953	time 0.5572 (0.5674)	loss 3.2138 (3.7608)	grad_norm 1.2405 (1.2370)	mem 17413MB
[2023-01-31 21:26:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [41/300][1250/1251]	eta 0:00:00 lr 0.000953	time 0.6118 (0.5674)	loss 4.2373 (3.7597)	grad_norm 1.2966 (1.2366)	mem 17413MB
[2023-01-31 21:26:26 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 41 training takes 0:11:49
[2023-01-31 21:26:27 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_41.pth saving......
[2023-01-31 21:26:28 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_41.pth saved !!!
[2023-01-31 21:26:29 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.869 (0.869)	Loss 1.1028 (1.1028)	Acc@1 73.828 (73.828)	Acc@5 92.676 (92.676)	Mem 17413MB
[2023-01-31 21:26:37 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 73.172 Acc@5 92.106
[2023-01-31 21:26:37 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 73.2%
[2023-01-31 21:26:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.368 (1.368)	Loss 1.0930 (1.0930)	Acc@1 73.438 (73.438)	Acc@5 92.773 (92.773)	Mem 17413MB
[2023-01-31 21:26:46 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 74.288 Acc@5 92.394
[2023-01-31 21:26:46 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 74.3%
[2023-01-31 21:26:46 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 74.29% at 41 epoch
[2023-01-31 21:26:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][0/1251]	eta 0:38:28 lr 0.000953	time 1.8457 (1.8457)	loss 3.6143 (3.6143)	grad_norm 1.2125 (1.2125)	mem 17413MB
[2023-01-31 21:27:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][50/1251]	eta 0:11:53 lr 0.000953	time 0.6347 (0.5938)	loss 3.2279 (3.8846)	grad_norm 1.1795 (1.2140)	mem 17413MB
[2023-01-31 21:27:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][100/1251]	eta 0:11:08 lr 0.000953	time 0.5662 (0.5806)	loss 4.4639 (3.8064)	grad_norm 1.3969 (1.2249)	mem 17413MB
[2023-01-31 21:28:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][150/1251]	eta 0:10:34 lr 0.000953	time 0.5615 (0.5762)	loss 3.8215 (3.7298)	grad_norm 1.1134 (1.2309)	mem 17413MB
[2023-01-31 21:28:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][200/1251]	eta 0:10:03 lr 0.000953	time 0.5584 (0.5739)	loss 2.6811 (3.7446)	grad_norm 1.2548 (1.2391)	mem 17413MB
[2023-01-31 21:29:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][250/1251]	eta 0:09:33 lr 0.000952	time 0.5574 (0.5725)	loss 4.0313 (3.7313)	grad_norm 1.2177 (1.2396)	mem 17413MB
[2023-01-31 21:29:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][300/1251]	eta 0:09:03 lr 0.000952	time 0.5578 (0.5714)	loss 3.7357 (3.7133)	grad_norm 1.2737 (1.2376)	mem 17413MB
[2023-01-31 21:30:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][350/1251]	eta 0:08:33 lr 0.000952	time 0.5525 (0.5704)	loss 3.4621 (3.7269)	grad_norm 1.3132 (1.2352)	mem 17413MB
[2023-01-31 21:30:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][400/1251]	eta 0:08:04 lr 0.000952	time 0.5555 (0.5698)	loss 3.8846 (3.7200)	grad_norm 1.2781 (1.2383)	mem 17413MB
[2023-01-31 21:31:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][450/1251]	eta 0:07:35 lr 0.000952	time 0.5615 (0.5692)	loss 4.2344 (3.7173)	grad_norm 1.1871 (1.2340)	mem 17413MB
[2023-01-31 21:31:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][500/1251]	eta 0:07:07 lr 0.000952	time 0.5555 (0.5690)	loss 3.2580 (3.7214)	grad_norm 1.2272 (1.2340)	mem 17413MB
[2023-01-31 21:32:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][550/1251]	eta 0:06:38 lr 0.000952	time 0.5552 (0.5692)	loss 2.5715 (3.7202)	grad_norm 1.1774 (1.2349)	mem 17413MB
[2023-01-31 21:32:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][600/1251]	eta 0:06:10 lr 0.000952	time 0.5618 (0.5689)	loss 3.4668 (3.7232)	grad_norm 1.2262 (1.2361)	mem 17413MB
[2023-01-31 21:32:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][650/1251]	eta 0:05:41 lr 0.000952	time 0.5571 (0.5689)	loss 4.3517 (3.7264)	grad_norm 1.0986 (1.2374)	mem 17413MB
[2023-01-31 21:33:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][700/1251]	eta 0:05:13 lr 0.000952	time 0.5581 (0.5689)	loss 3.4118 (3.7176)	grad_norm 1.2058 (1.2373)	mem 17413MB
[2023-01-31 21:33:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][750/1251]	eta 0:04:44 lr 0.000952	time 0.5553 (0.5687)	loss 3.2094 (3.7162)	grad_norm 1.1622 (1.2386)	mem 17413MB
[2023-01-31 21:34:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][800/1251]	eta 0:04:16 lr 0.000951	time 0.5550 (0.5686)	loss 3.2044 (3.7127)	grad_norm 1.2129 (1.2381)	mem 17413MB
[2023-01-31 21:34:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][850/1251]	eta 0:03:47 lr 0.000951	time 0.5578 (0.5683)	loss 3.8820 (3.7086)	grad_norm 1.2982 (1.2387)	mem 17413MB
[2023-01-31 21:35:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][900/1251]	eta 0:03:19 lr 0.000951	time 0.5500 (0.5683)	loss 4.3884 (3.7141)	grad_norm 1.1048 (1.2374)	mem 17413MB
[2023-01-31 21:35:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][950/1251]	eta 0:02:51 lr 0.000951	time 0.5579 (0.5683)	loss 4.4750 (3.7126)	grad_norm 1.3137 (1.2377)	mem 17413MB
[2023-01-31 21:36:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][1000/1251]	eta 0:02:22 lr 0.000951	time 0.5492 (0.5683)	loss 3.0265 (3.7148)	grad_norm 1.1115 (1.2371)	mem 17413MB
[2023-01-31 21:36:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][1050/1251]	eta 0:01:54 lr 0.000951	time 0.5567 (0.5683)	loss 3.8243 (3.7185)	grad_norm 1.3638 (nan)	mem 17413MB
[2023-01-31 21:37:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][1100/1251]	eta 0:01:25 lr 0.000951	time 0.5616 (0.5681)	loss 3.7881 (3.7145)	grad_norm 1.2258 (nan)	mem 17413MB
[2023-01-31 21:37:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][1150/1251]	eta 0:00:57 lr 0.000951	time 0.6159 (0.5680)	loss 3.7072 (3.7122)	grad_norm 1.2584 (nan)	mem 17413MB
[2023-01-31 21:38:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][1200/1251]	eta 0:00:28 lr 0.000951	time 0.5598 (0.5680)	loss 4.3322 (3.7151)	grad_norm 1.3244 (nan)	mem 17413MB
[2023-01-31 21:38:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [42/300][1250/1251]	eta 0:00:00 lr 0.000951	time 0.5509 (0.5679)	loss 2.7476 (3.7143)	grad_norm 1.1445 (nan)	mem 17413MB
[2023-01-31 21:38:37 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 42 training takes 0:11:50
[2023-01-31 21:38:37 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_42.pth saving......
[2023-01-31 21:38:39 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_42.pth saved !!!
[2023-01-31 21:38:40 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.834 (0.834)	Loss 1.1261 (1.1261)	Acc@1 73.926 (73.926)	Acc@5 91.406 (91.406)	Mem 17413MB
[2023-01-31 21:38:48 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 73.052 Acc@5 91.964
[2023-01-31 21:38:48 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 73.1%
[2023-01-31 21:38:49 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.319 (1.319)	Loss 1.0790 (1.0790)	Acc@1 75.098 (75.098)	Acc@5 92.871 (92.871)	Mem 17413MB
[2023-01-31 21:38:57 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 74.536 Acc@5 92.546
[2023-01-31 21:38:57 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 74.5%
[2023-01-31 21:38:57 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 74.54% at 42 epoch
[2023-01-31 21:38:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][0/1251]	eta 0:35:42 lr 0.000951	time 1.7122 (1.7122)	loss 3.7522 (3.7522)	grad_norm 1.2190 (1.2190)	mem 17413MB
[2023-01-31 21:39:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][50/1251]	eta 0:11:54 lr 0.000951	time 0.6239 (0.5947)	loss 2.9514 (3.8032)	grad_norm 1.4148 (1.2643)	mem 17413MB
[2023-01-31 21:39:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][100/1251]	eta 0:11:07 lr 0.000950	time 0.5541 (0.5801)	loss 3.7083 (3.7918)	grad_norm 1.2551 (1.2672)	mem 17413MB
[2023-01-31 21:40:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][150/1251]	eta 0:10:33 lr 0.000950	time 0.5614 (0.5755)	loss 4.1074 (3.7941)	grad_norm 1.2895 (1.2654)	mem 17413MB
[2023-01-31 21:40:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][200/1251]	eta 0:10:02 lr 0.000950	time 0.5617 (0.5737)	loss 4.0267 (3.7629)	grad_norm 1.1910 (1.2540)	mem 17413MB
[2023-01-31 21:41:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][250/1251]	eta 0:09:32 lr 0.000950	time 0.6232 (0.5721)	loss 3.3376 (3.7558)	grad_norm 1.1907 (1.2592)	mem 17413MB
[2023-01-31 21:41:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][300/1251]	eta 0:09:03 lr 0.000950	time 0.5596 (0.5718)	loss 3.8774 (3.7760)	grad_norm 1.2778 (1.2573)	mem 17413MB
[2023-01-31 21:42:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][350/1251]	eta 0:08:34 lr 0.000950	time 0.5549 (0.5708)	loss 2.8719 (3.7442)	grad_norm 1.2626 (1.2499)	mem 17413MB
[2023-01-31 21:42:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][400/1251]	eta 0:08:05 lr 0.000950	time 0.5581 (0.5704)	loss 2.9135 (3.7343)	grad_norm 1.1624 (1.2450)	mem 17413MB
[2023-01-31 21:43:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][450/1251]	eta 0:07:36 lr 0.000950	time 0.5528 (0.5700)	loss 4.4587 (3.7392)	grad_norm 1.1881 (1.2417)	mem 17413MB
[2023-01-31 21:43:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][500/1251]	eta 0:07:07 lr 0.000950	time 0.5641 (0.5693)	loss 3.8695 (3.7447)	grad_norm 1.1700 (1.2389)	mem 17413MB
[2023-01-31 21:44:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][550/1251]	eta 0:06:39 lr 0.000950	time 0.5554 (0.5693)	loss 3.9432 (3.7386)	grad_norm 1.1110 (1.2410)	mem 17413MB
[2023-01-31 21:44:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][600/1251]	eta 0:06:10 lr 0.000950	time 0.5583 (0.5690)	loss 3.5003 (3.7291)	grad_norm 1.1382 (1.2396)	mem 17413MB
[2023-01-31 21:45:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][650/1251]	eta 0:05:41 lr 0.000949	time 0.5640 (0.5690)	loss 3.9165 (3.7204)	grad_norm 1.1439 (1.2372)	mem 17413MB
[2023-01-31 21:45:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][700/1251]	eta 0:05:13 lr 0.000949	time 0.5571 (0.5687)	loss 4.8411 (3.7189)	grad_norm 1.2371 (1.2376)	mem 17413MB
[2023-01-31 21:46:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][750/1251]	eta 0:04:44 lr 0.000949	time 0.5569 (0.5686)	loss 4.1969 (3.7176)	grad_norm 1.3478 (1.2376)	mem 17413MB
[2023-01-31 21:46:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][800/1251]	eta 0:04:16 lr 0.000949	time 0.5592 (0.5684)	loss 4.7614 (3.7247)	grad_norm 1.1827 (1.2374)	mem 17413MB
[2023-01-31 21:47:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][850/1251]	eta 0:03:47 lr 0.000949	time 0.6107 (0.5684)	loss 4.1392 (3.7254)	grad_norm 1.4331 (1.2391)	mem 17413MB
[2023-01-31 21:47:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][900/1251]	eta 0:03:19 lr 0.000949	time 0.5582 (0.5682)	loss 3.4828 (3.7223)	grad_norm 1.3163 (1.2387)	mem 17413MB
[2023-01-31 21:47:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][950/1251]	eta 0:02:51 lr 0.000949	time 0.5538 (0.5682)	loss 4.1541 (3.7117)	grad_norm 1.1643 (1.2378)	mem 17413MB
[2023-01-31 21:48:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][1000/1251]	eta 0:02:22 lr 0.000949	time 0.5609 (0.5681)	loss 3.5308 (3.7097)	grad_norm 1.2344 (1.2392)	mem 17413MB
[2023-01-31 21:48:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][1050/1251]	eta 0:01:54 lr 0.000949	time 0.5542 (0.5680)	loss 3.8386 (3.7097)	grad_norm 1.3304 (1.2400)	mem 17413MB
[2023-01-31 21:49:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][1100/1251]	eta 0:01:25 lr 0.000949	time 0.5590 (0.5679)	loss 3.8181 (3.7139)	grad_norm 1.2411 (1.2400)	mem 17413MB
[2023-01-31 21:49:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][1150/1251]	eta 0:00:57 lr 0.000949	time 0.5709 (0.5678)	loss 4.8023 (3.7197)	grad_norm 1.3620 (1.2391)	mem 17413MB
[2023-01-31 21:50:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][1200/1251]	eta 0:00:28 lr 0.000948	time 0.5647 (0.5678)	loss 2.7640 (3.7143)	grad_norm 1.3073 (1.2393)	mem 17413MB
[2023-01-31 21:50:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [43/300][1250/1251]	eta 0:00:00 lr 0.000948	time 0.5504 (0.5678)	loss 4.2642 (3.7151)	grad_norm 1.2762 (1.2397)	mem 17413MB
[2023-01-31 21:50:47 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 43 training takes 0:11:50
[2023-01-31 21:50:48 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_43.pth saving......
[2023-01-31 21:50:49 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_43.pth saved !!!
[2023-01-31 21:50:50 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.927 (0.927)	Loss 1.2058 (1.2058)	Acc@1 71.484 (71.484)	Acc@5 91.113 (91.113)	Mem 17413MB
[2023-01-31 21:50:58 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 73.156 Acc@5 92.136
[2023-01-31 21:50:58 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 73.2%
[2023-01-31 21:51:00 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.268 (1.268)	Loss 1.0645 (1.0645)	Acc@1 74.512 (74.512)	Acc@5 92.773 (92.773)	Mem 17413MB
[2023-01-31 21:51:07 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 74.818 Acc@5 92.726
[2023-01-31 21:51:07 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 74.8%
[2023-01-31 21:51:07 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 74.82% at 43 epoch
[2023-01-31 21:51:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][0/1251]	eta 0:35:37 lr 0.000948	time 1.7086 (1.7086)	loss 3.4444 (3.4444)	grad_norm 1.2304 (1.2304)	mem 17413MB
[2023-01-31 21:51:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][50/1251]	eta 0:11:50 lr 0.000948	time 0.5591 (0.5914)	loss 2.8289 (3.7336)	grad_norm 1.1667 (1.2211)	mem 17413MB
[2023-01-31 21:52:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][100/1251]	eta 0:11:07 lr 0.000948	time 0.6158 (0.5800)	loss 3.6352 (3.7085)	grad_norm 1.1904 (1.2303)	mem 17413MB
[2023-01-31 21:52:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][150/1251]	eta 0:10:33 lr 0.000948	time 0.5625 (0.5754)	loss 3.9273 (3.6902)	grad_norm 1.1614 (1.2325)	mem 17413MB
[2023-01-31 21:53:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][200/1251]	eta 0:10:02 lr 0.000948	time 0.5590 (0.5729)	loss 2.6866 (3.6952)	grad_norm 1.1363 (1.2331)	mem 17413MB
[2023-01-31 21:53:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][250/1251]	eta 0:09:32 lr 0.000948	time 0.5546 (0.5716)	loss 3.5357 (3.6866)	grad_norm 1.2468 (1.2360)	mem 17413MB
[2023-01-31 21:53:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][300/1251]	eta 0:09:03 lr 0.000948	time 0.5532 (0.5713)	loss 3.8923 (3.6977)	grad_norm 1.2962 (1.2377)	mem 17413MB
[2023-01-31 21:54:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][350/1251]	eta 0:08:33 lr 0.000948	time 0.5565 (0.5704)	loss 3.4821 (3.7036)	grad_norm 1.4495 (1.2370)	mem 17413MB
[2023-01-31 21:54:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][400/1251]	eta 0:08:05 lr 0.000948	time 0.5549 (0.5701)	loss 3.6556 (3.7101)	grad_norm 1.1668 (1.2390)	mem 17413MB
[2023-01-31 21:55:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][450/1251]	eta 0:07:36 lr 0.000948	time 0.5578 (0.5696)	loss 2.8658 (3.7092)	grad_norm 1.2934 (1.2399)	mem 17413MB
[2023-01-31 21:55:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][500/1251]	eta 0:07:07 lr 0.000947	time 0.6207 (0.5692)	loss 2.6979 (3.7076)	grad_norm 1.2872 (1.2391)	mem 17413MB
[2023-01-31 21:56:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][550/1251]	eta 0:06:38 lr 0.000947	time 0.5759 (0.5689)	loss 3.6323 (3.7142)	grad_norm 1.2729 (1.2389)	mem 17413MB
[2023-01-31 21:56:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][600/1251]	eta 0:06:10 lr 0.000947	time 0.5537 (0.5691)	loss 3.8183 (3.7125)	grad_norm 1.2872 (1.2393)	mem 17413MB
[2023-01-31 21:57:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][650/1251]	eta 0:05:41 lr 0.000947	time 0.5562 (0.5689)	loss 4.2253 (3.7095)	grad_norm 1.1850 (1.2397)	mem 17413MB
[2023-01-31 21:57:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][700/1251]	eta 0:05:13 lr 0.000947	time 0.5547 (0.5689)	loss 2.5662 (3.7066)	grad_norm 1.2127 (nan)	mem 17413MB
[2023-01-31 21:58:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][750/1251]	eta 0:04:44 lr 0.000947	time 0.5596 (0.5687)	loss 2.8196 (3.7041)	grad_norm 1.2146 (nan)	mem 17413MB
[2023-01-31 21:58:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][800/1251]	eta 0:04:16 lr 0.000947	time 0.5580 (0.5687)	loss 3.4976 (3.7010)	grad_norm 1.1608 (nan)	mem 17413MB
[2023-01-31 21:59:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][850/1251]	eta 0:03:48 lr 0.000947	time 0.5546 (0.5687)	loss 3.8412 (3.7014)	grad_norm 1.3403 (nan)	mem 17413MB
[2023-01-31 21:59:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][900/1251]	eta 0:03:19 lr 0.000947	time 0.6101 (0.5687)	loss 3.8293 (3.7036)	grad_norm 1.2461 (nan)	mem 17413MB
[2023-01-31 22:00:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][950/1251]	eta 0:02:51 lr 0.000947	time 0.5733 (0.5685)	loss 4.1239 (3.7090)	grad_norm 1.1941 (nan)	mem 17413MB
[2023-01-31 22:00:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][1000/1251]	eta 0:02:22 lr 0.000947	time 0.5559 (0.5685)	loss 3.6023 (3.7095)	grad_norm 1.1258 (nan)	mem 17413MB
[2023-01-31 22:01:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][1050/1251]	eta 0:01:54 lr 0.000946	time 0.5567 (0.5684)	loss 3.5976 (3.7080)	grad_norm 1.1059 (nan)	mem 17413MB
[2023-01-31 22:01:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][1100/1251]	eta 0:01:25 lr 0.000946	time 0.5649 (0.5686)	loss 4.0585 (3.7081)	grad_norm 1.0967 (nan)	mem 17413MB
[2023-01-31 22:02:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][1150/1251]	eta 0:00:57 lr 0.000946	time 0.5569 (0.5685)	loss 3.8639 (3.7075)	grad_norm 1.3868 (nan)	mem 17413MB
[2023-01-31 22:02:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][1200/1251]	eta 0:00:28 lr 0.000946	time 0.6226 (0.5686)	loss 3.3012 (3.7082)	grad_norm 1.1231 (nan)	mem 17413MB
[2023-01-31 22:02:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [44/300][1250/1251]	eta 0:00:00 lr 0.000946	time 0.5489 (0.5685)	loss 3.4093 (3.7088)	grad_norm 1.2204 (nan)	mem 17413MB
[2023-01-31 22:02:59 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 44 training takes 0:11:51
[2023-01-31 22:02:59 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_44.pth saving......
[2023-01-31 22:03:01 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_44.pth saved !!!
[2023-01-31 22:03:02 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.837 (0.837)	Loss 0.9677 (0.9677)	Acc@1 75.098 (75.098)	Acc@5 94.629 (94.629)	Mem 17413MB
[2023-01-31 22:03:10 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 73.656 Acc@5 92.340
[2023-01-31 22:03:10 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 73.7%
[2023-01-31 22:03:11 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.229 (1.229)	Loss 1.0880 (1.0880)	Acc@1 73.633 (73.633)	Acc@5 92.285 (92.285)	Mem 17413MB
[2023-01-31 22:03:19 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.096 Acc@5 92.898
[2023-01-31 22:03:19 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 75.1%
[2023-01-31 22:03:19 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 75.10% at 44 epoch
[2023-01-31 22:03:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][0/1251]	eta 0:35:25 lr 0.000946	time 1.6993 (1.6993)	loss 4.4411 (4.4411)	grad_norm 1.1270 (1.1270)	mem 17413MB
[2023-01-31 22:03:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][50/1251]	eta 0:11:47 lr 0.000946	time 0.5604 (0.5893)	loss 3.4726 (3.8528)	grad_norm 1.1426 (1.2411)	mem 17413MB
[2023-01-31 22:04:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][100/1251]	eta 0:11:05 lr 0.000946	time 0.5644 (0.5785)	loss 3.6525 (3.8387)	grad_norm 1.3181 (1.2583)	mem 17413MB
[2023-01-31 22:04:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][150/1251]	eta 0:10:32 lr 0.000946	time 0.5543 (0.5746)	loss 3.4494 (3.7994)	grad_norm 1.1349 (1.2371)	mem 17413MB
[2023-01-31 22:05:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][200/1251]	eta 0:10:01 lr 0.000946	time 0.5634 (0.5721)	loss 4.4116 (3.7541)	grad_norm 1.1823 (1.2452)	mem 17413MB
[2023-01-31 22:05:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][250/1251]	eta 0:09:31 lr 0.000946	time 0.5570 (0.5711)	loss 4.0691 (3.7437)	grad_norm 1.1798 (1.2506)	mem 17413MB
[2023-01-31 22:06:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][300/1251]	eta 0:09:02 lr 0.000945	time 0.5563 (0.5700)	loss 3.3487 (3.7305)	grad_norm 1.3156 (1.2478)	mem 17413MB
[2023-01-31 22:06:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][350/1251]	eta 0:08:33 lr 0.000945	time 0.5522 (0.5695)	loss 2.8524 (3.7303)	grad_norm 1.2542 (1.2526)	mem 17413MB
[2023-01-31 22:07:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][400/1251]	eta 0:08:04 lr 0.000945	time 0.5539 (0.5691)	loss 3.9254 (3.7327)	grad_norm 1.2829 (1.2539)	mem 17413MB
[2023-01-31 22:07:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][450/1251]	eta 0:07:35 lr 0.000945	time 0.6231 (0.5689)	loss 3.8734 (3.7253)	grad_norm 1.2662 (1.2542)	mem 17413MB
[2023-01-31 22:08:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][500/1251]	eta 0:07:07 lr 0.000945	time 0.5501 (0.5686)	loss 2.8996 (3.7224)	grad_norm 1.1902 (1.2524)	mem 17413MB
[2023-01-31 22:08:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][550/1251]	eta 0:06:38 lr 0.000945	time 0.5677 (0.5684)	loss 3.8107 (3.7280)	grad_norm 1.2023 (1.2500)	mem 17413MB
[2023-01-31 22:09:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][600/1251]	eta 0:06:09 lr 0.000945	time 0.5555 (0.5679)	loss 4.1576 (3.7208)	grad_norm 1.2990 (1.2489)	mem 17413MB
[2023-01-31 22:09:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][650/1251]	eta 0:05:41 lr 0.000945	time 0.5755 (0.5679)	loss 4.3093 (3.7243)	grad_norm 1.3081 (1.2460)	mem 17413MB
[2023-01-31 22:09:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][700/1251]	eta 0:05:12 lr 0.000945	time 0.5534 (0.5679)	loss 4.1101 (3.7223)	grad_norm 1.1913 (1.2448)	mem 17413MB
[2023-01-31 22:10:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][750/1251]	eta 0:04:44 lr 0.000945	time 0.5509 (0.5677)	loss 4.5270 (3.7135)	grad_norm 1.3319 (1.2458)	mem 17413MB
[2023-01-31 22:10:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][800/1251]	eta 0:04:16 lr 0.000945	time 0.5629 (0.5677)	loss 3.7530 (3.7125)	grad_norm 1.2563 (1.2454)	mem 17413MB
[2023-01-31 22:11:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][850/1251]	eta 0:03:47 lr 0.000944	time 0.5568 (0.5675)	loss 3.8743 (3.7123)	grad_norm 1.3382 (1.2429)	mem 17413MB
[2023-01-31 22:11:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][900/1251]	eta 0:03:19 lr 0.000944	time 0.5605 (0.5675)	loss 3.7106 (3.7096)	grad_norm 1.1318 (1.2410)	mem 17413MB
[2023-01-31 22:12:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][950/1251]	eta 0:02:50 lr 0.000944	time 0.5613 (0.5675)	loss 4.0232 (3.7019)	grad_norm 1.1683 (1.2396)	mem 17413MB
[2023-01-31 22:12:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][1000/1251]	eta 0:02:22 lr 0.000944	time 0.5556 (0.5674)	loss 4.4776 (3.7001)	grad_norm 1.1787 (1.2418)	mem 17413MB
[2023-01-31 22:13:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][1050/1251]	eta 0:01:54 lr 0.000944	time 0.5574 (0.5675)	loss 3.3295 (3.7054)	grad_norm 1.3336 (1.2422)	mem 17413MB
[2023-01-31 22:13:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][1100/1251]	eta 0:01:25 lr 0.000944	time 0.5589 (0.5673)	loss 2.7617 (3.7018)	grad_norm 1.4084 (1.2411)	mem 17413MB
[2023-01-31 22:14:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][1150/1251]	eta 0:00:57 lr 0.000944	time 0.6165 (0.5673)	loss 3.6596 (3.7013)	grad_norm 1.4197 (1.2421)	mem 17413MB
[2023-01-31 22:14:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][1200/1251]	eta 0:00:28 lr 0.000944	time 0.6173 (0.5675)	loss 4.1657 (3.6959)	grad_norm 1.2363 (1.2415)	mem 17413MB
[2023-01-31 22:15:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [45/300][1250/1251]	eta 0:00:00 lr 0.000944	time 0.5492 (0.5672)	loss 4.0032 (3.6982)	grad_norm 1.3831 (1.2423)	mem 17413MB
[2023-01-31 22:15:08 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 45 training takes 0:11:49
[2023-01-31 22:15:09 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_45.pth saving......
[2023-01-31 22:15:10 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_45.pth saved !!!
[2023-01-31 22:15:11 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.862 (0.862)	Loss 1.0395 (1.0395)	Acc@1 73.828 (73.828)	Acc@5 94.141 (94.141)	Mem 17413MB
[2023-01-31 22:15:19 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 73.698 Acc@5 92.246
[2023-01-31 22:15:19 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 73.7%
[2023-01-31 22:15:20 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.215 (1.215)	Loss 0.9750 (0.9750)	Acc@1 77.051 (77.051)	Acc@5 93.652 (93.652)	Mem 17413MB
[2023-01-31 22:15:28 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.324 Acc@5 92.994
[2023-01-31 22:15:28 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 75.3%
[2023-01-31 22:15:28 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 75.32% at 45 epoch
[2023-01-31 22:15:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][0/1251]	eta 0:34:25 lr 0.000944	time 1.6512 (1.6512)	loss 3.0289 (3.0289)	grad_norm 1.3957 (1.3957)	mem 17413MB
[2023-01-31 22:15:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][50/1251]	eta 0:11:47 lr 0.000944	time 0.5571 (0.5895)	loss 3.0614 (3.7010)	grad_norm 1.2281 (1.2299)	mem 17413MB
[2023-01-31 22:16:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][100/1251]	eta 0:11:05 lr 0.000943	time 0.5629 (0.5784)	loss 3.6610 (3.8058)	grad_norm 1.4035 (1.2494)	mem 17413MB
[2023-01-31 22:16:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][150/1251]	eta 0:10:32 lr 0.000943	time 0.5542 (0.5744)	loss 3.9536 (3.7769)	grad_norm 1.4224 (1.2449)	mem 17413MB
[2023-01-31 22:17:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][200/1251]	eta 0:10:01 lr 0.000943	time 0.5620 (0.5725)	loss 3.7776 (3.7424)	grad_norm 1.0999 (1.2450)	mem 17413MB
[2023-01-31 22:17:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][250/1251]	eta 0:09:31 lr 0.000943	time 0.5651 (0.5711)	loss 3.3711 (3.7300)	grad_norm 1.1594 (nan)	mem 17413MB
[2023-01-31 22:18:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][300/1251]	eta 0:09:02 lr 0.000943	time 0.5582 (0.5706)	loss 4.1627 (3.7085)	grad_norm 1.1668 (nan)	mem 17413MB
[2023-01-31 22:18:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][350/1251]	eta 0:08:33 lr 0.000943	time 0.5590 (0.5699)	loss 2.8896 (3.6758)	grad_norm 1.4101 (nan)	mem 17413MB
[2023-01-31 22:19:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][400/1251]	eta 0:08:04 lr 0.000943	time 0.6495 (0.5696)	loss 4.3385 (3.6759)	grad_norm 1.4081 (nan)	mem 17413MB
[2023-01-31 22:19:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][450/1251]	eta 0:07:35 lr 0.000943	time 0.5574 (0.5692)	loss 4.1055 (3.6770)	grad_norm 1.2681 (nan)	mem 17413MB
[2023-01-31 22:20:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][500/1251]	eta 0:07:07 lr 0.000943	time 0.5538 (0.5688)	loss 3.6857 (3.6878)	grad_norm 1.3457 (nan)	mem 17413MB
[2023-01-31 22:20:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][550/1251]	eta 0:06:38 lr 0.000943	time 0.5597 (0.5688)	loss 3.9270 (3.6893)	grad_norm 1.2116 (nan)	mem 17413MB
[2023-01-31 22:21:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][600/1251]	eta 0:06:10 lr 0.000943	time 0.5706 (0.5685)	loss 3.2282 (3.6913)	grad_norm 1.3730 (nan)	mem 17413MB
[2023-01-31 22:21:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][650/1251]	eta 0:05:41 lr 0.000942	time 0.5527 (0.5685)	loss 3.6354 (3.6855)	grad_norm 1.2854 (nan)	mem 17413MB
[2023-01-31 22:22:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][700/1251]	eta 0:05:13 lr 0.000942	time 0.5529 (0.5683)	loss 3.7625 (3.6854)	grad_norm 1.2529 (nan)	mem 17413MB
[2023-01-31 22:22:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][750/1251]	eta 0:04:44 lr 0.000942	time 0.5590 (0.5683)	loss 4.2816 (3.6823)	grad_norm 1.2341 (nan)	mem 17413MB
[2023-01-31 22:23:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][800/1251]	eta 0:04:16 lr 0.000942	time 0.6238 (0.5683)	loss 4.2941 (3.6912)	grad_norm 1.1315 (nan)	mem 17413MB
[2023-01-31 22:23:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][850/1251]	eta 0:03:47 lr 0.000942	time 0.6083 (0.5681)	loss 4.2960 (3.6809)	grad_norm 1.1778 (nan)	mem 17413MB
[2023-01-31 22:24:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][900/1251]	eta 0:03:19 lr 0.000942	time 0.5646 (0.5679)	loss 4.0222 (3.6838)	grad_norm 1.2907 (nan)	mem 17413MB
[2023-01-31 22:24:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][950/1251]	eta 0:02:50 lr 0.000942	time 0.5583 (0.5681)	loss 3.7656 (3.6881)	grad_norm 1.3566 (nan)	mem 17413MB
[2023-01-31 22:24:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][1000/1251]	eta 0:02:22 lr 0.000942	time 0.5527 (0.5679)	loss 2.8555 (3.6861)	grad_norm 1.1374 (nan)	mem 17413MB
[2023-01-31 22:25:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][1050/1251]	eta 0:01:54 lr 0.000942	time 0.5624 (0.5679)	loss 4.2900 (3.6820)	grad_norm 1.1266 (nan)	mem 17413MB
[2023-01-31 22:25:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][1100/1251]	eta 0:01:25 lr 0.000942	time 0.5596 (0.5677)	loss 2.7865 (3.6781)	grad_norm 1.3790 (nan)	mem 17413MB
[2023-01-31 22:26:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][1150/1251]	eta 0:00:57 lr 0.000941	time 0.5529 (0.5677)	loss 3.8147 (3.6815)	grad_norm 1.2162 (nan)	mem 17413MB
[2023-01-31 22:26:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][1200/1251]	eta 0:00:28 lr 0.000941	time 0.6273 (0.5678)	loss 4.0275 (3.6827)	grad_norm 1.4317 (nan)	mem 17413MB
[2023-01-31 22:27:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [46/300][1250/1251]	eta 0:00:00 lr 0.000941	time 0.5507 (0.5675)	loss 3.6758 (3.6874)	grad_norm 1.2095 (nan)	mem 17413MB
[2023-01-31 22:27:18 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 46 training takes 0:11:50
[2023-01-31 22:27:19 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_46.pth saving......
[2023-01-31 22:27:20 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_46.pth saved !!!
[2023-01-31 22:27:21 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.862 (0.862)	Loss 1.1753 (1.1753)	Acc@1 72.754 (72.754)	Acc@5 91.895 (91.895)	Mem 17413MB
[2023-01-31 22:27:29 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 73.996 Acc@5 92.484
[2023-01-31 22:27:29 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 74.0%
[2023-01-31 22:27:30 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.226 (1.226)	Loss 1.1565 (1.1565)	Acc@1 72.363 (72.363)	Acc@5 91.406 (91.406)	Mem 17413MB
[2023-01-31 22:27:39 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.522 Acc@5 93.094
[2023-01-31 22:27:39 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 75.5%
[2023-01-31 22:27:39 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 75.52% at 46 epoch
[2023-01-31 22:27:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][0/1251]	eta 0:34:54 lr 0.000941	time 1.6746 (1.6746)	loss 3.9828 (3.9828)	grad_norm 1.2940 (1.2940)	mem 17413MB
[2023-01-31 22:28:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][50/1251]	eta 0:11:47 lr 0.000941	time 0.5626 (0.5894)	loss 3.8317 (3.6368)	grad_norm 1.2181 (1.2508)	mem 17413MB
[2023-01-31 22:28:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][100/1251]	eta 0:11:07 lr 0.000941	time 0.6469 (0.5799)	loss 3.4856 (3.6704)	grad_norm 1.2457 (1.2391)	mem 17413MB
[2023-01-31 22:29:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][150/1251]	eta 0:10:31 lr 0.000941	time 0.5643 (0.5736)	loss 3.7271 (3.6393)	grad_norm 1.0786 (1.2339)	mem 17413MB
[2023-01-31 22:29:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][200/1251]	eta 0:10:01 lr 0.000941	time 0.5574 (0.5721)	loss 3.5331 (3.6707)	grad_norm 1.3617 (1.2403)	mem 17413MB
[2023-01-31 22:30:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][250/1251]	eta 0:09:31 lr 0.000941	time 0.6117 (0.5707)	loss 3.0285 (3.6570)	grad_norm 1.3992 (1.2445)	mem 17413MB
[2023-01-31 22:30:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][300/1251]	eta 0:09:01 lr 0.000941	time 0.5641 (0.5693)	loss 3.8433 (3.6540)	grad_norm 1.2081 (1.2443)	mem 17413MB
[2023-01-31 22:30:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][350/1251]	eta 0:08:32 lr 0.000941	time 0.5557 (0.5690)	loss 3.0891 (3.6672)	grad_norm 1.2999 (1.2478)	mem 17413MB
[2023-01-31 22:31:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][400/1251]	eta 0:08:03 lr 0.000940	time 0.5514 (0.5680)	loss 4.2455 (3.6679)	grad_norm 1.2992 (1.2471)	mem 17413MB
[2023-01-31 22:31:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][450/1251]	eta 0:07:34 lr 0.000940	time 0.5663 (0.5678)	loss 4.2274 (3.6809)	grad_norm 1.3940 (1.2456)	mem 17413MB
[2023-01-31 22:32:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][500/1251]	eta 0:07:06 lr 0.000940	time 0.6256 (0.5676)	loss 3.5689 (3.6648)	grad_norm 1.1628 (1.2447)	mem 17413MB
[2023-01-31 22:32:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][550/1251]	eta 0:06:37 lr 0.000940	time 0.5494 (0.5671)	loss 4.2387 (3.6758)	grad_norm 1.3455 (1.2448)	mem 17413MB
[2023-01-31 22:33:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][600/1251]	eta 0:06:09 lr 0.000940	time 0.5814 (0.5671)	loss 3.2588 (3.6880)	grad_norm 1.2608 (1.2447)	mem 17413MB
[2023-01-31 22:33:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][650/1251]	eta 0:05:40 lr 0.000940	time 0.5557 (0.5669)	loss 3.2851 (3.6896)	grad_norm 1.1633 (1.2441)	mem 17413MB
[2023-01-31 22:34:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][700/1251]	eta 0:05:12 lr 0.000940	time 0.5495 (0.5665)	loss 3.7670 (3.6796)	grad_norm 1.1579 (1.2433)	mem 17413MB
[2023-01-31 22:34:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][750/1251]	eta 0:04:43 lr 0.000940	time 0.5553 (0.5665)	loss 4.3557 (3.6848)	grad_norm 1.2020 (1.2428)	mem 17413MB
[2023-01-31 22:35:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][800/1251]	eta 0:04:15 lr 0.000940	time 0.5628 (0.5664)	loss 4.0553 (3.6905)	grad_norm 1.1640 (1.2426)	mem 17413MB
[2023-01-31 22:35:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][850/1251]	eta 0:03:47 lr 0.000940	time 0.5609 (0.5664)	loss 2.5959 (3.6904)	grad_norm 1.1907 (1.2418)	mem 17413MB
[2023-01-31 22:36:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][900/1251]	eta 0:03:18 lr 0.000939	time 0.6175 (0.5666)	loss 2.3463 (3.6775)	grad_norm 1.3977 (1.2419)	mem 17413MB
[2023-01-31 22:36:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][950/1251]	eta 0:02:50 lr 0.000939	time 0.5544 (0.5664)	loss 3.9946 (3.6764)	grad_norm 1.2709 (1.2427)	mem 17413MB
[2023-01-31 22:37:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][1000/1251]	eta 0:02:22 lr 0.000939	time 0.5600 (0.5665)	loss 4.5705 (3.6695)	grad_norm 1.2213 (1.2420)	mem 17413MB
[2023-01-31 22:37:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][1050/1251]	eta 0:01:53 lr 0.000939	time 0.5555 (0.5665)	loss 4.1795 (3.6707)	grad_norm 1.1529 (1.2430)	mem 17413MB
[2023-01-31 22:38:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][1100/1251]	eta 0:01:25 lr 0.000939	time 0.5560 (0.5663)	loss 3.7127 (3.6737)	grad_norm 1.2248 (1.2432)	mem 17413MB
[2023-01-31 22:38:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][1150/1251]	eta 0:00:57 lr 0.000939	time 0.5533 (0.5664)	loss 3.8212 (3.6706)	grad_norm 1.1161 (1.2425)	mem 17413MB
[2023-01-31 22:38:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][1200/1251]	eta 0:00:28 lr 0.000939	time 0.5564 (0.5662)	loss 3.8433 (3.6753)	grad_norm 1.3496 (1.2431)	mem 17413MB
[2023-01-31 22:39:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [47/300][1250/1251]	eta 0:00:00 lr 0.000939	time 0.5493 (0.5661)	loss 3.6663 (3.6764)	grad_norm 1.2753 (1.2429)	mem 17413MB
[2023-01-31 22:39:27 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 47 training takes 0:11:48
[2023-01-31 22:39:27 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_47.pth saving......
[2023-01-31 22:39:29 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_47.pth saved !!!
[2023-01-31 22:39:30 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.861 (0.861)	Loss 1.0138 (1.0138)	Acc@1 76.465 (76.465)	Acc@5 94.141 (94.141)	Mem 17413MB
[2023-01-31 22:39:38 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 74.052 Acc@5 92.324
[2023-01-31 22:39:38 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 74.1%
[2023-01-31 22:39:39 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.225 (1.225)	Loss 0.9628 (0.9628)	Acc@1 79.199 (79.199)	Acc@5 93.262 (93.262)	Mem 17413MB
[2023-01-31 22:39:47 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.716 Acc@5 93.242
[2023-01-31 22:39:47 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 75.7%
[2023-01-31 22:39:47 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 75.72% at 47 epoch
[2023-01-31 22:39:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][0/1251]	eta 0:34:40 lr 0.000939	time 1.6628 (1.6628)	loss 3.8466 (3.8466)	grad_norm 1.1448 (1.1448)	mem 17413MB
[2023-01-31 22:40:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][50/1251]	eta 0:11:50 lr 0.000939	time 0.5509 (0.5914)	loss 3.8570 (3.6849)	grad_norm 1.2385 (1.2451)	mem 17413MB
[2023-01-31 22:40:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][100/1251]	eta 0:11:04 lr 0.000939	time 0.5577 (0.5772)	loss 2.5979 (3.6857)	grad_norm 1.2584 (1.2471)	mem 17413MB
[2023-01-31 22:41:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][150/1251]	eta 0:10:32 lr 0.000938	time 0.5573 (0.5747)	loss 3.3782 (3.6653)	grad_norm 1.2563 (1.2473)	mem 17413MB
[2023-01-31 22:41:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][200/1251]	eta 0:10:01 lr 0.000938	time 0.5570 (0.5727)	loss 3.9531 (3.6887)	grad_norm 1.2054 (1.2494)	mem 17413MB
[2023-01-31 22:42:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][250/1251]	eta 0:09:32 lr 0.000938	time 0.5532 (0.5714)	loss 3.1306 (3.6631)	grad_norm 1.4141 (1.2494)	mem 17413MB
[2023-01-31 22:42:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][300/1251]	eta 0:09:02 lr 0.000938	time 0.5588 (0.5703)	loss 3.9188 (3.6606)	grad_norm 1.1765 (1.2481)	mem 17413MB
[2023-01-31 22:43:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][350/1251]	eta 0:08:33 lr 0.000938	time 0.5518 (0.5698)	loss 3.3634 (3.6585)	grad_norm 1.1564 (1.2504)	mem 17413MB
[2023-01-31 22:43:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][400/1251]	eta 0:08:04 lr 0.000938	time 0.5598 (0.5692)	loss 4.0638 (3.6618)	grad_norm 1.3237 (1.2497)	mem 17413MB
[2023-01-31 22:44:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][450/1251]	eta 0:07:35 lr 0.000938	time 0.6322 (0.5692)	loss 3.4750 (3.6578)	grad_norm 1.3292 (1.2522)	mem 17413MB
[2023-01-31 22:44:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][500/1251]	eta 0:07:06 lr 0.000938	time 0.5621 (0.5684)	loss 4.0632 (3.6662)	grad_norm 1.2577 (1.2512)	mem 17413MB
[2023-01-31 22:45:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][550/1251]	eta 0:06:38 lr 0.000938	time 0.5479 (0.5685)	loss 2.8133 (3.6671)	grad_norm 1.2822 (1.2502)	mem 17413MB
[2023-01-31 22:45:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][600/1251]	eta 0:06:10 lr 0.000938	time 0.5553 (0.5684)	loss 3.5795 (3.6700)	grad_norm 1.2504 (1.2526)	mem 17413MB
[2023-01-31 22:45:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][650/1251]	eta 0:05:41 lr 0.000937	time 0.5556 (0.5683)	loss 3.4558 (3.6770)	grad_norm 1.1229 (1.2520)	mem 17413MB
[2023-01-31 22:46:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][700/1251]	eta 0:05:13 lr 0.000937	time 0.5554 (0.5682)	loss 4.0156 (3.6812)	grad_norm 1.2732 (1.2510)	mem 17413MB
[2023-01-31 22:46:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][750/1251]	eta 0:04:44 lr 0.000937	time 0.6191 (0.5682)	loss 4.2862 (3.6794)	grad_norm 1.4862 (1.2527)	mem 17413MB
[2023-01-31 22:47:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][800/1251]	eta 0:04:16 lr 0.000937	time 0.5559 (0.5680)	loss 3.9225 (3.6889)	grad_norm 1.3384 (1.2520)	mem 17413MB
[2023-01-31 22:47:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][850/1251]	eta 0:03:47 lr 0.000937	time 0.5849 (0.5680)	loss 3.1438 (3.6772)	grad_norm 1.2873 (1.2525)	mem 17413MB
[2023-01-31 22:48:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][900/1251]	eta 0:03:19 lr 0.000937	time 0.6212 (0.5680)	loss 3.7360 (3.6777)	grad_norm 1.1681 (1.2516)	mem 17413MB
[2023-01-31 22:48:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][950/1251]	eta 0:02:50 lr 0.000937	time 0.5511 (0.5677)	loss 3.9517 (3.6814)	grad_norm 1.2807 (1.2522)	mem 17413MB
[2023-01-31 22:49:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][1000/1251]	eta 0:02:22 lr 0.000937	time 0.5647 (0.5678)	loss 3.0140 (3.6803)	grad_norm 1.1653 (1.2519)	mem 17413MB
[2023-01-31 22:49:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][1050/1251]	eta 0:01:54 lr 0.000937	time 0.5575 (0.5676)	loss 3.3702 (3.6752)	grad_norm 1.2480 (1.2507)	mem 17413MB
[2023-01-31 22:50:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][1100/1251]	eta 0:01:25 lr 0.000937	time 0.5494 (0.5677)	loss 3.8065 (3.6768)	grad_norm 1.2806 (1.2511)	mem 17413MB
[2023-01-31 22:50:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][1150/1251]	eta 0:00:57 lr 0.000936	time 0.6247 (0.5676)	loss 3.8431 (3.6699)	grad_norm 1.1826 (1.2521)	mem 17413MB
[2023-01-31 22:51:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][1200/1251]	eta 0:00:28 lr 0.000936	time 0.5643 (0.5676)	loss 3.5179 (3.6745)	grad_norm 1.1498 (1.2505)	mem 17413MB
[2023-01-31 22:51:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [48/300][1250/1251]	eta 0:00:00 lr 0.000936	time 0.5491 (0.5675)	loss 3.7346 (3.6742)	grad_norm 1.1835 (1.2506)	mem 17413MB
[2023-01-31 22:51:37 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 48 training takes 0:11:50
[2023-01-31 22:51:37 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_48.pth saving......
[2023-01-31 22:51:39 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_48.pth saved !!!
[2023-01-31 22:51:40 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.886 (0.886)	Loss 0.9982 (0.9982)	Acc@1 74.902 (74.902)	Acc@5 93.262 (93.262)	Mem 17413MB
[2023-01-31 22:51:48 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 74.158 Acc@5 92.600
[2023-01-31 22:51:48 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 74.2%
[2023-01-31 22:51:49 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.185 (1.185)	Loss 1.0782 (1.0782)	Acc@1 74.219 (74.219)	Acc@5 92.676 (92.676)	Mem 17413MB
[2023-01-31 22:51:57 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.854 Acc@5 93.308
[2023-01-31 22:51:57 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 75.9%
[2023-01-31 22:51:57 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 75.85% at 48 epoch
[2023-01-31 22:51:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][0/1251]	eta 0:35:17 lr 0.000936	time 1.6927 (1.6927)	loss 3.9461 (3.9461)	grad_norm 1.1076 (1.1076)	mem 17413MB
[2023-01-31 22:52:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][50/1251]	eta 0:11:45 lr 0.000936	time 0.5598 (0.5876)	loss 2.7845 (3.7200)	grad_norm 1.2673 (1.2537)	mem 17413MB
[2023-01-31 22:52:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][100/1251]	eta 0:11:06 lr 0.000936	time 0.5495 (0.5793)	loss 3.0944 (3.6351)	grad_norm 1.1200 (1.2493)	mem 17413MB
[2023-01-31 22:53:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][150/1251]	eta 0:10:33 lr 0.000936	time 0.5584 (0.5756)	loss 3.9053 (3.6191)	grad_norm 1.2986 (1.2487)	mem 17413MB
[2023-01-31 22:53:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][200/1251]	eta 0:10:03 lr 0.000936	time 0.5557 (0.5742)	loss 3.7706 (3.6009)	grad_norm 1.3914 (1.2473)	mem 17413MB
[2023-01-31 22:54:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][250/1251]	eta 0:09:33 lr 0.000936	time 0.5562 (0.5725)	loss 4.1785 (3.6031)	grad_norm 1.2155 (nan)	mem 17413MB
[2023-01-31 22:54:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][300/1251]	eta 0:09:03 lr 0.000936	time 0.6212 (0.5717)	loss 3.5432 (3.6145)	grad_norm 1.3283 (nan)	mem 17413MB
[2023-01-31 22:55:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][350/1251]	eta 0:08:34 lr 0.000936	time 0.5577 (0.5710)	loss 3.7205 (3.6178)	grad_norm 1.2242 (nan)	mem 17413MB
[2023-01-31 22:55:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][400/1251]	eta 0:08:05 lr 0.000935	time 0.5617 (0.5705)	loss 3.7575 (3.6344)	grad_norm 1.3123 (nan)	mem 17413MB
[2023-01-31 22:56:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][450/1251]	eta 0:07:37 lr 0.000935	time 0.5548 (0.5706)	loss 3.8493 (3.6434)	grad_norm 1.3264 (nan)	mem 17413MB
[2023-01-31 22:56:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][500/1251]	eta 0:07:08 lr 0.000935	time 0.5541 (0.5701)	loss 2.9496 (3.6386)	grad_norm 1.2407 (nan)	mem 17413MB
[2023-01-31 22:57:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][550/1251]	eta 0:06:39 lr 0.000935	time 0.5540 (0.5697)	loss 3.9841 (3.6404)	grad_norm 1.1872 (nan)	mem 17413MB
[2023-01-31 22:57:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][600/1251]	eta 0:06:10 lr 0.000935	time 0.5583 (0.5697)	loss 4.1464 (3.6460)	grad_norm 1.3485 (nan)	mem 17413MB
[2023-01-31 22:58:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][650/1251]	eta 0:05:42 lr 0.000935	time 0.5578 (0.5695)	loss 3.6605 (3.6571)	grad_norm 1.1700 (nan)	mem 17413MB
[2023-01-31 22:58:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][700/1251]	eta 0:05:13 lr 0.000935	time 0.5563 (0.5694)	loss 3.5522 (3.6520)	grad_norm 1.3654 (nan)	mem 17413MB
[2023-01-31 22:59:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][750/1251]	eta 0:04:45 lr 0.000935	time 0.5583 (0.5693)	loss 3.9101 (3.6544)	grad_norm 1.1981 (nan)	mem 17413MB
[2023-01-31 22:59:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][800/1251]	eta 0:04:16 lr 0.000935	time 0.6110 (0.5694)	loss 3.4560 (3.6487)	grad_norm 1.2044 (nan)	mem 17413MB
[2023-01-31 23:00:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][850/1251]	eta 0:03:48 lr 0.000935	time 0.6217 (0.5692)	loss 4.0711 (3.6416)	grad_norm 1.1271 (nan)	mem 17413MB
[2023-01-31 23:00:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][900/1251]	eta 0:03:19 lr 0.000934	time 0.5573 (0.5692)	loss 2.7004 (3.6454)	grad_norm 1.3373 (nan)	mem 17413MB
[2023-01-31 23:00:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][950/1251]	eta 0:02:51 lr 0.000934	time 0.5557 (0.5690)	loss 3.6268 (3.6438)	grad_norm 1.2548 (nan)	mem 17413MB
[2023-01-31 23:01:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][1000/1251]	eta 0:02:22 lr 0.000934	time 0.6187 (0.5691)	loss 4.0508 (3.6442)	grad_norm 1.3039 (nan)	mem 17413MB
[2023-01-31 23:01:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][1050/1251]	eta 0:01:54 lr 0.000934	time 0.5587 (0.5689)	loss 3.5094 (3.6451)	grad_norm 1.1679 (nan)	mem 17413MB
[2023-01-31 23:02:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][1100/1251]	eta 0:01:25 lr 0.000934	time 0.5580 (0.5689)	loss 3.5175 (3.6445)	grad_norm 1.3535 (nan)	mem 17413MB
[2023-01-31 23:02:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][1150/1251]	eta 0:00:57 lr 0.000934	time 0.5532 (0.5688)	loss 4.3253 (3.6444)	grad_norm 1.3267 (nan)	mem 17413MB
[2023-01-31 23:03:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][1200/1251]	eta 0:00:29 lr 0.000934	time 0.6287 (0.5687)	loss 4.2806 (3.6435)	grad_norm 1.2541 (nan)	mem 17413MB
[2023-01-31 23:03:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [49/300][1250/1251]	eta 0:00:00 lr 0.000934	time 0.5486 (0.5687)	loss 3.6020 (3.6457)	grad_norm 1.1892 (nan)	mem 17413MB
[2023-01-31 23:03:48 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 49 training takes 0:11:51
[2023-01-31 23:03:49 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_49.pth saving......
[2023-01-31 23:03:50 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_49.pth saved !!!
[2023-01-31 23:03:51 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.821 (0.821)	Loss 1.0507 (1.0507)	Acc@1 73.535 (73.535)	Acc@5 93.652 (93.652)	Mem 17413MB
[2023-01-31 23:03:59 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 74.452 Acc@5 92.598
[2023-01-31 23:03:59 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 74.5%
[2023-01-31 23:04:00 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.171 (1.171)	Loss 0.9029 (0.9029)	Acc@1 77.930 (77.930)	Acc@5 94.434 (94.434)	Mem 17413MB
[2023-01-31 23:04:08 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.078 Acc@5 93.406
[2023-01-31 23:04:08 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 76.1%
[2023-01-31 23:04:08 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 76.08% at 49 epoch
[2023-01-31 23:04:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][0/1251]	eta 0:36:08 lr 0.000934	time 1.7335 (1.7335)	loss 3.3205 (3.3205)	grad_norm 1.5302 (1.5302)	mem 17413MB
[2023-01-31 23:04:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][50/1251]	eta 0:11:49 lr 0.000934	time 0.5519 (0.5906)	loss 4.1978 (3.5871)	grad_norm 1.1444 (1.2475)	mem 17413MB
[2023-01-31 23:05:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][100/1251]	eta 0:11:06 lr 0.000933	time 0.6349 (0.5791)	loss 3.5803 (3.5884)	grad_norm 1.5297 (1.2609)	mem 17413MB
[2023-01-31 23:05:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][150/1251]	eta 0:10:33 lr 0.000933	time 0.5539 (0.5755)	loss 3.7876 (3.6610)	grad_norm 1.1699 (1.2590)	mem 17413MB
[2023-01-31 23:06:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][200/1251]	eta 0:10:02 lr 0.000933	time 0.5481 (0.5729)	loss 3.8726 (3.6436)	grad_norm 1.1584 (1.2500)	mem 17413MB
[2023-01-31 23:06:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][250/1251]	eta 0:09:31 lr 0.000933	time 0.5555 (0.5711)	loss 3.8146 (3.6423)	grad_norm 1.1628 (1.2500)	mem 17413MB
[2023-01-31 23:07:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][300/1251]	eta 0:09:02 lr 0.000933	time 0.5550 (0.5707)	loss 2.7508 (3.6321)	grad_norm 1.2570 (1.2528)	mem 17413MB
[2023-01-31 23:07:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][350/1251]	eta 0:08:33 lr 0.000933	time 0.5524 (0.5696)	loss 3.2525 (3.6683)	grad_norm 1.5368 (1.2527)	mem 17413MB
[2023-01-31 23:07:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][400/1251]	eta 0:08:04 lr 0.000933	time 0.5605 (0.5691)	loss 3.4230 (3.6675)	grad_norm 1.4010 (1.2586)	mem 17413MB
[2023-01-31 23:08:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][450/1251]	eta 0:07:35 lr 0.000933	time 0.5528 (0.5686)	loss 3.1098 (3.6703)	grad_norm 1.2514 (1.2589)	mem 17413MB
[2023-01-31 23:08:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][500/1251]	eta 0:07:06 lr 0.000933	time 0.6216 (0.5684)	loss 4.1398 (3.6641)	grad_norm 1.2068 (1.2594)	mem 17413MB
[2023-01-31 23:09:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][550/1251]	eta 0:06:38 lr 0.000933	time 0.5533 (0.5682)	loss 3.8088 (3.6683)	grad_norm 1.2821 (1.2575)	mem 17413MB
[2023-01-31 23:09:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][600/1251]	eta 0:06:09 lr 0.000932	time 0.5553 (0.5678)	loss 3.3369 (3.6661)	grad_norm 1.2286 (1.2578)	mem 17413MB
[2023-01-31 23:10:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][650/1251]	eta 0:05:41 lr 0.000932	time 0.5534 (0.5679)	loss 3.2677 (3.6607)	grad_norm 1.2485 (1.2571)	mem 17413MB
[2023-01-31 23:10:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][700/1251]	eta 0:05:12 lr 0.000932	time 0.5842 (0.5680)	loss 2.9312 (3.6598)	grad_norm 1.4517 (1.2579)	mem 17413MB
[2023-01-31 23:11:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][750/1251]	eta 0:04:44 lr 0.000932	time 0.5542 (0.5679)	loss 2.5671 (3.6591)	grad_norm 1.2216 (1.2567)	mem 17413MB
[2023-01-31 23:11:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][800/1251]	eta 0:04:16 lr 0.000932	time 0.5590 (0.5678)	loss 2.5883 (3.6705)	grad_norm 1.1635 (1.2563)	mem 17413MB
[2023-01-31 23:12:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][850/1251]	eta 0:03:47 lr 0.000932	time 0.5596 (0.5677)	loss 3.4957 (3.6706)	grad_norm 1.2799 (1.2557)	mem 17413MB
[2023-01-31 23:12:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][900/1251]	eta 0:03:19 lr 0.000932	time 0.6259 (0.5677)	loss 4.2733 (3.6713)	grad_norm 1.1685 (1.2556)	mem 17413MB
[2023-01-31 23:13:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][950/1251]	eta 0:02:50 lr 0.000932	time 0.5629 (0.5676)	loss 4.3006 (3.6671)	grad_norm 1.2353 (1.2563)	mem 17413MB
[2023-01-31 23:13:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][1000/1251]	eta 0:02:22 lr 0.000932	time 0.5522 (0.5677)	loss 3.2974 (3.6661)	grad_norm 1.2394 (1.2540)	mem 17413MB
[2023-01-31 23:14:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][1050/1251]	eta 0:01:54 lr 0.000931	time 0.5716 (0.5675)	loss 4.0343 (3.6627)	grad_norm 1.1538 (1.2554)	mem 17413MB
[2023-01-31 23:14:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][1100/1251]	eta 0:01:25 lr 0.000931	time 0.6568 (0.5677)	loss 3.7900 (3.6611)	grad_norm 1.2789 (1.2546)	mem 17413MB
[2023-01-31 23:15:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][1150/1251]	eta 0:00:57 lr 0.000931	time 0.5602 (0.5676)	loss 3.9564 (3.6641)	grad_norm 1.2625 (1.2547)	mem 17413MB
[2023-01-31 23:15:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][1200/1251]	eta 0:00:28 lr 0.000931	time 0.5571 (0.5677)	loss 3.3686 (3.6609)	grad_norm 1.2305 (1.2547)	mem 17413MB
[2023-01-31 23:15:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [50/300][1250/1251]	eta 0:00:00 lr 0.000931	time 0.5497 (0.5675)	loss 4.2000 (3.6624)	grad_norm 1.1729 (1.2556)	mem 17413MB
[2023-01-31 23:15:58 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 50 training takes 0:11:50
[2023-01-31 23:15:58 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_50.pth saving......
[2023-01-31 23:16:00 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_50.pth saved !!!
[2023-01-31 23:16:01 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.847 (0.847)	Loss 1.0943 (1.0943)	Acc@1 74.805 (74.805)	Acc@5 92.383 (92.383)	Mem 17413MB
[2023-01-31 23:16:09 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 74.240 Acc@5 92.606
[2023-01-31 23:16:09 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 74.2%
[2023-01-31 23:16:10 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.198 (1.198)	Loss 1.0018 (1.0018)	Acc@1 75.391 (75.391)	Acc@5 92.480 (92.480)	Mem 17413MB
[2023-01-31 23:16:18 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.294 Acc@5 93.506
[2023-01-31 23:16:18 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 76.3%
[2023-01-31 23:16:18 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 76.29% at 50 epoch
[2023-01-31 23:16:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][0/1251]	eta 0:34:52 lr 0.000931	time 1.6727 (1.6727)	loss 2.6375 (2.6375)	grad_norm 1.1159 (1.1159)	mem 17413MB
[2023-01-31 23:16:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][50/1251]	eta 0:11:47 lr 0.000931	time 0.5605 (0.5888)	loss 4.0436 (3.6836)	grad_norm 1.3460 (1.2384)	mem 17413MB
[2023-01-31 23:17:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][100/1251]	eta 0:11:07 lr 0.000931	time 0.6314 (0.5795)	loss 3.0209 (3.6986)	grad_norm 1.1360 (1.2358)	mem 17413MB
[2023-01-31 23:17:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][150/1251]	eta 0:10:33 lr 0.000931	time 0.5578 (0.5754)	loss 4.0425 (3.6666)	grad_norm 1.3880 (1.2444)	mem 17413MB
[2023-01-31 23:18:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][200/1251]	eta 0:10:02 lr 0.000931	time 0.5563 (0.5729)	loss 4.3872 (3.6776)	grad_norm 1.2292 (1.2518)	mem 17413MB
[2023-01-31 23:18:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][250/1251]	eta 0:09:32 lr 0.000931	time 0.6461 (0.5724)	loss 2.8026 (3.6562)	grad_norm 1.2619 (1.2534)	mem 17413MB
[2023-01-31 23:19:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][300/1251]	eta 0:09:03 lr 0.000930	time 0.5573 (0.5712)	loss 3.6752 (3.6617)	grad_norm 1.2699 (1.2553)	mem 17413MB
[2023-01-31 23:19:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][350/1251]	eta 0:08:34 lr 0.000930	time 0.6444 (0.5711)	loss 2.9290 (3.6462)	grad_norm 1.0904 (1.2581)	mem 17413MB
[2023-01-31 23:20:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][400/1251]	eta 0:08:05 lr 0.000930	time 0.5629 (0.5705)	loss 3.8714 (3.6402)	grad_norm 1.1383 (1.2551)	mem 17413MB
[2023-01-31 23:20:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][450/1251]	eta 0:07:36 lr 0.000930	time 0.6219 (0.5702)	loss 3.9579 (3.6431)	grad_norm 1.1035 (nan)	mem 17413MB
[2023-01-31 23:21:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][500/1251]	eta 0:07:07 lr 0.000930	time 0.5591 (0.5697)	loss 4.2109 (3.6394)	grad_norm 1.3595 (nan)	mem 17413MB
[2023-01-31 23:21:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][550/1251]	eta 0:06:39 lr 0.000930	time 0.6313 (0.5695)	loss 2.7317 (3.6383)	grad_norm 1.2249 (nan)	mem 17413MB
[2023-01-31 23:22:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][600/1251]	eta 0:06:10 lr 0.000930	time 0.5583 (0.5694)	loss 3.3303 (3.6391)	grad_norm 1.2218 (nan)	mem 17413MB
[2023-01-31 23:22:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][650/1251]	eta 0:05:42 lr 0.000930	time 0.5598 (0.5691)	loss 3.4478 (3.6368)	grad_norm 1.5705 (nan)	mem 17413MB
[2023-01-31 23:22:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][700/1251]	eta 0:05:13 lr 0.000930	time 0.5576 (0.5691)	loss 2.8135 (3.6376)	grad_norm 1.3510 (nan)	mem 17413MB
[2023-01-31 23:23:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][750/1251]	eta 0:04:44 lr 0.000929	time 0.5503 (0.5688)	loss 3.6126 (3.6280)	grad_norm 1.2676 (nan)	mem 17413MB
[2023-01-31 23:23:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][800/1251]	eta 0:04:16 lr 0.000929	time 0.5520 (0.5688)	loss 3.2892 (3.6304)	grad_norm 1.3722 (nan)	mem 17413MB
[2023-01-31 23:24:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][850/1251]	eta 0:03:48 lr 0.000929	time 0.5451 (0.5687)	loss 3.7576 (3.6331)	grad_norm 1.1572 (nan)	mem 17413MB
[2023-01-31 23:24:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][900/1251]	eta 0:03:19 lr 0.000929	time 0.5585 (0.5686)	loss 3.6244 (3.6294)	grad_norm 1.2453 (nan)	mem 17413MB
[2023-01-31 23:25:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][950/1251]	eta 0:02:51 lr 0.000929	time 0.5527 (0.5685)	loss 2.8837 (3.6300)	grad_norm 1.3531 (nan)	mem 17413MB
[2023-01-31 23:25:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][1000/1251]	eta 0:02:22 lr 0.000929	time 0.5575 (0.5682)	loss 2.7421 (3.6257)	grad_norm 1.3684 (nan)	mem 17413MB
[2023-01-31 23:26:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][1050/1251]	eta 0:01:54 lr 0.000929	time 0.5567 (0.5682)	loss 4.3134 (3.6196)	grad_norm 1.3318 (nan)	mem 17413MB
[2023-01-31 23:26:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][1100/1251]	eta 0:01:25 lr 0.000929	time 0.5567 (0.5682)	loss 3.8017 (3.6250)	grad_norm 1.2372 (nan)	mem 17413MB
[2023-01-31 23:27:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][1150/1251]	eta 0:00:57 lr 0.000929	time 0.5574 (0.5680)	loss 3.5929 (3.6269)	grad_norm 1.3094 (nan)	mem 17413MB
[2023-01-31 23:27:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][1200/1251]	eta 0:00:28 lr 0.000929	time 0.5563 (0.5679)	loss 3.3426 (3.6264)	grad_norm 1.2518 (nan)	mem 17413MB
[2023-01-31 23:28:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [51/300][1250/1251]	eta 0:00:00 lr 0.000928	time 0.5493 (0.5679)	loss 3.9580 (3.6273)	grad_norm 1.2525 (nan)	mem 17413MB
[2023-01-31 23:28:09 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 51 training takes 0:11:50
[2023-01-31 23:28:09 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_51.pth saving......
[2023-01-31 23:28:11 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_51.pth saved !!!
[2023-01-31 23:28:12 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.836 (0.836)	Loss 1.0139 (1.0139)	Acc@1 74.805 (74.805)	Acc@5 93.555 (93.555)	Mem 17413MB
[2023-01-31 23:28:19 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 74.398 Acc@5 92.450
[2023-01-31 23:28:19 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 74.4%
[2023-01-31 23:28:21 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.189 (1.189)	Loss 0.9488 (0.9488)	Acc@1 75.879 (75.879)	Acc@5 94.336 (94.336)	Mem 17413MB
[2023-01-31 23:28:29 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.470 Acc@5 93.562
[2023-01-31 23:28:29 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 76.5%
[2023-01-31 23:28:29 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 76.47% at 51 epoch
[2023-01-31 23:28:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][0/1251]	eta 0:35:40 lr 0.000928	time 1.7113 (1.7113)	loss 3.4976 (3.4976)	grad_norm 1.3587 (1.3587)	mem 17413MB
[2023-01-31 23:28:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][50/1251]	eta 0:11:51 lr 0.000928	time 0.5531 (0.5925)	loss 3.7292 (3.6183)	grad_norm 1.1339 (1.2502)	mem 17413MB
[2023-01-31 23:29:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][100/1251]	eta 0:11:07 lr 0.000928	time 0.5526 (0.5799)	loss 4.1977 (3.5964)	grad_norm 1.4896 (1.2477)	mem 17413MB
[2023-01-31 23:29:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][150/1251]	eta 0:10:33 lr 0.000928	time 0.5601 (0.5753)	loss 4.0817 (3.6857)	grad_norm 1.2991 (1.2515)	mem 17413MB
[2023-01-31 23:30:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][200/1251]	eta 0:10:02 lr 0.000928	time 0.5584 (0.5736)	loss 3.5919 (3.6806)	grad_norm 1.2731 (1.2524)	mem 17413MB
[2023-01-31 23:30:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][250/1251]	eta 0:09:32 lr 0.000928	time 0.6127 (0.5720)	loss 3.7596 (3.6828)	grad_norm 1.3751 (1.2569)	mem 17413MB
[2023-01-31 23:31:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][300/1251]	eta 0:09:03 lr 0.000928	time 0.5572 (0.5711)	loss 4.5701 (3.6759)	grad_norm 1.1940 (1.2587)	mem 17413MB
[2023-01-31 23:31:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][350/1251]	eta 0:08:33 lr 0.000928	time 0.5515 (0.5705)	loss 4.9743 (3.6753)	grad_norm 1.2629 (1.2536)	mem 17413MB
[2023-01-31 23:32:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][400/1251]	eta 0:08:05 lr 0.000928	time 0.5556 (0.5700)	loss 4.1964 (3.6886)	grad_norm 1.2285 (1.2545)	mem 17413MB
[2023-01-31 23:32:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][450/1251]	eta 0:07:36 lr 0.000927	time 0.5669 (0.5695)	loss 4.2747 (3.6871)	grad_norm 1.2615 (1.2523)	mem 17413MB
[2023-01-31 23:33:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][500/1251]	eta 0:07:07 lr 0.000927	time 0.5602 (0.5694)	loss 4.3133 (3.6974)	grad_norm 1.1395 (1.2555)	mem 17413MB
[2023-01-31 23:33:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][550/1251]	eta 0:06:38 lr 0.000927	time 0.5521 (0.5688)	loss 3.3109 (3.6932)	grad_norm 1.3347 (1.2531)	mem 17413MB
[2023-01-31 23:34:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][600/1251]	eta 0:06:10 lr 0.000927	time 0.5587 (0.5688)	loss 3.9874 (3.6855)	grad_norm 1.3503 (1.2542)	mem 17413MB
[2023-01-31 23:34:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][650/1251]	eta 0:05:41 lr 0.000927	time 0.5582 (0.5686)	loss 4.2965 (3.6783)	grad_norm 1.3664 (1.2536)	mem 17413MB
[2023-01-31 23:35:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][700/1251]	eta 0:05:13 lr 0.000927	time 0.5526 (0.5687)	loss 3.6160 (3.6700)	grad_norm 1.3530 (1.2553)	mem 17413MB
[2023-01-31 23:35:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][750/1251]	eta 0:04:44 lr 0.000927	time 0.5550 (0.5684)	loss 3.0626 (3.6723)	grad_norm 1.3413 (1.2556)	mem 17413MB
[2023-01-31 23:36:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][800/1251]	eta 0:04:16 lr 0.000927	time 0.6308 (0.5683)	loss 4.2979 (3.6619)	grad_norm 1.3085 (1.2544)	mem 17413MB
[2023-01-31 23:36:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][850/1251]	eta 0:03:47 lr 0.000927	time 0.5541 (0.5680)	loss 4.0874 (3.6612)	grad_norm 1.3232 (1.2543)	mem 17413MB
[2023-01-31 23:37:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][900/1251]	eta 0:03:19 lr 0.000926	time 0.6277 (0.5681)	loss 4.0150 (3.6632)	grad_norm 1.1785 (1.2549)	mem 17413MB
[2023-01-31 23:37:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][950/1251]	eta 0:02:50 lr 0.000926	time 0.5552 (0.5680)	loss 3.8500 (3.6588)	grad_norm 1.1772 (1.2547)	mem 17413MB
[2023-01-31 23:37:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][1000/1251]	eta 0:02:22 lr 0.000926	time 0.5605 (0.5681)	loss 3.7685 (3.6592)	grad_norm 1.1683 (1.2535)	mem 17413MB
[2023-01-31 23:38:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][1050/1251]	eta 0:01:54 lr 0.000926	time 0.5582 (0.5680)	loss 2.6345 (3.6601)	grad_norm 1.2596 (1.2554)	mem 17413MB
[2023-01-31 23:38:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][1100/1251]	eta 0:01:25 lr 0.000926	time 0.5528 (0.5680)	loss 3.6441 (3.6620)	grad_norm 1.2340 (1.2556)	mem 17413MB
[2023-01-31 23:39:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][1150/1251]	eta 0:00:57 lr 0.000926	time 0.5599 (0.5681)	loss 3.5293 (3.6630)	grad_norm 1.2801 (1.2561)	mem 17413MB
[2023-01-31 23:39:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][1200/1251]	eta 0:00:28 lr 0.000926	time 0.5584 (0.5680)	loss 3.5340 (3.6633)	grad_norm 1.1522 (1.2546)	mem 17413MB
[2023-01-31 23:40:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [52/300][1250/1251]	eta 0:00:00 lr 0.000926	time 0.5499 (0.5681)	loss 4.0911 (3.6595)	grad_norm 1.3388 (1.2544)	mem 17413MB
[2023-01-31 23:40:19 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 52 training takes 0:11:50
[2023-01-31 23:40:20 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_52.pth saving......
[2023-01-31 23:40:21 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_52.pth saved !!!
[2023-01-31 23:40:22 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.876 (0.876)	Loss 1.0955 (1.0955)	Acc@1 73.926 (73.926)	Acc@5 93.555 (93.555)	Mem 17413MB
[2023-01-31 23:40:30 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 74.866 Acc@5 92.742
[2023-01-31 23:40:30 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 74.9%
[2023-01-31 23:40:31 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.311 (1.311)	Loss 0.8919 (0.8919)	Acc@1 79.199 (79.199)	Acc@5 95.215 (95.215)	Mem 17413MB
[2023-01-31 23:40:39 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.670 Acc@5 93.658
[2023-01-31 23:40:39 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 76.7%
[2023-01-31 23:40:39 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 76.67% at 52 epoch
[2023-01-31 23:40:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][0/1251]	eta 0:34:01 lr 0.000926	time 1.6316 (1.6316)	loss 3.9799 (3.9799)	grad_norm 1.0789 (1.0789)	mem 17413MB
[2023-01-31 23:41:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][50/1251]	eta 0:11:52 lr 0.000926	time 0.5568 (0.5933)	loss 4.2818 (3.5662)	grad_norm 1.1269 (1.2907)	mem 17413MB
[2023-01-31 23:41:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][100/1251]	eta 0:11:07 lr 0.000925	time 0.5609 (0.5802)	loss 2.9953 (3.6305)	grad_norm 1.2023 (1.2577)	mem 17413MB
[2023-01-31 23:42:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][150/1251]	eta 0:10:34 lr 0.000925	time 0.5557 (0.5767)	loss 3.8360 (3.5948)	grad_norm 1.5142 (1.2569)	mem 17413MB
[2023-01-31 23:42:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][200/1251]	eta 0:10:03 lr 0.000925	time 0.5520 (0.5738)	loss 4.5073 (3.6072)	grad_norm 1.2244 (1.2655)	mem 17413MB
[2023-01-31 23:43:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][250/1251]	eta 0:09:33 lr 0.000925	time 0.6456 (0.5727)	loss 4.5814 (3.6199)	grad_norm 1.2827 (1.2638)	mem 17413MB
[2023-01-31 23:43:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][300/1251]	eta 0:09:03 lr 0.000925	time 0.5611 (0.5720)	loss 2.4811 (3.6187)	grad_norm 1.1321 (1.2629)	mem 17413MB
[2023-01-31 23:44:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][350/1251]	eta 0:08:34 lr 0.000925	time 0.5591 (0.5713)	loss 3.1733 (3.6006)	grad_norm 1.3142 (1.2625)	mem 17413MB
[2023-01-31 23:44:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][400/1251]	eta 0:08:05 lr 0.000925	time 0.5573 (0.5710)	loss 3.9308 (3.6130)	grad_norm 1.5666 (1.2638)	mem 17413MB
[2023-01-31 23:44:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][450/1251]	eta 0:07:37 lr 0.000925	time 0.5561 (0.5707)	loss 3.1247 (3.6172)	grad_norm 1.2191 (1.2666)	mem 17413MB
[2023-01-31 23:45:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][500/1251]	eta 0:07:08 lr 0.000925	time 0.5490 (0.5703)	loss 4.2796 (3.6190)	grad_norm 1.3187 (1.2673)	mem 17413MB
[2023-01-31 23:45:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][550/1251]	eta 0:06:39 lr 0.000924	time 0.5584 (0.5702)	loss 4.4533 (3.6380)	grad_norm 1.2718 (1.2680)	mem 17413MB
[2023-01-31 23:46:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][600/1251]	eta 0:06:11 lr 0.000924	time 0.5531 (0.5701)	loss 3.7878 (3.6270)	grad_norm 1.1406 (1.2663)	mem 17413MB
[2023-01-31 23:46:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][650/1251]	eta 0:05:42 lr 0.000924	time 0.5570 (0.5699)	loss 4.5379 (3.6332)	grad_norm 1.3266 (1.2670)	mem 17413MB
[2023-01-31 23:47:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][700/1251]	eta 0:05:13 lr 0.000924	time 0.5610 (0.5698)	loss 2.9673 (3.6299)	grad_norm 1.1870 (1.2662)	mem 17413MB
[2023-01-31 23:47:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][750/1251]	eta 0:04:45 lr 0.000924	time 0.5551 (0.5696)	loss 3.9107 (3.6248)	grad_norm 1.1786 (1.2669)	mem 17413MB
[2023-01-31 23:48:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][800/1251]	eta 0:04:16 lr 0.000924	time 0.5602 (0.5693)	loss 3.1810 (3.6195)	grad_norm 1.2908 (1.2654)	mem 17413MB
[2023-01-31 23:48:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][850/1251]	eta 0:03:48 lr 0.000924	time 0.5570 (0.5692)	loss 4.0777 (3.6151)	grad_norm 1.3052 (1.2633)	mem 17413MB
[2023-01-31 23:49:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][900/1251]	eta 0:03:19 lr 0.000924	time 0.5604 (0.5692)	loss 3.5630 (3.6145)	grad_norm 1.2497 (1.2632)	mem 17413MB
[2023-01-31 23:49:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][950/1251]	eta 0:02:51 lr 0.000924	time 0.5543 (0.5692)	loss 2.7879 (3.6114)	grad_norm 1.1996 (1.2634)	mem 17413MB
[2023-01-31 23:50:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][1000/1251]	eta 0:02:22 lr 0.000923	time 0.5543 (0.5692)	loss 2.4508 (3.6089)	grad_norm 1.1985 (1.2630)	mem 17413MB
[2023-01-31 23:50:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][1050/1251]	eta 0:01:54 lr 0.000923	time 0.5539 (0.5691)	loss 3.7848 (3.6066)	grad_norm 1.1847 (1.2636)	mem 17413MB
[2023-01-31 23:51:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][1100/1251]	eta 0:01:25 lr 0.000923	time 0.5607 (0.5691)	loss 3.4619 (3.6040)	grad_norm 1.1819 (1.2635)	mem 17413MB
[2023-01-31 23:51:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][1150/1251]	eta 0:00:57 lr 0.000923	time 0.5549 (0.5690)	loss 3.1800 (3.6041)	grad_norm 1.4192 (1.2634)	mem 17413MB
[2023-01-31 23:52:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][1200/1251]	eta 0:00:29 lr 0.000923	time 0.5604 (0.5690)	loss 3.8102 (3.6062)	grad_norm 1.2363 (1.2637)	mem 17413MB
[2023-01-31 23:52:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [53/300][1250/1251]	eta 0:00:00 lr 0.000923	time 0.5536 (0.5690)	loss 3.7375 (3.5988)	grad_norm 1.1890 (1.2643)	mem 17413MB
[2023-01-31 23:52:31 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 53 training takes 0:11:51
[2023-01-31 23:52:32 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_53.pth saving......
[2023-01-31 23:52:33 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_53.pth saved !!!
[2023-01-31 23:52:34 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.858 (0.858)	Loss 1.0846 (1.0846)	Acc@1 73.047 (73.047)	Acc@5 92.090 (92.090)	Mem 17413MB
[2023-01-31 23:52:42 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 74.720 Acc@5 92.766
[2023-01-31 23:52:42 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 74.7%
[2023-01-31 23:52:43 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.211 (1.211)	Loss 0.8682 (0.8682)	Acc@1 78.027 (78.027)	Acc@5 95.703 (95.703)	Mem 17413MB
[2023-01-31 23:52:51 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.806 Acc@5 93.750
[2023-01-31 23:52:51 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 76.8%
[2023-01-31 23:52:51 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 76.81% at 53 epoch
[2023-01-31 23:52:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][0/1251]	eta 0:34:12 lr 0.000923	time 1.6405 (1.6405)	loss 2.6495 (2.6495)	grad_norm 1.3830 (1.3830)	mem 17413MB
[2023-01-31 23:53:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][50/1251]	eta 0:11:48 lr 0.000923	time 0.5537 (0.5898)	loss 4.1611 (3.7289)	grad_norm 1.3253 (1.2556)	mem 17413MB
[2023-01-31 23:53:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][100/1251]	eta 0:11:06 lr 0.000923	time 0.5541 (0.5790)	loss 3.9359 (3.6608)	grad_norm 1.5581 (1.2755)	mem 17413MB
[2023-01-31 23:54:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][150/1251]	eta 0:10:33 lr 0.000923	time 0.5546 (0.5752)	loss 4.1843 (3.6883)	grad_norm 1.2397 (1.2729)	mem 17413MB
[2023-01-31 23:54:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][200/1251]	eta 0:10:02 lr 0.000922	time 0.5689 (0.5733)	loss 3.8075 (3.6579)	grad_norm 1.1876 (1.2693)	mem 17413MB
[2023-01-31 23:55:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][250/1251]	eta 0:09:31 lr 0.000922	time 0.5579 (0.5714)	loss 4.2423 (3.6504)	grad_norm 1.3714 (1.2694)	mem 17413MB
[2023-01-31 23:55:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][300/1251]	eta 0:09:02 lr 0.000922	time 0.5486 (0.5706)	loss 3.4056 (3.6377)	grad_norm 1.1678 (1.2669)	mem 17413MB
[2023-01-31 23:56:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][350/1251]	eta 0:08:33 lr 0.000922	time 0.5567 (0.5696)	loss 3.6302 (3.6359)	grad_norm 1.2472 (1.2669)	mem 17413MB
[2023-01-31 23:56:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][400/1251]	eta 0:08:04 lr 0.000922	time 0.5530 (0.5695)	loss 3.8519 (3.6255)	grad_norm 1.2247 (1.2651)	mem 17413MB
[2023-01-31 23:57:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][450/1251]	eta 0:07:35 lr 0.000922	time 0.5590 (0.5691)	loss 3.7772 (3.6231)	grad_norm 1.2785 (1.2648)	mem 17413MB
[2023-01-31 23:57:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][500/1251]	eta 0:07:07 lr 0.000922	time 0.5618 (0.5687)	loss 2.3915 (3.6203)	grad_norm 1.3351 (1.2658)	mem 17413MB
[2023-01-31 23:58:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][550/1251]	eta 0:06:38 lr 0.000922	time 0.5587 (0.5687)	loss 4.2858 (3.6236)	grad_norm 1.2519 (1.2657)	mem 17413MB
[2023-01-31 23:58:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][600/1251]	eta 0:06:10 lr 0.000922	time 0.5520 (0.5686)	loss 3.4637 (3.6241)	grad_norm 1.1864 (1.2654)	mem 17413MB
[2023-01-31 23:59:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][650/1251]	eta 0:05:41 lr 0.000921	time 0.5585 (0.5687)	loss 3.5365 (3.6309)	grad_norm 1.1703 (1.2669)	mem 17413MB
[2023-01-31 23:59:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][700/1251]	eta 0:05:13 lr 0.000921	time 0.5570 (0.5684)	loss 3.8132 (3.6385)	grad_norm 1.4036 (nan)	mem 17413MB
[2023-01-31 23:59:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][750/1251]	eta 0:04:44 lr 0.000921	time 0.5585 (0.5682)	loss 2.6157 (3.6377)	grad_norm 1.2231 (nan)	mem 17413MB
[2023-02-01 00:00:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][800/1251]	eta 0:04:16 lr 0.000921	time 0.5542 (0.5680)	loss 3.9529 (3.6443)	grad_norm 1.4033 (nan)	mem 17413MB
[2023-02-01 00:00:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][850/1251]	eta 0:03:47 lr 0.000921	time 0.5520 (0.5679)	loss 2.8330 (3.6487)	grad_norm 1.3264 (nan)	mem 17413MB
[2023-02-01 00:01:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][900/1251]	eta 0:03:19 lr 0.000921	time 0.5549 (0.5679)	loss 4.0389 (3.6524)	grad_norm 1.2794 (nan)	mem 17413MB
[2023-02-01 00:01:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][950/1251]	eta 0:02:50 lr 0.000921	time 0.5566 (0.5678)	loss 4.0656 (3.6499)	grad_norm 1.2061 (nan)	mem 17413MB
[2023-02-01 00:02:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][1000/1251]	eta 0:02:22 lr 0.000921	time 0.6325 (0.5678)	loss 3.6056 (3.6530)	grad_norm 1.2171 (nan)	mem 17413MB
[2023-02-01 00:02:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][1050/1251]	eta 0:01:54 lr 0.000921	time 0.5620 (0.5677)	loss 4.2690 (3.6547)	grad_norm 1.3966 (nan)	mem 17413MB
[2023-02-01 00:03:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][1100/1251]	eta 0:01:25 lr 0.000920	time 0.5643 (0.5679)	loss 4.3946 (3.6581)	grad_norm 1.2218 (nan)	mem 17413MB
[2023-02-01 00:03:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][1150/1251]	eta 0:00:57 lr 0.000920	time 0.6231 (0.5678)	loss 3.7820 (3.6523)	grad_norm 1.1756 (nan)	mem 17413MB
[2023-02-01 00:04:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][1200/1251]	eta 0:00:28 lr 0.000920	time 0.6183 (0.5679)	loss 4.0927 (3.6554)	grad_norm 1.1603 (nan)	mem 17413MB
[2023-02-01 00:04:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [54/300][1250/1251]	eta 0:00:00 lr 0.000920	time 0.6111 (0.5677)	loss 2.7105 (3.6500)	grad_norm 1.3123 (nan)	mem 17413MB
[2023-02-01 00:04:42 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 54 training takes 0:11:50
[2023-02-01 00:04:42 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_54.pth saving......
[2023-02-01 00:04:44 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_54.pth saved !!!
[2023-02-01 00:04:44 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.974 (0.974)	Loss 1.0992 (1.0992)	Acc@1 74.512 (74.512)	Acc@5 92.676 (92.676)	Mem 17413MB
[2023-02-01 00:04:53 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 74.578 Acc@5 92.808
[2023-02-01 00:04:53 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 74.6%
[2023-02-01 00:04:54 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.187 (1.187)	Loss 0.9344 (0.9344)	Acc@1 77.051 (77.051)	Acc@5 94.922 (94.922)	Mem 17413MB
[2023-02-01 00:05:02 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.968 Acc@5 93.802
[2023-02-01 00:05:02 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 77.0%
[2023-02-01 00:05:02 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 76.97% at 54 epoch
[2023-02-01 00:05:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][0/1251]	eta 0:35:46 lr 0.000920	time 1.7160 (1.7160)	loss 3.5662 (3.5662)	grad_norm 1.3550 (1.3550)	mem 17413MB
[2023-02-01 00:05:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][50/1251]	eta 0:11:46 lr 0.000920	time 0.5552 (0.5879)	loss 3.6018 (3.6330)	grad_norm 1.2564 (1.2572)	mem 17413MB
[2023-02-01 00:06:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][100/1251]	eta 0:11:07 lr 0.000920	time 0.5580 (0.5795)	loss 3.7199 (3.6091)	grad_norm 1.2913 (1.2741)	mem 17413MB
[2023-02-01 00:06:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][150/1251]	eta 0:10:33 lr 0.000920	time 0.5591 (0.5750)	loss 3.6537 (3.6387)	grad_norm 1.2118 (1.2617)	mem 17413MB
[2023-02-01 00:06:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][200/1251]	eta 0:10:02 lr 0.000920	time 0.5494 (0.5729)	loss 3.9187 (3.6583)	grad_norm 1.4863 (1.2646)	mem 17413MB
[2023-02-01 00:07:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][250/1251]	eta 0:09:32 lr 0.000920	time 0.5529 (0.5720)	loss 4.6735 (3.6605)	grad_norm 1.2391 (1.2601)	mem 17413MB
[2023-02-01 00:07:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][300/1251]	eta 0:09:03 lr 0.000919	time 0.5559 (0.5717)	loss 3.0386 (3.6248)	grad_norm 1.2229 (1.2590)	mem 17413MB
[2023-02-01 00:08:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][350/1251]	eta 0:08:34 lr 0.000919	time 0.5581 (0.5705)	loss 3.1180 (3.6152)	grad_norm 1.3334 (1.2599)	mem 17413MB
[2023-02-01 00:08:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][400/1251]	eta 0:08:05 lr 0.000919	time 0.5549 (0.5705)	loss 2.5600 (3.6128)	grad_norm 1.2617 (1.2611)	mem 17413MB
[2023-02-01 00:09:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][450/1251]	eta 0:07:36 lr 0.000919	time 0.5567 (0.5700)	loss 4.3238 (3.6102)	grad_norm 1.2046 (1.2603)	mem 17413MB
[2023-02-01 00:09:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][500/1251]	eta 0:07:07 lr 0.000919	time 0.5561 (0.5695)	loss 2.6452 (3.6088)	grad_norm 1.1926 (1.2600)	mem 17413MB
[2023-02-01 00:10:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][550/1251]	eta 0:06:39 lr 0.000919	time 0.5754 (0.5696)	loss 3.8429 (3.6175)	grad_norm 1.3577 (1.2616)	mem 17413MB
[2023-02-01 00:10:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][600/1251]	eta 0:06:10 lr 0.000919	time 0.5597 (0.5692)	loss 3.5119 (3.6158)	grad_norm 1.4034 (1.2597)	mem 17413MB
[2023-02-01 00:11:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][650/1251]	eta 0:05:42 lr 0.000919	time 0.5564 (0.5692)	loss 3.2443 (3.6241)	grad_norm 1.1550 (1.2603)	mem 17413MB
[2023-02-01 00:11:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][700/1251]	eta 0:05:13 lr 0.000919	time 0.5549 (0.5691)	loss 4.1063 (3.6172)	grad_norm 1.1955 (1.2609)	mem 17413MB
[2023-02-01 00:12:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][750/1251]	eta 0:04:45 lr 0.000918	time 0.5556 (0.5689)	loss 2.7807 (3.6195)	grad_norm 1.1235 (1.2600)	mem 17413MB
[2023-02-01 00:12:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][800/1251]	eta 0:04:16 lr 0.000918	time 0.5785 (0.5690)	loss 2.9209 (3.6092)	grad_norm 1.2914 (1.2607)	mem 17413MB
[2023-02-01 00:13:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][850/1251]	eta 0:03:48 lr 0.000918	time 0.6156 (0.5687)	loss 2.5514 (3.6045)	grad_norm 1.2414 (1.2594)	mem 17413MB
[2023-02-01 00:13:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][900/1251]	eta 0:03:19 lr 0.000918	time 0.5555 (0.5687)	loss 3.5637 (3.6065)	grad_norm 1.2412 (1.2600)	mem 17413MB
[2023-02-01 00:14:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][950/1251]	eta 0:02:51 lr 0.000918	time 0.5561 (0.5687)	loss 4.2493 (3.6099)	grad_norm 1.3641 (1.2587)	mem 17413MB
[2023-02-01 00:14:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][1000/1251]	eta 0:02:22 lr 0.000918	time 0.5620 (0.5686)	loss 3.7916 (3.6151)	grad_norm 1.2718 (1.2599)	mem 17413MB
[2023-02-01 00:14:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][1050/1251]	eta 0:01:54 lr 0.000918	time 0.5590 (0.5685)	loss 2.4426 (3.6106)	grad_norm 1.4291 (1.2610)	mem 17413MB
[2023-02-01 00:15:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][1100/1251]	eta 0:01:25 lr 0.000918	time 0.6370 (0.5685)	loss 3.9978 (3.6073)	grad_norm 1.1300 (1.2614)	mem 17413MB
[2023-02-01 00:15:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][1150/1251]	eta 0:00:57 lr 0.000918	time 0.5611 (0.5684)	loss 4.6211 (3.6120)	grad_norm 1.2623 (1.2604)	mem 17413MB
[2023-02-01 00:16:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][1200/1251]	eta 0:00:28 lr 0.000917	time 0.5542 (0.5684)	loss 3.1301 (3.6034)	grad_norm 1.2637 (1.2599)	mem 17413MB
[2023-02-01 00:16:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [55/300][1250/1251]	eta 0:00:00 lr 0.000917	time 0.5579 (0.5683)	loss 4.0719 (3.6033)	grad_norm 1.1525 (1.2604)	mem 17413MB
[2023-02-01 00:16:53 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 55 training takes 0:11:51
[2023-02-01 00:16:53 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_55.pth saving......
[2023-02-01 00:16:55 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_55.pth saved !!!
[2023-02-01 00:16:56 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.885 (0.885)	Loss 1.1139 (1.1139)	Acc@1 75.586 (75.586)	Acc@5 91.895 (91.895)	Mem 17413MB
[2023-02-01 00:17:04 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 74.822 Acc@5 92.846
[2023-02-01 00:17:04 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 74.8%
[2023-02-01 00:17:05 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.203 (1.203)	Loss 0.9447 (0.9447)	Acc@1 78.223 (78.223)	Acc@5 93.848 (93.848)	Mem 17413MB
[2023-02-01 00:17:13 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.172 Acc@5 93.890
[2023-02-01 00:17:13 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 77.2%
[2023-02-01 00:17:13 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 77.17% at 55 epoch
[2023-02-01 00:17:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][0/1251]	eta 0:37:48 lr 0.000917	time 1.8130 (1.8130)	loss 3.6039 (3.6039)	grad_norm 1.2489 (1.2489)	mem 17413MB
[2023-02-01 00:17:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][50/1251]	eta 0:11:47 lr 0.000917	time 0.5548 (0.5894)	loss 3.2325 (3.5259)	grad_norm 1.1481 (1.2661)	mem 17413MB
[2023-02-01 00:18:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][100/1251]	eta 0:11:07 lr 0.000917	time 0.6368 (0.5797)	loss 2.8128 (3.5854)	grad_norm 1.1907 (1.2633)	mem 17413MB
[2023-02-01 00:18:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][150/1251]	eta 0:10:32 lr 0.000917	time 0.5589 (0.5741)	loss 3.1360 (3.6262)	grad_norm 1.1539 (1.2509)	mem 17413MB
[2023-02-01 00:19:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][200/1251]	eta 0:10:01 lr 0.000917	time 0.5769 (0.5720)	loss 3.0061 (3.5974)	grad_norm 1.2289 (1.2474)	mem 17413MB
[2023-02-01 00:19:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][250/1251]	eta 0:09:30 lr 0.000917	time 0.5493 (0.5703)	loss 3.3484 (3.5914)	grad_norm 1.1151 (nan)	mem 17413MB
[2023-02-01 00:20:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][300/1251]	eta 0:09:02 lr 0.000917	time 0.5584 (0.5699)	loss 4.1211 (3.5986)	grad_norm 1.2903 (nan)	mem 17413MB
[2023-02-01 00:20:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][350/1251]	eta 0:08:33 lr 0.000916	time 0.5605 (0.5694)	loss 3.6764 (3.6136)	grad_norm 1.2704 (nan)	mem 17413MB
[2023-02-01 00:21:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][400/1251]	eta 0:08:04 lr 0.000916	time 0.5600 (0.5691)	loss 4.1305 (3.6163)	grad_norm 1.2325 (nan)	mem 17413MB
[2023-02-01 00:21:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][450/1251]	eta 0:07:35 lr 0.000916	time 0.5574 (0.5691)	loss 3.5735 (3.6135)	grad_norm 1.2058 (nan)	mem 17413MB
[2023-02-01 00:21:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][500/1251]	eta 0:07:07 lr 0.000916	time 0.6190 (0.5689)	loss 3.8966 (3.6198)	grad_norm 1.2632 (nan)	mem 17413MB
[2023-02-01 00:22:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][550/1251]	eta 0:06:38 lr 0.000916	time 0.5537 (0.5686)	loss 3.4139 (3.6244)	grad_norm 1.3292 (nan)	mem 17413MB
[2023-02-01 00:22:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][600/1251]	eta 0:06:10 lr 0.000916	time 0.5607 (0.5686)	loss 3.5655 (3.6202)	grad_norm 1.2939 (nan)	mem 17413MB
[2023-02-01 00:23:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][650/1251]	eta 0:05:41 lr 0.000916	time 0.5538 (0.5685)	loss 3.3875 (3.6285)	grad_norm 1.2690 (nan)	mem 17413MB
[2023-02-01 00:23:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][700/1251]	eta 0:05:13 lr 0.000916	time 0.5604 (0.5683)	loss 3.2273 (3.6241)	grad_norm 1.4390 (nan)	mem 17413MB
[2023-02-01 00:24:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][750/1251]	eta 0:04:44 lr 0.000916	time 0.5580 (0.5681)	loss 4.2997 (3.6148)	grad_norm 1.2168 (nan)	mem 17413MB
[2023-02-01 00:24:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][800/1251]	eta 0:04:16 lr 0.000915	time 0.5660 (0.5681)	loss 3.8923 (3.6151)	grad_norm 1.1002 (nan)	mem 17413MB
[2023-02-01 00:25:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][850/1251]	eta 0:03:47 lr 0.000915	time 0.5545 (0.5680)	loss 3.8495 (3.6103)	grad_norm 1.3536 (nan)	mem 17413MB
[2023-02-01 00:25:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][900/1251]	eta 0:03:19 lr 0.000915	time 0.6251 (0.5680)	loss 3.7288 (3.6145)	grad_norm 1.4672 (nan)	mem 17413MB
[2023-02-01 00:26:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][950/1251]	eta 0:02:50 lr 0.000915	time 0.5634 (0.5679)	loss 3.9139 (3.6174)	grad_norm 1.2140 (nan)	mem 17413MB
[2023-02-01 00:26:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][1000/1251]	eta 0:02:22 lr 0.000915	time 0.5601 (0.5677)	loss 3.9950 (3.6249)	grad_norm 1.4960 (nan)	mem 17413MB
[2023-02-01 00:27:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][1050/1251]	eta 0:01:54 lr 0.000915	time 0.5586 (0.5677)	loss 3.5801 (3.6151)	grad_norm 1.2559 (nan)	mem 17413MB
[2023-02-01 00:27:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][1100/1251]	eta 0:01:25 lr 0.000915	time 0.5517 (0.5677)	loss 2.9600 (3.6158)	grad_norm 1.2863 (nan)	mem 17413MB
[2023-02-01 00:28:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][1150/1251]	eta 0:00:57 lr 0.000915	time 0.5541 (0.5676)	loss 3.6679 (3.6139)	grad_norm 1.4242 (nan)	mem 17413MB
[2023-02-01 00:28:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][1200/1251]	eta 0:00:28 lr 0.000915	time 0.5524 (0.5675)	loss 2.9738 (3.6171)	grad_norm 1.5962 (nan)	mem 17413MB
[2023-02-01 00:29:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [56/300][1250/1251]	eta 0:00:00 lr 0.000914	time 0.5513 (0.5675)	loss 3.6586 (3.6180)	grad_norm 1.1843 (nan)	mem 17413MB
[2023-02-01 00:29:03 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 56 training takes 0:11:50
[2023-02-01 00:29:03 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_56.pth saving......
[2023-02-01 00:29:05 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_56.pth saved !!!
[2023-02-01 00:29:06 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.001 (1.001)	Loss 1.0847 (1.0847)	Acc@1 74.414 (74.414)	Acc@5 93.848 (93.848)	Mem 17413MB
[2023-02-01 00:29:14 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 74.824 Acc@5 92.784
[2023-02-01 00:29:14 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 74.8%
[2023-02-01 00:29:15 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.359 (1.359)	Loss 0.9767 (0.9767)	Acc@1 76.855 (76.855)	Acc@5 94.141 (94.141)	Mem 17413MB
[2023-02-01 00:29:23 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.304 Acc@5 93.944
[2023-02-01 00:29:23 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 77.3%
[2023-02-01 00:29:23 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 77.30% at 56 epoch
[2023-02-01 00:29:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][0/1251]	eta 0:35:06 lr 0.000914	time 1.6840 (1.6840)	loss 2.4859 (2.4859)	grad_norm 1.2463 (1.2463)	mem 17413MB
[2023-02-01 00:29:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][50/1251]	eta 0:11:46 lr 0.000914	time 0.5618 (0.5883)	loss 3.8853 (3.4801)	grad_norm 1.3992 (1.2611)	mem 17413MB
[2023-02-01 00:30:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][100/1251]	eta 0:11:04 lr 0.000914	time 0.5550 (0.5775)	loss 4.4142 (3.5785)	grad_norm 1.1716 (1.2651)	mem 17413MB
[2023-02-01 00:30:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][150/1251]	eta 0:10:31 lr 0.000914	time 0.5590 (0.5732)	loss 3.4773 (3.5811)	grad_norm 1.2438 (1.2608)	mem 17413MB
[2023-02-01 00:31:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][200/1251]	eta 0:10:00 lr 0.000914	time 0.5529 (0.5710)	loss 3.0944 (3.5804)	grad_norm 1.3207 (1.2654)	mem 17413MB
[2023-02-01 00:31:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][250/1251]	eta 0:09:30 lr 0.000914	time 0.5567 (0.5699)	loss 4.3135 (3.5606)	grad_norm 1.1867 (1.2629)	mem 17413MB
[2023-02-01 00:32:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][300/1251]	eta 0:09:01 lr 0.000914	time 0.5615 (0.5691)	loss 2.8006 (3.5568)	grad_norm 1.1999 (1.2648)	mem 17413MB
[2023-02-01 00:32:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][350/1251]	eta 0:08:32 lr 0.000914	time 0.5568 (0.5688)	loss 4.5833 (3.5654)	grad_norm 1.2042 (1.2663)	mem 17413MB
[2023-02-01 00:33:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][400/1251]	eta 0:08:03 lr 0.000913	time 0.5539 (0.5680)	loss 3.9710 (3.5929)	grad_norm 1.3462 (1.2702)	mem 17413MB
[2023-02-01 00:33:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][450/1251]	eta 0:07:34 lr 0.000913	time 0.6210 (0.5676)	loss 3.6049 (3.5981)	grad_norm 1.2758 (1.2718)	mem 17413MB
[2023-02-01 00:34:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][500/1251]	eta 0:07:06 lr 0.000913	time 0.5510 (0.5674)	loss 4.1252 (3.5874)	grad_norm 1.2493 (1.2727)	mem 17413MB
[2023-02-01 00:34:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][550/1251]	eta 0:06:37 lr 0.000913	time 0.5523 (0.5675)	loss 3.7568 (3.5929)	grad_norm 1.3366 (1.2710)	mem 17413MB
[2023-02-01 00:35:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][600/1251]	eta 0:06:09 lr 0.000913	time 0.5697 (0.5673)	loss 2.7464 (3.5804)	grad_norm 1.2530 (1.2704)	mem 17413MB
[2023-02-01 00:35:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][650/1251]	eta 0:05:40 lr 0.000913	time 0.5563 (0.5672)	loss 2.2065 (3.5795)	grad_norm 1.2284 (1.2710)	mem 17413MB
[2023-02-01 00:36:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][700/1251]	eta 0:05:12 lr 0.000913	time 0.5614 (0.5670)	loss 4.6897 (3.5895)	grad_norm 1.2339 (1.2687)	mem 17413MB
[2023-02-01 00:36:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][750/1251]	eta 0:04:44 lr 0.000913	time 0.5505 (0.5670)	loss 3.1918 (3.5889)	grad_norm 1.3974 (1.2690)	mem 17413MB
[2023-02-01 00:36:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][800/1251]	eta 0:04:15 lr 0.000913	time 0.5584 (0.5671)	loss 3.4131 (3.5907)	grad_norm 1.1870 (1.2680)	mem 17413MB
[2023-02-01 00:37:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][850/1251]	eta 0:03:47 lr 0.000912	time 0.5625 (0.5668)	loss 3.2388 (3.5877)	grad_norm 1.3514 (1.2692)	mem 17413MB
[2023-02-01 00:37:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][900/1251]	eta 0:03:19 lr 0.000912	time 0.6117 (0.5670)	loss 3.6799 (3.5814)	grad_norm 1.2045 (1.2701)	mem 17413MB
[2023-02-01 00:38:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][950/1251]	eta 0:02:50 lr 0.000912	time 0.5597 (0.5668)	loss 4.0262 (3.5881)	grad_norm 1.2716 (1.2698)	mem 17413MB
[2023-02-01 00:38:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][1000/1251]	eta 0:02:22 lr 0.000912	time 0.5559 (0.5669)	loss 3.4923 (3.5936)	grad_norm 1.1620 (1.2694)	mem 17413MB
[2023-02-01 00:39:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][1050/1251]	eta 0:01:53 lr 0.000912	time 0.5530 (0.5672)	loss 3.5525 (3.5900)	grad_norm 1.1943 (1.2690)	mem 17413MB
[2023-02-01 00:39:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][1100/1251]	eta 0:01:25 lr 0.000912	time 0.6190 (0.5671)	loss 3.7819 (3.5897)	grad_norm 1.2423 (1.2686)	mem 17413MB
[2023-02-01 00:40:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][1150/1251]	eta 0:00:57 lr 0.000912	time 0.6173 (0.5671)	loss 4.4112 (3.5908)	grad_norm 1.1952 (1.2695)	mem 17413MB
[2023-02-01 00:40:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][1200/1251]	eta 0:00:28 lr 0.000912	time 0.5559 (0.5670)	loss 3.8799 (3.5901)	grad_norm 1.3606 (1.2688)	mem 17413MB
[2023-02-01 00:41:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [57/300][1250/1251]	eta 0:00:00 lr 0.000911	time 0.5602 (0.5670)	loss 3.8670 (3.5859)	grad_norm 1.4698 (1.2686)	mem 17413MB
[2023-02-01 00:41:13 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 57 training takes 0:11:49
[2023-02-01 00:41:13 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_57.pth saving......
[2023-02-01 00:41:15 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_57.pth saved !!!
[2023-02-01 00:41:16 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.905 (0.905)	Loss 1.0633 (1.0633)	Acc@1 75.684 (75.684)	Acc@5 92.773 (92.773)	Mem 17413MB
[2023-02-01 00:41:24 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.120 Acc@5 92.872
[2023-02-01 00:41:24 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 75.1%
[2023-02-01 00:41:25 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.170 (1.170)	Loss 0.9318 (0.9318)	Acc@1 77.734 (77.734)	Acc@5 94.727 (94.727)	Mem 17413MB
[2023-02-01 00:41:33 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.430 Acc@5 93.994
[2023-02-01 00:41:33 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 77.4%
[2023-02-01 00:41:33 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 77.43% at 57 epoch
[2023-02-01 00:41:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][0/1251]	eta 0:34:56 lr 0.000911	time 1.6762 (1.6762)	loss 3.6989 (3.6989)	grad_norm 1.2185 (1.2185)	mem 17413MB
[2023-02-01 00:42:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][50/1251]	eta 0:11:50 lr 0.000911	time 0.5490 (0.5912)	loss 3.8324 (3.4460)	grad_norm 1.1723 (1.2549)	mem 17413MB
[2023-02-01 00:42:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][100/1251]	eta 0:11:08 lr 0.000911	time 0.6193 (0.5811)	loss 4.3286 (3.5580)	grad_norm 1.3505 (1.2639)	mem 17413MB
[2023-02-01 00:43:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][150/1251]	eta 0:10:33 lr 0.000911	time 0.5487 (0.5758)	loss 3.5274 (3.5735)	grad_norm 1.3964 (1.2766)	mem 17413MB
[2023-02-01 00:43:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][200/1251]	eta 0:10:03 lr 0.000911	time 0.5636 (0.5741)	loss 3.2469 (3.5843)	grad_norm 1.1245 (1.2737)	mem 17413MB
[2023-02-01 00:43:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][250/1251]	eta 0:09:33 lr 0.000911	time 0.5580 (0.5728)	loss 4.4459 (3.5791)	grad_norm 1.2780 (1.2731)	mem 17413MB
[2023-02-01 00:44:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][300/1251]	eta 0:09:03 lr 0.000911	time 0.5510 (0.5719)	loss 3.9044 (3.5943)	grad_norm 1.1792 (1.2754)	mem 17413MB
[2023-02-01 00:44:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][350/1251]	eta 0:08:34 lr 0.000911	time 0.5791 (0.5713)	loss 4.4204 (3.6040)	grad_norm 1.3663 (1.2758)	mem 17413MB
[2023-02-01 00:45:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][400/1251]	eta 0:08:05 lr 0.000911	time 0.6225 (0.5706)	loss 3.3252 (3.6069)	grad_norm 1.1541 (1.2758)	mem 17413MB
[2023-02-01 00:45:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][450/1251]	eta 0:07:37 lr 0.000910	time 0.5547 (0.5706)	loss 3.1613 (3.6220)	grad_norm 1.2103 (1.2730)	mem 17413MB
[2023-02-01 00:46:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][500/1251]	eta 0:07:08 lr 0.000910	time 0.6263 (0.5700)	loss 2.4834 (3.6112)	grad_norm 1.1453 (1.2743)	mem 17413MB
[2023-02-01 00:46:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][550/1251]	eta 0:06:39 lr 0.000910	time 0.5609 (0.5698)	loss 3.2827 (3.6214)	grad_norm 1.2011 (1.2741)	mem 17413MB
[2023-02-01 00:47:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][600/1251]	eta 0:06:10 lr 0.000910	time 0.5547 (0.5696)	loss 4.0478 (3.6321)	grad_norm 1.3121 (1.2729)	mem 17413MB
[2023-02-01 00:47:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][650/1251]	eta 0:05:42 lr 0.000910	time 0.5543 (0.5697)	loss 2.5419 (3.6333)	grad_norm 1.2000 (1.2721)	mem 17413MB
[2023-02-01 00:48:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][700/1251]	eta 0:05:13 lr 0.000910	time 0.5628 (0.5693)	loss 3.5104 (3.6321)	grad_norm 1.3027 (1.2710)	mem 17413MB
[2023-02-01 00:48:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][750/1251]	eta 0:04:45 lr 0.000910	time 0.5564 (0.5693)	loss 4.0151 (3.6329)	grad_norm 1.1247 (1.2713)	mem 17413MB
[2023-02-01 00:49:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][800/1251]	eta 0:04:16 lr 0.000910	time 0.6158 (0.5691)	loss 2.5061 (3.6290)	grad_norm 1.3930 (1.2709)	mem 17413MB
[2023-02-01 00:49:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][850/1251]	eta 0:03:48 lr 0.000909	time 0.5633 (0.5691)	loss 4.1460 (3.6282)	grad_norm 1.5056 (1.2702)	mem 17413MB
[2023-02-01 00:50:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][900/1251]	eta 0:03:19 lr 0.000909	time 0.6194 (0.5691)	loss 3.4594 (3.6276)	grad_norm 1.1985 (1.2708)	mem 17413MB
[2023-02-01 00:50:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][950/1251]	eta 0:02:51 lr 0.000909	time 0.5566 (0.5689)	loss 3.5769 (3.6267)	grad_norm 1.3421 (1.2687)	mem 17413MB
[2023-02-01 00:51:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][1000/1251]	eta 0:02:22 lr 0.000909	time 0.5665 (0.5688)	loss 3.4202 (3.6209)	grad_norm 1.2644 (1.2685)	mem 17413MB
[2023-02-01 00:51:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][1050/1251]	eta 0:01:54 lr 0.000909	time 0.5736 (0.5688)	loss 3.9663 (3.6196)	grad_norm 1.2935 (1.2693)	mem 17413MB
[2023-02-01 00:51:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][1100/1251]	eta 0:01:25 lr 0.000909	time 0.5538 (0.5686)	loss 3.7503 (3.6168)	grad_norm 1.3822 (1.2705)	mem 17413MB
[2023-02-01 00:52:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][1150/1251]	eta 0:00:57 lr 0.000909	time 0.5590 (0.5687)	loss 3.9282 (3.6134)	grad_norm 1.2981 (1.2708)	mem 17413MB
[2023-02-01 00:52:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][1200/1251]	eta 0:00:28 lr 0.000909	time 0.6271 (0.5686)	loss 3.7827 (3.6101)	grad_norm 1.3960 (1.2726)	mem 17413MB
[2023-02-01 00:53:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [58/300][1250/1251]	eta 0:00:00 lr 0.000908	time 0.5504 (0.5686)	loss 2.6861 (3.6113)	grad_norm 1.2470 (1.2716)	mem 17413MB
[2023-02-01 00:53:24 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 58 training takes 0:11:51
[2023-02-01 00:53:24 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_58.pth saving......
[2023-02-01 00:53:26 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_58.pth saved !!!
[2023-02-01 00:53:27 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.821 (0.821)	Loss 1.1443 (1.1443)	Acc@1 73.926 (73.926)	Acc@5 92.188 (92.188)	Mem 17413MB
[2023-02-01 00:53:35 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.196 Acc@5 93.022
[2023-02-01 00:53:35 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 75.2%
[2023-02-01 00:53:36 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.280 (1.280)	Loss 0.9527 (0.9527)	Acc@1 78.027 (78.027)	Acc@5 94.824 (94.824)	Mem 17413MB
[2023-02-01 00:53:44 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.532 Acc@5 94.064
[2023-02-01 00:53:44 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 77.5%
[2023-02-01 00:53:44 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 77.53% at 58 epoch
[2023-02-01 00:53:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][0/1251]	eta 0:34:49 lr 0.000908	time 1.6701 (1.6701)	loss 4.1410 (4.1410)	grad_norm 1.3110 (1.3110)	mem 17413MB
[2023-02-01 00:54:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][50/1251]	eta 0:11:46 lr 0.000908	time 0.5644 (0.5881)	loss 3.5412 (3.6019)	grad_norm 1.2495 (1.2660)	mem 17413MB
[2023-02-01 00:54:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][100/1251]	eta 0:11:05 lr 0.000908	time 0.5585 (0.5784)	loss 2.9722 (3.5308)	grad_norm 1.2740 (1.2808)	mem 17413MB
[2023-02-01 00:55:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][150/1251]	eta 0:10:32 lr 0.000908	time 0.5515 (0.5745)	loss 3.8885 (3.5367)	grad_norm 1.4358 (1.2869)	mem 17413MB
[2023-02-01 00:55:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][200/1251]	eta 0:10:01 lr 0.000908	time 0.5536 (0.5727)	loss 4.1248 (3.5635)	grad_norm 1.2404 (1.2848)	mem 17413MB
[2023-02-01 00:56:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][250/1251]	eta 0:09:32 lr 0.000908	time 0.5544 (0.5717)	loss 3.8029 (3.5729)	grad_norm 1.2128 (1.2832)	mem 17413MB
[2023-02-01 00:56:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][300/1251]	eta 0:09:02 lr 0.000908	time 0.5536 (0.5707)	loss 3.7388 (3.5782)	grad_norm 1.2066 (1.2820)	mem 17413MB
[2023-02-01 00:57:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][350/1251]	eta 0:08:33 lr 0.000908	time 0.5632 (0.5701)	loss 3.3814 (3.5897)	grad_norm 1.3894 (1.2836)	mem 17413MB
[2023-02-01 00:57:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][400/1251]	eta 0:08:04 lr 0.000908	time 0.5567 (0.5693)	loss 3.2971 (3.5825)	grad_norm 1.2476 (1.2833)	mem 17413MB
[2023-02-01 00:58:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][450/1251]	eta 0:07:35 lr 0.000907	time 0.6197 (0.5689)	loss 3.6674 (3.5689)	grad_norm 1.3214 (1.2825)	mem 17413MB
[2023-02-01 00:58:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][500/1251]	eta 0:07:07 lr 0.000907	time 0.5617 (0.5687)	loss 3.4385 (3.5793)	grad_norm 1.2693 (1.2824)	mem 17413MB
[2023-02-01 00:58:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][550/1251]	eta 0:06:38 lr 0.000907	time 0.5567 (0.5685)	loss 3.9891 (3.5959)	grad_norm 1.2119 (1.2849)	mem 17413MB
[2023-02-01 00:59:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][600/1251]	eta 0:06:10 lr 0.000907	time 0.5526 (0.5687)	loss 4.1627 (3.5950)	grad_norm 1.1760 (1.2838)	mem 17413MB
[2023-02-01 00:59:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][650/1251]	eta 0:05:41 lr 0.000907	time 0.5542 (0.5684)	loss 3.0422 (3.5879)	grad_norm 1.0544 (1.2824)	mem 17413MB
[2023-02-01 01:00:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][700/1251]	eta 0:05:13 lr 0.000907	time 0.5530 (0.5683)	loss 3.7767 (3.5892)	grad_norm 1.3424 (1.2837)	mem 17413MB
[2023-02-01 01:00:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][750/1251]	eta 0:04:44 lr 0.000907	time 0.5724 (0.5683)	loss 3.6402 (3.5807)	grad_norm 1.2641 (1.2840)	mem 17413MB
[2023-02-01 01:01:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][800/1251]	eta 0:04:16 lr 0.000907	time 0.5649 (0.5683)	loss 2.8576 (3.5862)	grad_norm 1.2199 (1.2865)	mem 17413MB
[2023-02-01 01:01:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][850/1251]	eta 0:03:47 lr 0.000906	time 0.5596 (0.5683)	loss 4.0917 (3.5898)	grad_norm 1.1759 (1.2838)	mem 17413MB
[2023-02-01 01:02:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][900/1251]	eta 0:03:19 lr 0.000906	time 0.5540 (0.5684)	loss 3.6882 (3.5960)	grad_norm 1.1787 (nan)	mem 17413MB
[2023-02-01 01:02:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][950/1251]	eta 0:02:51 lr 0.000906	time 0.5607 (0.5681)	loss 3.3812 (3.6015)	grad_norm 1.3279 (nan)	mem 17413MB
[2023-02-01 01:03:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][1000/1251]	eta 0:02:22 lr 0.000906	time 0.5487 (0.5683)	loss 2.8017 (3.6029)	grad_norm 1.1701 (nan)	mem 17413MB
[2023-02-01 01:03:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][1050/1251]	eta 0:01:54 lr 0.000906	time 0.5607 (0.5682)	loss 3.3425 (3.6030)	grad_norm 1.1929 (nan)	mem 17413MB
[2023-02-01 01:04:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][1100/1251]	eta 0:01:25 lr 0.000906	time 0.5555 (0.5682)	loss 4.1831 (3.6068)	grad_norm 1.2467 (nan)	mem 17413MB
[2023-02-01 01:04:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][1150/1251]	eta 0:00:57 lr 0.000906	time 0.5572 (0.5682)	loss 3.9899 (3.6057)	grad_norm 1.2802 (nan)	mem 17413MB
[2023-02-01 01:05:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][1200/1251]	eta 0:00:28 lr 0.000906	time 0.5622 (0.5682)	loss 4.0160 (3.6020)	grad_norm 1.1840 (nan)	mem 17413MB
[2023-02-01 01:05:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [59/300][1250/1251]	eta 0:00:00 lr 0.000905	time 0.5491 (0.5681)	loss 4.1674 (3.6047)	grad_norm 1.3800 (nan)	mem 17413MB
[2023-02-01 01:05:35 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 59 training takes 0:11:50
[2023-02-01 01:05:35 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_59.pth saving......
[2023-02-01 01:05:37 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_59.pth saved !!!
[2023-02-01 01:05:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.925 (0.925)	Loss 0.9692 (0.9692)	Acc@1 77.441 (77.441)	Acc@5 94.531 (94.531)	Mem 17413MB
[2023-02-01 01:05:46 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.338 Acc@5 93.140
[2023-02-01 01:05:46 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 75.3%
[2023-02-01 01:05:47 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.459 (1.459)	Loss 0.9814 (0.9814)	Acc@1 76.465 (76.465)	Acc@5 93.848 (93.848)	Mem 17413MB
[2023-02-01 01:05:55 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.646 Acc@5 94.114
[2023-02-01 01:05:55 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 77.6%
[2023-02-01 01:05:55 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 77.65% at 59 epoch
[2023-02-01 01:05:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][0/1251]	eta 0:34:11 lr 0.000905	time 1.6399 (1.6399)	loss 3.6426 (3.6426)	grad_norm 1.2469 (1.2469)	mem 17413MB
[2023-02-01 01:06:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][50/1251]	eta 0:11:47 lr 0.000905	time 0.5559 (0.5894)	loss 4.0707 (3.5878)	grad_norm 1.3208 (1.2754)	mem 17413MB
[2023-02-01 01:06:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][100/1251]	eta 0:11:06 lr 0.000905	time 0.5575 (0.5792)	loss 3.9169 (3.5546)	grad_norm 1.2579 (1.2754)	mem 17413MB
[2023-02-01 01:07:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][150/1251]	eta 0:10:33 lr 0.000905	time 0.5583 (0.5757)	loss 3.2199 (3.5647)	grad_norm 1.2649 (1.2711)	mem 17413MB
[2023-02-01 01:07:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][200/1251]	eta 0:10:03 lr 0.000905	time 0.5586 (0.5739)	loss 3.8359 (3.5903)	grad_norm 1.2046 (1.2758)	mem 17413MB
[2023-02-01 01:08:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][250/1251]	eta 0:09:33 lr 0.000905	time 0.5607 (0.5728)	loss 3.6713 (3.5940)	grad_norm 1.3603 (1.2765)	mem 17413MB
[2023-02-01 01:08:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][300/1251]	eta 0:09:03 lr 0.000905	time 0.5561 (0.5717)	loss 4.4538 (3.5930)	grad_norm 1.2546 (1.2712)	mem 17413MB
[2023-02-01 01:09:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][350/1251]	eta 0:08:34 lr 0.000905	time 0.5574 (0.5712)	loss 2.9215 (3.5883)	grad_norm 1.2534 (1.2720)	mem 17413MB
[2023-02-01 01:09:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][400/1251]	eta 0:08:06 lr 0.000904	time 0.5533 (0.5712)	loss 3.8185 (3.6032)	grad_norm 1.2295 (1.2752)	mem 17413MB
[2023-02-01 01:10:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][450/1251]	eta 0:07:37 lr 0.000904	time 0.5594 (0.5707)	loss 3.7244 (3.5951)	grad_norm 1.4135 (1.2763)	mem 17413MB
[2023-02-01 01:10:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][500/1251]	eta 0:07:08 lr 0.000904	time 0.5553 (0.5701)	loss 3.3421 (3.5936)	grad_norm 1.3312 (1.2766)	mem 17413MB
[2023-02-01 01:11:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][550/1251]	eta 0:06:39 lr 0.000904	time 0.5540 (0.5700)	loss 4.1469 (3.6079)	grad_norm 1.1839 (1.2762)	mem 17413MB
[2023-02-01 01:11:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][600/1251]	eta 0:06:10 lr 0.000904	time 0.5591 (0.5699)	loss 3.8066 (3.6108)	grad_norm 1.2022 (nan)	mem 17413MB
[2023-02-01 01:12:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][650/1251]	eta 0:05:42 lr 0.000904	time 0.5678 (0.5697)	loss 3.0668 (3.6139)	grad_norm 1.5169 (nan)	mem 17413MB
[2023-02-01 01:12:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][700/1251]	eta 0:05:13 lr 0.000904	time 0.5628 (0.5694)	loss 3.5387 (3.6139)	grad_norm 1.1779 (nan)	mem 17413MB
[2023-02-01 01:13:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][750/1251]	eta 0:04:45 lr 0.000904	time 0.6411 (0.5693)	loss 4.5779 (3.6110)	grad_norm 1.2776 (nan)	mem 17413MB
[2023-02-01 01:13:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][800/1251]	eta 0:04:16 lr 0.000904	time 0.6286 (0.5691)	loss 2.4661 (3.6071)	grad_norm 1.2784 (nan)	mem 17413MB
[2023-02-01 01:13:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][850/1251]	eta 0:03:48 lr 0.000903	time 0.5543 (0.5689)	loss 2.5371 (3.6037)	grad_norm 1.2881 (nan)	mem 17413MB
[2023-02-01 01:14:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][900/1251]	eta 0:03:19 lr 0.000903	time 0.5599 (0.5688)	loss 2.4260 (3.5989)	grad_norm 1.1839 (nan)	mem 17413MB
[2023-02-01 01:14:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][950/1251]	eta 0:02:51 lr 0.000903	time 0.5544 (0.5688)	loss 3.8233 (3.5940)	grad_norm 1.3728 (nan)	mem 17413MB
[2023-02-01 01:15:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][1000/1251]	eta 0:02:22 lr 0.000903	time 0.5562 (0.5686)	loss 2.5989 (3.5924)	grad_norm 1.1615 (nan)	mem 17413MB
[2023-02-01 01:15:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][1050/1251]	eta 0:01:54 lr 0.000903	time 0.5519 (0.5687)	loss 3.9838 (3.5958)	grad_norm 1.4115 (nan)	mem 17413MB
[2023-02-01 01:16:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][1100/1251]	eta 0:01:25 lr 0.000903	time 0.5665 (0.5686)	loss 2.6218 (3.5964)	grad_norm 1.4768 (nan)	mem 17413MB
[2023-02-01 01:16:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][1150/1251]	eta 0:00:57 lr 0.000903	time 0.6270 (0.5685)	loss 4.1345 (3.5937)	grad_norm 1.1616 (nan)	mem 17413MB
[2023-02-01 01:17:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][1200/1251]	eta 0:00:28 lr 0.000903	time 0.5549 (0.5685)	loss 4.3170 (3.5978)	grad_norm 1.2142 (nan)	mem 17413MB
[2023-02-01 01:17:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [60/300][1250/1251]	eta 0:00:00 lr 0.000902	time 0.5510 (0.5684)	loss 3.8698 (3.5963)	grad_norm 1.3602 (nan)	mem 17413MB
[2023-02-01 01:17:46 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 60 training takes 0:11:51
[2023-02-01 01:17:46 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_60.pth saving......
[2023-02-01 01:17:48 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_60.pth saved !!!
[2023-02-01 01:17:49 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.840 (0.840)	Loss 1.1031 (1.1031)	Acc@1 74.609 (74.609)	Acc@5 92.676 (92.676)	Mem 17413MB
[2023-02-01 01:17:57 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.052 Acc@5 93.016
[2023-02-01 01:17:57 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 75.1%
[2023-02-01 01:17:58 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.248 (1.248)	Loss 0.9063 (0.9063)	Acc@1 79.199 (79.199)	Acc@5 94.727 (94.727)	Mem 17413MB
[2023-02-01 01:18:06 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.764 Acc@5 94.170
[2023-02-01 01:18:06 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 77.8%
[2023-02-01 01:18:06 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 77.76% at 60 epoch
[2023-02-01 01:18:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][0/1251]	eta 0:39:21 lr 0.000902	time 1.8873 (1.8873)	loss 4.6231 (4.6231)	grad_norm 1.3593 (1.3593)	mem 17413MB
[2023-02-01 01:18:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][50/1251]	eta 0:11:54 lr 0.000902	time 0.5581 (0.5947)	loss 3.5485 (3.5530)	grad_norm 1.1921 (1.2960)	mem 17413MB
[2023-02-01 01:19:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][100/1251]	eta 0:11:10 lr 0.000902	time 0.5526 (0.5821)	loss 4.1490 (3.5734)	grad_norm 1.2865 (1.2707)	mem 17413MB
[2023-02-01 01:19:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][150/1251]	eta 0:10:35 lr 0.000902	time 0.5572 (0.5776)	loss 4.2581 (3.5623)	grad_norm 1.4771 (1.2640)	mem 17413MB
[2023-02-01 01:20:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][200/1251]	eta 0:10:04 lr 0.000902	time 0.5565 (0.5752)	loss 3.8014 (3.5661)	grad_norm 1.3281 (1.2648)	mem 17413MB
[2023-02-01 01:20:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][250/1251]	eta 0:09:34 lr 0.000902	time 0.5578 (0.5739)	loss 4.2071 (3.5729)	grad_norm 1.2267 (1.2694)	mem 17413MB
[2023-02-01 01:20:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][300/1251]	eta 0:09:04 lr 0.000902	time 0.5567 (0.5728)	loss 4.0603 (3.5804)	grad_norm 1.3028 (1.2817)	mem 17413MB
[2023-02-01 01:21:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][350/1251]	eta 0:08:35 lr 0.000902	time 0.5583 (0.5720)	loss 3.4522 (3.5850)	grad_norm 1.2157 (1.2823)	mem 17413MB
[2023-02-01 01:21:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][400/1251]	eta 0:08:06 lr 0.000901	time 0.5554 (0.5712)	loss 3.6814 (3.5899)	grad_norm 1.5629 (1.2859)	mem 17413MB
[2023-02-01 01:22:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][450/1251]	eta 0:07:37 lr 0.000901	time 0.5595 (0.5713)	loss 3.6415 (3.5824)	grad_norm 1.3245 (1.2851)	mem 17413MB
[2023-02-01 01:22:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][500/1251]	eta 0:07:08 lr 0.000901	time 0.5538 (0.5709)	loss 2.6569 (3.5830)	grad_norm 1.2604 (1.2811)	mem 17413MB
[2023-02-01 01:23:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][550/1251]	eta 0:06:40 lr 0.000901	time 0.5522 (0.5707)	loss 4.4136 (3.5897)	grad_norm 1.4657 (1.2801)	mem 17413MB
[2023-02-01 01:23:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][600/1251]	eta 0:06:11 lr 0.000901	time 0.5584 (0.5704)	loss 3.2836 (3.5960)	grad_norm 1.3615 (1.2787)	mem 17413MB
[2023-02-01 01:24:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][650/1251]	eta 0:05:42 lr 0.000901	time 0.5560 (0.5703)	loss 2.8698 (3.5893)	grad_norm 1.2785 (1.2777)	mem 17413MB
[2023-02-01 01:24:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][700/1251]	eta 0:05:14 lr 0.000901	time 0.5561 (0.5700)	loss 2.9173 (3.5856)	grad_norm 1.2836 (1.2782)	mem 17413MB
[2023-02-01 01:25:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][750/1251]	eta 0:04:45 lr 0.000901	time 0.5534 (0.5697)	loss 4.2197 (3.5812)	grad_norm 1.2046 (1.2775)	mem 17413MB
[2023-02-01 01:25:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][800/1251]	eta 0:04:16 lr 0.000900	time 0.6197 (0.5696)	loss 3.9440 (3.5871)	grad_norm 1.3058 (1.2778)	mem 17413MB
[2023-02-01 01:26:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][850/1251]	eta 0:03:48 lr 0.000900	time 0.6119 (0.5695)	loss 2.7240 (3.5894)	grad_norm 1.2436 (1.2764)	mem 17413MB
[2023-02-01 01:26:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][900/1251]	eta 0:03:19 lr 0.000900	time 0.5517 (0.5693)	loss 4.0488 (3.6005)	grad_norm 1.3538 (1.2757)	mem 17413MB
[2023-02-01 01:27:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][950/1251]	eta 0:02:51 lr 0.000900	time 0.5618 (0.5693)	loss 3.1173 (3.5999)	grad_norm 1.1843 (1.2766)	mem 17413MB
[2023-02-01 01:27:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][1000/1251]	eta 0:02:22 lr 0.000900	time 0.6087 (0.5692)	loss 3.9389 (3.5999)	grad_norm 1.1969 (1.2769)	mem 17413MB
[2023-02-01 01:28:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][1050/1251]	eta 0:01:54 lr 0.000900	time 0.5680 (0.5691)	loss 2.2671 (3.6041)	grad_norm 1.3717 (1.2776)	mem 17413MB
[2023-02-01 01:28:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][1100/1251]	eta 0:01:25 lr 0.000900	time 0.6206 (0.5692)	loss 3.6191 (3.6065)	grad_norm 1.4209 (1.2788)	mem 17413MB
[2023-02-01 01:29:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][1150/1251]	eta 0:00:57 lr 0.000900	time 0.5544 (0.5692)	loss 3.7758 (3.6004)	grad_norm 1.2539 (1.2791)	mem 17413MB
[2023-02-01 01:29:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][1200/1251]	eta 0:00:29 lr 0.000899	time 0.5606 (0.5689)	loss 2.5896 (3.6001)	grad_norm 1.3523 (1.2807)	mem 17413MB
[2023-02-01 01:29:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [61/300][1250/1251]	eta 0:00:00 lr 0.000899	time 0.6120 (0.5690)	loss 3.5502 (3.5973)	grad_norm 1.2725 (1.2813)	mem 17413MB
[2023-02-01 01:29:58 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 61 training takes 0:11:51
[2023-02-01 01:29:58 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_61.pth saving......
[2023-02-01 01:30:00 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_61.pth saved !!!
[2023-02-01 01:30:01 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.895 (0.895)	Loss 1.1283 (1.1283)	Acc@1 73.438 (73.438)	Acc@5 93.164 (93.164)	Mem 17413MB
[2023-02-01 01:30:09 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.360 Acc@5 93.200
[2023-02-01 01:30:09 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 75.4%
[2023-02-01 01:30:10 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.320 (1.320)	Loss 0.9411 (0.9411)	Acc@1 77.344 (77.344)	Acc@5 94.238 (94.238)	Mem 17413MB
[2023-02-01 01:30:18 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.866 Acc@5 94.196
[2023-02-01 01:30:18 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 77.9%
[2023-02-01 01:30:18 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 77.87% at 61 epoch
[2023-02-01 01:30:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][0/1251]	eta 0:36:54 lr 0.000899	time 1.7703 (1.7703)	loss 4.0449 (4.0449)	grad_norm 1.2578 (1.2578)	mem 17413MB
[2023-02-01 01:30:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][50/1251]	eta 0:11:47 lr 0.000899	time 0.5646 (0.5893)	loss 3.0547 (3.6017)	grad_norm 1.2593 (1.2618)	mem 17413MB
[2023-02-01 01:31:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][100/1251]	eta 0:11:08 lr 0.000899	time 0.6173 (0.5809)	loss 4.2376 (3.5183)	grad_norm 1.2647 (1.2741)	mem 17413MB
[2023-02-01 01:31:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][150/1251]	eta 0:10:34 lr 0.000899	time 0.5588 (0.5763)	loss 4.3257 (3.5007)	grad_norm 1.2623 (1.2788)	mem 17413MB
[2023-02-01 01:32:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][200/1251]	eta 0:10:03 lr 0.000899	time 0.5600 (0.5743)	loss 4.0513 (3.5026)	grad_norm 1.2010 (1.2853)	mem 17413MB
[2023-02-01 01:32:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][250/1251]	eta 0:09:33 lr 0.000899	time 0.5525 (0.5726)	loss 3.4707 (3.5217)	grad_norm 1.1524 (nan)	mem 17413MB
[2023-02-01 01:33:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][300/1251]	eta 0:09:04 lr 0.000899	time 0.5527 (0.5722)	loss 3.9411 (3.5223)	grad_norm 1.3218 (nan)	mem 17413MB
[2023-02-01 01:33:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][350/1251]	eta 0:08:34 lr 0.000898	time 0.5554 (0.5709)	loss 4.3857 (3.5301)	grad_norm 1.2301 (nan)	mem 17413MB
[2023-02-01 01:34:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][400/1251]	eta 0:08:05 lr 0.000898	time 0.5563 (0.5710)	loss 3.6757 (3.5536)	grad_norm 1.2865 (nan)	mem 17413MB
[2023-02-01 01:34:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][450/1251]	eta 0:07:36 lr 0.000898	time 0.5647 (0.5701)	loss 3.1565 (3.5393)	grad_norm 1.2932 (nan)	mem 17413MB
[2023-02-01 01:35:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][500/1251]	eta 0:07:08 lr 0.000898	time 0.6239 (0.5700)	loss 3.2477 (3.5491)	grad_norm 1.2990 (nan)	mem 17413MB
[2023-02-01 01:35:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][550/1251]	eta 0:06:39 lr 0.000898	time 0.5525 (0.5698)	loss 4.1178 (3.5548)	grad_norm 1.2196 (nan)	mem 17413MB
[2023-02-01 01:36:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][600/1251]	eta 0:06:10 lr 0.000898	time 0.5633 (0.5695)	loss 3.0232 (3.5609)	grad_norm 1.2236 (nan)	mem 17413MB
[2023-02-01 01:36:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][650/1251]	eta 0:05:42 lr 0.000898	time 0.5601 (0.5694)	loss 3.7571 (3.5584)	grad_norm 1.1800 (nan)	mem 17413MB
[2023-02-01 01:36:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][700/1251]	eta 0:05:13 lr 0.000898	time 0.5617 (0.5691)	loss 4.4205 (3.5604)	grad_norm 1.3028 (nan)	mem 17413MB
[2023-02-01 01:37:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][750/1251]	eta 0:04:45 lr 0.000897	time 0.5545 (0.5690)	loss 4.2545 (3.5590)	grad_norm 1.4302 (nan)	mem 17413MB
[2023-02-01 01:37:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][800/1251]	eta 0:04:16 lr 0.000897	time 0.5592 (0.5689)	loss 2.5176 (3.5584)	grad_norm 1.2765 (nan)	mem 17413MB
[2023-02-01 01:38:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][850/1251]	eta 0:03:48 lr 0.000897	time 0.5622 (0.5687)	loss 3.6948 (3.5595)	grad_norm 1.3337 (nan)	mem 17413MB
[2023-02-01 01:38:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][900/1251]	eta 0:03:19 lr 0.000897	time 0.6245 (0.5686)	loss 3.0045 (3.5513)	grad_norm 1.1546 (nan)	mem 17413MB
[2023-02-01 01:39:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][950/1251]	eta 0:02:51 lr 0.000897	time 0.5554 (0.5685)	loss 3.7393 (3.5504)	grad_norm 1.3444 (nan)	mem 17413MB
[2023-02-01 01:39:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][1000/1251]	eta 0:02:22 lr 0.000897	time 0.5572 (0.5685)	loss 3.1424 (3.5479)	grad_norm 1.2002 (nan)	mem 17413MB
[2023-02-01 01:40:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][1050/1251]	eta 0:01:54 lr 0.000897	time 0.5565 (0.5685)	loss 3.6336 (3.5508)	grad_norm 1.2771 (nan)	mem 17413MB
[2023-02-01 01:40:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][1100/1251]	eta 0:01:25 lr 0.000897	time 0.6385 (0.5686)	loss 4.0322 (3.5529)	grad_norm 1.1557 (nan)	mem 17413MB
[2023-02-01 01:41:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][1150/1251]	eta 0:00:57 lr 0.000896	time 0.5575 (0.5683)	loss 4.1058 (3.5573)	grad_norm 1.2176 (nan)	mem 17413MB
[2023-02-01 01:41:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][1200/1251]	eta 0:00:28 lr 0.000896	time 0.5628 (0.5683)	loss 3.8171 (3.5599)	grad_norm 1.1567 (nan)	mem 17413MB
[2023-02-01 01:42:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [62/300][1250/1251]	eta 0:00:00 lr 0.000896	time 0.5509 (0.5682)	loss 3.8970 (3.5584)	grad_norm 1.3904 (nan)	mem 17413MB
[2023-02-01 01:42:09 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 62 training takes 0:11:51
[2023-02-01 01:42:09 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_62.pth saving......
[2023-02-01 01:42:11 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_62.pth saved !!!
[2023-02-01 01:42:12 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.976 (0.976)	Loss 1.1331 (1.1331)	Acc@1 72.754 (72.754)	Acc@5 92.480 (92.480)	Mem 17413MB
[2023-02-01 01:42:20 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.534 Acc@5 93.186
[2023-02-01 01:42:20 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 75.5%
[2023-02-01 01:42:21 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.122 (1.122)	Loss 0.9483 (0.9483)	Acc@1 76.660 (76.660)	Acc@5 94.141 (94.141)	Mem 17413MB
[2023-02-01 01:42:29 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.942 Acc@5 94.234
[2023-02-01 01:42:29 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 77.9%
[2023-02-01 01:42:29 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 77.94% at 62 epoch
[2023-02-01 01:42:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][0/1251]	eta 0:34:42 lr 0.000896	time 1.6644 (1.6644)	loss 3.9036 (3.9036)	grad_norm 1.2330 (1.2330)	mem 17413MB
[2023-02-01 01:42:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][50/1251]	eta 0:11:49 lr 0.000896	time 0.6311 (0.5907)	loss 3.3965 (3.5246)	grad_norm 1.2765 (1.2857)	mem 17413MB
[2023-02-01 01:43:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][100/1251]	eta 0:11:07 lr 0.000896	time 0.5520 (0.5799)	loss 3.6827 (3.5400)	grad_norm 1.1469 (1.2772)	mem 17413MB
[2023-02-01 01:43:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][150/1251]	eta 0:10:33 lr 0.000896	time 0.5579 (0.5754)	loss 3.3353 (3.5318)	grad_norm 1.3797 (1.2892)	mem 17413MB
[2023-02-01 01:44:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][200/1251]	eta 0:10:02 lr 0.000896	time 0.5576 (0.5732)	loss 3.7376 (3.5156)	grad_norm 1.3265 (1.2911)	mem 17413MB
[2023-02-01 01:44:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][250/1251]	eta 0:09:32 lr 0.000895	time 0.5592 (0.5718)	loss 2.2323 (3.5142)	grad_norm 1.2932 (1.2942)	mem 17413MB
[2023-02-01 01:45:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][300/1251]	eta 0:09:03 lr 0.000895	time 0.5635 (0.5713)	loss 2.8150 (3.5099)	grad_norm 1.3619 (1.2928)	mem 17413MB
[2023-02-01 01:45:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][350/1251]	eta 0:08:34 lr 0.000895	time 0.5504 (0.5710)	loss 4.0235 (3.5167)	grad_norm 1.3267 (1.2910)	mem 17413MB
[2023-02-01 01:46:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][400/1251]	eta 0:08:05 lr 0.000895	time 0.5619 (0.5706)	loss 3.3205 (3.5327)	grad_norm 1.2519 (1.2935)	mem 17413MB
[2023-02-01 01:46:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][450/1251]	eta 0:07:36 lr 0.000895	time 0.6242 (0.5705)	loss 3.7938 (3.5573)	grad_norm 1.2062 (1.2888)	mem 17413MB
[2023-02-01 01:47:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][500/1251]	eta 0:07:08 lr 0.000895	time 0.5593 (0.5699)	loss 3.7042 (3.5599)	grad_norm 1.3079 (1.2888)	mem 17413MB
[2023-02-01 01:47:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][550/1251]	eta 0:06:39 lr 0.000895	time 0.6400 (0.5699)	loss 4.2586 (3.5745)	grad_norm 1.3413 (1.2864)	mem 17413MB
[2023-02-01 01:48:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][600/1251]	eta 0:06:10 lr 0.000895	time 0.5620 (0.5696)	loss 2.6780 (3.5635)	grad_norm 1.4700 (1.2856)	mem 17413MB
[2023-02-01 01:48:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][650/1251]	eta 0:05:42 lr 0.000894	time 0.5561 (0.5694)	loss 3.6451 (3.5757)	grad_norm 1.2435 (1.2849)	mem 17413MB
[2023-02-01 01:49:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][700/1251]	eta 0:05:13 lr 0.000894	time 0.5546 (0.5692)	loss 3.5931 (3.5729)	grad_norm 1.3861 (1.2862)	mem 17413MB
[2023-02-01 01:49:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][750/1251]	eta 0:04:45 lr 0.000894	time 0.5602 (0.5692)	loss 3.5576 (3.5672)	grad_norm 1.2307 (1.2848)	mem 17413MB
[2023-02-01 01:50:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][800/1251]	eta 0:04:16 lr 0.000894	time 0.5558 (0.5692)	loss 3.9949 (3.5602)	grad_norm 1.1711 (1.2844)	mem 17413MB
[2023-02-01 01:50:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][850/1251]	eta 0:03:48 lr 0.000894	time 0.5597 (0.5690)	loss 3.2938 (3.5576)	grad_norm 1.2604 (1.2836)	mem 17413MB
[2023-02-01 01:51:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][900/1251]	eta 0:03:19 lr 0.000894	time 0.5612 (0.5691)	loss 3.5390 (3.5545)	grad_norm 1.2124 (1.2848)	mem 17413MB
[2023-02-01 01:51:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][950/1251]	eta 0:02:51 lr 0.000894	time 0.5561 (0.5688)	loss 2.9639 (3.5540)	grad_norm 1.1792 (1.2834)	mem 17413MB
[2023-02-01 01:51:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][1000/1251]	eta 0:02:22 lr 0.000894	time 0.6126 (0.5688)	loss 3.9863 (3.5567)	grad_norm 1.3070 (1.2838)	mem 17413MB
[2023-02-01 01:52:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][1050/1251]	eta 0:01:54 lr 0.000893	time 0.5588 (0.5687)	loss 2.8736 (3.5521)	grad_norm 1.1062 (1.2833)	mem 17413MB
[2023-02-01 01:52:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][1100/1251]	eta 0:01:25 lr 0.000893	time 0.5613 (0.5687)	loss 3.5516 (3.5508)	grad_norm 1.4194 (1.2842)	mem 17413MB
[2023-02-01 01:53:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][1150/1251]	eta 0:00:57 lr 0.000893	time 0.5587 (0.5688)	loss 4.0365 (3.5525)	grad_norm 1.1669 (1.2850)	mem 17413MB
[2023-02-01 01:53:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][1200/1251]	eta 0:00:29 lr 0.000893	time 0.5634 (0.5688)	loss 3.1018 (3.5558)	grad_norm 1.2872 (1.2852)	mem 17413MB
[2023-02-01 01:54:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [63/300][1250/1251]	eta 0:00:00 lr 0.000893	time 0.6074 (0.5689)	loss 2.5315 (3.5523)	grad_norm 1.3306 (1.2859)	mem 17413MB
[2023-02-01 01:54:21 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 63 training takes 0:11:51
[2023-02-01 01:54:21 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_63.pth saving......
[2023-02-01 01:54:23 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_63.pth saved !!!
[2023-02-01 01:54:24 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.845 (0.845)	Loss 1.0490 (1.0490)	Acc@1 74.121 (74.121)	Acc@5 92.969 (92.969)	Mem 17413MB
[2023-02-01 01:54:32 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.572 Acc@5 93.154
[2023-02-01 01:54:32 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 75.6%
[2023-02-01 01:54:33 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.332 (1.332)	Loss 0.8599 (0.8599)	Acc@1 79.199 (79.199)	Acc@5 95.117 (95.117)	Mem 17413MB
[2023-02-01 01:54:41 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.976 Acc@5 94.306
[2023-02-01 01:54:41 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 78.0%
[2023-02-01 01:54:41 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 77.98% at 63 epoch
[2023-02-01 01:54:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][0/1251]	eta 0:37:39 lr 0.000893	time 1.8060 (1.8060)	loss 3.5421 (3.5421)	grad_norm 1.2173 (1.2173)	mem 17413MB
[2023-02-01 01:55:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][50/1251]	eta 0:11:56 lr 0.000893	time 0.5556 (0.5964)	loss 3.2181 (3.5776)	grad_norm 1.2164 (1.2489)	mem 17413MB
[2023-02-01 01:55:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][100/1251]	eta 0:11:11 lr 0.000893	time 0.5692 (0.5833)	loss 3.8308 (3.5588)	grad_norm 1.2855 (1.2702)	mem 17413MB
[2023-02-01 01:56:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][150/1251]	eta 0:10:37 lr 0.000893	time 0.5650 (0.5791)	loss 4.1234 (3.5223)	grad_norm 1.4182 (1.2821)	mem 17413MB
[2023-02-01 01:56:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][200/1251]	eta 0:10:06 lr 0.000892	time 0.5563 (0.5767)	loss 3.1634 (3.5551)	grad_norm 1.3408 (1.2808)	mem 17413MB
[2023-02-01 01:57:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][250/1251]	eta 0:09:35 lr 0.000892	time 0.5688 (0.5749)	loss 3.3974 (3.5568)	grad_norm 1.3163 (1.2882)	mem 17413MB
[2023-02-01 01:57:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][300/1251]	eta 0:09:05 lr 0.000892	time 0.5521 (0.5740)	loss 3.3880 (3.5520)	grad_norm 1.2590 (1.2871)	mem 17413MB
[2023-02-01 01:58:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][350/1251]	eta 0:08:36 lr 0.000892	time 0.5521 (0.5732)	loss 2.1735 (3.5554)	grad_norm 1.2086 (1.2859)	mem 17413MB
[2023-02-01 01:58:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][400/1251]	eta 0:08:07 lr 0.000892	time 0.5583 (0.5726)	loss 3.3006 (3.5435)	grad_norm 1.5079 (1.2838)	mem 17413MB
[2023-02-01 01:58:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][450/1251]	eta 0:07:38 lr 0.000892	time 0.5578 (0.5722)	loss 3.4072 (3.5460)	grad_norm 1.2813 (1.2839)	mem 17413MB
[2023-02-01 01:59:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][500/1251]	eta 0:07:09 lr 0.000892	time 0.5568 (0.5721)	loss 3.5581 (3.5532)	grad_norm 1.3213 (1.2864)	mem 17413MB
[2023-02-01 01:59:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][550/1251]	eta 0:06:40 lr 0.000892	time 0.5568 (0.5718)	loss 3.8528 (3.5586)	grad_norm 1.2345 (1.2855)	mem 17413MB
[2023-02-01 02:00:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][600/1251]	eta 0:06:12 lr 0.000891	time 0.5641 (0.5716)	loss 4.3180 (3.5581)	grad_norm 1.4947 (1.2845)	mem 17413MB
[2023-02-01 02:00:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][650/1251]	eta 0:05:43 lr 0.000891	time 0.5553 (0.5713)	loss 2.4628 (3.5530)	grad_norm 1.3251 (1.2845)	mem 17413MB
[2023-02-01 02:01:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][700/1251]	eta 0:05:14 lr 0.000891	time 0.5457 (0.5714)	loss 3.4312 (3.5535)	grad_norm 1.2624 (1.2840)	mem 17413MB
[2023-02-01 02:01:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][750/1251]	eta 0:04:46 lr 0.000891	time 0.5590 (0.5711)	loss 3.6622 (3.5520)	grad_norm 1.1901 (1.2832)	mem 17413MB
[2023-02-01 02:02:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][800/1251]	eta 0:04:17 lr 0.000891	time 0.6207 (0.5711)	loss 4.3264 (3.5581)	grad_norm 1.4480 (1.2835)	mem 17413MB
[2023-02-01 02:02:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][850/1251]	eta 0:03:48 lr 0.000891	time 0.5559 (0.5707)	loss 3.8774 (3.5606)	grad_norm 1.2482 (1.2832)	mem 17413MB
[2023-02-01 02:03:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][900/1251]	eta 0:03:20 lr 0.000891	time 0.5525 (0.5709)	loss 3.7129 (3.5641)	grad_norm 1.2434 (1.2826)	mem 17413MB
[2023-02-01 02:03:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][950/1251]	eta 0:02:51 lr 0.000890	time 0.5662 (0.5706)	loss 3.6242 (3.5730)	grad_norm 1.2484 (1.2818)	mem 17413MB
[2023-02-01 02:04:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][1000/1251]	eta 0:02:23 lr 0.000890	time 0.5582 (0.5706)	loss 3.4631 (3.5652)	grad_norm 1.2872 (1.2808)	mem 17413MB
[2023-02-01 02:04:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][1050/1251]	eta 0:01:54 lr 0.000890	time 0.5586 (0.5705)	loss 3.0838 (3.5630)	grad_norm 1.2310 (1.2804)	mem 17413MB
[2023-02-01 02:05:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][1100/1251]	eta 0:01:26 lr 0.000890	time 0.5529 (0.5705)	loss 3.3228 (3.5612)	grad_norm 1.2003 (1.2817)	mem 17413MB
[2023-02-01 02:05:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][1150/1251]	eta 0:00:57 lr 0.000890	time 0.5628 (0.5706)	loss 3.2402 (3.5613)	grad_norm 1.0799 (1.2817)	mem 17413MB
[2023-02-01 02:06:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][1200/1251]	eta 0:00:29 lr 0.000890	time 0.6200 (0.5705)	loss 3.9543 (3.5580)	grad_norm 1.3611 (1.2814)	mem 17413MB
[2023-02-01 02:06:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [64/300][1250/1251]	eta 0:00:00 lr 0.000890	time 0.5560 (0.5705)	loss 3.4019 (3.5547)	grad_norm 1.4058 (1.2816)	mem 17413MB
[2023-02-01 02:06:35 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 64 training takes 0:11:53
[2023-02-01 02:06:35 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_64.pth saving......
[2023-02-01 02:06:37 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_64.pth saved !!!
[2023-02-01 02:06:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.979 (0.979)	Loss 1.0094 (1.0094)	Acc@1 76.562 (76.562)	Acc@5 92.969 (92.969)	Mem 17413MB
[2023-02-01 02:06:46 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.798 Acc@5 93.346
[2023-02-01 02:06:46 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 75.8%
[2023-02-01 02:06:47 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.223 (1.223)	Loss 0.8913 (0.8913)	Acc@1 77.734 (77.734)	Acc@5 95.020 (95.020)	Mem 17413MB
[2023-02-01 02:06:55 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.106 Acc@5 94.350
[2023-02-01 02:06:55 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 78.1%
[2023-02-01 02:06:55 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 78.11% at 64 epoch
[2023-02-01 02:06:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][0/1251]	eta 0:34:36 lr 0.000890	time 1.6596 (1.6596)	loss 3.0400 (3.0400)	grad_norm 1.3305 (1.3305)	mem 17417MB
[2023-02-01 02:07:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][50/1251]	eta 0:11:53 lr 0.000890	time 0.5620 (0.5944)	loss 3.3829 (3.5395)	grad_norm 1.2261 (1.3337)	mem 17417MB
[2023-02-01 02:07:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][100/1251]	eta 0:11:08 lr 0.000889	time 0.5557 (0.5805)	loss 3.8506 (3.4822)	grad_norm 1.1971 (1.3186)	mem 17417MB
[2023-02-01 02:08:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][150/1251]	eta 0:10:35 lr 0.000889	time 0.5513 (0.5771)	loss 3.5808 (3.5166)	grad_norm 1.3608 (1.3034)	mem 17417MB
[2023-02-01 02:08:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][200/1251]	eta 0:10:03 lr 0.000889	time 0.5595 (0.5739)	loss 3.9930 (3.4979)	grad_norm 1.1722 (1.2978)	mem 17417MB
[2023-02-01 02:09:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][250/1251]	eta 0:09:33 lr 0.000889	time 0.6165 (0.5730)	loss 4.2520 (3.5030)	grad_norm 1.2059 (1.2963)	mem 17417MB
[2023-02-01 02:09:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][300/1251]	eta 0:09:03 lr 0.000889	time 0.5820 (0.5715)	loss 3.1948 (3.5058)	grad_norm 1.4278 (1.2979)	mem 17417MB
[2023-02-01 02:10:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][350/1251]	eta 0:08:34 lr 0.000889	time 0.5564 (0.5711)	loss 2.7484 (3.5264)	grad_norm 1.3470 (1.3008)	mem 17417MB
[2023-02-01 02:10:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][400/1251]	eta 0:08:05 lr 0.000889	time 0.5523 (0.5706)	loss 2.8911 (3.5318)	grad_norm 1.3316 (1.2983)	mem 17417MB
[2023-02-01 02:11:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][450/1251]	eta 0:07:36 lr 0.000889	time 0.5575 (0.5702)	loss 3.4548 (3.5321)	grad_norm 1.5055 (1.2973)	mem 17417MB
[2023-02-01 02:11:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][500/1251]	eta 0:07:07 lr 0.000888	time 0.5569 (0.5698)	loss 2.6640 (3.5419)	grad_norm 1.2744 (1.2966)	mem 17417MB
[2023-02-01 02:12:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][550/1251]	eta 0:06:39 lr 0.000888	time 0.5515 (0.5694)	loss 3.4636 (3.5417)	grad_norm 1.2040 (1.2958)	mem 17417MB
[2023-02-01 02:12:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][600/1251]	eta 0:06:10 lr 0.000888	time 0.5575 (0.5692)	loss 3.9434 (3.5434)	grad_norm 1.2120 (nan)	mem 17417MB
[2023-02-01 02:13:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][650/1251]	eta 0:05:42 lr 0.000888	time 0.6302 (0.5692)	loss 3.9659 (3.5423)	grad_norm 1.1936 (nan)	mem 17417MB
[2023-02-01 02:13:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][700/1251]	eta 0:05:13 lr 0.000888	time 0.5533 (0.5689)	loss 3.7496 (3.5521)	grad_norm 1.3275 (nan)	mem 17417MB
[2023-02-01 02:14:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][750/1251]	eta 0:04:44 lr 0.000888	time 0.5528 (0.5688)	loss 3.0445 (3.5600)	grad_norm 1.3819 (nan)	mem 17417MB
[2023-02-01 02:14:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][800/1251]	eta 0:04:16 lr 0.000888	time 0.5463 (0.5686)	loss 2.9792 (3.5651)	grad_norm 1.2439 (nan)	mem 17417MB
[2023-02-01 02:14:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][850/1251]	eta 0:03:48 lr 0.000887	time 0.5605 (0.5687)	loss 3.5009 (3.5661)	grad_norm 1.3992 (nan)	mem 17417MB
[2023-02-01 02:15:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][900/1251]	eta 0:03:19 lr 0.000887	time 0.5619 (0.5685)	loss 2.8664 (3.5641)	grad_norm 1.1880 (nan)	mem 17417MB
[2023-02-01 02:15:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][950/1251]	eta 0:02:51 lr 0.000887	time 0.5618 (0.5686)	loss 4.2508 (3.5637)	grad_norm 1.3030 (nan)	mem 17417MB
[2023-02-01 02:16:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][1000/1251]	eta 0:02:22 lr 0.000887	time 0.5596 (0.5685)	loss 2.5411 (3.5641)	grad_norm 1.2914 (nan)	mem 17417MB
[2023-02-01 02:16:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][1050/1251]	eta 0:01:54 lr 0.000887	time 0.6206 (0.5686)	loss 3.7715 (3.5606)	grad_norm 1.1222 (nan)	mem 17417MB
[2023-02-01 02:17:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][1100/1251]	eta 0:01:25 lr 0.000887	time 0.5558 (0.5685)	loss 3.7395 (3.5597)	grad_norm 1.2309 (nan)	mem 17417MB
[2023-02-01 02:17:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][1150/1251]	eta 0:00:57 lr 0.000887	time 0.5613 (0.5684)	loss 2.9338 (3.5639)	grad_norm 1.3007 (nan)	mem 17417MB
[2023-02-01 02:18:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][1200/1251]	eta 0:00:28 lr 0.000887	time 0.5573 (0.5683)	loss 4.0480 (3.5676)	grad_norm 1.2713 (nan)	mem 17417MB
[2023-02-01 02:18:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [65/300][1250/1251]	eta 0:00:00 lr 0.000886	time 0.5531 (0.5683)	loss 4.0212 (3.5691)	grad_norm 1.2308 (nan)	mem 17417MB
[2023-02-01 02:18:46 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 65 training takes 0:11:51
[2023-02-01 02:18:46 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_65.pth saving......
[2023-02-01 02:18:48 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_65.pth saved !!!
[2023-02-01 02:18:49 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.230 (1.230)	Loss 1.0974 (1.0974)	Acc@1 73.438 (73.438)	Acc@5 92.090 (92.090)	Mem 17417MB
[2023-02-01 02:18:57 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.594 Acc@5 93.386
[2023-02-01 02:18:57 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 75.6%
[2023-02-01 02:18:58 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.166 (1.166)	Loss 0.9125 (0.9125)	Acc@1 78.320 (78.320)	Acc@5 94.824 (94.824)	Mem 17417MB
[2023-02-01 02:19:06 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.248 Acc@5 94.402
[2023-02-01 02:19:06 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 78.2%
[2023-02-01 02:19:06 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 78.25% at 65 epoch
[2023-02-01 02:19:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][0/1251]	eta 0:34:37 lr 0.000886	time 1.6604 (1.6604)	loss 2.9273 (2.9273)	grad_norm 1.2643 (1.2643)	mem 17417MB
[2023-02-01 02:19:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][50/1251]	eta 0:11:52 lr 0.000886	time 0.5500 (0.5931)	loss 4.1862 (3.6594)	grad_norm 1.2380 (1.3086)	mem 17417MB
[2023-02-01 02:20:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][100/1251]	eta 0:11:07 lr 0.000886	time 0.5593 (0.5803)	loss 3.3411 (3.5522)	grad_norm 1.3990 (1.3001)	mem 17417MB
[2023-02-01 02:20:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][150/1251]	eta 0:10:35 lr 0.000886	time 0.5527 (0.5770)	loss 3.8957 (3.5731)	grad_norm 1.1413 (1.2997)	mem 17417MB
[2023-02-01 02:21:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][200/1251]	eta 0:10:04 lr 0.000886	time 0.5600 (0.5748)	loss 2.9166 (3.5592)	grad_norm 1.4471 (1.2987)	mem 17417MB
[2023-02-01 02:21:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][250/1251]	eta 0:09:33 lr 0.000886	time 0.5507 (0.5730)	loss 2.6857 (3.5429)	grad_norm 1.2965 (1.2961)	mem 17417MB
[2023-02-01 02:21:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][300/1251]	eta 0:09:04 lr 0.000886	time 0.5615 (0.5721)	loss 3.6667 (3.5638)	grad_norm 1.2736 (1.2945)	mem 17417MB
[2023-02-01 02:22:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][350/1251]	eta 0:08:34 lr 0.000885	time 0.5577 (0.5713)	loss 2.7617 (3.5569)	grad_norm 1.4236 (1.2970)	mem 17417MB
[2023-02-01 02:22:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][400/1251]	eta 0:08:05 lr 0.000885	time 0.5535 (0.5706)	loss 3.9595 (3.5722)	grad_norm 1.3069 (1.2987)	mem 17417MB
[2023-02-01 02:23:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][450/1251]	eta 0:07:36 lr 0.000885	time 0.5602 (0.5703)	loss 3.2106 (3.5605)	grad_norm 1.3511 (1.2980)	mem 17417MB
[2023-02-01 02:23:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][500/1251]	eta 0:07:07 lr 0.000885	time 0.5586 (0.5699)	loss 3.6941 (3.5506)	grad_norm 1.0945 (1.2948)	mem 17417MB
[2023-02-01 02:24:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][550/1251]	eta 0:06:39 lr 0.000885	time 0.5534 (0.5698)	loss 4.1418 (3.5641)	grad_norm 1.3853 (1.2973)	mem 17417MB
[2023-02-01 02:24:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][600/1251]	eta 0:06:10 lr 0.000885	time 0.5553 (0.5698)	loss 3.7184 (3.5668)	grad_norm 1.4830 (1.2986)	mem 17417MB
[2023-02-01 02:25:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][650/1251]	eta 0:05:42 lr 0.000885	time 0.5544 (0.5698)	loss 3.9789 (3.5687)	grad_norm 1.2290 (1.2999)	mem 17417MB
[2023-02-01 02:25:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][700/1251]	eta 0:05:13 lr 0.000885	time 0.5586 (0.5696)	loss 2.5735 (3.5714)	grad_norm 1.1313 (1.2998)	mem 17417MB
[2023-02-01 02:26:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][750/1251]	eta 0:04:45 lr 0.000884	time 0.5534 (0.5695)	loss 3.2091 (3.5745)	grad_norm 1.2024 (1.2992)	mem 17417MB
[2023-02-01 02:26:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][800/1251]	eta 0:04:16 lr 0.000884	time 0.5619 (0.5693)	loss 3.6190 (3.5666)	grad_norm 1.2273 (1.2987)	mem 17417MB
[2023-02-01 02:27:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][850/1251]	eta 0:03:48 lr 0.000884	time 0.5532 (0.5694)	loss 3.7139 (3.5684)	grad_norm 1.1745 (1.2975)	mem 17417MB
[2023-02-01 02:27:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][900/1251]	eta 0:03:19 lr 0.000884	time 0.5534 (0.5692)	loss 2.7736 (3.5675)	grad_norm 1.2930 (1.2979)	mem 17417MB
[2023-02-01 02:28:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][950/1251]	eta 0:02:51 lr 0.000884	time 0.5592 (0.5692)	loss 2.7825 (3.5673)	grad_norm 1.2555 (1.2968)	mem 17417MB
[2023-02-01 02:28:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][1000/1251]	eta 0:02:22 lr 0.000884	time 0.5492 (0.5692)	loss 2.8117 (3.5653)	grad_norm 1.3764 (1.2960)	mem 17417MB
[2023-02-01 02:29:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][1050/1251]	eta 0:01:54 lr 0.000884	time 0.5670 (0.5692)	loss 2.9497 (3.5696)	grad_norm 1.2775 (1.2971)	mem 17417MB
[2023-02-01 02:29:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][1100/1251]	eta 0:01:25 lr 0.000883	time 0.5686 (0.5692)	loss 3.5031 (3.5674)	grad_norm 1.2963 (1.2977)	mem 17417MB
[2023-02-01 02:30:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][1150/1251]	eta 0:00:57 lr 0.000883	time 0.6226 (0.5692)	loss 3.8300 (3.5671)	grad_norm 1.4095 (1.2966)	mem 17417MB
[2023-02-01 02:30:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][1200/1251]	eta 0:00:29 lr 0.000883	time 0.5578 (0.5690)	loss 3.8341 (3.5647)	grad_norm 1.2061 (1.2953)	mem 17417MB
[2023-02-01 02:30:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [66/300][1250/1251]	eta 0:00:00 lr 0.000883	time 0.5489 (0.5690)	loss 3.6059 (3.5678)	grad_norm 1.2530 (1.2961)	mem 17417MB
[2023-02-01 02:30:58 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 66 training takes 0:11:51
[2023-02-01 02:30:58 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_66.pth saving......
[2023-02-01 02:31:00 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_66.pth saved !!!
[2023-02-01 02:31:01 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.933 (0.933)	Loss 1.0392 (1.0392)	Acc@1 75.488 (75.488)	Acc@5 94.043 (94.043)	Mem 17417MB
[2023-02-01 02:31:09 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.808 Acc@5 93.356
[2023-02-01 02:31:09 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 75.8%
[2023-02-01 02:31:10 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.344 (1.344)	Loss 0.8966 (0.8966)	Acc@1 79.492 (79.492)	Acc@5 94.238 (94.238)	Mem 17417MB
[2023-02-01 02:31:18 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.314 Acc@5 94.460
[2023-02-01 02:31:18 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 78.3%
[2023-02-01 02:31:18 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 78.31% at 66 epoch
[2023-02-01 02:31:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][0/1251]	eta 0:35:26 lr 0.000883	time 1.6997 (1.6997)	loss 3.8467 (3.8467)	grad_norm 1.2538 (1.2538)	mem 17417MB
[2023-02-01 02:31:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][50/1251]	eta 0:11:52 lr 0.000883	time 0.5735 (0.5933)	loss 4.5920 (3.5036)	grad_norm 1.2674 (1.2758)	mem 17417MB
[2023-02-01 02:32:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][100/1251]	eta 0:11:07 lr 0.000883	time 0.6259 (0.5803)	loss 3.3709 (3.5005)	grad_norm 1.3687 (1.2695)	mem 17417MB
[2023-02-01 02:32:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][150/1251]	eta 0:10:33 lr 0.000883	time 0.5537 (0.5752)	loss 2.8917 (3.4993)	grad_norm 1.2472 (1.2775)	mem 17417MB
[2023-02-01 02:33:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][200/1251]	eta 0:10:03 lr 0.000883	time 0.6281 (0.5741)	loss 4.4657 (3.5277)	grad_norm 1.1208 (1.2835)	mem 17417MB
[2023-02-01 02:33:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][250/1251]	eta 0:09:33 lr 0.000882	time 0.5566 (0.5729)	loss 3.6448 (3.5137)	grad_norm 1.3858 (1.2813)	mem 17417MB
[2023-02-01 02:34:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][300/1251]	eta 0:09:04 lr 0.000882	time 0.5540 (0.5724)	loss 4.0639 (3.5401)	grad_norm 1.2166 (1.2826)	mem 17417MB
[2023-02-01 02:34:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][350/1251]	eta 0:08:35 lr 0.000882	time 0.5488 (0.5718)	loss 4.3323 (3.5479)	grad_norm 1.2535 (1.2908)	mem 17417MB
[2023-02-01 02:35:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][400/1251]	eta 0:08:06 lr 0.000882	time 0.5573 (0.5711)	loss 2.8303 (3.5421)	grad_norm 1.4828 (1.2911)	mem 17417MB
[2023-02-01 02:35:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][450/1251]	eta 0:07:37 lr 0.000882	time 0.5578 (0.5707)	loss 3.6667 (3.5414)	grad_norm 1.2725 (1.2911)	mem 17417MB
[2023-02-01 02:36:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][500/1251]	eta 0:07:08 lr 0.000882	time 0.6177 (0.5705)	loss 3.8456 (3.5487)	grad_norm 1.4531 (1.2894)	mem 17417MB
[2023-02-01 02:36:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][550/1251]	eta 0:06:39 lr 0.000882	time 0.5522 (0.5702)	loss 4.1944 (3.5593)	grad_norm 1.3765 (1.2896)	mem 17417MB
[2023-02-01 02:37:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][600/1251]	eta 0:06:11 lr 0.000881	time 0.6231 (0.5703)	loss 4.0347 (3.5563)	grad_norm 1.1956 (1.2909)	mem 17417MB
[2023-02-01 02:37:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][650/1251]	eta 0:05:42 lr 0.000881	time 0.5630 (0.5699)	loss 2.5897 (3.5549)	grad_norm 1.6458 (1.2913)	mem 17417MB
[2023-02-01 02:37:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][700/1251]	eta 0:05:14 lr 0.000881	time 0.5587 (0.5699)	loss 3.9303 (3.5536)	grad_norm 1.1699 (1.2911)	mem 17417MB
[2023-02-01 02:38:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][750/1251]	eta 0:04:45 lr 0.000881	time 0.5553 (0.5697)	loss 3.7786 (3.5495)	grad_norm 1.3875 (1.2915)	mem 17417MB
[2023-02-01 02:38:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][800/1251]	eta 0:04:16 lr 0.000881	time 0.5578 (0.5695)	loss 2.1090 (3.5507)	grad_norm 1.2326 (1.2903)	mem 17417MB
[2023-02-01 02:39:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][850/1251]	eta 0:03:48 lr 0.000881	time 0.6097 (0.5695)	loss 2.7277 (3.5565)	grad_norm 1.2727 (1.2905)	mem 17417MB
[2023-02-01 02:39:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][900/1251]	eta 0:03:19 lr 0.000881	time 0.6203 (0.5695)	loss 2.5292 (3.5649)	grad_norm 1.2757 (1.2899)	mem 17417MB
[2023-02-01 02:40:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][950/1251]	eta 0:02:51 lr 0.000881	time 0.5556 (0.5692)	loss 3.7136 (3.5609)	grad_norm 1.2970 (1.2899)	mem 17417MB
[2023-02-01 02:40:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][1000/1251]	eta 0:02:22 lr 0.000880	time 0.6177 (0.5693)	loss 3.2184 (3.5607)	grad_norm 1.2593 (1.2900)	mem 17417MB
[2023-02-01 02:41:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][1050/1251]	eta 0:01:54 lr 0.000880	time 0.5621 (0.5692)	loss 2.6249 (3.5639)	grad_norm 1.2276 (1.2895)	mem 17417MB
[2023-02-01 02:41:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][1100/1251]	eta 0:01:25 lr 0.000880	time 0.6595 (0.5693)	loss 3.9439 (3.5650)	grad_norm 1.3663 (1.2893)	mem 17417MB
[2023-02-01 02:42:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][1150/1251]	eta 0:00:57 lr 0.000880	time 0.5537 (0.5691)	loss 3.8538 (3.5680)	grad_norm 1.2283 (1.2901)	mem 17417MB
[2023-02-01 02:42:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][1200/1251]	eta 0:00:29 lr 0.000880	time 0.5586 (0.5690)	loss 4.3511 (3.5655)	grad_norm 1.4101 (1.2889)	mem 17417MB
[2023-02-01 02:43:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [67/300][1250/1251]	eta 0:00:00 lr 0.000880	time 0.5502 (0.5690)	loss 3.8286 (3.5620)	grad_norm 1.3627 (1.2876)	mem 17417MB
[2023-02-01 02:43:10 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 67 training takes 0:11:51
[2023-02-01 02:43:11 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_67.pth saving......
[2023-02-01 02:43:12 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_67.pth saved !!!
[2023-02-01 02:43:13 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.879 (0.879)	Loss 1.0147 (1.0147)	Acc@1 75.391 (75.391)	Acc@5 93.457 (93.457)	Mem 17417MB
[2023-02-01 02:43:21 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.978 Acc@5 93.440
[2023-02-01 02:43:21 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.0%
[2023-02-01 02:43:22 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.220 (1.220)	Loss 0.8981 (0.8981)	Acc@1 79.102 (79.102)	Acc@5 94.141 (94.141)	Mem 17417MB
[2023-02-01 02:43:30 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.406 Acc@5 94.480
[2023-02-01 02:43:30 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 78.4%
[2023-02-01 02:43:30 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 78.41% at 67 epoch
[2023-02-01 02:43:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][0/1251]	eta 0:38:21 lr 0.000880	time 1.8398 (1.8398)	loss 3.8835 (3.8835)	grad_norm 1.3104 (1.3104)	mem 17417MB
[2023-02-01 02:44:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][50/1251]	eta 0:11:58 lr 0.000880	time 0.5561 (0.5979)	loss 4.0709 (3.5219)	grad_norm 1.3019 (1.2898)	mem 17417MB
[2023-02-01 02:44:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][100/1251]	eta 0:11:11 lr 0.000879	time 0.6142 (0.5833)	loss 2.4268 (3.5646)	grad_norm 1.3117 (1.2975)	mem 17417MB
[2023-02-01 02:44:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][150/1251]	eta 0:10:37 lr 0.000879	time 0.5567 (0.5787)	loss 2.9757 (3.5495)	grad_norm 1.3251 (1.2941)	mem 17417MB
[2023-02-01 02:45:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][200/1251]	eta 0:10:05 lr 0.000879	time 0.5569 (0.5758)	loss 2.5307 (3.5389)	grad_norm 1.4442 (1.2869)	mem 17417MB
[2023-02-01 02:45:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][250/1251]	eta 0:09:35 lr 0.000879	time 0.6526 (0.5745)	loss 3.6316 (3.5245)	grad_norm 1.2256 (1.2855)	mem 17417MB
[2023-02-01 02:46:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][300/1251]	eta 0:09:05 lr 0.000879	time 0.5626 (0.5736)	loss 3.8271 (3.5353)	grad_norm 1.2242 (1.2852)	mem 17417MB
[2023-02-01 02:46:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][350/1251]	eta 0:08:36 lr 0.000879	time 0.5549 (0.5733)	loss 3.7342 (3.5227)	grad_norm 1.3421 (1.2834)	mem 17417MB
[2023-02-01 02:47:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][400/1251]	eta 0:08:07 lr 0.000879	time 0.5548 (0.5726)	loss 4.0226 (3.5422)	grad_norm 1.2118 (1.2832)	mem 17417MB
[2023-02-01 02:47:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][450/1251]	eta 0:07:38 lr 0.000878	time 0.6156 (0.5724)	loss 3.7606 (3.5336)	grad_norm 1.1905 (1.2834)	mem 17417MB
[2023-02-01 02:48:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][500/1251]	eta 0:07:09 lr 0.000878	time 0.6226 (0.5718)	loss 3.8817 (3.5496)	grad_norm 1.2740 (1.2841)	mem 17417MB
[2023-02-01 02:48:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][550/1251]	eta 0:06:40 lr 0.000878	time 0.5645 (0.5712)	loss 2.2509 (3.5434)	grad_norm 1.2445 (1.2833)	mem 17417MB
[2023-02-01 02:49:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][600/1251]	eta 0:06:11 lr 0.000878	time 0.5533 (0.5713)	loss 3.1678 (3.5475)	grad_norm 1.4878 (1.2849)	mem 17417MB
[2023-02-01 02:49:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][650/1251]	eta 0:05:43 lr 0.000878	time 0.5524 (0.5709)	loss 3.9181 (3.5475)	grad_norm 1.3888 (1.2848)	mem 17417MB
[2023-02-01 02:50:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][700/1251]	eta 0:05:14 lr 0.000878	time 0.5539 (0.5709)	loss 3.9500 (3.5524)	grad_norm 1.3178 (1.2848)	mem 17417MB
[2023-02-01 02:50:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][750/1251]	eta 0:04:45 lr 0.000878	time 0.5545 (0.5706)	loss 3.0986 (3.5479)	grad_norm 1.3238 (1.2845)	mem 17417MB
[2023-02-01 02:51:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][800/1251]	eta 0:04:17 lr 0.000878	time 0.5536 (0.5706)	loss 2.9079 (3.5530)	grad_norm 1.2473 (1.2850)	mem 17417MB
[2023-02-01 02:51:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][850/1251]	eta 0:03:48 lr 0.000877	time 0.5563 (0.5705)	loss 3.8978 (3.5482)	grad_norm 1.2201 (1.2848)	mem 17417MB
[2023-02-01 02:52:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][900/1251]	eta 0:03:20 lr 0.000877	time 0.6113 (0.5704)	loss 3.6898 (3.5487)	grad_norm 1.2292 (1.2841)	mem 17417MB
[2023-02-01 02:52:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][950/1251]	eta 0:02:51 lr 0.000877	time 0.5569 (0.5701)	loss 3.2855 (3.5491)	grad_norm 1.2097 (1.2865)	mem 17417MB
[2023-02-01 02:53:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][1000/1251]	eta 0:02:23 lr 0.000877	time 0.5549 (0.5702)	loss 4.2600 (3.5407)	grad_norm 1.2237 (1.2861)	mem 17417MB
[2023-02-01 02:53:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][1050/1251]	eta 0:01:54 lr 0.000877	time 0.5562 (0.5700)	loss 3.8554 (3.5394)	grad_norm 1.3188 (1.2867)	mem 17417MB
[2023-02-01 02:53:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][1100/1251]	eta 0:01:26 lr 0.000877	time 0.5581 (0.5699)	loss 2.5541 (3.5366)	grad_norm 1.1619 (1.2862)	mem 17417MB
[2023-02-01 02:54:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][1150/1251]	eta 0:00:57 lr 0.000877	time 0.6253 (0.5699)	loss 3.8092 (3.5367)	grad_norm 1.3537 (1.2862)	mem 17417MB
[2023-02-01 02:54:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][1200/1251]	eta 0:00:29 lr 0.000876	time 0.5602 (0.5701)	loss 2.6724 (3.5329)	grad_norm 1.1266 (1.2878)	mem 17417MB
[2023-02-01 02:55:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [68/300][1250/1251]	eta 0:00:00 lr 0.000876	time 0.5507 (0.5700)	loss 2.9616 (3.5327)	grad_norm 1.2527 (1.2870)	mem 17417MB
[2023-02-01 02:55:23 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 68 training takes 0:11:53
[2023-02-01 02:55:24 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_68.pth saving......
[2023-02-01 02:55:25 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_68.pth saved !!!
[2023-02-01 02:55:26 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.850 (0.850)	Loss 0.9824 (0.9824)	Acc@1 75.488 (75.488)	Acc@5 94.043 (94.043)	Mem 17417MB
[2023-02-01 02:55:34 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.744 Acc@5 93.204
[2023-02-01 02:55:34 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 75.7%
[2023-02-01 02:55:35 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.263 (1.263)	Loss 0.9181 (0.9181)	Acc@1 78.711 (78.711)	Acc@5 94.434 (94.434)	Mem 17417MB
[2023-02-01 02:55:44 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.452 Acc@5 94.530
[2023-02-01 02:55:44 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 78.5%
[2023-02-01 02:55:44 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 78.45% at 68 epoch
[2023-02-01 02:55:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][0/1251]	eta 0:36:04 lr 0.000876	time 1.7305 (1.7305)	loss 2.9913 (2.9913)	grad_norm 1.2539 (1.2539)	mem 17417MB
[2023-02-01 02:56:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][50/1251]	eta 0:11:49 lr 0.000876	time 0.5568 (0.5910)	loss 3.7901 (3.4802)	grad_norm 1.2811 (1.3163)	mem 17417MB
[2023-02-01 02:56:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][100/1251]	eta 0:11:07 lr 0.000876	time 0.5672 (0.5798)	loss 4.1911 (3.5234)	grad_norm 1.2858 (1.3151)	mem 17417MB
[2023-02-01 02:57:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][150/1251]	eta 0:10:34 lr 0.000876	time 0.5512 (0.5764)	loss 3.2033 (3.5316)	grad_norm 1.3076 (1.3126)	mem 17417MB
[2023-02-01 02:57:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][200/1251]	eta 0:10:04 lr 0.000876	time 0.5597 (0.5748)	loss 3.5537 (3.5032)	grad_norm 1.2259 (1.3091)	mem 17417MB
[2023-02-01 02:58:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][250/1251]	eta 0:09:33 lr 0.000876	time 0.5551 (0.5732)	loss 3.0889 (3.4852)	grad_norm 1.1332 (1.3082)	mem 17417MB
[2023-02-01 02:58:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][300/1251]	eta 0:09:03 lr 0.000875	time 0.5661 (0.5719)	loss 3.9642 (3.4919)	grad_norm 1.1973 (nan)	mem 17417MB
[2023-02-01 02:59:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][350/1251]	eta 0:08:34 lr 0.000875	time 0.6369 (0.5714)	loss 3.8110 (3.4926)	grad_norm 1.2395 (nan)	mem 17417MB
[2023-02-01 02:59:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][400/1251]	eta 0:08:05 lr 0.000875	time 0.5609 (0.5711)	loss 3.6173 (3.4877)	grad_norm 1.1690 (nan)	mem 17417MB
[2023-02-01 03:00:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][450/1251]	eta 0:07:37 lr 0.000875	time 0.6238 (0.5709)	loss 2.5938 (3.4881)	grad_norm 1.2742 (nan)	mem 17417MB
[2023-02-01 03:00:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][500/1251]	eta 0:07:08 lr 0.000875	time 0.5486 (0.5710)	loss 3.9816 (3.4824)	grad_norm 1.2761 (nan)	mem 17417MB
[2023-02-01 03:00:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][550/1251]	eta 0:06:39 lr 0.000875	time 0.6208 (0.5706)	loss 4.1419 (3.4936)	grad_norm 1.3825 (nan)	mem 17417MB
[2023-02-01 03:01:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][600/1251]	eta 0:06:11 lr 0.000875	time 0.5566 (0.5704)	loss 4.2307 (3.5070)	grad_norm 1.3255 (nan)	mem 17417MB
[2023-02-01 03:01:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][650/1251]	eta 0:05:42 lr 0.000875	time 0.5577 (0.5703)	loss 3.7184 (3.5115)	grad_norm 1.2460 (nan)	mem 17417MB
[2023-02-01 03:02:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][700/1251]	eta 0:05:14 lr 0.000874	time 0.5556 (0.5705)	loss 3.5802 (3.5129)	grad_norm 1.3201 (nan)	mem 17417MB
[2023-02-01 03:02:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][750/1251]	eta 0:04:45 lr 0.000874	time 0.5620 (0.5702)	loss 3.2375 (3.5170)	grad_norm 1.2691 (nan)	mem 17417MB
[2023-02-01 03:03:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][800/1251]	eta 0:04:17 lr 0.000874	time 0.6202 (0.5703)	loss 3.8746 (3.5177)	grad_norm 1.2082 (nan)	mem 17417MB
[2023-02-01 03:03:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][850/1251]	eta 0:03:48 lr 0.000874	time 0.6154 (0.5699)	loss 2.8410 (3.5135)	grad_norm 1.3078 (nan)	mem 17417MB
[2023-02-01 03:04:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][900/1251]	eta 0:03:20 lr 0.000874	time 0.5614 (0.5699)	loss 3.0721 (3.5203)	grad_norm 1.3364 (nan)	mem 17417MB
[2023-02-01 03:04:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][950/1251]	eta 0:02:51 lr 0.000874	time 0.5584 (0.5699)	loss 2.8673 (3.5266)	grad_norm 1.2922 (nan)	mem 17417MB
[2023-02-01 03:05:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][1000/1251]	eta 0:02:23 lr 0.000874	time 0.5535 (0.5701)	loss 4.0739 (3.5287)	grad_norm 1.5625 (nan)	mem 17417MB
[2023-02-01 03:05:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][1050/1251]	eta 0:01:54 lr 0.000873	time 0.5584 (0.5699)	loss 4.6072 (3.5374)	grad_norm 1.4400 (nan)	mem 17417MB
[2023-02-01 03:06:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][1100/1251]	eta 0:01:26 lr 0.000873	time 0.6336 (0.5698)	loss 3.4980 (3.5350)	grad_norm 1.1808 (nan)	mem 17417MB
[2023-02-01 03:06:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][1150/1251]	eta 0:00:57 lr 0.000873	time 0.5608 (0.5697)	loss 2.7686 (3.5372)	grad_norm 1.3940 (nan)	mem 17417MB
[2023-02-01 03:07:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][1200/1251]	eta 0:00:29 lr 0.000873	time 0.5606 (0.5698)	loss 2.4077 (3.5343)	grad_norm 1.3042 (nan)	mem 17417MB
[2023-02-01 03:07:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [69/300][1250/1251]	eta 0:00:00 lr 0.000873	time 0.5670 (0.5698)	loss 4.0455 (3.5384)	grad_norm 1.3858 (nan)	mem 17417MB
[2023-02-01 03:07:36 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 69 training takes 0:11:52
[2023-02-01 03:07:37 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_69.pth saving......
[2023-02-01 03:07:38 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_69.pth saved !!!
[2023-02-01 03:07:39 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.851 (0.851)	Loss 1.0949 (1.0949)	Acc@1 72.754 (72.754)	Acc@5 92.480 (92.480)	Mem 17417MB
[2023-02-01 03:07:47 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 75.940 Acc@5 93.464
[2023-02-01 03:07:47 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 75.9%
[2023-02-01 03:07:48 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.217 (1.217)	Loss 0.8254 (0.8254)	Acc@1 80.273 (80.273)	Acc@5 95.508 (95.508)	Mem 17417MB
[2023-02-01 03:07:56 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.502 Acc@5 94.570
[2023-02-01 03:07:56 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 78.5%
[2023-02-01 03:07:56 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 78.50% at 69 epoch
[2023-02-01 03:07:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][0/1251]	eta 0:35:36 lr 0.000873	time 1.7079 (1.7079)	loss 3.6770 (3.6770)	grad_norm 1.2648 (1.2648)	mem 17417MB
[2023-02-01 03:08:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][50/1251]	eta 0:11:56 lr 0.000873	time 0.5627 (0.5964)	loss 3.2825 (3.4973)	grad_norm 1.2711 (1.2763)	mem 17417MB
[2023-02-01 03:08:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][100/1251]	eta 0:11:10 lr 0.000873	time 0.6238 (0.5823)	loss 2.8968 (3.4807)	grad_norm 1.3364 (1.2825)	mem 17417MB
[2023-02-01 03:09:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][150/1251]	eta 0:10:35 lr 0.000872	time 0.5547 (0.5776)	loss 3.4995 (3.4883)	grad_norm 1.4333 (1.2883)	mem 17417MB
[2023-02-01 03:09:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][200/1251]	eta 0:10:04 lr 0.000872	time 0.5573 (0.5749)	loss 2.8943 (3.5052)	grad_norm 1.3193 (1.2960)	mem 17417MB
[2023-02-01 03:10:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][250/1251]	eta 0:09:33 lr 0.000872	time 0.5535 (0.5724)	loss 3.5202 (3.5035)	grad_norm 1.2981 (1.2989)	mem 17417MB
[2023-02-01 03:10:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][300/1251]	eta 0:09:04 lr 0.000872	time 0.5548 (0.5722)	loss 4.1960 (3.5104)	grad_norm 1.2583 (1.2974)	mem 17417MB
[2023-02-01 03:11:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][350/1251]	eta 0:08:34 lr 0.000872	time 0.5534 (0.5713)	loss 3.4721 (3.5055)	grad_norm 1.3296 (1.2971)	mem 17417MB
[2023-02-01 03:11:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][400/1251]	eta 0:08:06 lr 0.000872	time 0.6313 (0.5712)	loss 3.8966 (3.5038)	grad_norm 1.4971 (1.2997)	mem 17417MB
[2023-02-01 03:12:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][450/1251]	eta 0:07:37 lr 0.000872	time 0.5569 (0.5708)	loss 2.5391 (3.5087)	grad_norm 1.3488 (1.2990)	mem 17417MB
[2023-02-01 03:12:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][500/1251]	eta 0:07:08 lr 0.000871	time 0.6282 (0.5704)	loss 3.4670 (3.5062)	grad_norm 1.2903 (1.2988)	mem 17417MB
[2023-02-01 03:13:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][550/1251]	eta 0:06:39 lr 0.000871	time 0.5575 (0.5702)	loss 2.7267 (3.5006)	grad_norm 1.1664 (1.2988)	mem 17417MB
[2023-02-01 03:13:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][600/1251]	eta 0:06:11 lr 0.000871	time 0.5842 (0.5703)	loss 3.5177 (3.4964)	grad_norm 1.5295 (1.3000)	mem 17417MB
[2023-02-01 03:14:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][650/1251]	eta 0:05:42 lr 0.000871	time 0.5546 (0.5701)	loss 3.5767 (3.4984)	grad_norm 1.2563 (1.2979)	mem 17417MB
[2023-02-01 03:14:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][700/1251]	eta 0:05:14 lr 0.000871	time 0.5532 (0.5702)	loss 3.4502 (3.4977)	grad_norm 1.4980 (1.2966)	mem 17417MB
[2023-02-01 03:15:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][750/1251]	eta 0:04:45 lr 0.000871	time 0.5582 (0.5698)	loss 4.4368 (3.4986)	grad_norm 1.5295 (1.2974)	mem 17417MB
[2023-02-01 03:15:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][800/1251]	eta 0:04:16 lr 0.000871	time 0.6160 (0.5698)	loss 4.0475 (3.5004)	grad_norm 1.2823 (1.2999)	mem 17417MB
[2023-02-01 03:16:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][850/1251]	eta 0:03:48 lr 0.000870	time 0.5544 (0.5698)	loss 2.9129 (3.5077)	grad_norm 1.2229 (1.3000)	mem 17417MB
[2023-02-01 03:16:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][900/1251]	eta 0:03:19 lr 0.000870	time 0.6235 (0.5696)	loss 4.2689 (3.5128)	grad_norm 1.3872 (1.3019)	mem 17417MB
[2023-02-01 03:16:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][950/1251]	eta 0:02:51 lr 0.000870	time 0.5598 (0.5696)	loss 4.2188 (3.5168)	grad_norm 1.2900 (1.3020)	mem 17417MB
[2023-02-01 03:17:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][1000/1251]	eta 0:02:22 lr 0.000870	time 0.5560 (0.5694)	loss 4.1921 (3.5165)	grad_norm 1.2552 (1.3018)	mem 17417MB
[2023-02-01 03:17:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][1050/1251]	eta 0:01:54 lr 0.000870	time 0.5555 (0.5693)	loss 3.5339 (3.5227)	grad_norm 1.3639 (1.3021)	mem 17417MB
[2023-02-01 03:18:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][1100/1251]	eta 0:01:25 lr 0.000870	time 0.5487 (0.5693)	loss 4.1483 (3.5251)	grad_norm 1.2803 (1.3035)	mem 17417MB
[2023-02-01 03:18:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][1150/1251]	eta 0:00:57 lr 0.000870	time 0.5515 (0.5692)	loss 3.9691 (3.5277)	grad_norm 1.4404 (1.3029)	mem 17417MB
[2023-02-01 03:19:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][1200/1251]	eta 0:00:29 lr 0.000870	time 0.6490 (0.5692)	loss 3.3326 (3.5260)	grad_norm 1.3186 (1.3027)	mem 17417MB
[2023-02-01 03:19:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [70/300][1250/1251]	eta 0:00:00 lr 0.000869	time 0.5510 (0.5692)	loss 3.5961 (3.5226)	grad_norm 1.3149 (1.3023)	mem 17417MB
[2023-02-01 03:19:49 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 70 training takes 0:11:52
[2023-02-01 03:19:49 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_70.pth saving......
[2023-02-01 03:19:51 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_70.pth saved !!!
[2023-02-01 03:19:51 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.855 (0.855)	Loss 1.0174 (1.0174)	Acc@1 76.758 (76.758)	Acc@5 93.359 (93.359)	Mem 17417MB
[2023-02-01 03:19:59 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.008 Acc@5 93.362
[2023-02-01 03:19:59 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.0%
[2023-02-01 03:20:00 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.186 (1.186)	Loss 0.9484 (0.9484)	Acc@1 75.879 (75.879)	Acc@5 93.848 (93.848)	Mem 17417MB
[2023-02-01 03:20:08 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.574 Acc@5 94.614
[2023-02-01 03:20:08 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 78.6%
[2023-02-01 03:20:08 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 78.57% at 70 epoch
[2023-02-01 03:20:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][0/1251]	eta 0:35:58 lr 0.000869	time 1.7252 (1.7252)	loss 2.7197 (2.7197)	grad_norm 1.1877 (1.1877)	mem 17417MB
[2023-02-01 03:20:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][50/1251]	eta 0:11:50 lr 0.000869	time 0.5519 (0.5913)	loss 3.6703 (3.4697)	grad_norm 1.2241 (1.2932)	mem 17417MB
[2023-02-01 03:21:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][100/1251]	eta 0:11:08 lr 0.000869	time 0.5522 (0.5811)	loss 3.8920 (3.4969)	grad_norm 1.4711 (1.3028)	mem 17417MB
[2023-02-01 03:21:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][150/1251]	eta 0:10:34 lr 0.000869	time 0.5598 (0.5765)	loss 4.0435 (3.4980)	grad_norm 1.2027 (1.2991)	mem 17417MB
[2023-02-01 03:22:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][200/1251]	eta 0:10:04 lr 0.000869	time 0.5584 (0.5752)	loss 3.9947 (3.4900)	grad_norm 1.3026 (1.3024)	mem 17417MB
[2023-02-01 03:22:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][250/1251]	eta 0:09:33 lr 0.000869	time 0.5554 (0.5732)	loss 3.2593 (3.4764)	grad_norm 1.2835 (1.3021)	mem 17417MB
[2023-02-01 03:23:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][300/1251]	eta 0:09:04 lr 0.000869	time 0.5718 (0.5730)	loss 3.9750 (3.4629)	grad_norm 1.4000 (1.3020)	mem 17417MB
[2023-02-01 03:23:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][350/1251]	eta 0:08:35 lr 0.000868	time 0.5621 (0.5717)	loss 3.4980 (3.4545)	grad_norm 1.2118 (1.3010)	mem 17417MB
[2023-02-01 03:23:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][400/1251]	eta 0:08:06 lr 0.000868	time 0.5549 (0.5715)	loss 2.9646 (3.4549)	grad_norm 1.1946 (1.2987)	mem 17417MB
[2023-02-01 03:24:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][450/1251]	eta 0:07:37 lr 0.000868	time 0.6348 (0.5711)	loss 2.5904 (3.4447)	grad_norm 1.3109 (1.2973)	mem 17417MB
[2023-02-01 03:24:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][500/1251]	eta 0:07:08 lr 0.000868	time 0.6240 (0.5710)	loss 3.1090 (3.4592)	grad_norm 1.7176 (1.2984)	mem 17417MB
[2023-02-01 03:25:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][550/1251]	eta 0:06:39 lr 0.000868	time 0.5648 (0.5704)	loss 2.9564 (3.4619)	grad_norm 1.3237 (1.2987)	mem 17417MB
[2023-02-01 03:25:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][600/1251]	eta 0:06:11 lr 0.000868	time 0.5553 (0.5706)	loss 3.0385 (3.4618)	grad_norm 1.4119 (1.3003)	mem 17417MB
[2023-02-01 03:26:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][650/1251]	eta 0:05:42 lr 0.000868	time 0.5602 (0.5702)	loss 3.4111 (3.4757)	grad_norm 1.4481 (1.3018)	mem 17417MB
[2023-02-01 03:26:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][700/1251]	eta 0:05:14 lr 0.000867	time 0.5571 (0.5701)	loss 3.7595 (3.4867)	grad_norm 1.5376 (1.3022)	mem 17417MB
[2023-02-01 03:27:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][750/1251]	eta 0:04:45 lr 0.000867	time 0.5559 (0.5700)	loss 3.9586 (3.4819)	grad_norm 1.2569 (1.2995)	mem 17417MB
[2023-02-01 03:27:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][800/1251]	eta 0:04:17 lr 0.000867	time 0.5505 (0.5700)	loss 4.1755 (3.4948)	grad_norm 1.2608 (1.2985)	mem 17417MB
[2023-02-01 03:28:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][850/1251]	eta 0:03:48 lr 0.000867	time 0.5574 (0.5698)	loss 3.4757 (3.4954)	grad_norm 1.3768 (1.3002)	mem 17417MB
[2023-02-01 03:28:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][900/1251]	eta 0:03:20 lr 0.000867	time 0.5561 (0.5700)	loss 2.8135 (3.4965)	grad_norm 1.1571 (1.3005)	mem 17417MB
[2023-02-01 03:29:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][950/1251]	eta 0:02:51 lr 0.000867	time 0.5750 (0.5698)	loss 2.7136 (3.4963)	grad_norm 1.2904 (1.3001)	mem 17417MB
[2023-02-01 03:29:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][1000/1251]	eta 0:02:23 lr 0.000867	time 0.5753 (0.5700)	loss 3.6714 (3.5020)	grad_norm 1.2368 (1.3012)	mem 17417MB
[2023-02-01 03:30:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][1050/1251]	eta 0:01:54 lr 0.000866	time 0.5656 (0.5698)	loss 3.6155 (3.4998)	grad_norm 1.2272 (1.3016)	mem 17417MB
[2023-02-01 03:30:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][1100/1251]	eta 0:01:26 lr 0.000866	time 0.5541 (0.5699)	loss 3.1222 (3.5032)	grad_norm 1.2826 (1.3003)	mem 17417MB
[2023-02-01 03:31:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][1150/1251]	eta 0:00:57 lr 0.000866	time 0.5511 (0.5698)	loss 3.6086 (3.5034)	grad_norm 1.3477 (1.3006)	mem 17417MB
[2023-02-01 03:31:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][1200/1251]	eta 0:00:29 lr 0.000866	time 0.5568 (0.5697)	loss 3.7789 (3.4988)	grad_norm 1.4615 (1.3011)	mem 17417MB
[2023-02-01 03:32:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [71/300][1250/1251]	eta 0:00:00 lr 0.000866	time 0.5584 (0.5695)	loss 2.4664 (3.4962)	grad_norm 1.3155 (1.3009)	mem 17417MB
[2023-02-01 03:32:01 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 71 training takes 0:11:52
[2023-02-01 03:32:01 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_71.pth saving......
[2023-02-01 03:32:03 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_71.pth saved !!!
[2023-02-01 03:32:04 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.864 (0.864)	Loss 1.0751 (1.0751)	Acc@1 74.023 (74.023)	Acc@5 92.676 (92.676)	Mem 17417MB
[2023-02-01 03:32:12 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.112 Acc@5 93.366
[2023-02-01 03:32:12 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.1%
[2023-02-01 03:32:13 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.243 (1.243)	Loss 0.9250 (0.9250)	Acc@1 79.199 (79.199)	Acc@5 94.141 (94.141)	Mem 17417MB
[2023-02-01 03:32:21 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.660 Acc@5 94.634
[2023-02-01 03:32:21 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 78.7%
[2023-02-01 03:32:21 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 78.66% at 71 epoch
[2023-02-01 03:32:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][0/1251]	eta 0:36:01 lr 0.000866	time 1.7278 (1.7278)	loss 3.6454 (3.6454)	grad_norm 1.4272 (1.4272)	mem 17417MB
[2023-02-01 03:32:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][50/1251]	eta 0:11:52 lr 0.000866	time 0.5541 (0.5935)	loss 3.3365 (3.5665)	grad_norm 1.2815 (1.3264)	mem 17417MB
[2023-02-01 03:33:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][100/1251]	eta 0:11:11 lr 0.000866	time 0.6538 (0.5833)	loss 2.2599 (3.4739)	grad_norm 1.2824 (1.3169)	mem 17417MB
[2023-02-01 03:33:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][150/1251]	eta 0:10:36 lr 0.000865	time 0.5518 (0.5781)	loss 3.1740 (3.4878)	grad_norm 1.1303 (1.3038)	mem 17417MB
[2023-02-01 03:34:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][200/1251]	eta 0:10:05 lr 0.000865	time 0.5632 (0.5761)	loss 4.2468 (3.5007)	grad_norm 1.4104 (1.3010)	mem 17417MB
[2023-02-01 03:34:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][250/1251]	eta 0:09:35 lr 0.000865	time 0.5673 (0.5751)	loss 3.6463 (3.4868)	grad_norm 1.2204 (1.2983)	mem 17417MB
[2023-02-01 03:35:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][300/1251]	eta 0:09:06 lr 0.000865	time 0.5556 (0.5744)	loss 3.7257 (3.4793)	grad_norm 1.2753 (1.2999)	mem 17417MB
[2023-02-01 03:35:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][350/1251]	eta 0:08:36 lr 0.000865	time 0.5568 (0.5737)	loss 3.8320 (3.4901)	grad_norm 1.2994 (1.3009)	mem 17417MB
[2023-02-01 03:36:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][400/1251]	eta 0:08:07 lr 0.000865	time 0.5545 (0.5733)	loss 4.1492 (3.4912)	grad_norm 1.3534 (1.3019)	mem 17417MB
[2023-02-01 03:36:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][450/1251]	eta 0:07:39 lr 0.000865	time 0.5590 (0.5734)	loss 2.4278 (3.4894)	grad_norm 1.2539 (1.3087)	mem 17417MB
[2023-02-01 03:37:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][500/1251]	eta 0:07:09 lr 0.000864	time 0.5534 (0.5724)	loss 2.5452 (3.4921)	grad_norm 1.3026 (1.3089)	mem 17417MB
[2023-02-01 03:37:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][550/1251]	eta 0:06:41 lr 0.000864	time 0.5519 (0.5724)	loss 3.1657 (3.4841)	grad_norm 1.2131 (1.3053)	mem 17417MB
[2023-02-01 03:38:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][600/1251]	eta 0:06:12 lr 0.000864	time 0.5575 (0.5722)	loss 3.6398 (3.4767)	grad_norm 1.2186 (1.3079)	mem 17417MB
[2023-02-01 03:38:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][650/1251]	eta 0:05:43 lr 0.000864	time 0.5516 (0.5724)	loss 3.6891 (3.4921)	grad_norm 1.3570 (1.3096)	mem 17417MB
[2023-02-01 03:39:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][700/1251]	eta 0:05:15 lr 0.000864	time 0.5581 (0.5720)	loss 4.3093 (3.4909)	grad_norm 1.3211 (1.3086)	mem 17417MB
[2023-02-01 03:39:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][750/1251]	eta 0:04:46 lr 0.000864	time 0.6301 (0.5719)	loss 3.3240 (3.4913)	grad_norm 1.4060 (1.3069)	mem 17417MB
[2023-02-01 03:39:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][800/1251]	eta 0:04:17 lr 0.000864	time 0.6230 (0.5716)	loss 3.7840 (3.5005)	grad_norm 1.2180 (1.3069)	mem 17417MB
[2023-02-01 03:40:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][850/1251]	eta 0:03:49 lr 0.000863	time 0.5577 (0.5717)	loss 2.8554 (3.5080)	grad_norm 1.3976 (1.3063)	mem 17417MB
[2023-02-01 03:40:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][900/1251]	eta 0:03:20 lr 0.000863	time 0.5582 (0.5715)	loss 3.6714 (3.5139)	grad_norm 1.2078 (1.3053)	mem 17417MB
[2023-02-01 03:41:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][950/1251]	eta 0:02:52 lr 0.000863	time 0.5588 (0.5715)	loss 2.9608 (3.5074)	grad_norm 1.4196 (1.3053)	mem 17417MB
[2023-02-01 03:41:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][1000/1251]	eta 0:02:23 lr 0.000863	time 0.5536 (0.5714)	loss 3.4673 (3.5083)	grad_norm 1.1938 (1.3045)	mem 17417MB
[2023-02-01 03:42:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][1050/1251]	eta 0:01:54 lr 0.000863	time 0.5605 (0.5712)	loss 2.1437 (3.5072)	grad_norm 1.3219 (1.3035)	mem 17417MB
[2023-02-01 03:42:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][1100/1251]	eta 0:01:26 lr 0.000863	time 0.5562 (0.5711)	loss 4.2273 (3.5179)	grad_norm 1.2652 (1.3020)	mem 17417MB
[2023-02-01 03:43:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][1150/1251]	eta 0:00:57 lr 0.000863	time 0.5512 (0.5711)	loss 2.7969 (3.5118)	grad_norm 1.4546 (nan)	mem 17417MB
[2023-02-01 03:43:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][1200/1251]	eta 0:00:29 lr 0.000862	time 0.5592 (0.5710)	loss 3.0745 (3.5127)	grad_norm 1.1703 (nan)	mem 17417MB
[2023-02-01 03:44:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [72/300][1250/1251]	eta 0:00:00 lr 0.000862	time 0.5491 (0.5710)	loss 4.0682 (3.5143)	grad_norm 1.2343 (nan)	mem 17417MB
[2023-02-01 03:44:16 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 72 training takes 0:11:54
[2023-02-01 03:44:16 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_72.pth saving......
[2023-02-01 03:44:18 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_72.pth saved !!!
[2023-02-01 03:44:18 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.852 (0.852)	Loss 1.0417 (1.0417)	Acc@1 76.367 (76.367)	Acc@5 92.676 (92.676)	Mem 17417MB
[2023-02-01 03:44:26 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.336 Acc@5 93.540
[2023-02-01 03:44:26 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.3%
[2023-02-01 03:44:28 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.289 (1.289)	Loss 0.9344 (0.9344)	Acc@1 78.223 (78.223)	Acc@5 94.727 (94.727)	Mem 17417MB
[2023-02-01 03:44:36 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.752 Acc@5 94.684
[2023-02-01 03:44:36 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 78.8%
[2023-02-01 03:44:36 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 78.75% at 72 epoch
[2023-02-01 03:44:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][0/1251]	eta 0:35:46 lr 0.000862	time 1.7160 (1.7160)	loss 3.4760 (3.4760)	grad_norm 1.2202 (1.2202)	mem 17417MB
[2023-02-01 03:45:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][50/1251]	eta 0:11:49 lr 0.000862	time 0.5545 (0.5911)	loss 3.3578 (3.2638)	grad_norm 1.2642 (1.2953)	mem 17417MB
[2023-02-01 03:45:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][100/1251]	eta 0:11:08 lr 0.000862	time 0.5581 (0.5811)	loss 3.4117 (3.3440)	grad_norm 1.2368 (1.3213)	mem 17417MB
[2023-02-01 03:46:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][150/1251]	eta 0:10:36 lr 0.000862	time 0.5521 (0.5781)	loss 3.5838 (3.4176)	grad_norm 1.2762 (1.3128)	mem 17417MB
[2023-02-01 03:46:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][200/1251]	eta 0:10:05 lr 0.000862	time 0.5555 (0.5759)	loss 3.1125 (3.4198)	grad_norm 1.2974 (1.3120)	mem 17417MB
[2023-02-01 03:47:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][250/1251]	eta 0:09:35 lr 0.000862	time 0.5615 (0.5748)	loss 3.8044 (3.4502)	grad_norm 1.4269 (1.3085)	mem 17417MB
[2023-02-01 03:47:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][300/1251]	eta 0:09:06 lr 0.000861	time 0.5559 (0.5749)	loss 3.2196 (3.4525)	grad_norm 1.2055 (1.3101)	mem 17417MB
[2023-02-01 03:47:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][350/1251]	eta 0:08:36 lr 0.000861	time 0.5588 (0.5736)	loss 3.4727 (3.4539)	grad_norm 1.1740 (1.3067)	mem 17417MB
[2023-02-01 03:48:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][400/1251]	eta 0:08:08 lr 0.000861	time 0.5598 (0.5735)	loss 3.3267 (3.4657)	grad_norm 1.1876 (1.3053)	mem 17417MB
[2023-02-01 03:48:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][450/1251]	eta 0:07:39 lr 0.000861	time 0.5552 (0.5732)	loss 3.5069 (3.4570)	grad_norm 1.3922 (1.3049)	mem 17417MB
[2023-02-01 03:49:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][500/1251]	eta 0:07:10 lr 0.000861	time 0.5579 (0.5728)	loss 3.8722 (3.4521)	grad_norm 1.2358 (1.3032)	mem 17417MB
[2023-02-01 03:49:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][550/1251]	eta 0:06:41 lr 0.000861	time 0.5639 (0.5728)	loss 2.6479 (3.4436)	grad_norm 1.3060 (1.3011)	mem 17417MB
[2023-02-01 03:50:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][600/1251]	eta 0:06:12 lr 0.000861	time 0.5549 (0.5725)	loss 3.1526 (3.4469)	grad_norm 1.2072 (1.3011)	mem 17417MB
[2023-02-01 03:50:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][650/1251]	eta 0:05:43 lr 0.000860	time 0.5561 (0.5723)	loss 4.2399 (3.4492)	grad_norm 1.2728 (1.3004)	mem 17417MB
[2023-02-01 03:51:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][700/1251]	eta 0:05:15 lr 0.000860	time 0.5558 (0.5722)	loss 3.7099 (3.4538)	grad_norm 1.2659 (1.3018)	mem 17417MB
[2023-02-01 03:51:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][750/1251]	eta 0:04:46 lr 0.000860	time 0.5565 (0.5715)	loss 2.6962 (3.4549)	grad_norm 1.2144 (nan)	mem 17417MB
[2023-02-01 03:52:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][800/1251]	eta 0:04:17 lr 0.000860	time 0.5695 (0.5717)	loss 3.5487 (3.4552)	grad_norm 1.2485 (nan)	mem 17417MB
[2023-02-01 03:52:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][850/1251]	eta 0:03:49 lr 0.000860	time 0.5533 (0.5713)	loss 3.4184 (3.4636)	grad_norm 1.3522 (nan)	mem 17417MB
[2023-02-01 03:53:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][900/1251]	eta 0:03:20 lr 0.000860	time 0.6434 (0.5714)	loss 4.1855 (3.4685)	grad_norm 1.2239 (nan)	mem 17417MB
[2023-02-01 03:53:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][950/1251]	eta 0:02:51 lr 0.000860	time 0.5515 (0.5712)	loss 3.3038 (3.4721)	grad_norm 1.3687 (nan)	mem 17417MB
[2023-02-01 03:54:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][1000/1251]	eta 0:02:23 lr 0.000859	time 0.6362 (0.5711)	loss 3.9592 (3.4702)	grad_norm 1.2384 (nan)	mem 17417MB
[2023-02-01 03:54:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][1050/1251]	eta 0:01:54 lr 0.000859	time 0.5747 (0.5709)	loss 4.2610 (3.4667)	grad_norm 1.2726 (nan)	mem 17417MB
[2023-02-01 03:55:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][1100/1251]	eta 0:01:26 lr 0.000859	time 0.6220 (0.5710)	loss 3.6353 (3.4628)	grad_norm 1.4398 (nan)	mem 17417MB
[2023-02-01 03:55:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][1150/1251]	eta 0:00:57 lr 0.000859	time 0.5538 (0.5708)	loss 3.5071 (3.4649)	grad_norm 1.4990 (nan)	mem 17417MB
[2023-02-01 03:56:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][1200/1251]	eta 0:00:29 lr 0.000859	time 0.5550 (0.5707)	loss 2.8875 (3.4626)	grad_norm 1.2658 (nan)	mem 17417MB
[2023-02-01 03:56:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [73/300][1250/1251]	eta 0:00:00 lr 0.000859	time 0.5500 (0.5706)	loss 3.6427 (3.4634)	grad_norm 1.2227 (nan)	mem 17417MB
[2023-02-01 03:56:30 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 73 training takes 0:11:53
[2023-02-01 03:56:30 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_73.pth saving......
[2023-02-01 03:56:31 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_73.pth saved !!!
[2023-02-01 03:56:32 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.848 (0.848)	Loss 0.9439 (0.9439)	Acc@1 78.320 (78.320)	Acc@5 94.727 (94.727)	Mem 17417MB
[2023-02-01 03:56:40 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.374 Acc@5 93.594
[2023-02-01 03:56:40 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.4%
[2023-02-01 03:56:42 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.167 (1.167)	Loss 0.9211 (0.9211)	Acc@1 78.223 (78.223)	Acc@5 94.434 (94.434)	Mem 17417MB
[2023-02-01 03:56:50 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.808 Acc@5 94.722
[2023-02-01 03:56:50 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 78.8%
[2023-02-01 03:56:50 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 78.81% at 73 epoch
[2023-02-01 03:56:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][0/1251]	eta 0:33:39 lr 0.000859	time 1.6145 (1.6145)	loss 3.6112 (3.6112)	grad_norm 1.3224 (1.3224)	mem 17417MB
[2023-02-01 03:57:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][50/1251]	eta 0:11:44 lr 0.000859	time 0.5561 (0.5868)	loss 2.8449 (3.3599)	grad_norm 1.3925 (1.2690)	mem 17417MB
[2023-02-01 03:57:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][100/1251]	eta 0:11:07 lr 0.000858	time 0.5677 (0.5803)	loss 3.4683 (3.5002)	grad_norm 1.2103 (1.2811)	mem 17417MB
[2023-02-01 03:58:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][150/1251]	eta 0:10:32 lr 0.000858	time 0.5536 (0.5748)	loss 3.8524 (3.5249)	grad_norm 1.2368 (1.2835)	mem 17417MB
[2023-02-01 03:58:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][200/1251]	eta 0:10:03 lr 0.000858	time 0.5582 (0.5739)	loss 2.5832 (3.5208)	grad_norm 1.4184 (1.2853)	mem 17417MB
[2023-02-01 03:59:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][250/1251]	eta 0:09:33 lr 0.000858	time 0.5612 (0.5726)	loss 2.7678 (3.4823)	grad_norm 1.3533 (1.2936)	mem 17417MB
[2023-02-01 03:59:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][300/1251]	eta 0:09:04 lr 0.000858	time 0.5511 (0.5722)	loss 4.0263 (3.4703)	grad_norm 1.2250 (1.2986)	mem 17417MB
[2023-02-01 04:00:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][350/1251]	eta 0:08:34 lr 0.000858	time 0.5627 (0.5713)	loss 3.0628 (3.4756)	grad_norm 1.1531 (1.2985)	mem 17417MB
[2023-02-01 04:00:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][400/1251]	eta 0:08:06 lr 0.000858	time 0.6190 (0.5714)	loss 3.8510 (3.5005)	grad_norm 1.2168 (1.3007)	mem 17417MB
[2023-02-01 04:01:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][450/1251]	eta 0:07:37 lr 0.000857	time 0.6227 (0.5705)	loss 3.9178 (3.5173)	grad_norm 1.2570 (1.3019)	mem 17417MB
[2023-02-01 04:01:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][500/1251]	eta 0:07:08 lr 0.000857	time 0.5521 (0.5703)	loss 2.9057 (3.5019)	grad_norm 1.4423 (1.3036)	mem 17417MB
[2023-02-01 04:02:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][550/1251]	eta 0:06:39 lr 0.000857	time 0.5621 (0.5702)	loss 3.6948 (3.5159)	grad_norm 1.2147 (1.3065)	mem 17417MB
[2023-02-01 04:02:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][600/1251]	eta 0:06:11 lr 0.000857	time 0.5576 (0.5701)	loss 2.6604 (3.5143)	grad_norm 1.2522 (1.3064)	mem 17417MB
[2023-02-01 04:03:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][650/1251]	eta 0:05:42 lr 0.000857	time 0.5508 (0.5704)	loss 4.5368 (3.5046)	grad_norm 1.2564 (1.3043)	mem 17417MB
[2023-02-01 04:03:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][700/1251]	eta 0:05:14 lr 0.000857	time 0.5506 (0.5701)	loss 4.2458 (3.5013)	grad_norm 1.4815 (1.3061)	mem 17417MB
[2023-02-01 04:03:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][750/1251]	eta 0:04:45 lr 0.000856	time 0.5515 (0.5699)	loss 3.6378 (3.4959)	grad_norm 1.2495 (1.3070)	mem 17417MB
[2023-02-01 04:04:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][800/1251]	eta 0:04:16 lr 0.000856	time 0.5545 (0.5697)	loss 3.8393 (3.4986)	grad_norm 1.3527 (1.3080)	mem 17417MB
[2023-02-01 04:04:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][850/1251]	eta 0:03:48 lr 0.000856	time 0.5683 (0.5697)	loss 2.9353 (3.4886)	grad_norm 1.3377 (1.3077)	mem 17417MB
[2023-02-01 04:05:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][900/1251]	eta 0:03:19 lr 0.000856	time 0.5579 (0.5697)	loss 4.2848 (3.4960)	grad_norm 1.2160 (1.3070)	mem 17417MB
[2023-02-01 04:05:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][950/1251]	eta 0:02:51 lr 0.000856	time 0.5460 (0.5697)	loss 3.5309 (3.5006)	grad_norm 1.3597 (1.3071)	mem 17417MB
[2023-02-01 04:06:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][1000/1251]	eta 0:02:22 lr 0.000856	time 0.5584 (0.5696)	loss 3.6537 (3.5000)	grad_norm 1.4313 (1.3069)	mem 17417MB
[2023-02-01 04:06:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][1050/1251]	eta 0:01:54 lr 0.000856	time 0.5629 (0.5698)	loss 2.9053 (3.4953)	grad_norm 1.4689 (1.3081)	mem 17417MB
[2023-02-01 04:07:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][1100/1251]	eta 0:01:26 lr 0.000855	time 0.6302 (0.5696)	loss 3.9816 (3.5021)	grad_norm 1.2756 (1.3069)	mem 17417MB
[2023-02-01 04:07:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][1150/1251]	eta 0:00:57 lr 0.000855	time 0.5565 (0.5695)	loss 4.1043 (3.5047)	grad_norm 1.2637 (1.3062)	mem 17417MB
[2023-02-01 04:08:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][1200/1251]	eta 0:00:29 lr 0.000855	time 0.5571 (0.5695)	loss 2.9730 (3.5021)	grad_norm 1.1678 (1.3056)	mem 17417MB
[2023-02-01 04:08:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [74/300][1250/1251]	eta 0:00:00 lr 0.000855	time 0.5532 (0.5694)	loss 3.7514 (3.5067)	grad_norm 1.3499 (1.3054)	mem 17417MB
[2023-02-01 04:08:42 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 74 training takes 0:11:52
[2023-02-01 04:08:42 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_74.pth saving......
[2023-02-01 04:08:44 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_74.pth saved !!!
[2023-02-01 04:08:45 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.882 (0.882)	Loss 0.9980 (0.9980)	Acc@1 76.367 (76.367)	Acc@5 93.945 (93.945)	Mem 17417MB
[2023-02-01 04:08:53 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.284 Acc@5 93.682
[2023-02-01 04:08:53 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.3%
[2023-02-01 04:08:54 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.183 (1.183)	Loss 0.8513 (0.8513)	Acc@1 79.688 (79.688)	Acc@5 95.020 (95.020)	Mem 17417MB
[2023-02-01 04:09:02 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.864 Acc@5 94.772
[2023-02-01 04:09:02 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 78.9%
[2023-02-01 04:09:02 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 78.86% at 74 epoch
[2023-02-01 04:09:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][0/1251]	eta 0:35:43 lr 0.000855	time 1.7132 (1.7132)	loss 4.0691 (4.0691)	grad_norm 1.3847 (1.3847)	mem 17417MB
[2023-02-01 04:09:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][50/1251]	eta 0:11:50 lr 0.000855	time 0.5535 (0.5919)	loss 3.7842 (3.5050)	grad_norm 1.3743 (1.3057)	mem 17417MB
[2023-02-01 04:10:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][100/1251]	eta 0:11:09 lr 0.000855	time 0.5581 (0.5817)	loss 3.7100 (3.4925)	grad_norm 1.2241 (1.3096)	mem 17417MB
[2023-02-01 04:10:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][150/1251]	eta 0:10:35 lr 0.000855	time 0.5541 (0.5775)	loss 3.1630 (3.5077)	grad_norm 1.2500 (1.3191)	mem 17417MB
[2023-02-01 04:10:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][200/1251]	eta 0:10:04 lr 0.000854	time 0.5524 (0.5749)	loss 3.6066 (3.5204)	grad_norm 1.3136 (1.3248)	mem 17417MB
[2023-02-01 04:11:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][250/1251]	eta 0:09:33 lr 0.000854	time 0.5638 (0.5731)	loss 3.4155 (3.5104)	grad_norm 1.2310 (1.3194)	mem 17417MB
[2023-02-01 04:11:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][300/1251]	eta 0:09:04 lr 0.000854	time 0.5502 (0.5724)	loss 3.2939 (3.5228)	grad_norm 1.2063 (1.3162)	mem 17417MB
[2023-02-01 04:12:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][350/1251]	eta 0:08:35 lr 0.000854	time 0.5572 (0.5722)	loss 3.5880 (3.5153)	grad_norm 1.3879 (1.3154)	mem 17417MB
[2023-02-01 04:12:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][400/1251]	eta 0:08:06 lr 0.000854	time 0.5533 (0.5717)	loss 4.2479 (3.5119)	grad_norm 1.2370 (1.3179)	mem 17417MB
[2023-02-01 04:13:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][450/1251]	eta 0:07:37 lr 0.000854	time 0.5577 (0.5717)	loss 2.8631 (3.5088)	grad_norm 1.3101 (1.3179)	mem 17417MB
[2023-02-01 04:13:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][500/1251]	eta 0:07:09 lr 0.000854	time 0.5649 (0.5713)	loss 3.3712 (3.5123)	grad_norm 1.3210 (1.3141)	mem 17417MB
[2023-02-01 04:14:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][550/1251]	eta 0:06:40 lr 0.000853	time 0.6344 (0.5713)	loss 3.2043 (3.5161)	grad_norm 1.3618 (1.3124)	mem 17417MB
[2023-02-01 04:14:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][600/1251]	eta 0:06:11 lr 0.000853	time 0.5623 (0.5708)	loss 3.1300 (3.5259)	grad_norm 1.2750 (1.3118)	mem 17417MB
[2023-02-01 04:15:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][650/1251]	eta 0:05:42 lr 0.000853	time 0.5566 (0.5707)	loss 3.8571 (3.5269)	grad_norm 1.2089 (1.3126)	mem 17417MB
[2023-02-01 04:15:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][700/1251]	eta 0:05:14 lr 0.000853	time 0.5591 (0.5705)	loss 3.8071 (3.5289)	grad_norm 1.2495 (1.3129)	mem 17417MB
[2023-02-01 04:16:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][750/1251]	eta 0:04:45 lr 0.000853	time 0.5520 (0.5703)	loss 4.0293 (3.5188)	grad_norm 1.3436 (1.3128)	mem 17417MB
[2023-02-01 04:16:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][800/1251]	eta 0:04:17 lr 0.000853	time 0.5590 (0.5701)	loss 2.6603 (3.5233)	grad_norm 1.3667 (1.3147)	mem 17417MB
[2023-02-01 04:17:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][850/1251]	eta 0:03:48 lr 0.000853	time 0.5570 (0.5702)	loss 3.7383 (3.5237)	grad_norm 1.2063 (1.3138)	mem 17417MB
[2023-02-01 04:17:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][900/1251]	eta 0:03:20 lr 0.000852	time 0.5594 (0.5702)	loss 3.9602 (3.5187)	grad_norm 1.4403 (1.3131)	mem 17417MB
[2023-02-01 04:18:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][950/1251]	eta 0:02:51 lr 0.000852	time 0.5604 (0.5700)	loss 4.1405 (3.5169)	grad_norm 1.4138 (1.3125)	mem 17417MB
[2023-02-01 04:18:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][1000/1251]	eta 0:02:23 lr 0.000852	time 0.6251 (0.5699)	loss 3.8677 (3.5183)	grad_norm 1.3994 (1.3133)	mem 17417MB
[2023-02-01 04:19:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][1050/1251]	eta 0:01:54 lr 0.000852	time 0.5556 (0.5700)	loss 4.4195 (3.5243)	grad_norm 1.3245 (1.3137)	mem 17417MB
[2023-02-01 04:19:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][1100/1251]	eta 0:01:26 lr 0.000852	time 0.5575 (0.5700)	loss 3.7490 (3.5207)	grad_norm 1.3423 (1.3113)	mem 17417MB
[2023-02-01 04:19:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][1150/1251]	eta 0:00:57 lr 0.000852	time 0.5564 (0.5700)	loss 3.3575 (3.5178)	grad_norm 1.1897 (1.3099)	mem 17417MB
[2023-02-01 04:20:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][1200/1251]	eta 0:00:29 lr 0.000851	time 0.5567 (0.5700)	loss 3.6871 (3.5173)	grad_norm 1.3802 (1.3102)	mem 17417MB
[2023-02-01 04:20:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [75/300][1250/1251]	eta 0:00:00 lr 0.000851	time 0.5487 (0.5700)	loss 3.8827 (3.5140)	grad_norm 1.4280 (1.3104)	mem 17417MB
[2023-02-01 04:20:55 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 75 training takes 0:11:53
[2023-02-01 04:20:56 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_75.pth saving......
[2023-02-01 04:20:58 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_75.pth saved !!!
[2023-02-01 04:20:58 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.839 (0.839)	Loss 0.9879 (0.9879)	Acc@1 76.562 (76.562)	Acc@5 94.434 (94.434)	Mem 17417MB
[2023-02-01 04:21:06 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.546 Acc@5 93.716
[2023-02-01 04:21:06 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.5%
[2023-02-01 04:21:08 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.402 (1.402)	Loss 0.8747 (0.8747)	Acc@1 79.297 (79.297)	Acc@5 94.531 (94.531)	Mem 17417MB
[2023-02-01 04:21:16 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.904 Acc@5 94.788
[2023-02-01 04:21:16 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 78.9%
[2023-02-01 04:21:16 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 78.90% at 75 epoch
[2023-02-01 04:21:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][0/1251]	eta 0:34:29 lr 0.000851	time 1.6546 (1.6546)	loss 3.7597 (3.7597)	grad_norm 1.2952 (1.2952)	mem 17417MB
[2023-02-01 04:21:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][50/1251]	eta 0:11:45 lr 0.000851	time 0.5610 (0.5873)	loss 3.1144 (3.5668)	grad_norm 1.2822 (1.3103)	mem 17417MB
[2023-02-01 04:22:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][100/1251]	eta 0:11:09 lr 0.000851	time 0.6428 (0.5815)	loss 3.4355 (3.5386)	grad_norm 1.3145 (1.3063)	mem 17417MB
[2023-02-01 04:22:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][150/1251]	eta 0:10:33 lr 0.000851	time 0.5523 (0.5751)	loss 3.4448 (3.5562)	grad_norm 1.2181 (1.3111)	mem 17417MB
[2023-02-01 04:23:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][200/1251]	eta 0:10:02 lr 0.000851	time 0.5542 (0.5737)	loss 2.4264 (3.5377)	grad_norm 1.1955 (1.3093)	mem 17417MB
[2023-02-01 04:23:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][250/1251]	eta 0:09:33 lr 0.000851	time 0.5777 (0.5727)	loss 2.6863 (3.5073)	grad_norm 1.3781 (1.3080)	mem 17417MB
[2023-02-01 04:24:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][300/1251]	eta 0:09:03 lr 0.000850	time 0.5547 (0.5716)	loss 2.9616 (3.4935)	grad_norm 1.3818 (1.3071)	mem 17417MB
[2023-02-01 04:24:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][350/1251]	eta 0:08:34 lr 0.000850	time 0.5561 (0.5712)	loss 3.5823 (3.4982)	grad_norm 1.2602 (1.3059)	mem 17417MB
[2023-02-01 04:25:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][400/1251]	eta 0:08:05 lr 0.000850	time 0.5571 (0.5708)	loss 2.7100 (3.4777)	grad_norm 1.2202 (1.3056)	mem 17417MB
[2023-02-01 04:25:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][450/1251]	eta 0:07:36 lr 0.000850	time 0.5620 (0.5703)	loss 3.2918 (3.4813)	grad_norm 1.2744 (1.3048)	mem 17417MB
[2023-02-01 04:26:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][500/1251]	eta 0:07:08 lr 0.000850	time 0.5494 (0.5703)	loss 3.0215 (3.4862)	grad_norm 1.1789 (1.3014)	mem 17417MB
[2023-02-01 04:26:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][550/1251]	eta 0:06:39 lr 0.000850	time 0.5559 (0.5699)	loss 3.5259 (3.4924)	grad_norm 1.4726 (1.3006)	mem 17417MB
[2023-02-01 04:26:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][600/1251]	eta 0:06:11 lr 0.000850	time 0.5542 (0.5700)	loss 3.7985 (3.4825)	grad_norm 1.4735 (1.3015)	mem 17417MB
[2023-02-01 04:27:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][650/1251]	eta 0:05:42 lr 0.000849	time 0.5555 (0.5700)	loss 4.0913 (3.4840)	grad_norm 1.4136 (1.3027)	mem 17417MB
[2023-02-01 04:27:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][700/1251]	eta 0:05:13 lr 0.000849	time 0.5588 (0.5698)	loss 4.4873 (3.4933)	grad_norm 1.3138 (1.3067)	mem 17417MB
[2023-02-01 04:28:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][750/1251]	eta 0:04:45 lr 0.000849	time 0.5509 (0.5698)	loss 3.6353 (3.4968)	grad_norm 1.2154 (1.3053)	mem 17417MB
[2023-02-01 04:28:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][800/1251]	eta 0:04:17 lr 0.000849	time 0.5582 (0.5699)	loss 3.7535 (3.4973)	grad_norm 1.1611 (1.3061)	mem 17417MB
[2023-02-01 04:29:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][850/1251]	eta 0:03:48 lr 0.000849	time 0.5655 (0.5697)	loss 3.6084 (3.5031)	grad_norm 1.1941 (1.3069)	mem 17417MB
[2023-02-01 04:29:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][900/1251]	eta 0:03:20 lr 0.000849	time 0.5560 (0.5699)	loss 3.2408 (3.5032)	grad_norm 1.4861 (1.3070)	mem 17417MB
[2023-02-01 04:30:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][950/1251]	eta 0:02:51 lr 0.000849	time 0.5465 (0.5696)	loss 3.4772 (3.4939)	grad_norm 1.3229 (1.3081)	mem 17417MB
[2023-02-01 04:30:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][1000/1251]	eta 0:02:22 lr 0.000848	time 0.5570 (0.5697)	loss 3.9574 (3.4949)	grad_norm 1.5306 (1.3083)	mem 17417MB
[2023-02-01 04:31:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][1050/1251]	eta 0:01:54 lr 0.000848	time 0.5574 (0.5697)	loss 4.4529 (3.4964)	grad_norm 1.4131 (1.3077)	mem 17417MB
[2023-02-01 04:31:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][1100/1251]	eta 0:01:25 lr 0.000848	time 0.5539 (0.5695)	loss 3.1957 (3.4986)	grad_norm 1.2765 (1.3076)	mem 17417MB
[2023-02-01 04:32:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][1150/1251]	eta 0:00:57 lr 0.000848	time 0.5580 (0.5696)	loss 2.3408 (3.4943)	grad_norm 1.3722 (1.3073)	mem 17417MB
[2023-02-01 04:32:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][1200/1251]	eta 0:00:29 lr 0.000848	time 0.6202 (0.5695)	loss 4.2116 (3.4926)	grad_norm 1.1350 (1.3073)	mem 17417MB
[2023-02-01 04:33:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [76/300][1250/1251]	eta 0:00:00 lr 0.000848	time 0.5535 (0.5694)	loss 3.2688 (3.4915)	grad_norm 1.3062 (1.3075)	mem 17417MB
[2023-02-01 04:33:08 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 76 training takes 0:11:52
[2023-02-01 04:33:08 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_76.pth saving......
[2023-02-01 04:33:10 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_76.pth saved !!!
[2023-02-01 04:33:11 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.837 (0.837)	Loss 1.0116 (1.0116)	Acc@1 76.855 (76.855)	Acc@5 93.457 (93.457)	Mem 17417MB
[2023-02-01 04:33:19 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.444 Acc@5 93.752
[2023-02-01 04:33:19 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.4%
[2023-02-01 04:33:20 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.251 (1.251)	Loss 0.8400 (0.8400)	Acc@1 79.688 (79.688)	Acc@5 95.703 (95.703)	Mem 17417MB
[2023-02-01 04:33:28 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.986 Acc@5 94.848
[2023-02-01 04:33:28 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.0%
[2023-02-01 04:33:28 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 78.99% at 76 epoch
[2023-02-01 04:33:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][0/1251]	eta 0:34:37 lr 0.000848	time 1.6605 (1.6605)	loss 2.5477 (2.5477)	grad_norm 1.2116 (1.2116)	mem 17417MB
[2023-02-01 04:33:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][50/1251]	eta 0:11:55 lr 0.000847	time 0.5569 (0.5955)	loss 2.9771 (3.3659)	grad_norm 1.3084 (1.2698)	mem 17417MB
[2023-02-01 04:34:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][100/1251]	eta 0:11:08 lr 0.000847	time 0.5558 (0.5806)	loss 3.0720 (3.5411)	grad_norm 1.3197 (1.2920)	mem 17417MB
[2023-02-01 04:34:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][150/1251]	eta 0:10:36 lr 0.000847	time 0.5558 (0.5783)	loss 3.0043 (3.5385)	grad_norm 1.3273 (1.3012)	mem 17417MB
[2023-02-01 04:35:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][200/1251]	eta 0:10:04 lr 0.000847	time 0.6140 (0.5754)	loss 2.6907 (3.5457)	grad_norm 1.2978 (1.3045)	mem 17417MB
[2023-02-01 04:35:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][250/1251]	eta 0:09:34 lr 0.000847	time 0.6308 (0.5742)	loss 3.7606 (3.5323)	grad_norm 1.1713 (1.3132)	mem 17417MB
[2023-02-01 04:36:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][300/1251]	eta 0:09:04 lr 0.000847	time 0.5554 (0.5729)	loss 4.0354 (3.5289)	grad_norm 1.3804 (1.3133)	mem 17417MB
[2023-02-01 04:36:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][350/1251]	eta 0:08:36 lr 0.000847	time 0.6397 (0.5730)	loss 3.6379 (3.5313)	grad_norm 1.4168 (1.3095)	mem 17417MB
[2023-02-01 04:37:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][400/1251]	eta 0:08:07 lr 0.000846	time 0.5564 (0.5724)	loss 2.9720 (3.5318)	grad_norm 1.2797 (1.3067)	mem 17417MB
[2023-02-01 04:37:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][450/1251]	eta 0:07:38 lr 0.000846	time 0.6395 (0.5723)	loss 3.5495 (3.5318)	grad_norm 1.3020 (1.3064)	mem 17417MB
[2023-02-01 04:38:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][500/1251]	eta 0:07:09 lr 0.000846	time 0.5640 (0.5717)	loss 2.3893 (3.5331)	grad_norm 1.2165 (1.3094)	mem 17417MB
[2023-02-01 04:38:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][550/1251]	eta 0:06:40 lr 0.000846	time 0.5487 (0.5718)	loss 3.9680 (3.5189)	grad_norm 1.4619 (1.3106)	mem 17417MB
[2023-02-01 04:39:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][600/1251]	eta 0:06:12 lr 0.000846	time 0.5504 (0.5715)	loss 3.8532 (3.5218)	grad_norm 1.2987 (1.3100)	mem 17417MB
[2023-02-01 04:39:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][650/1251]	eta 0:05:43 lr 0.000846	time 0.5531 (0.5715)	loss 3.5340 (3.5163)	grad_norm 1.2792 (1.3103)	mem 17417MB
[2023-02-01 04:40:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][700/1251]	eta 0:05:14 lr 0.000846	time 0.5568 (0.5713)	loss 3.3769 (3.5180)	grad_norm 1.2075 (1.3090)	mem 17417MB
[2023-02-01 04:40:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][750/1251]	eta 0:04:46 lr 0.000845	time 0.5217 (0.5712)	loss 4.1575 (3.5197)	grad_norm nan (nan)	mem 17417MB
[2023-02-01 04:41:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][800/1251]	eta 0:04:17 lr 0.000845	time 0.5536 (0.5710)	loss 2.7121 (3.5163)	grad_norm 1.1555 (nan)	mem 17417MB
[2023-02-01 04:41:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][850/1251]	eta 0:03:48 lr 0.000845	time 0.5589 (0.5711)	loss 3.7249 (3.5147)	grad_norm 1.2132 (nan)	mem 17417MB
[2023-02-01 04:42:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][900/1251]	eta 0:03:20 lr 0.000845	time 0.5564 (0.5708)	loss 2.4141 (3.5120)	grad_norm 1.4037 (nan)	mem 17417MB
[2023-02-01 04:42:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][950/1251]	eta 0:02:51 lr 0.000845	time 0.5538 (0.5710)	loss 3.1295 (3.5111)	grad_norm 1.3183 (nan)	mem 17417MB
[2023-02-01 04:42:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][1000/1251]	eta 0:02:23 lr 0.000845	time 0.5584 (0.5707)	loss 2.7581 (3.5109)	grad_norm 1.3929 (nan)	mem 17417MB
[2023-02-01 04:43:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][1050/1251]	eta 0:01:54 lr 0.000844	time 0.5673 (0.5708)	loss 3.7874 (3.5146)	grad_norm 1.4902 (nan)	mem 17417MB
[2023-02-01 04:43:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][1100/1251]	eta 0:01:26 lr 0.000844	time 0.5545 (0.5706)	loss 4.0109 (3.5112)	grad_norm 1.6018 (nan)	mem 17417MB
[2023-02-01 04:44:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][1150/1251]	eta 0:00:57 lr 0.000844	time 0.6303 (0.5708)	loss 3.3038 (3.5071)	grad_norm 1.2816 (nan)	mem 17417MB
[2023-02-01 04:44:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][1200/1251]	eta 0:00:29 lr 0.000844	time 0.5514 (0.5708)	loss 3.7386 (3.4981)	grad_norm 1.2489 (nan)	mem 17417MB
[2023-02-01 04:45:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [77/300][1250/1251]	eta 0:00:00 lr 0.000844	time 0.6374 (0.5707)	loss 3.6347 (3.5027)	grad_norm 1.3766 (nan)	mem 17417MB
[2023-02-01 04:45:22 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 77 training takes 0:11:54
[2023-02-01 04:45:22 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_77.pth saving......
[2023-02-01 04:45:24 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_77.pth saved !!!
[2023-02-01 04:45:25 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.865 (0.865)	Loss 1.0694 (1.0694)	Acc@1 74.902 (74.902)	Acc@5 93.359 (93.359)	Mem 17417MB
[2023-02-01 04:45:33 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.616 Acc@5 93.686
[2023-02-01 04:45:33 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.6%
[2023-02-01 04:45:34 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.209 (1.209)	Loss 0.8669 (0.8669)	Acc@1 79.395 (79.395)	Acc@5 95.898 (95.898)	Mem 17417MB
[2023-02-01 04:45:42 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.032 Acc@5 94.916
[2023-02-01 04:45:42 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.0%
[2023-02-01 04:45:42 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.03% at 77 epoch
[2023-02-01 04:45:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][0/1251]	eta 0:36:14 lr 0.000844	time 1.7378 (1.7378)	loss 4.1731 (4.1731)	grad_norm 1.4026 (1.4026)	mem 17417MB
[2023-02-01 04:46:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][50/1251]	eta 0:11:53 lr 0.000844	time 0.5610 (0.5938)	loss 2.8887 (3.5705)	grad_norm 1.3187 (1.2987)	mem 17417MB
[2023-02-01 04:46:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][100/1251]	eta 0:11:09 lr 0.000844	time 0.5477 (0.5813)	loss 3.8347 (3.5484)	grad_norm 1.2585 (1.2951)	mem 17417MB
[2023-02-01 04:47:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][150/1251]	eta 0:10:36 lr 0.000843	time 0.5577 (0.5784)	loss 2.7015 (3.5228)	grad_norm 1.1818 (1.3041)	mem 17417MB
[2023-02-01 04:47:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][200/1251]	eta 0:10:05 lr 0.000843	time 0.5552 (0.5765)	loss 3.6438 (3.4743)	grad_norm 1.3240 (1.3050)	mem 17417MB
[2023-02-01 04:48:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][250/1251]	eta 0:09:35 lr 0.000843	time 0.5527 (0.5754)	loss 3.5529 (3.4466)	grad_norm 1.2471 (1.3084)	mem 17417MB
[2023-02-01 04:48:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][300/1251]	eta 0:09:06 lr 0.000843	time 0.5623 (0.5749)	loss 2.2714 (3.4569)	grad_norm 1.3535 (1.3117)	mem 17417MB
[2023-02-01 04:49:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][350/1251]	eta 0:08:36 lr 0.000843	time 0.5553 (0.5732)	loss 2.2529 (3.4531)	grad_norm 1.1651 (1.3159)	mem 17417MB
[2023-02-01 04:49:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][400/1251]	eta 0:08:07 lr 0.000843	time 0.5641 (0.5730)	loss 3.9917 (3.4646)	grad_norm 1.3567 (1.3151)	mem 17417MB
[2023-02-01 04:50:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][450/1251]	eta 0:07:38 lr 0.000842	time 0.5609 (0.5728)	loss 3.5415 (3.4654)	grad_norm 1.4459 (1.3134)	mem 17417MB
[2023-02-01 04:50:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][500/1251]	eta 0:07:10 lr 0.000842	time 0.5595 (0.5726)	loss 4.2781 (3.4692)	grad_norm 1.3895 (1.3136)	mem 17417MB
[2023-02-01 04:50:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][550/1251]	eta 0:06:41 lr 0.000842	time 0.5531 (0.5728)	loss 3.5957 (3.4644)	grad_norm 1.3493 (1.3145)	mem 17417MB
[2023-02-01 04:51:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][600/1251]	eta 0:06:12 lr 0.000842	time 0.5548 (0.5726)	loss 2.6655 (3.4575)	grad_norm 1.3593 (1.3158)	mem 17417MB
[2023-02-01 04:51:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][650/1251]	eta 0:05:44 lr 0.000842	time 0.5588 (0.5726)	loss 3.6505 (3.4545)	grad_norm 1.3469 (1.3170)	mem 17417MB
[2023-02-01 04:52:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][700/1251]	eta 0:05:15 lr 0.000842	time 0.5627 (0.5726)	loss 3.5845 (3.4593)	grad_norm 1.3681 (1.3168)	mem 17417MB
[2023-02-01 04:52:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][750/1251]	eta 0:04:46 lr 0.000842	time 0.5602 (0.5725)	loss 3.8237 (3.4697)	grad_norm 1.3513 (1.3166)	mem 17417MB
[2023-02-01 04:53:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][800/1251]	eta 0:04:18 lr 0.000841	time 0.5561 (0.5724)	loss 3.0466 (3.4783)	grad_norm 1.1921 (1.3146)	mem 17417MB
[2023-02-01 04:53:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][850/1251]	eta 0:03:49 lr 0.000841	time 0.6068 (0.5724)	loss 3.5540 (3.4749)	grad_norm 1.2644 (1.3152)	mem 17417MB
[2023-02-01 04:54:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][900/1251]	eta 0:03:20 lr 0.000841	time 0.5556 (0.5722)	loss 3.6363 (3.4818)	grad_norm 1.2095 (1.3160)	mem 17417MB
[2023-02-01 04:54:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][950/1251]	eta 0:02:52 lr 0.000841	time 0.5616 (0.5723)	loss 3.4802 (3.4828)	grad_norm 1.3214 (1.3170)	mem 17417MB
[2023-02-01 04:55:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][1000/1251]	eta 0:02:23 lr 0.000841	time 0.5563 (0.5724)	loss 2.1562 (3.4862)	grad_norm 1.4211 (1.3171)	mem 17417MB
[2023-02-01 04:55:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][1050/1251]	eta 0:01:55 lr 0.000841	time 0.5623 (0.5724)	loss 3.4168 (3.4904)	grad_norm 1.3188 (1.3172)	mem 17417MB
[2023-02-01 04:56:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][1100/1251]	eta 0:01:26 lr 0.000841	time 0.6451 (0.5724)	loss 2.5534 (3.4889)	grad_norm 1.2754 (1.3169)	mem 17417MB
[2023-02-01 04:56:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][1150/1251]	eta 0:00:57 lr 0.000840	time 0.6181 (0.5720)	loss 3.4142 (3.4936)	grad_norm 1.2161 (1.3180)	mem 17417MB
[2023-02-01 04:57:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][1200/1251]	eta 0:00:29 lr 0.000840	time 0.5567 (0.5719)	loss 3.8699 (3.4954)	grad_norm 1.4442 (1.3174)	mem 17417MB
[2023-02-01 04:57:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [78/300][1250/1251]	eta 0:00:00 lr 0.000840	time 0.5508 (0.5717)	loss 3.9238 (3.4978)	grad_norm 1.3183 (1.3175)	mem 17417MB
[2023-02-01 04:57:37 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 78 training takes 0:11:55
[2023-02-01 04:57:38 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_78.pth saving......
[2023-02-01 04:57:39 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_78.pth saved !!!
[2023-02-01 04:57:40 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.917 (0.917)	Loss 1.0255 (1.0255)	Acc@1 75.684 (75.684)	Acc@5 93.750 (93.750)	Mem 17417MB
[2023-02-01 04:57:48 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.258 Acc@5 93.598
[2023-02-01 04:57:48 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.3%
[2023-02-01 04:57:50 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.246 (1.246)	Loss 0.8457 (0.8457)	Acc@1 80.664 (80.664)	Acc@5 95.020 (95.020)	Mem 17417MB
[2023-02-01 04:57:57 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.078 Acc@5 94.914
[2023-02-01 04:57:57 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.1%
[2023-02-01 04:57:57 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.08% at 78 epoch
[2023-02-01 04:57:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][0/1251]	eta 0:33:14 lr 0.000840	time 1.5941 (1.5941)	loss 2.8401 (2.8401)	grad_norm 1.3551 (1.3551)	mem 17417MB
[2023-02-01 04:58:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][50/1251]	eta 0:11:47 lr 0.000840	time 0.6618 (0.5891)	loss 2.2271 (3.4355)	grad_norm 1.4360 (1.3115)	mem 17417MB
[2023-02-01 04:58:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][100/1251]	eta 0:11:08 lr 0.000840	time 0.6199 (0.5808)	loss 3.0634 (3.4198)	grad_norm 1.2844 (1.3327)	mem 17417MB
[2023-02-01 04:59:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][150/1251]	eta 0:10:32 lr 0.000840	time 0.5526 (0.5743)	loss 3.7609 (3.4467)	grad_norm 1.2133 (1.3313)	mem 17417MB
[2023-02-01 04:59:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][200/1251]	eta 0:10:03 lr 0.000839	time 0.5542 (0.5742)	loss 2.9982 (3.4661)	grad_norm 1.2233 (1.3309)	mem 17417MB
[2023-02-01 05:00:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][250/1251]	eta 0:09:32 lr 0.000839	time 0.5534 (0.5718)	loss 2.5726 (3.4468)	grad_norm 1.2330 (1.3279)	mem 17417MB
[2023-02-01 05:00:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][300/1251]	eta 0:09:04 lr 0.000839	time 0.5550 (0.5724)	loss 3.3822 (3.4626)	grad_norm 1.3000 (1.3232)	mem 17417MB
[2023-02-01 05:01:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][350/1251]	eta 0:08:34 lr 0.000839	time 0.5606 (0.5714)	loss 3.8508 (3.4680)	grad_norm 1.4339 (1.3236)	mem 17417MB
[2023-02-01 05:01:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][400/1251]	eta 0:08:06 lr 0.000839	time 0.6317 (0.5714)	loss 2.7607 (3.4568)	grad_norm 1.4299 (1.3195)	mem 17417MB
[2023-02-01 05:02:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][450/1251]	eta 0:07:37 lr 0.000839	time 0.5684 (0.5709)	loss 3.9260 (3.4800)	grad_norm 1.2359 (1.3253)	mem 17417MB
[2023-02-01 05:02:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][500/1251]	eta 0:07:08 lr 0.000839	time 0.6226 (0.5707)	loss 3.0608 (3.4776)	grad_norm 1.3114 (1.3226)	mem 17417MB
[2023-02-01 05:03:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][550/1251]	eta 0:06:39 lr 0.000838	time 0.5559 (0.5704)	loss 3.8050 (3.4818)	grad_norm 1.2176 (1.3224)	mem 17417MB
[2023-02-01 05:03:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][600/1251]	eta 0:06:11 lr 0.000838	time 0.6502 (0.5705)	loss 3.2101 (3.4882)	grad_norm 1.2404 (1.3210)	mem 17417MB
[2023-02-01 05:04:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][650/1251]	eta 0:05:42 lr 0.000838	time 0.5630 (0.5700)	loss 3.0659 (3.4939)	grad_norm 1.3935 (1.3203)	mem 17417MB
[2023-02-01 05:04:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][700/1251]	eta 0:05:14 lr 0.000838	time 0.6492 (0.5701)	loss 3.8804 (3.4955)	grad_norm 1.2668 (1.3206)	mem 17417MB
[2023-02-01 05:05:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][750/1251]	eta 0:04:45 lr 0.000838	time 0.5573 (0.5700)	loss 3.0628 (3.4923)	grad_norm 1.3612 (1.3207)	mem 17417MB
[2023-02-01 05:05:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][800/1251]	eta 0:04:17 lr 0.000838	time 0.5581 (0.5700)	loss 3.5101 (3.4873)	grad_norm 1.2967 (1.3203)	mem 17417MB
[2023-02-01 05:06:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][850/1251]	eta 0:03:48 lr 0.000837	time 0.6135 (0.5698)	loss 3.3443 (3.4914)	grad_norm 1.2525 (1.3217)	mem 17417MB
[2023-02-01 05:06:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][900/1251]	eta 0:03:20 lr 0.000837	time 0.6212 (0.5699)	loss 3.3342 (3.4849)	grad_norm 1.2721 (1.3222)	mem 17417MB
[2023-02-01 05:06:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][950/1251]	eta 0:02:51 lr 0.000837	time 0.6548 (0.5697)	loss 3.7645 (3.4801)	grad_norm 1.2297 (1.3223)	mem 17417MB
[2023-02-01 05:07:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][1000/1251]	eta 0:02:23 lr 0.000837	time 0.5600 (0.5698)	loss 3.3728 (3.4807)	grad_norm 1.1202 (1.3222)	mem 17417MB
[2023-02-01 05:07:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][1050/1251]	eta 0:01:54 lr 0.000837	time 0.5564 (0.5696)	loss 4.0959 (3.4799)	grad_norm 1.3555 (1.3222)	mem 17417MB
[2023-02-01 05:08:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][1100/1251]	eta 0:01:26 lr 0.000837	time 0.6489 (0.5698)	loss 4.4331 (3.4843)	grad_norm 1.2543 (1.3215)	mem 17417MB
[2023-02-01 05:08:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][1150/1251]	eta 0:00:57 lr 0.000837	time 0.5572 (0.5697)	loss 4.0393 (3.4863)	grad_norm 1.4236 (1.3226)	mem 17417MB
[2023-02-01 05:09:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][1200/1251]	eta 0:00:29 lr 0.000836	time 0.6326 (0.5695)	loss 3.0294 (3.4843)	grad_norm 1.1938 (1.3245)	mem 17417MB
[2023-02-01 05:09:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [79/300][1250/1251]	eta 0:00:00 lr 0.000836	time 0.5511 (0.5695)	loss 4.0857 (3.4814)	grad_norm 1.4190 (1.3224)	mem 17417MB
[2023-02-01 05:09:50 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 79 training takes 0:11:52
[2023-02-01 05:09:50 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_79.pth saving......
[2023-02-01 05:09:52 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_79.pth saved !!!
[2023-02-01 05:09:53 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.958 (0.958)	Loss 0.9373 (0.9373)	Acc@1 77.344 (77.344)	Acc@5 94.434 (94.434)	Mem 17417MB
[2023-02-01 05:10:01 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.854 Acc@5 93.786
[2023-02-01 05:10:01 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.9%
[2023-02-01 05:10:02 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.217 (1.217)	Loss 0.8862 (0.8862)	Acc@1 79.980 (79.980)	Acc@5 95.020 (95.020)	Mem 17417MB
[2023-02-01 05:10:10 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.128 Acc@5 94.946
[2023-02-01 05:10:10 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.1%
[2023-02-01 05:10:10 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.13% at 79 epoch
[2023-02-01 05:10:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][0/1251]	eta 0:34:35 lr 0.000836	time 1.6592 (1.6592)	loss 2.4804 (2.4804)	grad_norm 1.2934 (1.2934)	mem 17417MB
[2023-02-01 05:10:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][50/1251]	eta 0:11:55 lr 0.000836	time 0.5603 (0.5956)	loss 3.8355 (3.3875)	grad_norm 1.3014 (1.3139)	mem 17417MB
[2023-02-01 05:11:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][100/1251]	eta 0:11:12 lr 0.000836	time 0.6186 (0.5841)	loss 3.6096 (3.4640)	grad_norm 1.3730 (1.3144)	mem 17417MB
[2023-02-01 05:11:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][150/1251]	eta 0:10:37 lr 0.000836	time 0.5496 (0.5789)	loss 3.3780 (3.4563)	grad_norm 1.3321 (1.3184)	mem 17417MB
[2023-02-01 05:12:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][200/1251]	eta 0:10:04 lr 0.000836	time 0.5606 (0.5752)	loss 3.6148 (3.4864)	grad_norm 1.4332 (1.3183)	mem 17417MB
[2023-02-01 05:12:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][250/1251]	eta 0:09:35 lr 0.000835	time 0.5545 (0.5746)	loss 3.9407 (3.4987)	grad_norm 1.2764 (1.3211)	mem 17417MB
[2023-02-01 05:13:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][300/1251]	eta 0:09:05 lr 0.000835	time 0.5527 (0.5733)	loss 3.3780 (3.4918)	grad_norm 1.3139 (1.3265)	mem 17417MB
[2023-02-01 05:13:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][350/1251]	eta 0:08:36 lr 0.000835	time 0.5634 (0.5730)	loss 3.7316 (3.4846)	grad_norm 1.3268 (1.3260)	mem 17417MB
[2023-02-01 05:14:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][400/1251]	eta 0:08:07 lr 0.000835	time 0.5557 (0.5724)	loss 3.6831 (3.4730)	grad_norm 1.3859 (1.3277)	mem 17417MB
[2023-02-01 05:14:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][450/1251]	eta 0:07:38 lr 0.000835	time 0.6169 (0.5723)	loss 3.2590 (3.4707)	grad_norm 1.4296 (1.3291)	mem 17417MB
[2023-02-01 05:14:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][500/1251]	eta 0:07:09 lr 0.000835	time 0.6258 (0.5720)	loss 3.7396 (3.4628)	grad_norm 1.3150 (1.3295)	mem 17417MB
[2023-02-01 05:15:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][550/1251]	eta 0:06:40 lr 0.000835	time 0.5574 (0.5716)	loss 3.3868 (3.4580)	grad_norm 1.2933 (1.3273)	mem 17417MB
[2023-02-01 05:15:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][600/1251]	eta 0:06:12 lr 0.000834	time 0.5599 (0.5716)	loss 2.9118 (3.4563)	grad_norm 1.2975 (1.3267)	mem 17417MB
[2023-02-01 05:16:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][650/1251]	eta 0:05:43 lr 0.000834	time 0.5584 (0.5715)	loss 3.2893 (3.4571)	grad_norm 1.2128 (1.3243)	mem 17417MB
[2023-02-01 05:16:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][700/1251]	eta 0:05:14 lr 0.000834	time 0.5596 (0.5710)	loss 2.7529 (3.4549)	grad_norm 1.3848 (1.3271)	mem 17417MB
[2023-02-01 05:17:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][750/1251]	eta 0:04:46 lr 0.000834	time 0.5636 (0.5711)	loss 3.1527 (3.4558)	grad_norm 1.2457 (1.3259)	mem 17417MB
[2023-02-01 05:17:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][800/1251]	eta 0:04:17 lr 0.000834	time 0.5620 (0.5711)	loss 4.0969 (3.4606)	grad_norm 1.2401 (1.3268)	mem 17417MB
[2023-02-01 05:18:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][850/1251]	eta 0:03:48 lr 0.000834	time 0.5598 (0.5711)	loss 3.9912 (3.4527)	grad_norm 1.2556 (1.3255)	mem 17417MB
[2023-02-01 05:18:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][900/1251]	eta 0:03:20 lr 0.000833	time 0.6127 (0.5711)	loss 3.4749 (3.4484)	grad_norm 1.2402 (1.3243)	mem 17417MB
[2023-02-01 05:19:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][950/1251]	eta 0:02:51 lr 0.000833	time 0.5534 (0.5708)	loss 4.1284 (3.4521)	grad_norm 1.3273 (1.3234)	mem 17417MB
[2023-02-01 05:19:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][1000/1251]	eta 0:02:23 lr 0.000833	time 0.5516 (0.5709)	loss 2.8073 (3.4542)	grad_norm 1.3363 (1.3230)	mem 17417MB
[2023-02-01 05:20:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][1050/1251]	eta 0:01:54 lr 0.000833	time 0.5641 (0.5709)	loss 3.4975 (3.4516)	grad_norm 1.2159 (nan)	mem 17417MB
[2023-02-01 05:20:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][1100/1251]	eta 0:01:26 lr 0.000833	time 0.5643 (0.5709)	loss 2.6444 (3.4574)	grad_norm 1.5367 (nan)	mem 17417MB
[2023-02-01 05:21:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][1150/1251]	eta 0:00:57 lr 0.000833	time 0.6296 (0.5709)	loss 2.6531 (3.4519)	grad_norm 1.2606 (nan)	mem 17417MB
[2023-02-01 05:21:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][1200/1251]	eta 0:00:29 lr 0.000833	time 0.5607 (0.5708)	loss 3.8871 (3.4573)	grad_norm 1.2287 (nan)	mem 17417MB
[2023-02-01 05:22:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [80/300][1250/1251]	eta 0:00:00 lr 0.000832	time 0.5633 (0.5707)	loss 3.8120 (3.4649)	grad_norm 1.3905 (nan)	mem 17417MB
[2023-02-01 05:22:04 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 80 training takes 0:11:54
[2023-02-01 05:22:04 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_80.pth saving......
[2023-02-01 05:22:06 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_80.pth saved !!!
[2023-02-01 05:22:07 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.886 (0.886)	Loss 1.0036 (1.0036)	Acc@1 77.832 (77.832)	Acc@5 93.848 (93.848)	Mem 17417MB
[2023-02-01 05:22:15 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.730 Acc@5 93.778
[2023-02-01 05:22:15 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.7%
[2023-02-01 05:22:16 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.230 (1.230)	Loss 0.7812 (0.7812)	Acc@1 82.031 (82.031)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-01 05:22:24 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.228 Acc@5 94.968
[2023-02-01 05:22:24 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.2%
[2023-02-01 05:22:24 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.23% at 80 epoch
[2023-02-01 05:22:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][0/1251]	eta 0:35:30 lr 0.000832	time 1.7031 (1.7031)	loss 2.9228 (2.9228)	grad_norm 1.1836 (1.1836)	mem 17417MB
[2023-02-01 05:22:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][50/1251]	eta 0:11:51 lr 0.000832	time 0.6341 (0.5921)	loss 3.9951 (3.4179)	grad_norm 1.1513 (1.2829)	mem 17417MB
[2023-02-01 05:23:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][100/1251]	eta 0:11:08 lr 0.000832	time 0.6356 (0.5808)	loss 3.7190 (3.4749)	grad_norm 1.1873 (nan)	mem 17417MB
[2023-02-01 05:23:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][150/1251]	eta 0:10:33 lr 0.000832	time 0.5585 (0.5757)	loss 3.9388 (3.4363)	grad_norm 1.3354 (nan)	mem 17417MB
[2023-02-01 05:24:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][200/1251]	eta 0:10:02 lr 0.000832	time 0.5747 (0.5734)	loss 3.1146 (3.4490)	grad_norm 1.2717 (nan)	mem 17417MB
[2023-02-01 05:24:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][250/1251]	eta 0:09:33 lr 0.000832	time 0.6057 (0.5732)	loss 3.3224 (3.4488)	grad_norm 1.1338 (nan)	mem 17417MB
[2023-02-01 05:25:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][300/1251]	eta 0:09:03 lr 0.000831	time 0.5555 (0.5716)	loss 3.9859 (3.4586)	grad_norm 1.2941 (nan)	mem 17417MB
[2023-02-01 05:25:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][350/1251]	eta 0:08:34 lr 0.000831	time 0.5558 (0.5713)	loss 3.3205 (3.4563)	grad_norm 1.1447 (nan)	mem 17417MB
[2023-02-01 05:26:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][400/1251]	eta 0:08:06 lr 0.000831	time 0.5616 (0.5712)	loss 4.1950 (3.4697)	grad_norm 1.3180 (nan)	mem 17417MB
[2023-02-01 05:26:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][450/1251]	eta 0:07:37 lr 0.000831	time 0.6273 (0.5709)	loss 3.0076 (3.4711)	grad_norm 1.4113 (nan)	mem 17417MB
[2023-02-01 05:27:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][500/1251]	eta 0:07:08 lr 0.000831	time 0.5582 (0.5709)	loss 3.8836 (3.4806)	grad_norm 1.3470 (nan)	mem 17417MB
[2023-02-01 05:27:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][550/1251]	eta 0:06:39 lr 0.000831	time 0.5638 (0.5703)	loss 4.1069 (3.4735)	grad_norm 1.3759 (nan)	mem 17417MB
[2023-02-01 05:28:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][600/1251]	eta 0:06:11 lr 0.000830	time 0.5531 (0.5701)	loss 3.5031 (3.4816)	grad_norm 1.3220 (nan)	mem 17417MB
[2023-02-01 05:28:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][650/1251]	eta 0:05:42 lr 0.000830	time 0.5555 (0.5700)	loss 3.7580 (3.4899)	grad_norm 1.4065 (nan)	mem 17417MB
[2023-02-01 05:29:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][700/1251]	eta 0:05:14 lr 0.000830	time 0.5553 (0.5699)	loss 3.9901 (3.4924)	grad_norm 1.5879 (nan)	mem 17417MB
[2023-02-01 05:29:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][750/1251]	eta 0:04:45 lr 0.000830	time 0.5522 (0.5697)	loss 3.3899 (3.4864)	grad_norm 1.3190 (nan)	mem 17417MB
[2023-02-01 05:30:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][800/1251]	eta 0:04:16 lr 0.000830	time 0.6141 (0.5698)	loss 4.2399 (3.4808)	grad_norm 1.2405 (nan)	mem 17417MB
[2023-02-01 05:30:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][850/1251]	eta 0:03:48 lr 0.000830	time 0.6279 (0.5697)	loss 3.6544 (3.4894)	grad_norm 1.3273 (nan)	mem 17417MB
[2023-02-01 05:30:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][900/1251]	eta 0:03:19 lr 0.000830	time 0.5623 (0.5697)	loss 3.9681 (3.4907)	grad_norm 1.2933 (nan)	mem 17417MB
[2023-02-01 05:31:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][950/1251]	eta 0:02:51 lr 0.000829	time 0.5661 (0.5696)	loss 3.9955 (3.4875)	grad_norm 1.1103 (nan)	mem 17417MB
[2023-02-01 05:31:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][1000/1251]	eta 0:02:22 lr 0.000829	time 0.5553 (0.5696)	loss 3.7760 (3.4879)	grad_norm 1.2912 (nan)	mem 17417MB
[2023-02-01 05:32:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][1050/1251]	eta 0:01:54 lr 0.000829	time 0.5546 (0.5696)	loss 3.9820 (3.4879)	grad_norm 1.3097 (nan)	mem 17417MB
[2023-02-01 05:32:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][1100/1251]	eta 0:01:25 lr 0.000829	time 0.5587 (0.5693)	loss 3.4358 (3.4799)	grad_norm 1.3215 (nan)	mem 17417MB
[2023-02-01 05:33:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][1150/1251]	eta 0:00:57 lr 0.000829	time 0.5533 (0.5693)	loss 4.3050 (3.4746)	grad_norm 1.3246 (nan)	mem 17417MB
[2023-02-01 05:33:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][1200/1251]	eta 0:00:29 lr 0.000829	time 0.5514 (0.5694)	loss 2.9280 (3.4787)	grad_norm 1.4567 (nan)	mem 17417MB
[2023-02-01 05:34:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [81/300][1250/1251]	eta 0:00:00 lr 0.000828	time 0.5550 (0.5693)	loss 3.8399 (3.4808)	grad_norm 1.4121 (nan)	mem 17417MB
[2023-02-01 05:34:16 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 81 training takes 0:11:52
[2023-02-01 05:34:16 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_81.pth saving......
[2023-02-01 05:34:18 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_81.pth saved !!!
[2023-02-01 05:34:19 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.858 (0.858)	Loss 0.9466 (0.9466)	Acc@1 78.125 (78.125)	Acc@5 95.215 (95.215)	Mem 17417MB
[2023-02-01 05:34:27 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.916 Acc@5 93.936
[2023-02-01 05:34:27 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.9%
[2023-02-01 05:34:28 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.243 (1.243)	Loss 0.8891 (0.8891)	Acc@1 77.441 (77.441)	Acc@5 95.215 (95.215)	Mem 17417MB
[2023-02-01 05:34:36 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.264 Acc@5 94.988
[2023-02-01 05:34:36 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.3%
[2023-02-01 05:34:36 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.26% at 81 epoch
[2023-02-01 05:34:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][0/1251]	eta 0:34:24 lr 0.000828	time 1.6502 (1.6502)	loss 2.0854 (2.0854)	grad_norm 1.3219 (1.3219)	mem 17417MB
[2023-02-01 05:35:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][50/1251]	eta 0:11:54 lr 0.000828	time 0.5547 (0.5947)	loss 4.0343 (3.5169)	grad_norm 1.3588 (1.3121)	mem 17417MB
[2023-02-01 05:35:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][100/1251]	eta 0:11:07 lr 0.000828	time 0.6228 (0.5801)	loss 3.6580 (3.4512)	grad_norm 1.4831 (1.3135)	mem 17417MB
[2023-02-01 05:36:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][150/1251]	eta 0:10:35 lr 0.000828	time 0.5523 (0.5770)	loss 3.7300 (3.4872)	grad_norm 1.2019 (1.3148)	mem 17417MB
[2023-02-01 05:36:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][200/1251]	eta 0:10:04 lr 0.000828	time 0.5577 (0.5753)	loss 2.6854 (3.4901)	grad_norm 1.3085 (1.3155)	mem 17417MB
[2023-02-01 05:37:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][250/1251]	eta 0:09:34 lr 0.000828	time 0.5623 (0.5737)	loss 2.9318 (3.4850)	grad_norm 1.4437 (1.3235)	mem 17417MB
[2023-02-01 05:37:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][300/1251]	eta 0:09:04 lr 0.000828	time 0.5563 (0.5730)	loss 3.6336 (3.4886)	grad_norm 1.2668 (1.3199)	mem 17417MB
[2023-02-01 05:37:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][350/1251]	eta 0:08:35 lr 0.000827	time 0.5508 (0.5726)	loss 3.7653 (3.4795)	grad_norm 1.3132 (1.3181)	mem 17417MB
[2023-02-01 05:38:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][400/1251]	eta 0:08:06 lr 0.000827	time 0.5550 (0.5720)	loss 2.6499 (3.4807)	grad_norm 1.2128 (1.3198)	mem 17417MB
[2023-02-01 05:38:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][450/1251]	eta 0:07:38 lr 0.000827	time 0.5612 (0.5719)	loss 3.8110 (3.4752)	grad_norm 1.3045 (1.3221)	mem 17417MB
[2023-02-01 05:39:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][500/1251]	eta 0:07:09 lr 0.000827	time 0.6273 (0.5716)	loss 3.8361 (3.4695)	grad_norm 1.1807 (1.3214)	mem 17417MB
[2023-02-01 05:39:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][550/1251]	eta 0:06:40 lr 0.000827	time 0.5521 (0.5714)	loss 3.1324 (3.4723)	grad_norm 1.3044 (1.3201)	mem 17417MB
[2023-02-01 05:40:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][600/1251]	eta 0:06:12 lr 0.000827	time 0.5585 (0.5715)	loss 3.8486 (3.4606)	grad_norm 1.5320 (1.3172)	mem 17417MB
[2023-02-01 05:40:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][650/1251]	eta 0:05:43 lr 0.000826	time 0.5781 (0.5712)	loss 3.8514 (3.4698)	grad_norm 1.3050 (1.3188)	mem 17417MB
[2023-02-01 05:41:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][700/1251]	eta 0:05:14 lr 0.000826	time 0.5593 (0.5711)	loss 3.9946 (3.4711)	grad_norm 1.5392 (1.3190)	mem 17417MB
[2023-02-01 05:41:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][750/1251]	eta 0:04:46 lr 0.000826	time 0.5557 (0.5711)	loss 3.6023 (3.4724)	grad_norm 1.1700 (1.3199)	mem 17417MB
[2023-02-01 05:42:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][800/1251]	eta 0:04:17 lr 0.000826	time 0.6140 (0.5708)	loss 2.6433 (3.4707)	grad_norm 1.3721 (1.3213)	mem 17417MB
[2023-02-01 05:42:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][850/1251]	eta 0:03:48 lr 0.000826	time 0.5619 (0.5708)	loss 4.0525 (3.4833)	grad_norm 1.2615 (1.3230)	mem 17417MB
[2023-02-01 05:43:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][900/1251]	eta 0:03:20 lr 0.000826	time 0.6347 (0.5706)	loss 3.6258 (3.4740)	grad_norm 1.2404 (1.3240)	mem 17417MB
[2023-02-01 05:43:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][950/1251]	eta 0:02:51 lr 0.000825	time 0.5556 (0.5706)	loss 3.4198 (3.4723)	grad_norm 1.1506 (1.3250)	mem 17417MB
[2023-02-01 05:44:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][1000/1251]	eta 0:02:23 lr 0.000825	time 0.5621 (0.5708)	loss 2.9374 (3.4728)	grad_norm 1.2807 (1.3262)	mem 17417MB
[2023-02-01 05:44:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][1050/1251]	eta 0:01:54 lr 0.000825	time 0.5524 (0.5706)	loss 3.9137 (3.4679)	grad_norm 1.2678 (nan)	mem 17417MB
[2023-02-01 05:45:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][1100/1251]	eta 0:01:26 lr 0.000825	time 0.5636 (0.5705)	loss 3.7237 (3.4694)	grad_norm 1.0968 (nan)	mem 17417MB
[2023-02-01 05:45:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][1150/1251]	eta 0:00:57 lr 0.000825	time 0.5580 (0.5705)	loss 2.6687 (3.4667)	grad_norm 1.3570 (nan)	mem 17417MB
[2023-02-01 05:46:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][1200/1251]	eta 0:00:29 lr 0.000825	time 0.5563 (0.5705)	loss 4.3119 (3.4620)	grad_norm 1.5376 (nan)	mem 17417MB
[2023-02-01 05:46:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [82/300][1250/1251]	eta 0:00:00 lr 0.000825	time 0.5541 (0.5705)	loss 3.8276 (3.4611)	grad_norm 1.4264 (nan)	mem 17417MB
[2023-02-01 05:46:30 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 82 training takes 0:11:53
[2023-02-01 05:46:30 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_82.pth saving......
[2023-02-01 05:46:32 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_82.pth saved !!!
[2023-02-01 05:46:33 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.826 (0.826)	Loss 0.9499 (0.9499)	Acc@1 77.930 (77.930)	Acc@5 94.629 (94.629)	Mem 17417MB
[2023-02-01 05:46:41 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.816 Acc@5 93.910
[2023-02-01 05:46:41 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.8%
[2023-02-01 05:46:42 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.207 (1.207)	Loss 0.8596 (0.8596)	Acc@1 80.469 (80.469)	Acc@5 95.605 (95.605)	Mem 17417MB
[2023-02-01 05:46:50 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.324 Acc@5 95.074
[2023-02-01 05:46:50 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.3%
[2023-02-01 05:46:50 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.32% at 82 epoch
[2023-02-01 05:46:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][0/1251]	eta 0:40:01 lr 0.000825	time 1.9196 (1.9196)	loss 3.3231 (3.3231)	grad_norm 1.7066 (1.7066)	mem 17417MB
[2023-02-01 05:47:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][50/1251]	eta 0:11:59 lr 0.000824	time 0.5598 (0.5987)	loss 4.1440 (3.4743)	grad_norm 1.1768 (1.3375)	mem 17417MB
[2023-02-01 05:47:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][100/1251]	eta 0:11:12 lr 0.000824	time 0.5592 (0.5842)	loss 3.8237 (3.5694)	grad_norm 1.3519 (1.3305)	mem 17417MB
[2023-02-01 05:48:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][150/1251]	eta 0:10:38 lr 0.000824	time 0.5575 (0.5797)	loss 3.5064 (3.5404)	grad_norm 1.5030 (1.3329)	mem 17417MB
[2023-02-01 05:48:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][200/1251]	eta 0:10:06 lr 0.000824	time 0.5572 (0.5769)	loss 3.1543 (3.5277)	grad_norm 1.3739 (1.3345)	mem 17417MB
[2023-02-01 05:49:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][250/1251]	eta 0:09:36 lr 0.000824	time 0.5564 (0.5758)	loss 2.7666 (3.5189)	grad_norm 1.5512 (1.3332)	mem 17417MB
[2023-02-01 05:49:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][300/1251]	eta 0:09:06 lr 0.000824	time 0.5623 (0.5744)	loss 4.2301 (3.5066)	grad_norm 1.3443 (1.3312)	mem 17417MB
[2023-02-01 05:50:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][350/1251]	eta 0:08:36 lr 0.000823	time 0.5753 (0.5732)	loss 3.2897 (3.4953)	grad_norm 1.2727 (1.3253)	mem 17417MB
[2023-02-01 05:50:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][400/1251]	eta 0:08:07 lr 0.000823	time 0.5510 (0.5726)	loss 3.0158 (3.4875)	grad_norm 1.2625 (1.3236)	mem 17417MB
[2023-02-01 05:51:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][450/1251]	eta 0:07:38 lr 0.000823	time 0.6271 (0.5726)	loss 3.8330 (3.4793)	grad_norm 1.5633 (1.3247)	mem 17417MB
[2023-02-01 05:51:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][500/1251]	eta 0:07:09 lr 0.000823	time 0.5655 (0.5723)	loss 3.1913 (3.4689)	grad_norm 1.2654 (1.3218)	mem 17417MB
[2023-02-01 05:52:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][550/1251]	eta 0:06:40 lr 0.000823	time 0.6303 (0.5718)	loss 3.5409 (3.4682)	grad_norm 1.4215 (1.3232)	mem 17417MB
[2023-02-01 05:52:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][600/1251]	eta 0:06:12 lr 0.000823	time 0.5600 (0.5719)	loss 2.8778 (3.4683)	grad_norm 1.3156 (1.3278)	mem 17417MB
[2023-02-01 05:53:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][650/1251]	eta 0:05:43 lr 0.000822	time 0.5566 (0.5715)	loss 4.4461 (3.4789)	grad_norm 1.4093 (1.3268)	mem 17417MB
[2023-02-01 05:53:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][700/1251]	eta 0:05:14 lr 0.000822	time 0.5543 (0.5715)	loss 2.5003 (3.4715)	grad_norm 1.2759 (1.3261)	mem 17417MB
[2023-02-01 05:53:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][750/1251]	eta 0:04:46 lr 0.000822	time 0.5554 (0.5711)	loss 4.0668 (3.4720)	grad_norm 1.2003 (1.3238)	mem 17417MB
[2023-02-01 05:54:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][800/1251]	eta 0:04:17 lr 0.000822	time 0.5587 (0.5709)	loss 3.2215 (3.4688)	grad_norm 1.4852 (1.3258)	mem 17417MB
[2023-02-01 05:54:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][850/1251]	eta 0:03:48 lr 0.000822	time 0.5600 (0.5709)	loss 3.6218 (3.4618)	grad_norm 1.3118 (1.3257)	mem 17417MB
[2023-02-01 05:55:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][900/1251]	eta 0:03:20 lr 0.000822	time 0.5544 (0.5708)	loss 3.0823 (3.4637)	grad_norm 1.2769 (1.3247)	mem 17417MB
[2023-02-01 05:55:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][950/1251]	eta 0:02:51 lr 0.000821	time 0.5565 (0.5707)	loss 3.3565 (3.4620)	grad_norm 1.2820 (1.3256)	mem 17417MB
[2023-02-01 05:56:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][1000/1251]	eta 0:02:23 lr 0.000821	time 0.5568 (0.5707)	loss 3.7781 (3.4632)	grad_norm 1.2167 (1.3249)	mem 17417MB
[2023-02-01 05:56:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][1050/1251]	eta 0:01:54 lr 0.000821	time 0.5601 (0.5706)	loss 3.7262 (3.4554)	grad_norm 1.4353 (1.3232)	mem 17417MB
[2023-02-01 05:57:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][1100/1251]	eta 0:01:26 lr 0.000821	time 0.6286 (0.5706)	loss 3.4573 (3.4562)	grad_norm 1.1258 (1.3232)	mem 17417MB
[2023-02-01 05:57:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][1150/1251]	eta 0:00:57 lr 0.000821	time 0.5577 (0.5703)	loss 2.4556 (3.4578)	grad_norm 1.3338 (1.3255)	mem 17417MB
[2023-02-01 05:58:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][1200/1251]	eta 0:00:29 lr 0.000821	time 0.5615 (0.5702)	loss 2.9688 (3.4598)	grad_norm 1.3250 (1.3252)	mem 17417MB
[2023-02-01 05:58:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [83/300][1250/1251]	eta 0:00:00 lr 0.000821	time 0.5499 (0.5701)	loss 3.5328 (3.4590)	grad_norm 1.2732 (1.3254)	mem 17417MB
[2023-02-01 05:58:43 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 83 training takes 0:11:53
[2023-02-01 05:58:43 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_83.pth saving......
[2023-02-01 05:58:45 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_83.pth saved !!!
[2023-02-01 05:58:46 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.883 (0.883)	Loss 0.9534 (0.9534)	Acc@1 78.125 (78.125)	Acc@5 94.043 (94.043)	Mem 17417MB
[2023-02-01 05:58:54 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.822 Acc@5 93.848
[2023-02-01 05:58:54 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.8%
[2023-02-01 05:58:55 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.451 (1.451)	Loss 0.8229 (0.8229)	Acc@1 79.395 (79.395)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-01 05:59:03 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.402 Acc@5 95.062
[2023-02-01 05:59:03 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.4%
[2023-02-01 05:59:03 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.40% at 83 epoch
[2023-02-01 05:59:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][0/1251]	eta 0:33:52 lr 0.000821	time 1.6248 (1.6248)	loss 3.5801 (3.5801)	grad_norm 1.2542 (1.2542)	mem 17417MB
[2023-02-01 05:59:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][50/1251]	eta 0:11:51 lr 0.000820	time 0.5741 (0.5927)	loss 3.1696 (3.4219)	grad_norm 1.4196 (1.3002)	mem 17417MB
[2023-02-01 06:00:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][100/1251]	eta 0:11:07 lr 0.000820	time 0.5529 (0.5801)	loss 2.5326 (3.4200)	grad_norm 1.2456 (1.3094)	mem 17417MB
[2023-02-01 06:00:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][150/1251]	eta 0:10:34 lr 0.000820	time 0.5589 (0.5764)	loss 2.9168 (3.4477)	grad_norm 1.3377 (1.3193)	mem 17417MB
[2023-02-01 06:00:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][200/1251]	eta 0:10:03 lr 0.000820	time 0.5551 (0.5745)	loss 3.9700 (3.4443)	grad_norm 1.4073 (1.3301)	mem 17417MB
[2023-02-01 06:01:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][250/1251]	eta 0:09:33 lr 0.000820	time 0.5551 (0.5731)	loss 2.8314 (3.4163)	grad_norm 1.2371 (1.3259)	mem 17417MB
[2023-02-01 06:01:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][300/1251]	eta 0:09:04 lr 0.000820	time 0.5570 (0.5725)	loss 2.3504 (3.4127)	grad_norm 1.2943 (1.3288)	mem 17417MB
[2023-02-01 06:02:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][350/1251]	eta 0:08:35 lr 0.000819	time 0.5562 (0.5720)	loss 2.7525 (3.4250)	grad_norm 1.3385 (1.3306)	mem 17417MB
[2023-02-01 06:02:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][400/1251]	eta 0:08:06 lr 0.000819	time 0.5589 (0.5711)	loss 2.6265 (3.4372)	grad_norm 1.4125 (1.3294)	mem 17417MB
[2023-02-01 06:03:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][450/1251]	eta 0:07:37 lr 0.000819	time 0.5551 (0.5707)	loss 3.6570 (3.4441)	grad_norm 1.1128 (1.3303)	mem 17417MB
[2023-02-01 06:03:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][500/1251]	eta 0:07:08 lr 0.000819	time 0.5570 (0.5700)	loss 3.5621 (3.4513)	grad_norm 1.2955 (1.3308)	mem 17417MB
[2023-02-01 06:04:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][550/1251]	eta 0:06:39 lr 0.000819	time 0.5555 (0.5700)	loss 3.5318 (3.4506)	grad_norm 1.3148 (1.3307)	mem 17417MB
[2023-02-01 06:04:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][600/1251]	eta 0:06:11 lr 0.000819	time 0.5624 (0.5700)	loss 3.8640 (3.4446)	grad_norm 1.3772 (1.3307)	mem 17417MB
[2023-02-01 06:05:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][650/1251]	eta 0:05:42 lr 0.000818	time 0.5574 (0.5698)	loss 4.0562 (3.4430)	grad_norm 1.3934 (1.3316)	mem 17417MB
[2023-02-01 06:05:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][700/1251]	eta 0:05:13 lr 0.000818	time 0.5577 (0.5699)	loss 2.9786 (3.4557)	grad_norm 1.3585 (1.3313)	mem 17417MB
[2023-02-01 06:06:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][750/1251]	eta 0:04:45 lr 0.000818	time 0.5655 (0.5698)	loss 3.7013 (3.4586)	grad_norm 1.4353 (1.3304)	mem 17417MB
[2023-02-01 06:06:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][800/1251]	eta 0:04:16 lr 0.000818	time 0.6247 (0.5696)	loss 3.9452 (3.4614)	grad_norm 1.3225 (nan)	mem 17417MB
[2023-02-01 06:07:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][850/1251]	eta 0:03:48 lr 0.000818	time 0.5610 (0.5696)	loss 4.1819 (3.4679)	grad_norm 1.4264 (nan)	mem 17417MB
[2023-02-01 06:07:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][900/1251]	eta 0:03:19 lr 0.000818	time 0.5560 (0.5695)	loss 3.3359 (3.4680)	grad_norm 1.3606 (nan)	mem 17417MB
[2023-02-01 06:08:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][950/1251]	eta 0:02:51 lr 0.000817	time 0.5594 (0.5694)	loss 3.9704 (3.4686)	grad_norm 1.4096 (nan)	mem 17417MB
[2023-02-01 06:08:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][1000/1251]	eta 0:02:22 lr 0.000817	time 0.6195 (0.5694)	loss 2.9831 (3.4678)	grad_norm 1.3464 (nan)	mem 17417MB
[2023-02-01 06:09:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][1050/1251]	eta 0:01:54 lr 0.000817	time 0.5610 (0.5693)	loss 3.6152 (3.4673)	grad_norm 1.3292 (nan)	mem 17417MB
[2023-02-01 06:09:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][1100/1251]	eta 0:01:25 lr 0.000817	time 0.5619 (0.5694)	loss 2.6567 (3.4641)	grad_norm 1.3521 (nan)	mem 17417MB
[2023-02-01 06:09:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][1150/1251]	eta 0:00:57 lr 0.000817	time 0.5609 (0.5694)	loss 3.2973 (3.4625)	grad_norm 1.4309 (nan)	mem 17417MB
[2023-02-01 06:10:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][1200/1251]	eta 0:00:29 lr 0.000817	time 0.5509 (0.5693)	loss 4.3461 (3.4641)	grad_norm 1.3482 (nan)	mem 17417MB
[2023-02-01 06:10:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [84/300][1250/1251]	eta 0:00:00 lr 0.000817	time 0.6109 (0.5693)	loss 3.7582 (3.4647)	grad_norm 1.1781 (nan)	mem 17417MB
[2023-02-01 06:10:56 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 84 training takes 0:11:52
[2023-02-01 06:10:56 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_84.pth saving......
[2023-02-01 06:10:57 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_84.pth saved !!!
[2023-02-01 06:10:58 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.851 (0.851)	Loss 1.0298 (1.0298)	Acc@1 73.926 (73.926)	Acc@5 92.969 (92.969)	Mem 17417MB
[2023-02-01 06:11:06 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.926 Acc@5 93.830
[2023-02-01 06:11:06 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.9%
[2023-02-01 06:11:08 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.339 (1.339)	Loss 0.8848 (0.8848)	Acc@1 78.809 (78.809)	Acc@5 94.727 (94.727)	Mem 17417MB
[2023-02-01 06:11:15 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.450 Acc@5 95.084
[2023-02-01 06:11:15 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.4%
[2023-02-01 06:11:15 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.45% at 84 epoch
[2023-02-01 06:11:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][0/1251]	eta 0:37:29 lr 0.000817	time 1.7982 (1.7982)	loss 2.4671 (2.4671)	grad_norm 1.4229 (1.4229)	mem 17417MB
[2023-02-01 06:11:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][50/1251]	eta 0:11:48 lr 0.000816	time 0.5813 (0.5898)	loss 4.5116 (3.4777)	grad_norm 1.3467 (1.3139)	mem 17417MB
[2023-02-01 06:12:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][100/1251]	eta 0:11:07 lr 0.000816	time 0.5513 (0.5802)	loss 2.2822 (3.4466)	grad_norm 1.3075 (1.3279)	mem 17417MB
[2023-02-01 06:12:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][150/1251]	eta 0:10:34 lr 0.000816	time 0.5590 (0.5763)	loss 3.5107 (3.4117)	grad_norm 1.4103 (1.3243)	mem 17417MB
[2023-02-01 06:13:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][200/1251]	eta 0:10:03 lr 0.000816	time 0.5552 (0.5745)	loss 3.9124 (3.4271)	grad_norm 1.4039 (1.3273)	mem 17417MB
[2023-02-01 06:13:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][250/1251]	eta 0:09:34 lr 0.000816	time 0.5563 (0.5736)	loss 3.7220 (3.4134)	grad_norm 1.2182 (1.3313)	mem 17417MB
[2023-02-01 06:14:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][300/1251]	eta 0:09:05 lr 0.000816	time 0.6410 (0.5735)	loss 3.8744 (3.4341)	grad_norm 1.4408 (1.3348)	mem 17417MB
[2023-02-01 06:14:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][350/1251]	eta 0:08:35 lr 0.000815	time 0.5539 (0.5723)	loss 3.8453 (3.4407)	grad_norm 1.2508 (1.3371)	mem 17417MB
[2023-02-01 06:15:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][400/1251]	eta 0:08:06 lr 0.000815	time 0.6457 (0.5721)	loss 3.6113 (3.4375)	grad_norm 1.3532 (1.3346)	mem 17417MB
[2023-02-01 06:15:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][450/1251]	eta 0:07:37 lr 0.000815	time 0.5563 (0.5713)	loss 3.4703 (3.4361)	grad_norm 1.3185 (1.3332)	mem 17417MB
[2023-02-01 06:16:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][500/1251]	eta 0:07:09 lr 0.000815	time 0.5644 (0.5713)	loss 3.1885 (3.4297)	grad_norm 1.2156 (1.3357)	mem 17417MB
[2023-02-01 06:16:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][550/1251]	eta 0:06:40 lr 0.000815	time 0.5560 (0.5715)	loss 3.6219 (3.4283)	grad_norm 1.4648 (1.3380)	mem 17417MB
[2023-02-01 06:16:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][600/1251]	eta 0:06:12 lr 0.000815	time 0.5566 (0.5715)	loss 2.8417 (3.4388)	grad_norm 1.3529 (1.3378)	mem 17417MB
[2023-02-01 06:17:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][650/1251]	eta 0:05:43 lr 0.000814	time 0.5633 (0.5712)	loss 3.4554 (3.4447)	grad_norm 1.4230 (1.3368)	mem 17417MB
[2023-02-01 06:17:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][700/1251]	eta 0:05:14 lr 0.000814	time 0.5513 (0.5711)	loss 4.2162 (3.4462)	grad_norm 1.4499 (1.3371)	mem 17417MB
[2023-02-01 06:18:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][750/1251]	eta 0:04:45 lr 0.000814	time 0.5632 (0.5705)	loss 3.5439 (3.4449)	grad_norm 1.2720 (1.3352)	mem 17417MB
[2023-02-01 06:18:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][800/1251]	eta 0:04:17 lr 0.000814	time 0.5738 (0.5707)	loss 3.9348 (3.4406)	grad_norm 1.2312 (1.3332)	mem 17417MB
[2023-02-01 06:19:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][850/1251]	eta 0:03:48 lr 0.000814	time 0.5556 (0.5703)	loss 3.5956 (3.4364)	grad_norm 1.1723 (1.3342)	mem 17417MB
[2023-02-01 06:19:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][900/1251]	eta 0:03:20 lr 0.000814	time 0.5571 (0.5705)	loss 3.7791 (3.4367)	grad_norm 1.2370 (1.3345)	mem 17417MB
[2023-02-01 06:20:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][950/1251]	eta 0:02:51 lr 0.000813	time 0.5554 (0.5705)	loss 3.6137 (3.4408)	grad_norm 1.4988 (1.3327)	mem 17417MB
[2023-02-01 06:20:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][1000/1251]	eta 0:02:23 lr 0.000813	time 0.6250 (0.5705)	loss 3.0054 (3.4405)	grad_norm 1.3063 (1.3309)	mem 17417MB
[2023-02-01 06:21:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][1050/1251]	eta 0:01:54 lr 0.000813	time 0.5543 (0.5704)	loss 4.0976 (3.4413)	grad_norm 1.2357 (1.3313)	mem 17417MB
[2023-02-01 06:21:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][1100/1251]	eta 0:01:26 lr 0.000813	time 0.5528 (0.5704)	loss 3.9562 (3.4416)	grad_norm 1.2144 (1.3322)	mem 17417MB
[2023-02-01 06:22:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][1150/1251]	eta 0:00:57 lr 0.000813	time 0.5505 (0.5702)	loss 4.3415 (3.4484)	grad_norm 1.5118 (1.3318)	mem 17417MB
[2023-02-01 06:22:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][1200/1251]	eta 0:00:29 lr 0.000813	time 0.5587 (0.5703)	loss 3.9054 (3.4453)	grad_norm 1.1945 (1.3320)	mem 17417MB
[2023-02-01 06:23:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [85/300][1250/1251]	eta 0:00:00 lr 0.000812	time 0.6132 (0.5701)	loss 3.6885 (3.4478)	grad_norm 1.3890 (1.3322)	mem 17417MB
[2023-02-01 06:23:09 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 85 training takes 0:11:53
[2023-02-01 06:23:09 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_85.pth saving......
[2023-02-01 06:23:11 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_85.pth saved !!!
[2023-02-01 06:23:12 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.893 (0.893)	Loss 0.9896 (0.9896)	Acc@1 76.562 (76.562)	Acc@5 93.750 (93.750)	Mem 17417MB
[2023-02-01 06:23:20 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.950 Acc@5 93.880
[2023-02-01 06:23:20 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.0%
[2023-02-01 06:23:21 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.283 (1.283)	Loss 0.8709 (0.8709)	Acc@1 79.980 (79.980)	Acc@5 95.996 (95.996)	Mem 17417MB
[2023-02-01 06:23:29 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.506 Acc@5 95.126
[2023-02-01 06:23:29 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.5%
[2023-02-01 06:23:29 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.51% at 85 epoch
[2023-02-01 06:23:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][0/1251]	eta 0:34:41 lr 0.000812	time 1.6638 (1.6638)	loss 3.7013 (3.7013)	grad_norm 1.4655 (1.4655)	mem 17417MB
[2023-02-01 06:23:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][50/1251]	eta 0:11:47 lr 0.000812	time 0.5529 (0.5890)	loss 2.2910 (3.5322)	grad_norm 1.2439 (1.3405)	mem 17417MB
[2023-02-01 06:24:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][100/1251]	eta 0:11:10 lr 0.000812	time 0.5574 (0.5827)	loss 4.0948 (3.5071)	grad_norm 1.3265 (1.3479)	mem 17417MB
[2023-02-01 06:24:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][150/1251]	eta 0:10:34 lr 0.000812	time 0.5724 (0.5760)	loss 2.6483 (3.4799)	grad_norm 1.2365 (1.3355)	mem 17417MB
[2023-02-01 06:25:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][200/1251]	eta 0:10:04 lr 0.000812	time 0.5514 (0.5749)	loss 3.7614 (3.4887)	grad_norm 1.2817 (1.3278)	mem 17417MB
[2023-02-01 06:25:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][250/1251]	eta 0:09:33 lr 0.000812	time 0.6194 (0.5729)	loss 3.5028 (3.5113)	grad_norm 1.2079 (1.3256)	mem 17417MB
[2023-02-01 06:26:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][300/1251]	eta 0:09:04 lr 0.000811	time 0.5655 (0.5725)	loss 3.5903 (3.5329)	grad_norm 1.4840 (1.3270)	mem 17417MB
[2023-02-01 06:26:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][350/1251]	eta 0:08:35 lr 0.000811	time 0.5623 (0.5720)	loss 3.3958 (3.5130)	grad_norm 1.3094 (1.3266)	mem 17417MB
[2023-02-01 06:27:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][400/1251]	eta 0:08:06 lr 0.000811	time 0.6407 (0.5718)	loss 3.4952 (3.5034)	grad_norm 1.3074 (1.3233)	mem 17417MB
[2023-02-01 06:27:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][450/1251]	eta 0:07:37 lr 0.000811	time 0.5540 (0.5712)	loss 4.2898 (3.4957)	grad_norm 1.3842 (1.3256)	mem 17417MB
[2023-02-01 06:28:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][500/1251]	eta 0:07:08 lr 0.000811	time 0.5540 (0.5710)	loss 3.9780 (3.4805)	grad_norm 1.3242 (1.3271)	mem 17417MB
[2023-02-01 06:28:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][550/1251]	eta 0:06:39 lr 0.000811	time 0.5556 (0.5704)	loss 2.5513 (3.4748)	grad_norm 1.2617 (1.3314)	mem 17417MB
[2023-02-01 06:29:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][600/1251]	eta 0:06:11 lr 0.000811	time 0.5571 (0.5704)	loss 4.4705 (3.4733)	grad_norm 1.2004 (1.3306)	mem 17417MB
[2023-02-01 06:29:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][650/1251]	eta 0:05:42 lr 0.000810	time 0.5572 (0.5704)	loss 4.0705 (3.4813)	grad_norm 1.4710 (1.3317)	mem 17417MB
[2023-02-01 06:30:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][700/1251]	eta 0:05:14 lr 0.000810	time 0.5557 (0.5704)	loss 2.7672 (3.4738)	grad_norm 1.2663 (1.3332)	mem 17417MB
[2023-02-01 06:30:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][750/1251]	eta 0:04:45 lr 0.000810	time 0.6244 (0.5702)	loss 2.3203 (3.4725)	grad_norm 1.3472 (1.3330)	mem 17417MB
[2023-02-01 06:31:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][800/1251]	eta 0:04:17 lr 0.000810	time 0.5567 (0.5700)	loss 4.2558 (3.4737)	grad_norm 1.4647 (1.3336)	mem 17417MB
[2023-02-01 06:31:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][850/1251]	eta 0:03:48 lr 0.000810	time 0.5602 (0.5699)	loss 3.6565 (3.4774)	grad_norm 1.5197 (1.3335)	mem 17417MB
[2023-02-01 06:32:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][900/1251]	eta 0:03:20 lr 0.000810	time 0.5587 (0.5700)	loss 4.2724 (3.4745)	grad_norm 1.3852 (1.3344)	mem 17417MB
[2023-02-01 06:32:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][950/1251]	eta 0:02:51 lr 0.000809	time 0.5536 (0.5699)	loss 3.7045 (3.4729)	grad_norm 1.4344 (1.3336)	mem 17417MB
[2023-02-01 06:33:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][1000/1251]	eta 0:02:23 lr 0.000809	time 0.5535 (0.5699)	loss 3.9615 (3.4647)	grad_norm 1.4176 (1.3346)	mem 17417MB
[2023-02-01 06:33:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][1050/1251]	eta 0:01:54 lr 0.000809	time 0.5561 (0.5698)	loss 2.9805 (3.4591)	grad_norm 1.2576 (1.3351)	mem 17417MB
[2023-02-01 06:33:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][1100/1251]	eta 0:01:26 lr 0.000809	time 0.6272 (0.5698)	loss 3.5542 (3.4601)	grad_norm 1.1615 (1.3346)	mem 17417MB
[2023-02-01 06:34:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][1150/1251]	eta 0:00:57 lr 0.000809	time 0.5625 (0.5698)	loss 4.0890 (3.4655)	grad_norm 1.3894 (1.3343)	mem 17417MB
[2023-02-01 06:34:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][1200/1251]	eta 0:00:29 lr 0.000809	time 0.5489 (0.5697)	loss 3.9126 (3.4594)	grad_norm 1.3014 (1.3339)	mem 17417MB
[2023-02-01 06:35:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [86/300][1250/1251]	eta 0:00:00 lr 0.000808	time 0.5513 (0.5697)	loss 3.3934 (3.4621)	grad_norm 1.2874 (1.3328)	mem 17417MB
[2023-02-01 06:35:22 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 86 training takes 0:11:52
[2023-02-01 06:35:22 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_86.pth saving......
[2023-02-01 06:35:24 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_86.pth saved !!!
[2023-02-01 06:35:25 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.844 (0.844)	Loss 1.0310 (1.0310)	Acc@1 77.148 (77.148)	Acc@5 93.555 (93.555)	Mem 17417MB
[2023-02-01 06:35:33 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 76.944 Acc@5 93.912
[2023-02-01 06:35:33 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 76.9%
[2023-02-01 06:35:34 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.279 (1.279)	Loss 0.8793 (0.8793)	Acc@1 78.516 (78.516)	Acc@5 94.238 (94.238)	Mem 17417MB
[2023-02-01 06:35:42 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.562 Acc@5 95.166
[2023-02-01 06:35:42 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.6%
[2023-02-01 06:35:42 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.56% at 86 epoch
[2023-02-01 06:35:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][0/1251]	eta 0:34:34 lr 0.000808	time 1.6585 (1.6585)	loss 3.5632 (3.5632)	grad_norm 1.2210 (1.2210)	mem 17417MB
[2023-02-01 06:36:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][50/1251]	eta 0:11:48 lr 0.000808	time 0.5539 (0.5900)	loss 3.3224 (3.4091)	grad_norm 1.1366 (1.3334)	mem 17417MB
[2023-02-01 06:36:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][100/1251]	eta 0:11:07 lr 0.000808	time 0.5571 (0.5801)	loss 3.9336 (3.4483)	grad_norm 1.3550 (1.3269)	mem 17417MB
[2023-02-01 06:37:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][150/1251]	eta 0:10:34 lr 0.000808	time 0.5533 (0.5767)	loss 3.7590 (3.3695)	grad_norm 1.2888 (1.3192)	mem 17417MB
[2023-02-01 06:37:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][200/1251]	eta 0:10:02 lr 0.000808	time 0.5612 (0.5735)	loss 2.8537 (3.3604)	grad_norm 1.3111 (1.3293)	mem 17417MB
[2023-02-01 06:38:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][250/1251]	eta 0:09:33 lr 0.000808	time 0.5574 (0.5728)	loss 2.9121 (3.3802)	grad_norm 1.4557 (1.3352)	mem 17417MB
[2023-02-01 06:38:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][300/1251]	eta 0:09:04 lr 0.000807	time 0.6462 (0.5723)	loss 3.4789 (3.3928)	grad_norm 1.4626 (1.3371)	mem 17417MB
[2023-02-01 06:39:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][350/1251]	eta 0:08:35 lr 0.000807	time 0.5570 (0.5718)	loss 2.7002 (3.3898)	grad_norm 1.3617 (1.3352)	mem 17417MB
[2023-02-01 06:39:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][400/1251]	eta 0:08:05 lr 0.000807	time 0.5578 (0.5710)	loss 2.4705 (3.3947)	grad_norm 1.4568 (1.3386)	mem 17417MB
[2023-02-01 06:39:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][450/1251]	eta 0:07:37 lr 0.000807	time 0.5541 (0.5706)	loss 3.7879 (3.3936)	grad_norm 1.2355 (1.3376)	mem 17417MB
[2023-02-01 06:40:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][500/1251]	eta 0:07:08 lr 0.000807	time 0.5533 (0.5702)	loss 3.7573 (3.4064)	grad_norm 1.2893 (1.3376)	mem 17417MB
[2023-02-01 06:40:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][550/1251]	eta 0:06:39 lr 0.000807	time 0.5587 (0.5702)	loss 2.8814 (3.4058)	grad_norm 1.2459 (1.3376)	mem 17417MB
[2023-02-01 06:41:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][600/1251]	eta 0:06:11 lr 0.000806	time 0.5634 (0.5702)	loss 3.5195 (3.4125)	grad_norm 1.2100 (1.3340)	mem 17417MB
[2023-02-01 06:41:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][650/1251]	eta 0:05:42 lr 0.000806	time 0.5555 (0.5703)	loss 4.0454 (3.4204)	grad_norm 1.4413 (1.3348)	mem 17417MB
[2023-02-01 06:42:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][700/1251]	eta 0:05:14 lr 0.000806	time 0.5536 (0.5702)	loss 2.5078 (3.4159)	grad_norm 1.3330 (1.3344)	mem 17417MB
[2023-02-01 06:42:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][750/1251]	eta 0:04:45 lr 0.000806	time 0.5541 (0.5699)	loss 2.9892 (3.4179)	grad_norm 1.2349 (1.3344)	mem 17417MB
[2023-02-01 06:43:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][800/1251]	eta 0:04:16 lr 0.000806	time 0.5556 (0.5698)	loss 3.4359 (3.4175)	grad_norm 1.4676 (1.3345)	mem 17417MB
[2023-02-01 06:43:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][850/1251]	eta 0:03:48 lr 0.000806	time 0.5565 (0.5698)	loss 2.8819 (3.4118)	grad_norm 1.2621 (1.3378)	mem 17417MB
[2023-02-01 06:44:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][900/1251]	eta 0:03:20 lr 0.000805	time 0.5596 (0.5698)	loss 3.3166 (3.4126)	grad_norm 1.2717 (1.3380)	mem 17417MB
[2023-02-01 06:44:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][950/1251]	eta 0:02:51 lr 0.000805	time 0.5485 (0.5698)	loss 3.4248 (3.4145)	grad_norm 1.2337 (1.3370)	mem 17417MB
[2023-02-01 06:45:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][1000/1251]	eta 0:02:23 lr 0.000805	time 0.6162 (0.5698)	loss 2.3856 (3.4131)	grad_norm 1.2266 (1.3355)	mem 17417MB
[2023-02-01 06:45:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][1050/1251]	eta 0:01:54 lr 0.000805	time 0.5628 (0.5698)	loss 3.3622 (3.4172)	grad_norm 1.2113 (nan)	mem 17417MB
[2023-02-01 06:46:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][1100/1251]	eta 0:01:26 lr 0.000805	time 0.5568 (0.5700)	loss 3.6978 (3.4225)	grad_norm 1.4051 (nan)	mem 17417MB
[2023-02-01 06:46:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][1150/1251]	eta 0:00:57 lr 0.000805	time 0.5633 (0.5696)	loss 3.6058 (3.4251)	grad_norm 1.3200 (nan)	mem 17417MB
[2023-02-01 06:47:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][1200/1251]	eta 0:00:29 lr 0.000804	time 0.5612 (0.5699)	loss 3.8211 (3.4247)	grad_norm 1.5709 (nan)	mem 17417MB
[2023-02-01 06:47:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [87/300][1250/1251]	eta 0:00:00 lr 0.000804	time 0.6178 (0.5698)	loss 2.8573 (3.4250)	grad_norm 1.3397 (nan)	mem 17417MB
[2023-02-01 06:47:35 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 87 training takes 0:11:52
[2023-02-01 06:47:35 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_87.pth saving......
[2023-02-01 06:47:37 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_87.pth saved !!!
[2023-02-01 06:47:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.876 (0.876)	Loss 0.9240 (0.9240)	Acc@1 78.418 (78.418)	Acc@5 94.922 (94.922)	Mem 17417MB
[2023-02-01 06:47:46 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.136 Acc@5 94.026
[2023-02-01 06:47:46 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.1%
[2023-02-01 06:47:47 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.197 (1.197)	Loss 0.8917 (0.8917)	Acc@1 77.539 (77.539)	Acc@5 95.898 (95.898)	Mem 17417MB
[2023-02-01 06:47:55 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.594 Acc@5 95.166
[2023-02-01 06:47:55 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.6%
[2023-02-01 06:47:55 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.59% at 87 epoch
[2023-02-01 06:47:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][0/1251]	eta 0:36:55 lr 0.000804	time 1.7712 (1.7712)	loss 3.7863 (3.7863)	grad_norm 1.2577 (1.2577)	mem 17417MB
[2023-02-01 06:48:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][50/1251]	eta 0:11:46 lr 0.000804	time 0.5587 (0.5884)	loss 2.4653 (3.4125)	grad_norm 1.4068 (1.3728)	mem 17417MB
[2023-02-01 06:48:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][100/1251]	eta 0:11:10 lr 0.000804	time 0.6178 (0.5822)	loss 4.0678 (3.3996)	grad_norm 1.3548 (1.3384)	mem 17417MB
[2023-02-01 06:49:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][150/1251]	eta 0:10:34 lr 0.000804	time 0.5625 (0.5760)	loss 4.1298 (3.4277)	grad_norm 1.4089 (1.3395)	mem 17417MB
[2023-02-01 06:49:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][200/1251]	eta 0:10:04 lr 0.000804	time 0.5542 (0.5748)	loss 4.2168 (3.4207)	grad_norm 1.3305 (1.3418)	mem 17417MB
[2023-02-01 06:50:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][250/1251]	eta 0:09:33 lr 0.000803	time 0.6375 (0.5731)	loss 3.5946 (3.4201)	grad_norm 1.2504 (1.3443)	mem 17417MB
[2023-02-01 06:50:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][300/1251]	eta 0:09:03 lr 0.000803	time 0.5648 (0.5718)	loss 3.9255 (3.4301)	grad_norm 1.5202 (1.3406)	mem 17417MB
[2023-02-01 06:51:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][350/1251]	eta 0:08:34 lr 0.000803	time 0.5607 (0.5711)	loss 2.4771 (3.4180)	grad_norm 1.3576 (1.3366)	mem 17417MB
[2023-02-01 06:51:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][400/1251]	eta 0:08:06 lr 0.000803	time 0.6266 (0.5711)	loss 3.3740 (3.4156)	grad_norm 1.4345 (1.3404)	mem 17417MB
[2023-02-01 06:52:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][450/1251]	eta 0:07:36 lr 0.000803	time 0.5549 (0.5704)	loss 4.0070 (3.4355)	grad_norm 1.4273 (1.3382)	mem 17417MB
[2023-02-01 06:52:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][500/1251]	eta 0:07:08 lr 0.000803	time 0.6193 (0.5703)	loss 2.4381 (3.4321)	grad_norm 1.1030 (1.3402)	mem 17417MB
[2023-02-01 06:53:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][550/1251]	eta 0:06:39 lr 0.000802	time 0.5559 (0.5697)	loss 3.3031 (3.4290)	grad_norm 1.1892 (1.3399)	mem 17417MB
[2023-02-01 06:53:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][600/1251]	eta 0:06:10 lr 0.000802	time 0.5659 (0.5697)	loss 3.8759 (3.4314)	grad_norm 1.3759 (1.3405)	mem 17417MB
[2023-02-01 06:54:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][650/1251]	eta 0:05:42 lr 0.000802	time 0.5560 (0.5696)	loss 3.6088 (3.4197)	grad_norm 1.2978 (1.3428)	mem 17417MB
[2023-02-01 06:54:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][700/1251]	eta 0:05:13 lr 0.000802	time 0.5567 (0.5692)	loss 4.0178 (3.4258)	grad_norm 1.3058 (1.3415)	mem 17417MB
[2023-02-01 06:55:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][750/1251]	eta 0:04:45 lr 0.000802	time 0.5600 (0.5693)	loss 2.2278 (3.4216)	grad_norm 1.4435 (1.3420)	mem 17417MB
[2023-02-01 06:55:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][800/1251]	eta 0:04:16 lr 0.000802	time 0.5555 (0.5690)	loss 2.1150 (3.4261)	grad_norm 1.3577 (1.3430)	mem 17417MB
[2023-02-01 06:55:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][850/1251]	eta 0:03:48 lr 0.000801	time 0.5613 (0.5689)	loss 3.8287 (3.4279)	grad_norm 1.3354 (1.3417)	mem 17417MB
[2023-02-01 06:56:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][900/1251]	eta 0:03:19 lr 0.000801	time 0.6240 (0.5690)	loss 2.9906 (3.4340)	grad_norm 1.4293 (1.3415)	mem 17417MB
[2023-02-01 06:56:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][950/1251]	eta 0:02:51 lr 0.000801	time 0.5554 (0.5689)	loss 3.4979 (3.4391)	grad_norm 1.3914 (1.3412)	mem 17417MB
[2023-02-01 06:57:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][1000/1251]	eta 0:02:22 lr 0.000801	time 0.5607 (0.5689)	loss 3.5565 (3.4474)	grad_norm 1.4770 (1.3422)	mem 17417MB
[2023-02-01 06:57:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][1050/1251]	eta 0:01:54 lr 0.000801	time 0.5565 (0.5688)	loss 3.2858 (3.4501)	grad_norm 1.5802 (1.3435)	mem 17417MB
[2023-02-01 06:58:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][1100/1251]	eta 0:01:25 lr 0.000801	time 0.5658 (0.5687)	loss 3.2299 (3.4533)	grad_norm 1.3104 (1.3426)	mem 17417MB
[2023-02-01 06:58:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][1150/1251]	eta 0:00:57 lr 0.000800	time 0.5635 (0.5688)	loss 3.5579 (3.4553)	grad_norm 1.3128 (1.3420)	mem 17417MB
[2023-02-01 06:59:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][1200/1251]	eta 0:00:29 lr 0.000800	time 0.6278 (0.5688)	loss 3.9445 (3.4517)	grad_norm 1.3816 (1.3423)	mem 17417MB
[2023-02-01 06:59:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [88/300][1250/1251]	eta 0:00:00 lr 0.000800	time 0.5502 (0.5687)	loss 3.6206 (3.4471)	grad_norm 1.1715 (1.3418)	mem 17417MB
[2023-02-01 06:59:47 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 88 training takes 0:11:51
[2023-02-01 06:59:47 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_88.pth saving......
[2023-02-01 06:59:49 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_88.pth saved !!!
[2023-02-01 06:59:49 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.865 (0.865)	Loss 0.9505 (0.9505)	Acc@1 78.125 (78.125)	Acc@5 93.750 (93.750)	Mem 17417MB
[2023-02-01 06:59:57 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.016 Acc@5 94.026
[2023-02-01 06:59:57 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.0%
[2023-02-01 06:59:59 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.241 (1.241)	Loss 0.8313 (0.8313)	Acc@1 80.469 (80.469)	Acc@5 95.801 (95.801)	Mem 17417MB
[2023-02-01 07:00:07 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.646 Acc@5 95.168
[2023-02-01 07:00:07 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.6%
[2023-02-01 07:00:07 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.65% at 88 epoch
[2023-02-01 07:00:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][0/1251]	eta 0:36:42 lr 0.000800	time 1.7605 (1.7605)	loss 3.3934 (3.3934)	grad_norm 1.3246 (1.3246)	mem 17417MB
[2023-02-01 07:00:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][50/1251]	eta 0:11:57 lr 0.000800	time 0.5658 (0.5975)	loss 3.9816 (3.4202)	grad_norm 1.4883 (1.3322)	mem 17417MB
[2023-02-01 07:01:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][100/1251]	eta 0:11:12 lr 0.000800	time 0.6312 (0.5841)	loss 3.1667 (3.3437)	grad_norm 1.2010 (1.3304)	mem 17417MB
[2023-02-01 07:01:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][150/1251]	eta 0:10:37 lr 0.000800	time 0.5565 (0.5792)	loss 3.4662 (3.3751)	grad_norm 1.6170 (1.3371)	mem 17417MB
[2023-02-01 07:02:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][200/1251]	eta 0:10:06 lr 0.000799	time 0.5611 (0.5772)	loss 3.9336 (3.3971)	grad_norm 1.3354 (1.3375)	mem 17417MB
[2023-02-01 07:02:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][250/1251]	eta 0:09:36 lr 0.000799	time 0.5554 (0.5756)	loss 3.4110 (3.4210)	grad_norm 1.2250 (1.3332)	mem 17417MB
[2023-02-01 07:03:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][300/1251]	eta 0:09:06 lr 0.000799	time 0.5589 (0.5746)	loss 4.0440 (3.4314)	grad_norm 1.4272 (nan)	mem 17417MB
[2023-02-01 07:03:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][350/1251]	eta 0:08:37 lr 0.000799	time 0.5534 (0.5738)	loss 3.6160 (3.4293)	grad_norm 1.3222 (nan)	mem 17417MB
[2023-02-01 07:03:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][400/1251]	eta 0:08:07 lr 0.000799	time 0.5540 (0.5726)	loss 3.5021 (3.4193)	grad_norm 1.2612 (nan)	mem 17417MB
[2023-02-01 07:04:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][450/1251]	eta 0:07:38 lr 0.000799	time 0.6170 (0.5729)	loss 4.2617 (3.4191)	grad_norm 1.2426 (nan)	mem 17417MB
[2023-02-01 07:04:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][500/1251]	eta 0:07:09 lr 0.000798	time 0.6178 (0.5720)	loss 3.7991 (3.4209)	grad_norm 1.3855 (nan)	mem 17417MB
[2023-02-01 07:05:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][550/1251]	eta 0:06:40 lr 0.000798	time 0.5512 (0.5720)	loss 3.5305 (3.4150)	grad_norm 1.1973 (nan)	mem 17417MB
[2023-02-01 07:05:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][600/1251]	eta 0:06:12 lr 0.000798	time 0.5525 (0.5719)	loss 3.9899 (3.4203)	grad_norm 1.3867 (nan)	mem 17417MB
[2023-02-01 07:06:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][650/1251]	eta 0:05:43 lr 0.000798	time 0.5563 (0.5717)	loss 2.8012 (3.4187)	grad_norm 1.6938 (nan)	mem 17417MB
[2023-02-01 07:06:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][700/1251]	eta 0:05:14 lr 0.000798	time 0.5920 (0.5715)	loss 3.5161 (3.4299)	grad_norm 1.2189 (nan)	mem 17417MB
[2023-02-01 07:07:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][750/1251]	eta 0:04:46 lr 0.000798	time 0.5592 (0.5711)	loss 2.2785 (3.4306)	grad_norm 1.4478 (nan)	mem 17417MB
[2023-02-01 07:07:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][800/1251]	eta 0:04:17 lr 0.000797	time 0.5585 (0.5710)	loss 3.1433 (3.4374)	grad_norm 1.2023 (nan)	mem 17417MB
[2023-02-01 07:08:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][850/1251]	eta 0:03:48 lr 0.000797	time 0.5606 (0.5711)	loss 3.3858 (3.4405)	grad_norm 1.1764 (nan)	mem 17417MB
[2023-02-01 07:08:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][900/1251]	eta 0:03:20 lr 0.000797	time 0.6223 (0.5710)	loss 3.6037 (3.4415)	grad_norm 1.3182 (nan)	mem 17417MB
[2023-02-01 07:09:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][950/1251]	eta 0:02:51 lr 0.000797	time 0.5595 (0.5709)	loss 2.5579 (3.4494)	grad_norm 1.4098 (nan)	mem 17417MB
[2023-02-01 07:09:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][1000/1251]	eta 0:02:23 lr 0.000797	time 0.5651 (0.5708)	loss 3.0378 (3.4435)	grad_norm 1.3224 (nan)	mem 17417MB
[2023-02-01 07:10:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][1050/1251]	eta 0:01:54 lr 0.000797	time 0.5740 (0.5707)	loss 3.5797 (3.4464)	grad_norm 1.3126 (nan)	mem 17417MB
[2023-02-01 07:10:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][1100/1251]	eta 0:01:26 lr 0.000796	time 0.5634 (0.5706)	loss 4.1261 (3.4486)	grad_norm 1.2968 (nan)	mem 17417MB
[2023-02-01 07:11:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][1150/1251]	eta 0:00:57 lr 0.000796	time 0.5516 (0.5705)	loss 2.9255 (3.4421)	grad_norm 1.2002 (nan)	mem 17417MB
[2023-02-01 07:11:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][1200/1251]	eta 0:00:29 lr 0.000796	time 0.5575 (0.5704)	loss 3.6794 (3.4390)	grad_norm 1.3180 (nan)	mem 17417MB
[2023-02-01 07:12:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [89/300][1250/1251]	eta 0:00:00 lr 0.000796	time 0.5506 (0.5704)	loss 3.2394 (3.4351)	grad_norm 1.2521 (nan)	mem 17417MB
[2023-02-01 07:12:00 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 89 training takes 0:11:53
[2023-02-01 07:12:00 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_89.pth saving......
[2023-02-01 07:12:02 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_89.pth saved !!!
[2023-02-01 07:12:03 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.913 (0.913)	Loss 0.9663 (0.9663)	Acc@1 78.418 (78.418)	Acc@5 94.336 (94.336)	Mem 17417MB
[2023-02-01 07:12:11 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.372 Acc@5 94.070
[2023-02-01 07:12:11 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.4%
[2023-02-01 07:12:12 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.205 (1.205)	Loss 0.8573 (0.8573)	Acc@1 79.395 (79.395)	Acc@5 95.020 (95.020)	Mem 17417MB
[2023-02-01 07:12:20 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.720 Acc@5 95.190
[2023-02-01 07:12:20 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.7%
[2023-02-01 07:12:20 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.72% at 89 epoch
[2023-02-01 07:12:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][0/1251]	eta 0:34:41 lr 0.000796	time 1.6638 (1.6638)	loss 4.1348 (4.1348)	grad_norm 1.3004 (1.3004)	mem 17417MB
[2023-02-01 07:12:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][50/1251]	eta 0:11:45 lr 0.000796	time 0.5525 (0.5878)	loss 3.0088 (3.4845)	grad_norm 1.1845 (1.3429)	mem 17417MB
[2023-02-01 07:13:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][100/1251]	eta 0:11:07 lr 0.000796	time 0.6432 (0.5798)	loss 4.1231 (3.4941)	grad_norm 1.3527 (1.3435)	mem 17417MB
[2023-02-01 07:13:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][150/1251]	eta 0:10:33 lr 0.000795	time 0.5504 (0.5758)	loss 3.1789 (3.4259)	grad_norm 1.3448 (1.3440)	mem 17417MB
[2023-02-01 07:14:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][200/1251]	eta 0:10:03 lr 0.000795	time 0.5543 (0.5739)	loss 3.3841 (3.4122)	grad_norm 1.3332 (1.3433)	mem 17417MB
[2023-02-01 07:14:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][250/1251]	eta 0:09:33 lr 0.000795	time 0.5554 (0.5730)	loss 4.1602 (3.4067)	grad_norm 1.4858 (1.3396)	mem 17417MB
[2023-02-01 07:15:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][300/1251]	eta 0:09:03 lr 0.000795	time 0.5538 (0.5719)	loss 3.7276 (3.4149)	grad_norm 1.3442 (1.3390)	mem 17417MB
[2023-02-01 07:15:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][350/1251]	eta 0:08:34 lr 0.000795	time 0.5524 (0.5714)	loss 3.5366 (3.4193)	grad_norm 1.2510 (1.3399)	mem 17417MB
[2023-02-01 07:16:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][400/1251]	eta 0:08:06 lr 0.000795	time 0.5759 (0.5711)	loss 2.5006 (3.4184)	grad_norm 1.3611 (1.3390)	mem 17417MB
[2023-02-01 07:16:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][450/1251]	eta 0:07:37 lr 0.000794	time 0.6201 (0.5706)	loss 3.3899 (3.4296)	grad_norm 1.5516 (1.3413)	mem 17417MB
[2023-02-01 07:17:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][500/1251]	eta 0:07:08 lr 0.000794	time 0.5571 (0.5703)	loss 3.5879 (3.4265)	grad_norm 2.2877 (1.3413)	mem 17417MB
[2023-02-01 07:17:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][550/1251]	eta 0:06:39 lr 0.000794	time 0.5516 (0.5700)	loss 4.2413 (3.4252)	grad_norm 1.4235 (1.3411)	mem 17417MB
[2023-02-01 07:18:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][600/1251]	eta 0:06:11 lr 0.000794	time 0.5573 (0.5699)	loss 3.3606 (3.4221)	grad_norm 1.1980 (1.3407)	mem 17417MB
[2023-02-01 07:18:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][650/1251]	eta 0:05:42 lr 0.000794	time 0.5607 (0.5698)	loss 3.4313 (3.4260)	grad_norm 1.5074 (1.3382)	mem 17417MB
[2023-02-01 07:19:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][700/1251]	eta 0:05:13 lr 0.000794	time 0.5586 (0.5698)	loss 3.6591 (3.4258)	grad_norm 1.5669 (1.3413)	mem 17417MB
[2023-02-01 07:19:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][750/1251]	eta 0:04:45 lr 0.000793	time 0.5676 (0.5696)	loss 3.9024 (3.4282)	grad_norm 1.3650 (1.3423)	mem 17417MB
[2023-02-01 07:19:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][800/1251]	eta 0:04:16 lr 0.000793	time 0.6186 (0.5696)	loss 3.9578 (3.4218)	grad_norm 1.3008 (1.3397)	mem 17417MB
[2023-02-01 07:20:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][850/1251]	eta 0:03:48 lr 0.000793	time 0.5570 (0.5693)	loss 3.1384 (3.4236)	grad_norm 1.2693 (1.3421)	mem 17417MB
[2023-02-01 07:20:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][900/1251]	eta 0:03:19 lr 0.000793	time 0.5587 (0.5694)	loss 3.3493 (3.4237)	grad_norm 1.4060 (1.3439)	mem 17417MB
[2023-02-01 07:21:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][950/1251]	eta 0:02:51 lr 0.000793	time 0.5558 (0.5693)	loss 2.9902 (3.4210)	grad_norm 1.2593 (1.3447)	mem 17417MB
[2023-02-01 07:21:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][1000/1251]	eta 0:02:22 lr 0.000793	time 0.5575 (0.5695)	loss 3.1932 (3.4205)	grad_norm 1.3419 (1.3453)	mem 17417MB
[2023-02-01 07:22:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][1050/1251]	eta 0:01:54 lr 0.000792	time 0.5586 (0.5694)	loss 3.4779 (3.4170)	grad_norm 1.4327 (1.3450)	mem 17417MB
[2023-02-01 07:22:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][1100/1251]	eta 0:01:25 lr 0.000792	time 0.6655 (0.5694)	loss 3.4351 (3.4181)	grad_norm 1.3894 (1.3438)	mem 17417MB
[2023-02-01 07:23:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][1150/1251]	eta 0:00:57 lr 0.000792	time 0.5658 (0.5692)	loss 2.2710 (3.4100)	grad_norm 1.3718 (1.3423)	mem 17417MB
[2023-02-01 07:23:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][1200/1251]	eta 0:00:29 lr 0.000792	time 0.6178 (0.5693)	loss 2.5409 (3.4097)	grad_norm 1.1432 (1.3421)	mem 17417MB
[2023-02-01 07:24:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [90/300][1250/1251]	eta 0:00:00 lr 0.000792	time 0.5517 (0.5691)	loss 3.2530 (3.4104)	grad_norm 1.2823 (1.3420)	mem 17417MB
[2023-02-01 07:24:12 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 90 training takes 0:11:52
[2023-02-01 07:24:13 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_90.pth saving......
[2023-02-01 07:24:15 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_90.pth saved !!!
[2023-02-01 07:24:16 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.841 (0.841)	Loss 0.8919 (0.8919)	Acc@1 77.539 (77.539)	Acc@5 95.703 (95.703)	Mem 17417MB
[2023-02-01 07:24:23 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.334 Acc@5 94.220
[2023-02-01 07:24:23 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.3%
[2023-02-01 07:24:25 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.330 (1.330)	Loss 0.8742 (0.8742)	Acc@1 78.320 (78.320)	Acc@5 95.410 (95.410)	Mem 17417MB
[2023-02-01 07:24:33 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.736 Acc@5 95.222
[2023-02-01 07:24:33 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.7%
[2023-02-01 07:24:33 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.74% at 90 epoch
[2023-02-01 07:24:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][0/1251]	eta 0:33:51 lr 0.000792	time 1.6242 (1.6242)	loss 2.9466 (2.9466)	grad_norm 1.3279 (1.3279)	mem 17417MB
[2023-02-01 07:25:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][50/1251]	eta 0:11:51 lr 0.000792	time 0.5552 (0.5922)	loss 4.0073 (3.4602)	grad_norm 1.2776 (1.3592)	mem 17417MB
[2023-02-01 07:25:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][100/1251]	eta 0:11:09 lr 0.000791	time 0.6235 (0.5817)	loss 3.7833 (3.4602)	grad_norm 1.2888 (1.3522)	mem 17417MB
[2023-02-01 07:26:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][150/1251]	eta 0:10:35 lr 0.000791	time 0.5505 (0.5770)	loss 3.4316 (3.4273)	grad_norm 1.2781 (1.3520)	mem 17417MB
[2023-02-01 07:26:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][200/1251]	eta 0:10:04 lr 0.000791	time 0.6377 (0.5755)	loss 4.0765 (3.4289)	grad_norm 1.3637 (1.3443)	mem 17417MB
[2023-02-01 07:26:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][250/1251]	eta 0:09:34 lr 0.000791	time 0.5537 (0.5736)	loss 2.6056 (3.4249)	grad_norm 1.2259 (1.3406)	mem 17417MB
[2023-02-01 07:27:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][300/1251]	eta 0:09:05 lr 0.000791	time 0.6230 (0.5732)	loss 3.8113 (3.4258)	grad_norm 1.4068 (1.3455)	mem 17417MB
[2023-02-01 07:27:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][350/1251]	eta 0:08:36 lr 0.000791	time 0.5560 (0.5728)	loss 3.9653 (3.4413)	grad_norm 1.3337 (1.3461)	mem 17417MB
[2023-02-01 07:28:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][400/1251]	eta 0:08:07 lr 0.000790	time 0.5526 (0.5723)	loss 2.9793 (3.4474)	grad_norm 1.4094 (nan)	mem 17417MB
[2023-02-01 07:28:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][450/1251]	eta 0:07:38 lr 0.000790	time 0.5588 (0.5722)	loss 2.9653 (3.4348)	grad_norm 1.4041 (nan)	mem 17417MB
[2023-02-01 07:29:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][500/1251]	eta 0:07:09 lr 0.000790	time 0.6169 (0.5714)	loss 3.0395 (3.4451)	grad_norm 1.1615 (nan)	mem 17417MB
[2023-02-01 07:29:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][550/1251]	eta 0:06:40 lr 0.000790	time 0.5590 (0.5712)	loss 3.5312 (3.4503)	grad_norm 1.2303 (nan)	mem 17417MB
[2023-02-01 07:30:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][600/1251]	eta 0:06:11 lr 0.000790	time 0.5560 (0.5710)	loss 3.6274 (3.4467)	grad_norm 1.3913 (nan)	mem 17417MB
[2023-02-01 07:30:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][650/1251]	eta 0:05:42 lr 0.000790	time 0.5534 (0.5707)	loss 4.0831 (3.4495)	grad_norm 1.3865 (nan)	mem 17417MB
[2023-02-01 07:31:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][700/1251]	eta 0:05:14 lr 0.000789	time 0.5545 (0.5707)	loss 4.2989 (3.4593)	grad_norm 1.4497 (nan)	mem 17417MB
[2023-02-01 07:31:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][750/1251]	eta 0:04:45 lr 0.000789	time 0.5522 (0.5706)	loss 3.0535 (3.4579)	grad_norm 1.4871 (nan)	mem 17417MB
[2023-02-01 07:32:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][800/1251]	eta 0:04:17 lr 0.000789	time 0.6142 (0.5705)	loss 3.7121 (3.4629)	grad_norm 1.5031 (nan)	mem 17417MB
[2023-02-01 07:32:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][850/1251]	eta 0:03:48 lr 0.000789	time 0.5536 (0.5703)	loss 3.5153 (3.4672)	grad_norm 1.2944 (nan)	mem 17417MB
[2023-02-01 07:33:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][900/1251]	eta 0:03:20 lr 0.000789	time 0.6231 (0.5703)	loss 3.9178 (3.4663)	grad_norm 1.7251 (nan)	mem 17417MB
[2023-02-01 07:33:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][950/1251]	eta 0:02:51 lr 0.000789	time 0.5593 (0.5704)	loss 2.5699 (3.4642)	grad_norm 1.2426 (nan)	mem 17417MB
[2023-02-01 07:34:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][1000/1251]	eta 0:02:23 lr 0.000788	time 0.5544 (0.5703)	loss 3.7140 (3.4678)	grad_norm 1.4449 (nan)	mem 17417MB
[2023-02-01 07:34:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][1050/1251]	eta 0:01:54 lr 0.000788	time 0.5677 (0.5702)	loss 4.5584 (3.4649)	grad_norm 1.3983 (nan)	mem 17417MB
[2023-02-01 07:35:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][1100/1251]	eta 0:01:26 lr 0.000788	time 0.6572 (0.5701)	loss 3.0239 (3.4648)	grad_norm 1.4033 (nan)	mem 17417MB
[2023-02-01 07:35:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][1150/1251]	eta 0:00:57 lr 0.000788	time 0.5630 (0.5701)	loss 3.5249 (3.4645)	grad_norm 1.2569 (nan)	mem 17417MB
[2023-02-01 07:35:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][1200/1251]	eta 0:00:29 lr 0.000788	time 0.5618 (0.5700)	loss 2.2911 (3.4593)	grad_norm 1.3211 (nan)	mem 17417MB
[2023-02-01 07:36:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [91/300][1250/1251]	eta 0:00:00 lr 0.000788	time 0.5514 (0.5701)	loss 4.0865 (3.4566)	grad_norm 1.3513 (nan)	mem 17417MB
[2023-02-01 07:36:26 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 91 training takes 0:11:53
[2023-02-01 07:36:26 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_91.pth saving......
[2023-02-01 07:36:28 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_91.pth saved !!!
[2023-02-01 07:36:29 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.843 (0.843)	Loss 0.9327 (0.9327)	Acc@1 77.637 (77.637)	Acc@5 95.117 (95.117)	Mem 17417MB
[2023-02-01 07:36:37 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.164 Acc@5 94.078
[2023-02-01 07:36:37 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.2%
[2023-02-01 07:36:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.176 (1.176)	Loss 0.8328 (0.8328)	Acc@1 80.859 (80.859)	Acc@5 95.801 (95.801)	Mem 17417MB
[2023-02-01 07:36:46 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.790 Acc@5 95.240
[2023-02-01 07:36:46 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.8%
[2023-02-01 07:36:46 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.79% at 91 epoch
[2023-02-01 07:36:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][0/1251]	eta 0:34:53 lr 0.000788	time 1.6732 (1.6732)	loss 3.8674 (3.8674)	grad_norm 1.4496 (1.4496)	mem 17417MB
[2023-02-01 07:37:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][50/1251]	eta 0:11:52 lr 0.000787	time 0.5589 (0.5933)	loss 4.0061 (3.3351)	grad_norm 1.3756 (1.3401)	mem 17417MB
[2023-02-01 07:37:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][100/1251]	eta 0:11:10 lr 0.000787	time 0.5598 (0.5827)	loss 3.4715 (3.3067)	grad_norm 1.3918 (1.3373)	mem 17417MB
[2023-02-01 07:38:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][150/1251]	eta 0:10:36 lr 0.000787	time 0.5633 (0.5777)	loss 3.2788 (3.3769)	grad_norm 1.3667 (1.3465)	mem 17417MB
[2023-02-01 07:38:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][200/1251]	eta 0:10:04 lr 0.000787	time 0.5568 (0.5753)	loss 2.8063 (3.3865)	grad_norm 1.3789 (1.3450)	mem 17417MB
[2023-02-01 07:39:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][250/1251]	eta 0:09:34 lr 0.000787	time 0.5554 (0.5743)	loss 2.5910 (3.4056)	grad_norm 1.2523 (1.3425)	mem 17417MB
[2023-02-01 07:39:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][300/1251]	eta 0:09:05 lr 0.000786	time 0.5576 (0.5736)	loss 3.2960 (3.4072)	grad_norm 1.3518 (1.3423)	mem 17417MB
[2023-02-01 07:40:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][350/1251]	eta 0:08:36 lr 0.000786	time 0.5521 (0.5728)	loss 3.8332 (3.4167)	grad_norm 1.2995 (1.3496)	mem 17417MB
[2023-02-01 07:40:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][400/1251]	eta 0:08:06 lr 0.000786	time 0.5589 (0.5722)	loss 3.5329 (3.4238)	grad_norm 1.2542 (1.3463)	mem 17417MB
[2023-02-01 07:41:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][450/1251]	eta 0:07:38 lr 0.000786	time 0.6201 (0.5718)	loss 2.7131 (3.4300)	grad_norm 1.2832 (1.3481)	mem 17417MB
[2023-02-01 07:41:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][500/1251]	eta 0:07:09 lr 0.000786	time 0.5605 (0.5718)	loss 2.1014 (3.4394)	grad_norm 1.3474 (1.3495)	mem 17417MB
[2023-02-01 07:42:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][550/1251]	eta 0:06:40 lr 0.000786	time 0.5520 (0.5713)	loss 3.9141 (3.4430)	grad_norm 1.2520 (1.3501)	mem 17417MB
[2023-02-01 07:42:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][600/1251]	eta 0:06:12 lr 0.000785	time 0.5587 (0.5715)	loss 3.7636 (3.4431)	grad_norm 1.2948 (1.3500)	mem 17417MB
[2023-02-01 07:42:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][650/1251]	eta 0:05:43 lr 0.000785	time 0.5510 (0.5712)	loss 3.7529 (3.4447)	grad_norm 1.2402 (1.3508)	mem 17417MB
[2023-02-01 07:43:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][700/1251]	eta 0:05:14 lr 0.000785	time 0.5588 (0.5712)	loss 3.3189 (3.4417)	grad_norm 1.3274 (1.3498)	mem 17417MB
[2023-02-01 07:43:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][750/1251]	eta 0:04:46 lr 0.000785	time 0.5578 (0.5709)	loss 4.0657 (3.4470)	grad_norm 1.4283 (1.3488)	mem 17417MB
[2023-02-01 07:44:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][800/1251]	eta 0:04:17 lr 0.000785	time 0.5647 (0.5709)	loss 3.9339 (3.4436)	grad_norm 1.4958 (1.3490)	mem 17417MB
[2023-02-01 07:44:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][850/1251]	eta 0:03:48 lr 0.000785	time 0.5558 (0.5707)	loss 3.8305 (3.4407)	grad_norm 1.3647 (1.3482)	mem 17417MB
[2023-02-01 07:45:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][900/1251]	eta 0:03:20 lr 0.000784	time 0.5586 (0.5707)	loss 3.9965 (3.4413)	grad_norm 1.3231 (1.3481)	mem 17417MB
[2023-02-01 07:45:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][950/1251]	eta 0:02:51 lr 0.000784	time 0.5552 (0.5704)	loss 2.3514 (3.4391)	grad_norm 1.4025 (1.3469)	mem 17417MB
[2023-02-01 07:46:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][1000/1251]	eta 0:02:23 lr 0.000784	time 0.5632 (0.5706)	loss 3.9335 (3.4358)	grad_norm 1.5396 (1.3475)	mem 17417MB
[2023-02-01 07:46:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][1050/1251]	eta 0:01:54 lr 0.000784	time 0.5620 (0.5704)	loss 3.2709 (3.4324)	grad_norm 1.2338 (1.3461)	mem 17417MB
[2023-02-01 07:47:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][1100/1251]	eta 0:01:26 lr 0.000784	time 0.5553 (0.5703)	loss 3.8288 (3.4315)	grad_norm 1.4526 (1.3455)	mem 17417MB
[2023-02-01 07:47:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][1150/1251]	eta 0:00:57 lr 0.000784	time 0.5599 (0.5701)	loss 3.9753 (3.4318)	grad_norm 1.5626 (1.3469)	mem 17417MB
[2023-02-01 07:48:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][1200/1251]	eta 0:00:29 lr 0.000783	time 0.5496 (0.5700)	loss 2.9903 (3.4305)	grad_norm 1.3408 (1.3477)	mem 17417MB
[2023-02-01 07:48:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [92/300][1250/1251]	eta 0:00:00 lr 0.000783	time 0.5490 (0.5699)	loss 3.1606 (3.4326)	grad_norm 1.2530 (1.3472)	mem 17417MB
[2023-02-01 07:48:39 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 92 training takes 0:11:53
[2023-02-01 07:48:39 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_92.pth saving......
[2023-02-01 07:48:41 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_92.pth saved !!!
[2023-02-01 07:48:42 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.889 (0.889)	Loss 1.0049 (1.0049)	Acc@1 77.832 (77.832)	Acc@5 93.750 (93.750)	Mem 17417MB
[2023-02-01 07:48:50 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.166 Acc@5 94.010
[2023-02-01 07:48:50 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.2%
[2023-02-01 07:48:51 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.259 (1.259)	Loss 0.8399 (0.8399)	Acc@1 80.176 (80.176)	Acc@5 95.117 (95.117)	Mem 17417MB
[2023-02-01 07:48:59 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.878 Acc@5 95.264
[2023-02-01 07:48:59 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 79.9%
[2023-02-01 07:48:59 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.88% at 92 epoch
[2023-02-01 07:49:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][0/1251]	eta 0:35:30 lr 0.000783	time 1.7034 (1.7034)	loss 3.8405 (3.8405)	grad_norm 1.2460 (1.2460)	mem 17417MB
[2023-02-01 07:49:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][50/1251]	eta 0:11:52 lr 0.000783	time 0.5667 (0.5931)	loss 3.1678 (3.4414)	grad_norm 1.3891 (1.3712)	mem 17417MB
[2023-02-01 07:49:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][100/1251]	eta 0:11:11 lr 0.000783	time 0.5588 (0.5836)	loss 3.8776 (3.4819)	grad_norm 1.4182 (1.3512)	mem 17417MB
[2023-02-01 07:50:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][150/1251]	eta 0:10:36 lr 0.000783	time 0.5588 (0.5780)	loss 4.0519 (3.4695)	grad_norm 1.3093 (1.3520)	mem 17417MB
[2023-02-01 07:50:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][200/1251]	eta 0:10:05 lr 0.000783	time 0.5543 (0.5763)	loss 3.5219 (3.4620)	grad_norm 1.2907 (1.3506)	mem 17417MB
[2023-02-01 07:51:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][250/1251]	eta 0:09:35 lr 0.000782	time 0.6228 (0.5747)	loss 3.8066 (3.4481)	grad_norm 1.3051 (1.3535)	mem 17417MB
[2023-02-01 07:51:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][300/1251]	eta 0:09:05 lr 0.000782	time 0.5573 (0.5741)	loss 2.3903 (3.4590)	grad_norm 1.4548 (1.3532)	mem 17417MB
[2023-02-01 07:52:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][350/1251]	eta 0:08:36 lr 0.000782	time 0.5650 (0.5736)	loss 4.0504 (3.4599)	grad_norm 1.4065 (nan)	mem 17417MB
[2023-02-01 07:52:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][400/1251]	eta 0:08:07 lr 0.000782	time 0.6182 (0.5732)	loss 2.7986 (3.4501)	grad_norm 1.2962 (nan)	mem 17417MB
[2023-02-01 07:53:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][450/1251]	eta 0:07:38 lr 0.000782	time 0.5533 (0.5727)	loss 2.8322 (3.4468)	grad_norm 1.2657 (nan)	mem 17417MB
[2023-02-01 07:53:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][500/1251]	eta 0:07:09 lr 0.000782	time 0.5551 (0.5722)	loss 3.6176 (3.4566)	grad_norm 1.2317 (nan)	mem 17417MB
[2023-02-01 07:54:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][550/1251]	eta 0:06:40 lr 0.000781	time 0.5590 (0.5717)	loss 3.3641 (3.4428)	grad_norm 1.5213 (nan)	mem 17417MB
[2023-02-01 07:54:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][600/1251]	eta 0:06:12 lr 0.000781	time 0.5689 (0.5717)	loss 3.1081 (3.4469)	grad_norm 1.3107 (nan)	mem 17417MB
[2023-02-01 07:55:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][650/1251]	eta 0:05:43 lr 0.000781	time 0.5566 (0.5714)	loss 3.2508 (3.4464)	grad_norm 1.3616 (nan)	mem 17417MB
[2023-02-01 07:55:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][700/1251]	eta 0:05:14 lr 0.000781	time 0.6502 (0.5714)	loss 4.3471 (3.4456)	grad_norm 1.4266 (nan)	mem 17417MB
[2023-02-01 07:56:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][750/1251]	eta 0:04:46 lr 0.000781	time 0.5563 (0.5710)	loss 3.9695 (3.4493)	grad_norm 1.2475 (nan)	mem 17417MB
[2023-02-01 07:56:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][800/1251]	eta 0:04:17 lr 0.000780	time 0.6267 (0.5709)	loss 2.6655 (3.4507)	grad_norm 1.4998 (nan)	mem 17417MB
[2023-02-01 07:57:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][850/1251]	eta 0:03:48 lr 0.000780	time 0.5513 (0.5708)	loss 3.6300 (3.4465)	grad_norm 1.2700 (nan)	mem 17417MB
[2023-02-01 07:57:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][900/1251]	eta 0:03:20 lr 0.000780	time 0.5545 (0.5707)	loss 2.2185 (3.4459)	grad_norm 1.3371 (nan)	mem 17417MB
[2023-02-01 07:58:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][950/1251]	eta 0:02:51 lr 0.000780	time 0.5753 (0.5705)	loss 3.2681 (3.4477)	grad_norm 1.4545 (nan)	mem 17417MB
[2023-02-01 07:58:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][1000/1251]	eta 0:02:23 lr 0.000780	time 0.6133 (0.5707)	loss 4.1176 (3.4428)	grad_norm 1.2825 (nan)	mem 17417MB
[2023-02-01 07:58:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][1050/1251]	eta 0:01:54 lr 0.000780	time 0.5551 (0.5705)	loss 3.0640 (3.4399)	grad_norm 1.3618 (nan)	mem 17417MB
[2023-02-01 07:59:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][1100/1251]	eta 0:01:26 lr 0.000779	time 0.5559 (0.5702)	loss 3.2946 (3.4435)	grad_norm 1.3475 (nan)	mem 17417MB
[2023-02-01 07:59:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][1150/1251]	eta 0:00:57 lr 0.000779	time 0.5612 (0.5703)	loss 2.7221 (3.4374)	grad_norm 1.2311 (nan)	mem 17417MB
[2023-02-01 08:00:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][1200/1251]	eta 0:00:29 lr 0.000779	time 0.5530 (0.5702)	loss 3.0003 (3.4394)	grad_norm 1.4176 (nan)	mem 17417MB
[2023-02-01 08:00:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [93/300][1250/1251]	eta 0:00:00 lr 0.000779	time 0.5498 (0.5701)	loss 3.7615 (3.4416)	grad_norm 1.3897 (nan)	mem 17417MB
[2023-02-01 08:00:52 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 93 training takes 0:11:53
[2023-02-01 08:00:53 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_93.pth saving......
[2023-02-01 08:00:54 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_93.pth saved !!!
[2023-02-01 08:00:55 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.869 (0.869)	Loss 0.9273 (0.9273)	Acc@1 78.320 (78.320)	Acc@5 94.434 (94.434)	Mem 17417MB
[2023-02-01 08:01:03 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.414 Acc@5 94.018
[2023-02-01 08:01:03 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.4%
[2023-02-01 08:01:04 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.183 (1.183)	Loss 0.7985 (0.7985)	Acc@1 81.836 (81.836)	Acc@5 95.605 (95.605)	Mem 17417MB
[2023-02-01 08:01:12 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.978 Acc@5 95.298
[2023-02-01 08:01:12 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.0%
[2023-02-01 08:01:12 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.98% at 93 epoch
[2023-02-01 08:01:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][0/1251]	eta 0:34:12 lr 0.000779	time 1.6404 (1.6404)	loss 3.3415 (3.3415)	grad_norm 1.3128 (1.3128)	mem 17417MB
[2023-02-01 08:01:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][50/1251]	eta 0:11:50 lr 0.000779	time 0.5648 (0.5918)	loss 3.9608 (3.4150)	grad_norm 1.3780 (1.3519)	mem 17417MB
[2023-02-01 08:02:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][100/1251]	eta 0:11:08 lr 0.000779	time 0.5616 (0.5807)	loss 4.0339 (3.4031)	grad_norm 1.5780 (1.3415)	mem 17417MB
[2023-02-01 08:02:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][150/1251]	eta 0:10:36 lr 0.000778	time 0.5576 (0.5780)	loss 3.5087 (3.4298)	grad_norm 1.5545 (1.3477)	mem 17417MB
[2023-02-01 08:03:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][200/1251]	eta 0:10:04 lr 0.000778	time 0.5563 (0.5747)	loss 2.5136 (3.4202)	grad_norm 1.2527 (1.3532)	mem 17417MB
[2023-02-01 08:03:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][250/1251]	eta 0:09:34 lr 0.000778	time 0.6217 (0.5740)	loss 3.5157 (3.4154)	grad_norm 1.3006 (1.3547)	mem 17417MB
[2023-02-01 08:04:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][300/1251]	eta 0:09:05 lr 0.000778	time 0.5614 (0.5732)	loss 3.0813 (3.4249)	grad_norm 1.4824 (1.3610)	mem 17417MB
[2023-02-01 08:04:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][350/1251]	eta 0:08:35 lr 0.000778	time 0.6332 (0.5725)	loss 3.7725 (3.4361)	grad_norm 1.2988 (1.3600)	mem 17417MB
[2023-02-01 08:05:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][400/1251]	eta 0:08:06 lr 0.000778	time 0.5529 (0.5721)	loss 3.4780 (3.4459)	grad_norm 1.2874 (1.3564)	mem 17417MB
[2023-02-01 08:05:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][450/1251]	eta 0:07:38 lr 0.000777	time 0.5514 (0.5720)	loss 3.5867 (3.4390)	grad_norm 1.5263 (1.3571)	mem 17417MB
[2023-02-01 08:05:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][500/1251]	eta 0:07:09 lr 0.000777	time 0.5540 (0.5714)	loss 3.6322 (3.4215)	grad_norm 1.3410 (1.3558)	mem 17417MB
[2023-02-01 08:06:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][550/1251]	eta 0:06:40 lr 0.000777	time 0.5542 (0.5716)	loss 3.3689 (3.4230)	grad_norm 1.3856 (1.3575)	mem 17417MB
[2023-02-01 08:06:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][600/1251]	eta 0:06:11 lr 0.000777	time 0.5557 (0.5713)	loss 3.0792 (3.4153)	grad_norm 1.1268 (1.3541)	mem 17417MB
[2023-02-01 08:07:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][650/1251]	eta 0:05:43 lr 0.000777	time 0.5611 (0.5712)	loss 3.4421 (3.4094)	grad_norm 1.2083 (1.3541)	mem 17417MB
[2023-02-01 08:07:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][700/1251]	eta 0:05:14 lr 0.000777	time 0.5528 (0.5713)	loss 3.0425 (3.4202)	grad_norm 1.3381 (1.3522)	mem 17417MB
[2023-02-01 08:08:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][750/1251]	eta 0:04:45 lr 0.000776	time 0.5573 (0.5708)	loss 3.7972 (3.4283)	grad_norm 1.4780 (1.3531)	mem 17417MB
[2023-02-01 08:08:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][800/1251]	eta 0:04:17 lr 0.000776	time 0.5617 (0.5709)	loss 3.7331 (3.4294)	grad_norm 1.4730 (1.3547)	mem 17417MB
[2023-02-01 08:09:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][850/1251]	eta 0:03:48 lr 0.000776	time 0.5535 (0.5708)	loss 3.7226 (3.4211)	grad_norm 1.3123 (1.3549)	mem 17417MB
[2023-02-01 08:09:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][900/1251]	eta 0:03:20 lr 0.000776	time 0.5709 (0.5708)	loss 3.8269 (3.4270)	grad_norm 1.3786 (1.3559)	mem 17417MB
[2023-02-01 08:10:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][950/1251]	eta 0:02:51 lr 0.000776	time 0.5567 (0.5708)	loss 2.7131 (3.4243)	grad_norm 1.3994 (1.3545)	mem 17417MB
[2023-02-01 08:10:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][1000/1251]	eta 0:02:23 lr 0.000775	time 0.6211 (0.5708)	loss 3.7643 (3.4272)	grad_norm 1.4053 (1.3555)	mem 17417MB
[2023-02-01 08:11:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][1050/1251]	eta 0:01:54 lr 0.000775	time 0.5480 (0.5707)	loss 3.9045 (3.4260)	grad_norm 1.3443 (1.3576)	mem 17417MB
[2023-02-01 08:11:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][1100/1251]	eta 0:01:26 lr 0.000775	time 0.5664 (0.5708)	loss 3.2843 (3.4243)	grad_norm 1.4182 (1.3568)	mem 17417MB
[2023-02-01 08:12:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][1150/1251]	eta 0:00:57 lr 0.000775	time 0.5565 (0.5705)	loss 2.9248 (3.4210)	grad_norm 1.2926 (1.3562)	mem 17417MB
[2023-02-01 08:12:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][1200/1251]	eta 0:00:29 lr 0.000775	time 0.5649 (0.5706)	loss 2.6092 (3.4175)	grad_norm 1.2707 (1.3569)	mem 17417MB
[2023-02-01 08:13:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [94/300][1250/1251]	eta 0:00:00 lr 0.000775	time 0.5492 (0.5705)	loss 3.5666 (3.4163)	grad_norm 1.2968 (1.3569)	mem 17417MB
[2023-02-01 08:13:06 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 94 training takes 0:11:53
[2023-02-01 08:13:06 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_94.pth saving......
[2023-02-01 08:13:08 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_94.pth saved !!!
[2023-02-01 08:13:09 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.836 (0.836)	Loss 0.9000 (0.9000)	Acc@1 78.027 (78.027)	Acc@5 94.922 (94.922)	Mem 17417MB
[2023-02-01 08:13:17 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.440 Acc@5 94.230
[2023-02-01 08:13:17 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.4%
[2023-02-01 08:13:18 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.265 (1.265)	Loss 0.8481 (0.8481)	Acc@1 81.250 (81.250)	Acc@5 95.117 (95.117)	Mem 17417MB
[2023-02-01 08:13:26 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.982 Acc@5 95.302
[2023-02-01 08:13:26 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.0%
[2023-02-01 08:13:26 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 79.98% at 94 epoch
[2023-02-01 08:13:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][0/1251]	eta 0:34:40 lr 0.000775	time 1.6627 (1.6627)	loss 3.5842 (3.5842)	grad_norm 1.3349 (1.3349)	mem 17417MB
[2023-02-01 08:13:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][50/1251]	eta 0:11:42 lr 0.000774	time 0.5556 (0.5850)	loss 3.5109 (3.3828)	grad_norm 1.2513 (1.3540)	mem 17417MB
[2023-02-01 08:14:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][100/1251]	eta 0:11:09 lr 0.000774	time 0.5485 (0.5813)	loss 2.6151 (3.4475)	grad_norm 1.2561 (1.3479)	mem 17417MB
[2023-02-01 08:14:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][150/1251]	eta 0:10:34 lr 0.000774	time 0.6462 (0.5763)	loss 3.7661 (3.4399)	grad_norm 1.3842 (1.3586)	mem 17417MB
[2023-02-01 08:15:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][200/1251]	eta 0:10:04 lr 0.000774	time 0.5558 (0.5751)	loss 2.6969 (3.4189)	grad_norm 1.4831 (1.3545)	mem 17417MB
[2023-02-01 08:15:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][250/1251]	eta 0:09:34 lr 0.000774	time 0.7308 (0.5736)	loss 4.3831 (3.4304)	grad_norm 1.2031 (1.3639)	mem 17417MB
[2023-02-01 08:16:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][300/1251]	eta 0:09:04 lr 0.000774	time 0.5553 (0.5726)	loss 4.1357 (3.4415)	grad_norm 1.4086 (1.3687)	mem 17417MB
[2023-02-01 08:16:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][350/1251]	eta 0:08:34 lr 0.000773	time 0.5599 (0.5715)	loss 2.8963 (3.4418)	grad_norm 1.5240 (1.3708)	mem 17417MB
[2023-02-01 08:17:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][400/1251]	eta 0:08:06 lr 0.000773	time 0.5602 (0.5715)	loss 3.8949 (3.4292)	grad_norm 1.3857 (nan)	mem 17417MB
[2023-02-01 08:17:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][450/1251]	eta 0:07:37 lr 0.000773	time 0.5543 (0.5707)	loss 3.2245 (3.4198)	grad_norm 1.2916 (nan)	mem 17417MB
[2023-02-01 08:18:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][500/1251]	eta 0:07:08 lr 0.000773	time 0.5502 (0.5708)	loss 2.4335 (3.4225)	grad_norm 1.4465 (nan)	mem 17417MB
[2023-02-01 08:18:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][550/1251]	eta 0:06:39 lr 0.000773	time 0.5557 (0.5702)	loss 3.3768 (3.4247)	grad_norm 1.2534 (nan)	mem 17417MB
[2023-02-01 08:19:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][600/1251]	eta 0:06:11 lr 0.000773	time 0.5615 (0.5701)	loss 2.2846 (3.4250)	grad_norm 1.3941 (nan)	mem 17417MB
[2023-02-01 08:19:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][650/1251]	eta 0:05:42 lr 0.000772	time 0.5550 (0.5702)	loss 4.2717 (3.4243)	grad_norm 1.2151 (nan)	mem 17417MB
[2023-02-01 08:20:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][700/1251]	eta 0:05:14 lr 0.000772	time 0.5598 (0.5699)	loss 3.0345 (3.4184)	grad_norm 1.2831 (nan)	mem 17417MB
[2023-02-01 08:20:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][750/1251]	eta 0:04:45 lr 0.000772	time 0.5593 (0.5697)	loss 3.6942 (3.4094)	grad_norm 1.1814 (nan)	mem 17417MB
[2023-02-01 08:21:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][800/1251]	eta 0:04:16 lr 0.000772	time 0.5704 (0.5697)	loss 3.3132 (3.4084)	grad_norm 1.3949 (nan)	mem 17417MB
[2023-02-01 08:21:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][850/1251]	eta 0:03:48 lr 0.000772	time 0.5560 (0.5695)	loss 3.4657 (3.4092)	grad_norm 1.3283 (nan)	mem 17417MB
[2023-02-01 08:21:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][900/1251]	eta 0:03:19 lr 0.000771	time 0.5534 (0.5696)	loss 3.6699 (3.4111)	grad_norm 1.2912 (nan)	mem 17417MB
[2023-02-01 08:22:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][950/1251]	eta 0:02:51 lr 0.000771	time 0.5582 (0.5695)	loss 3.0954 (3.4163)	grad_norm 1.4619 (nan)	mem 17417MB
[2023-02-01 08:22:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][1000/1251]	eta 0:02:22 lr 0.000771	time 0.5631 (0.5695)	loss 2.9135 (3.4113)	grad_norm 1.4923 (nan)	mem 17417MB
[2023-02-01 08:23:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][1050/1251]	eta 0:01:54 lr 0.000771	time 0.5518 (0.5696)	loss 2.9535 (3.4145)	grad_norm 1.2825 (nan)	mem 17417MB
[2023-02-01 08:23:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][1100/1251]	eta 0:01:25 lr 0.000771	time 0.6182 (0.5693)	loss 4.2253 (3.4161)	grad_norm 1.4548 (nan)	mem 17417MB
[2023-02-01 08:24:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][1150/1251]	eta 0:00:57 lr 0.000771	time 0.5634 (0.5693)	loss 3.9830 (3.4154)	grad_norm 1.4356 (nan)	mem 17417MB
[2023-02-01 08:24:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][1200/1251]	eta 0:00:29 lr 0.000770	time 0.6357 (0.5693)	loss 3.5822 (3.4158)	grad_norm 1.4279 (nan)	mem 17417MB
[2023-02-01 08:25:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [95/300][1250/1251]	eta 0:00:00 lr 0.000770	time 0.5497 (0.5691)	loss 4.0053 (3.4161)	grad_norm 1.4258 (nan)	mem 17417MB
[2023-02-01 08:25:18 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 95 training takes 0:11:52
[2023-02-01 08:25:18 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_95.pth saving......
[2023-02-01 08:25:20 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_95.pth saved !!!
[2023-02-01 08:25:21 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.870 (0.870)	Loss 1.1133 (1.1133)	Acc@1 72.656 (72.656)	Acc@5 91.992 (91.992)	Mem 17417MB
[2023-02-01 08:25:29 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.504 Acc@5 94.102
[2023-02-01 08:25:29 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.5%
[2023-02-01 08:25:30 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.139 (1.139)	Loss 0.8099 (0.8099)	Acc@1 82.129 (82.129)	Acc@5 94.629 (94.629)	Mem 17417MB
[2023-02-01 08:25:38 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.022 Acc@5 95.296
[2023-02-01 08:25:38 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.0%
[2023-02-01 08:25:38 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.02% at 95 epoch
[2023-02-01 08:25:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][0/1251]	eta 0:39:19 lr 0.000770	time 1.8863 (1.8863)	loss 4.1719 (4.1719)	grad_norm 1.5226 (1.5226)	mem 17417MB
[2023-02-01 08:26:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][50/1251]	eta 0:11:55 lr 0.000770	time 0.5624 (0.5957)	loss 3.1161 (3.2764)	grad_norm 1.3472 (1.4086)	mem 17417MB
[2023-02-01 08:26:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][100/1251]	eta 0:11:10 lr 0.000770	time 0.5664 (0.5827)	loss 3.9853 (3.3320)	grad_norm 1.5023 (1.4094)	mem 17417MB
[2023-02-01 08:27:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][150/1251]	eta 0:10:35 lr 0.000770	time 0.5501 (0.5776)	loss 4.3293 (3.3879)	grad_norm 1.3198 (1.3857)	mem 17417MB
[2023-02-01 08:27:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][200/1251]	eta 0:10:04 lr 0.000770	time 0.5532 (0.5754)	loss 2.4068 (3.3817)	grad_norm 1.3784 (1.3770)	mem 17417MB
[2023-02-01 08:28:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][250/1251]	eta 0:09:34 lr 0.000769	time 0.5523 (0.5735)	loss 3.7468 (3.3769)	grad_norm 1.2895 (1.3757)	mem 17417MB
[2023-02-01 08:28:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][300/1251]	eta 0:09:04 lr 0.000769	time 0.5625 (0.5729)	loss 2.6119 (3.3909)	grad_norm 1.3553 (1.3738)	mem 17417MB
[2023-02-01 08:28:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][350/1251]	eta 0:08:35 lr 0.000769	time 0.5644 (0.5721)	loss 3.8069 (3.3973)	grad_norm 1.3426 (1.3640)	mem 17417MB
[2023-02-01 08:29:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][400/1251]	eta 0:08:06 lr 0.000769	time 0.5551 (0.5712)	loss 2.5088 (3.3977)	grad_norm 1.4047 (1.3640)	mem 17417MB
[2023-02-01 08:29:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][450/1251]	eta 0:07:37 lr 0.000769	time 0.5557 (0.5712)	loss 4.1886 (3.4043)	grad_norm 1.4058 (1.3661)	mem 17417MB
[2023-02-01 08:30:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][500/1251]	eta 0:07:08 lr 0.000768	time 0.5547 (0.5703)	loss 3.1243 (3.3898)	grad_norm 1.4221 (1.3638)	mem 17417MB
[2023-02-01 08:30:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][550/1251]	eta 0:06:39 lr 0.000768	time 0.5592 (0.5704)	loss 3.2214 (3.4013)	grad_norm 1.3415 (1.3655)	mem 17417MB
[2023-02-01 08:31:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][600/1251]	eta 0:06:11 lr 0.000768	time 0.5599 (0.5701)	loss 3.4819 (3.4117)	grad_norm 1.3545 (1.3636)	mem 17417MB
[2023-02-01 08:31:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][650/1251]	eta 0:05:42 lr 0.000768	time 0.5584 (0.5698)	loss 2.8268 (3.4228)	grad_norm 1.3161 (1.3628)	mem 17417MB
[2023-02-01 08:32:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][700/1251]	eta 0:05:13 lr 0.000768	time 0.5592 (0.5695)	loss 4.2696 (3.4202)	grad_norm 1.4410 (1.3609)	mem 17417MB
[2023-02-01 08:32:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][750/1251]	eta 0:04:45 lr 0.000768	time 0.5638 (0.5694)	loss 2.9963 (3.4229)	grad_norm 1.3409 (1.3602)	mem 17417MB
[2023-02-01 08:33:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][800/1251]	eta 0:04:16 lr 0.000767	time 0.5580 (0.5692)	loss 3.8031 (3.4289)	grad_norm 1.1965 (1.3597)	mem 17417MB
[2023-02-01 08:33:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][850/1251]	eta 0:03:48 lr 0.000767	time 0.5601 (0.5693)	loss 4.1534 (3.4287)	grad_norm 1.4325 (1.3607)	mem 17417MB
[2023-02-01 08:34:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][900/1251]	eta 0:03:19 lr 0.000767	time 0.5626 (0.5692)	loss 4.3028 (3.4297)	grad_norm 1.2647 (1.3606)	mem 17417MB
[2023-02-01 08:34:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][950/1251]	eta 0:02:51 lr 0.000767	time 0.5573 (0.5693)	loss 3.0898 (3.4245)	grad_norm 1.3321 (1.3605)	mem 17417MB
[2023-02-01 08:35:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][1000/1251]	eta 0:02:22 lr 0.000767	time 0.6295 (0.5691)	loss 3.9318 (3.4252)	grad_norm 1.3168 (1.3598)	mem 17417MB
[2023-02-01 08:35:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][1050/1251]	eta 0:01:54 lr 0.000767	time 0.5708 (0.5691)	loss 3.5739 (3.4222)	grad_norm 1.4819 (1.3603)	mem 17417MB
[2023-02-01 08:36:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][1100/1251]	eta 0:01:25 lr 0.000766	time 0.5540 (0.5690)	loss 2.8495 (3.4280)	grad_norm 1.4277 (1.3624)	mem 17417MB
[2023-02-01 08:36:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][1150/1251]	eta 0:00:57 lr 0.000766	time 0.5531 (0.5689)	loss 3.2121 (3.4294)	grad_norm 1.2939 (1.3624)	mem 17417MB
[2023-02-01 08:37:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][1200/1251]	eta 0:00:29 lr 0.000766	time 0.6286 (0.5690)	loss 3.4160 (3.4289)	grad_norm 1.2923 (1.3633)	mem 17417MB
[2023-02-01 08:37:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [96/300][1250/1251]	eta 0:00:00 lr 0.000766	time 0.5513 (0.5690)	loss 4.2078 (3.4276)	grad_norm 1.3598 (1.3637)	mem 17417MB
[2023-02-01 08:37:30 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 96 training takes 0:11:51
[2023-02-01 08:37:30 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_96.pth saving......
[2023-02-01 08:37:32 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_96.pth saved !!!
[2023-02-01 08:37:33 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.872 (0.872)	Loss 0.9832 (0.9832)	Acc@1 77.051 (77.051)	Acc@5 94.824 (94.824)	Mem 17417MB
[2023-02-01 08:37:41 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.660 Acc@5 94.222
[2023-02-01 08:37:41 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.7%
[2023-02-01 08:37:42 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.418 (1.418)	Loss 0.8703 (0.8703)	Acc@1 77.930 (77.930)	Acc@5 94.727 (94.727)	Mem 17417MB
[2023-02-01 08:37:51 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.056 Acc@5 95.314
[2023-02-01 08:37:51 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.1%
[2023-02-01 08:37:51 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.06% at 96 epoch
[2023-02-01 08:37:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][0/1251]	eta 0:37:36 lr 0.000766	time 1.8040 (1.8040)	loss 3.3603 (3.3603)	grad_norm 1.2119 (1.2119)	mem 17417MB
[2023-02-01 08:38:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][50/1251]	eta 0:11:47 lr 0.000766	time 0.5642 (0.5888)	loss 3.3934 (3.4596)	grad_norm 1.2704 (1.3636)	mem 17417MB
[2023-02-01 08:38:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][100/1251]	eta 0:11:08 lr 0.000765	time 0.6400 (0.5806)	loss 3.5491 (3.3986)	grad_norm 1.1960 (1.3767)	mem 17417MB
[2023-02-01 08:39:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][150/1251]	eta 0:10:33 lr 0.000765	time 0.5536 (0.5750)	loss 3.9802 (3.4392)	grad_norm 1.2769 (1.3707)	mem 17417MB
[2023-02-01 08:39:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][200/1251]	eta 0:10:02 lr 0.000765	time 0.6146 (0.5737)	loss 3.4278 (3.4406)	grad_norm 1.3122 (nan)	mem 17417MB
[2023-02-01 08:40:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][250/1251]	eta 0:09:33 lr 0.000765	time 0.5532 (0.5726)	loss 3.1267 (3.4366)	grad_norm 1.3031 (nan)	mem 17417MB
[2023-02-01 08:40:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][300/1251]	eta 0:09:03 lr 0.000765	time 0.5575 (0.5720)	loss 3.7540 (3.4366)	grad_norm 1.2704 (nan)	mem 17417MB
[2023-02-01 08:41:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][350/1251]	eta 0:08:34 lr 0.000765	time 0.5599 (0.5715)	loss 2.6275 (3.4336)	grad_norm 1.5245 (nan)	mem 17417MB
[2023-02-01 08:41:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][400/1251]	eta 0:08:05 lr 0.000764	time 0.5653 (0.5709)	loss 3.4922 (3.4378)	grad_norm 1.1853 (nan)	mem 17417MB
[2023-02-01 08:42:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][450/1251]	eta 0:07:36 lr 0.000764	time 0.5560 (0.5705)	loss 4.0435 (3.4269)	grad_norm 1.5260 (nan)	mem 17417MB
[2023-02-01 08:42:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][500/1251]	eta 0:07:08 lr 0.000764	time 0.5522 (0.5703)	loss 3.5508 (3.4222)	grad_norm 1.3314 (nan)	mem 17417MB
[2023-02-01 08:43:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][550/1251]	eta 0:06:39 lr 0.000764	time 0.5565 (0.5700)	loss 3.7192 (3.4127)	grad_norm 1.4992 (nan)	mem 17417MB
[2023-02-01 08:43:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][600/1251]	eta 0:06:11 lr 0.000764	time 0.5611 (0.5699)	loss 4.1426 (3.4133)	grad_norm 1.3069 (nan)	mem 17417MB
[2023-02-01 08:44:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][650/1251]	eta 0:05:42 lr 0.000764	time 0.5550 (0.5698)	loss 3.1958 (3.4154)	grad_norm 1.1256 (nan)	mem 17417MB
[2023-02-01 08:44:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][700/1251]	eta 0:05:13 lr 0.000763	time 0.5599 (0.5696)	loss 3.2085 (3.4152)	grad_norm 1.2990 (nan)	mem 17417MB
[2023-02-01 08:44:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][750/1251]	eta 0:04:45 lr 0.000763	time 0.5533 (0.5694)	loss 2.5306 (3.4087)	grad_norm 1.3018 (nan)	mem 17417MB
[2023-02-01 08:45:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][800/1251]	eta 0:04:16 lr 0.000763	time 0.5562 (0.5694)	loss 4.1107 (3.4115)	grad_norm 1.2498 (nan)	mem 17417MB
[2023-02-01 08:45:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][850/1251]	eta 0:03:48 lr 0.000763	time 0.5630 (0.5692)	loss 3.9523 (3.4175)	grad_norm 1.3455 (nan)	mem 17417MB
[2023-02-01 08:46:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][900/1251]	eta 0:03:19 lr 0.000763	time 0.5632 (0.5693)	loss 4.5698 (3.4217)	grad_norm 1.3431 (nan)	mem 17417MB
[2023-02-01 08:46:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][950/1251]	eta 0:02:51 lr 0.000762	time 0.5545 (0.5692)	loss 3.2699 (3.4120)	grad_norm 1.5150 (nan)	mem 17417MB
[2023-02-01 08:47:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][1000/1251]	eta 0:02:22 lr 0.000762	time 0.5554 (0.5692)	loss 2.7202 (3.4090)	grad_norm 1.3943 (nan)	mem 17417MB
[2023-02-01 08:47:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][1050/1251]	eta 0:01:54 lr 0.000762	time 0.5610 (0.5691)	loss 3.9427 (3.4091)	grad_norm 1.3316 (nan)	mem 17417MB
[2023-02-01 08:48:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][1100/1251]	eta 0:01:25 lr 0.000762	time 0.5471 (0.5692)	loss 3.3845 (3.4028)	grad_norm 1.4265 (nan)	mem 17417MB
[2023-02-01 08:48:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][1150/1251]	eta 0:00:57 lr 0.000762	time 0.5576 (0.5692)	loss 3.1408 (3.4023)	grad_norm 1.3186 (nan)	mem 17417MB
[2023-02-01 08:49:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][1200/1251]	eta 0:00:29 lr 0.000762	time 0.6397 (0.5691)	loss 3.2185 (3.4077)	grad_norm 1.2878 (nan)	mem 17417MB
[2023-02-01 08:49:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [97/300][1250/1251]	eta 0:00:00 lr 0.000761	time 0.5506 (0.5691)	loss 4.1556 (3.4029)	grad_norm 1.4284 (nan)	mem 17417MB
[2023-02-01 08:49:43 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 97 training takes 0:11:52
[2023-02-01 08:49:43 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_97.pth saving......
[2023-02-01 08:49:44 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_97.pth saved !!!
[2023-02-01 08:49:45 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.838 (0.838)	Loss 0.9543 (0.9543)	Acc@1 78.223 (78.223)	Acc@5 94.531 (94.531)	Mem 17417MB
[2023-02-01 08:49:53 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.454 Acc@5 94.114
[2023-02-01 08:49:53 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.5%
[2023-02-01 08:49:55 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.320 (1.320)	Loss 0.8626 (0.8626)	Acc@1 79.785 (79.785)	Acc@5 94.336 (94.336)	Mem 17417MB
[2023-02-01 08:50:03 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.078 Acc@5 95.308
[2023-02-01 08:50:03 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.1%
[2023-02-01 08:50:03 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.08% at 97 epoch
[2023-02-01 08:50:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][0/1251]	eta 0:34:56 lr 0.000761	time 1.6755 (1.6755)	loss 3.9559 (3.9559)	grad_norm 1.3732 (1.3732)	mem 17417MB
[2023-02-01 08:50:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][50/1251]	eta 0:11:54 lr 0.000761	time 0.5612 (0.5948)	loss 3.5039 (3.4645)	grad_norm 1.4466 (1.3569)	mem 17417MB
[2023-02-01 08:51:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][100/1251]	eta 0:11:10 lr 0.000761	time 0.5822 (0.5821)	loss 3.9620 (3.4195)	grad_norm 1.3601 (1.3656)	mem 17417MB
[2023-02-01 08:51:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][150/1251]	eta 0:10:36 lr 0.000761	time 0.5499 (0.5781)	loss 3.8254 (3.4113)	grad_norm 1.3209 (1.3678)	mem 17417MB
[2023-02-01 08:51:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][200/1251]	eta 0:10:04 lr 0.000761	time 0.5532 (0.5753)	loss 4.0035 (3.4099)	grad_norm 1.3696 (1.3648)	mem 17417MB
[2023-02-01 08:52:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][250/1251]	eta 0:09:34 lr 0.000761	time 0.5544 (0.5742)	loss 2.9583 (3.4258)	grad_norm 1.4863 (1.3593)	mem 17417MB
[2023-02-01 08:52:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][300/1251]	eta 0:09:05 lr 0.000760	time 0.5549 (0.5738)	loss 3.5740 (3.4118)	grad_norm 1.4111 (1.3654)	mem 17417MB
[2023-02-01 08:53:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][350/1251]	eta 0:08:36 lr 0.000760	time 0.5542 (0.5733)	loss 3.6898 (3.4034)	grad_norm 1.3602 (1.3618)	mem 17417MB
[2023-02-01 08:53:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][400/1251]	eta 0:08:07 lr 0.000760	time 0.5577 (0.5725)	loss 2.8886 (3.4058)	grad_norm 1.3646 (1.3623)	mem 17417MB
[2023-02-01 08:54:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][450/1251]	eta 0:07:38 lr 0.000760	time 0.5543 (0.5719)	loss 3.5274 (3.4140)	grad_norm 1.2166 (1.3624)	mem 17417MB
[2023-02-01 08:54:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][500/1251]	eta 0:07:09 lr 0.000760	time 0.5553 (0.5713)	loss 3.1925 (3.3994)	grad_norm 1.3702 (1.3616)	mem 17417MB
[2023-02-01 08:55:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][550/1251]	eta 0:06:40 lr 0.000759	time 0.5568 (0.5711)	loss 2.4432 (3.3921)	grad_norm 1.2603 (1.3618)	mem 17417MB
[2023-02-01 08:55:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][600/1251]	eta 0:06:11 lr 0.000759	time 0.5537 (0.5707)	loss 3.5702 (3.3910)	grad_norm 1.5566 (1.3655)	mem 17417MB
[2023-02-01 08:56:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][650/1251]	eta 0:05:43 lr 0.000759	time 0.5597 (0.5707)	loss 3.0064 (3.3784)	grad_norm 1.3793 (1.3641)	mem 17417MB
[2023-02-01 08:56:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][700/1251]	eta 0:05:14 lr 0.000759	time 0.5530 (0.5704)	loss 2.8662 (3.3893)	grad_norm 1.4006 (1.3637)	mem 17417MB
[2023-02-01 08:57:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][750/1251]	eta 0:04:45 lr 0.000759	time 0.5526 (0.5706)	loss 2.5936 (3.3881)	grad_norm 1.2814 (1.3636)	mem 17417MB
[2023-02-01 08:57:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][800/1251]	eta 0:04:17 lr 0.000759	time 0.5594 (0.5704)	loss 3.3332 (3.3890)	grad_norm 1.3519 (1.3620)	mem 17417MB
[2023-02-01 08:58:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][850/1251]	eta 0:03:48 lr 0.000758	time 0.5556 (0.5702)	loss 3.9505 (3.3795)	grad_norm 1.5422 (1.3614)	mem 17417MB
[2023-02-01 08:58:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][900/1251]	eta 0:03:20 lr 0.000758	time 0.6282 (0.5701)	loss 3.0215 (3.3865)	grad_norm 1.2577 (1.3598)	mem 17417MB
[2023-02-01 08:59:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][950/1251]	eta 0:02:51 lr 0.000758	time 0.5508 (0.5700)	loss 4.1121 (3.3978)	grad_norm 1.4239 (1.3588)	mem 17417MB
[2023-02-01 08:59:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][1000/1251]	eta 0:02:23 lr 0.000758	time 0.5530 (0.5698)	loss 3.8779 (3.3994)	grad_norm 1.3705 (1.3606)	mem 17417MB
[2023-02-01 09:00:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][1050/1251]	eta 0:01:54 lr 0.000758	time 0.5469 (0.5698)	loss 3.5149 (3.4036)	grad_norm 1.4045 (1.3607)	mem 17417MB
[2023-02-01 09:00:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][1100/1251]	eta 0:01:26 lr 0.000758	time 0.6334 (0.5697)	loss 3.7897 (3.4021)	grad_norm 1.3067 (1.3607)	mem 17417MB
[2023-02-01 09:00:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][1150/1251]	eta 0:00:57 lr 0.000757	time 0.6259 (0.5696)	loss 4.1454 (3.4017)	grad_norm 1.3827 (1.3609)	mem 17417MB
[2023-02-01 09:01:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][1200/1251]	eta 0:00:29 lr 0.000757	time 0.5718 (0.5694)	loss 2.2473 (3.4037)	grad_norm 1.3474 (1.3605)	mem 17417MB
[2023-02-01 09:01:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [98/300][1250/1251]	eta 0:00:00 lr 0.000757	time 0.5507 (0.5694)	loss 3.4968 (3.4004)	grad_norm 1.4648 (1.3614)	mem 17417MB
[2023-02-01 09:01:55 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 98 training takes 0:11:52
[2023-02-01 09:01:55 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_98.pth saving......
[2023-02-01 09:01:57 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_98.pth saved !!!
[2023-02-01 09:01:58 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.960 (0.960)	Loss 0.9159 (0.9159)	Acc@1 79.395 (79.395)	Acc@5 94.238 (94.238)	Mem 17417MB
[2023-02-01 09:02:06 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.648 Acc@5 94.164
[2023-02-01 09:02:06 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.6%
[2023-02-01 09:02:07 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.222 (1.222)	Loss 0.8253 (0.8253)	Acc@1 80.859 (80.859)	Acc@5 94.824 (94.824)	Mem 17417MB
[2023-02-01 09:02:15 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.094 Acc@5 95.324
[2023-02-01 09:02:15 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.1%
[2023-02-01 09:02:15 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.09% at 98 epoch
[2023-02-01 09:02:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][0/1251]	eta 0:33:50 lr 0.000757	time 1.6230 (1.6230)	loss 2.9694 (2.9694)	grad_norm 1.4967 (1.4967)	mem 17417MB
[2023-02-01 09:02:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][50/1251]	eta 0:11:53 lr 0.000757	time 0.5587 (0.5942)	loss 3.2788 (3.4454)	grad_norm 1.3311 (1.3636)	mem 17417MB
[2023-02-01 09:03:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][100/1251]	eta 0:11:09 lr 0.000757	time 0.5575 (0.5819)	loss 2.1811 (3.3291)	grad_norm 1.3917 (1.3691)	mem 17417MB
[2023-02-01 09:03:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][150/1251]	eta 0:10:36 lr 0.000756	time 0.5543 (0.5782)	loss 3.3558 (3.3016)	grad_norm 1.5111 (1.3675)	mem 17417MB
[2023-02-01 09:04:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][200/1251]	eta 0:10:04 lr 0.000756	time 0.5684 (0.5756)	loss 3.1912 (3.3358)	grad_norm 1.4266 (1.3592)	mem 17417MB
[2023-02-01 09:04:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][250/1251]	eta 0:09:35 lr 0.000756	time 0.5599 (0.5751)	loss 3.4932 (3.3516)	grad_norm 1.3599 (1.3615)	mem 17417MB
[2023-02-01 09:05:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][300/1251]	eta 0:09:05 lr 0.000756	time 0.5596 (0.5740)	loss 2.4349 (3.3511)	grad_norm 1.2819 (1.3671)	mem 17417MB
[2023-02-01 09:05:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][350/1251]	eta 0:08:36 lr 0.000756	time 0.5517 (0.5735)	loss 2.7405 (3.3748)	grad_norm 1.3724 (1.3621)	mem 17417MB
[2023-02-01 09:06:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][400/1251]	eta 0:08:07 lr 0.000756	time 0.6249 (0.5725)	loss 3.1270 (3.3915)	grad_norm 1.6567 (1.3670)	mem 17417MB
[2023-02-01 09:06:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][450/1251]	eta 0:07:38 lr 0.000755	time 0.5580 (0.5724)	loss 2.7142 (3.3919)	grad_norm 1.4580 (1.3669)	mem 17417MB
[2023-02-01 09:07:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][500/1251]	eta 0:07:09 lr 0.000755	time 0.5560 (0.5720)	loss 2.6369 (3.3902)	grad_norm 1.3859 (1.3693)	mem 17417MB
[2023-02-01 09:07:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][550/1251]	eta 0:06:40 lr 0.000755	time 0.5750 (0.5718)	loss 2.4203 (3.3817)	grad_norm 1.5079 (1.3696)	mem 17417MB
[2023-02-01 09:07:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][600/1251]	eta 0:06:12 lr 0.000755	time 0.5551 (0.5716)	loss 3.8002 (3.3843)	grad_norm 1.3509 (1.3684)	mem 17417MB
[2023-02-01 09:08:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][650/1251]	eta 0:05:43 lr 0.000755	time 0.5550 (0.5718)	loss 4.2787 (3.3821)	grad_norm 1.3013 (1.3691)	mem 17417MB
[2023-02-01 09:08:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][700/1251]	eta 0:05:14 lr 0.000754	time 0.5580 (0.5713)	loss 3.4732 (3.3768)	grad_norm 1.2811 (1.3687)	mem 17417MB
[2023-02-01 09:09:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][750/1251]	eta 0:04:46 lr 0.000754	time 0.5567 (0.5713)	loss 3.7937 (3.3776)	grad_norm 1.1970 (1.3674)	mem 17417MB
[2023-02-01 09:09:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][800/1251]	eta 0:04:17 lr 0.000754	time 0.5578 (0.5711)	loss 3.3244 (3.3836)	grad_norm 1.2519 (1.3670)	mem 17417MB
[2023-02-01 09:10:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][850/1251]	eta 0:03:48 lr 0.000754	time 0.6168 (0.5710)	loss 3.0188 (3.3890)	grad_norm 1.3929 (1.3670)	mem 17417MB
[2023-02-01 09:10:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][900/1251]	eta 0:03:20 lr 0.000754	time 0.5540 (0.5710)	loss 2.7456 (3.3909)	grad_norm 1.3778 (1.3655)	mem 17417MB
[2023-02-01 09:11:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][950/1251]	eta 0:02:51 lr 0.000754	time 0.5526 (0.5709)	loss 3.8904 (3.3948)	grad_norm 1.5945 (1.3673)	mem 17417MB
[2023-02-01 09:11:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][1000/1251]	eta 0:02:23 lr 0.000753	time 0.5557 (0.5707)	loss 2.8933 (3.3980)	grad_norm 1.2368 (1.3661)	mem 17417MB
[2023-02-01 09:12:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][1050/1251]	eta 0:01:54 lr 0.000753	time 0.5552 (0.5707)	loss 2.5602 (3.3968)	grad_norm 1.3785 (1.3668)	mem 17417MB
[2023-02-01 09:12:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][1100/1251]	eta 0:01:26 lr 0.000753	time 0.5531 (0.5705)	loss 2.7531 (3.3971)	grad_norm 1.2539 (1.3679)	mem 17417MB
[2023-02-01 09:13:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][1150/1251]	eta 0:00:57 lr 0.000753	time 0.6180 (0.5704)	loss 3.8712 (3.3983)	grad_norm 1.5191 (1.3685)	mem 17417MB
[2023-02-01 09:13:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][1200/1251]	eta 0:00:29 lr 0.000753	time 0.5556 (0.5703)	loss 3.9198 (3.4017)	grad_norm 1.3839 (1.3679)	mem 17417MB
[2023-02-01 09:14:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [99/300][1250/1251]	eta 0:00:00 lr 0.000753	time 0.5531 (0.5703)	loss 4.3958 (3.4081)	grad_norm 1.5780 (1.3695)	mem 17417MB
[2023-02-01 09:14:09 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 99 training takes 0:11:53
[2023-02-01 09:14:09 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_99.pth saving......
[2023-02-01 09:14:11 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_99.pth saved !!!
[2023-02-01 09:14:11 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.868 (0.868)	Loss 1.0411 (1.0411)	Acc@1 75.293 (75.293)	Acc@5 93.457 (93.457)	Mem 17417MB
[2023-02-01 09:14:20 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.800 Acc@5 94.238
[2023-02-01 09:14:20 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.8%
[2023-02-01 09:14:21 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.187 (1.187)	Loss 0.8101 (0.8101)	Acc@1 79.590 (79.590)	Acc@5 95.801 (95.801)	Mem 17417MB
[2023-02-01 09:14:29 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.132 Acc@5 95.364
[2023-02-01 09:14:29 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.1%
[2023-02-01 09:14:29 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.13% at 99 epoch
[2023-02-01 09:14:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][0/1251]	eta 0:36:46 lr 0.000753	time 1.7641 (1.7641)	loss 2.7636 (2.7636)	grad_norm 1.3940 (1.3940)	mem 17417MB
[2023-02-01 09:14:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][50/1251]	eta 0:11:55 lr 0.000752	time 0.5634 (0.5959)	loss 4.2367 (3.4013)	grad_norm 1.4220 (1.3675)	mem 17417MB
[2023-02-01 09:15:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][100/1251]	eta 0:11:12 lr 0.000752	time 0.6129 (0.5844)	loss 2.4571 (3.3794)	grad_norm 1.3334 (1.3647)	mem 17417MB
[2023-02-01 09:15:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][150/1251]	eta 0:10:36 lr 0.000752	time 0.5550 (0.5778)	loss 3.6363 (3.3177)	grad_norm 1.2910 (1.3707)	mem 17417MB
[2023-02-01 09:16:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][200/1251]	eta 0:10:05 lr 0.000752	time 0.5575 (0.5766)	loss 3.0777 (3.3148)	grad_norm 1.4305 (1.3681)	mem 17417MB
[2023-02-01 09:16:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][250/1251]	eta 0:09:35 lr 0.000752	time 0.6208 (0.5745)	loss 3.2263 (3.3349)	grad_norm 1.3123 (1.3662)	mem 17417MB
[2023-02-01 09:17:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][300/1251]	eta 0:09:05 lr 0.000751	time 0.5515 (0.5738)	loss 3.1123 (3.3317)	grad_norm 1.2366 (1.3690)	mem 17417MB
[2023-02-01 09:17:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][350/1251]	eta 0:08:36 lr 0.000751	time 0.5827 (0.5730)	loss 3.2555 (3.3527)	grad_norm 1.3635 (1.3680)	mem 17417MB
[2023-02-01 09:18:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][400/1251]	eta 0:08:06 lr 0.000751	time 0.5592 (0.5721)	loss 3.2832 (3.3466)	grad_norm 1.3026 (1.3672)	mem 17417MB
[2023-02-01 09:18:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][450/1251]	eta 0:07:37 lr 0.000751	time 0.5530 (0.5715)	loss 2.7526 (3.3521)	grad_norm 1.2880 (nan)	mem 17417MB
[2023-02-01 09:19:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][500/1251]	eta 0:07:09 lr 0.000751	time 0.6191 (0.5712)	loss 3.6068 (3.3636)	grad_norm 1.3614 (nan)	mem 17417MB
[2023-02-01 09:19:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][550/1251]	eta 0:06:40 lr 0.000751	time 0.5548 (0.5711)	loss 4.2596 (3.3734)	grad_norm 1.3573 (nan)	mem 17417MB
[2023-02-01 09:20:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][600/1251]	eta 0:06:11 lr 0.000750	time 0.5535 (0.5712)	loss 3.0391 (3.3858)	grad_norm 1.2938 (nan)	mem 17417MB
[2023-02-01 09:20:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][650/1251]	eta 0:05:43 lr 0.000750	time 0.5557 (0.5708)	loss 2.6786 (3.3802)	grad_norm 1.3537 (nan)	mem 17417MB
[2023-02-01 09:21:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][700/1251]	eta 0:05:14 lr 0.000750	time 0.5466 (0.5707)	loss 3.9756 (3.3940)	grad_norm 1.3275 (nan)	mem 17417MB
[2023-02-01 09:21:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][750/1251]	eta 0:04:46 lr 0.000750	time 0.5629 (0.5709)	loss 4.2029 (3.3874)	grad_norm 1.4476 (nan)	mem 17417MB
[2023-02-01 09:22:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][800/1251]	eta 0:04:17 lr 0.000750	time 0.5555 (0.5705)	loss 3.6680 (3.3869)	grad_norm 1.3183 (nan)	mem 17417MB
[2023-02-01 09:22:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][850/1251]	eta 0:03:48 lr 0.000749	time 0.6237 (0.5707)	loss 2.9203 (3.3806)	grad_norm 1.2262 (nan)	mem 17417MB
[2023-02-01 09:23:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][900/1251]	eta 0:03:20 lr 0.000749	time 0.6189 (0.5706)	loss 3.7328 (3.3843)	grad_norm 1.4332 (nan)	mem 17417MB
[2023-02-01 09:23:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][950/1251]	eta 0:02:51 lr 0.000749	time 0.5593 (0.5704)	loss 3.1186 (3.3864)	grad_norm 1.3588 (nan)	mem 17417MB
[2023-02-01 09:24:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][1000/1251]	eta 0:02:23 lr 0.000749	time 0.5680 (0.5705)	loss 3.1502 (3.3819)	grad_norm 1.1849 (nan)	mem 17417MB
[2023-02-01 09:24:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][1050/1251]	eta 0:01:54 lr 0.000749	time 0.5545 (0.5704)	loss 3.3768 (3.3779)	grad_norm 1.3357 (nan)	mem 17417MB
[2023-02-01 09:24:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][1100/1251]	eta 0:01:26 lr 0.000749	time 0.6219 (0.5704)	loss 2.9966 (3.3870)	grad_norm 1.3679 (nan)	mem 17417MB
[2023-02-01 09:25:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][1150/1251]	eta 0:00:57 lr 0.000748	time 0.5587 (0.5705)	loss 2.6945 (3.3879)	grad_norm 1.3063 (nan)	mem 17417MB
[2023-02-01 09:25:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][1200/1251]	eta 0:00:29 lr 0.000748	time 0.5585 (0.5703)	loss 2.9411 (3.3851)	grad_norm 1.4566 (nan)	mem 17417MB
[2023-02-01 09:26:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [100/300][1250/1251]	eta 0:00:00 lr 0.000748	time 0.5512 (0.5703)	loss 3.4935 (3.3847)	grad_norm 1.3628 (nan)	mem 17417MB
[2023-02-01 09:26:22 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 100 training takes 0:11:53
[2023-02-01 09:26:23 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_100.pth saving......
[2023-02-01 09:26:25 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_100.pth saved !!!
[2023-02-01 09:26:26 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.867 (0.867)	Loss 0.8749 (0.8749)	Acc@1 79.199 (79.199)	Acc@5 95.020 (95.020)	Mem 17417MB
[2023-02-01 09:26:34 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.032 Acc@5 94.260
[2023-02-01 09:26:34 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.0%
[2023-02-01 09:26:35 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.339 (1.339)	Loss 0.7984 (0.7984)	Acc@1 80.859 (80.859)	Acc@5 95.703 (95.703)	Mem 17417MB
[2023-02-01 09:26:43 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.164 Acc@5 95.398
[2023-02-01 09:26:43 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.2%
[2023-02-01 09:26:43 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.16% at 100 epoch
[2023-02-01 09:26:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][0/1251]	eta 0:35:36 lr 0.000748	time 1.7080 (1.7080)	loss 2.9803 (2.9803)	grad_norm 1.2342 (1.2342)	mem 17417MB
[2023-02-01 09:27:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][50/1251]	eta 0:11:58 lr 0.000748	time 0.5534 (0.5980)	loss 3.7356 (3.3512)	grad_norm 1.3003 (1.3245)	mem 17417MB
[2023-02-01 09:27:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][100/1251]	eta 0:11:12 lr 0.000748	time 0.6157 (0.5841)	loss 3.6490 (3.4041)	grad_norm 1.2704 (1.3477)	mem 17417MB
[2023-02-01 09:28:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][150/1251]	eta 0:10:38 lr 0.000747	time 0.5526 (0.5796)	loss 3.4439 (3.4182)	grad_norm 1.3976 (1.3563)	mem 17417MB
[2023-02-01 09:28:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][200/1251]	eta 0:10:06 lr 0.000747	time 0.5589 (0.5773)	loss 3.4949 (3.4243)	grad_norm 1.4299 (1.3594)	mem 17417MB
[2023-02-01 09:29:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][250/1251]	eta 0:09:36 lr 0.000747	time 0.5610 (0.5758)	loss 2.8609 (3.3942)	grad_norm 1.4545 (1.3654)	mem 17417MB
[2023-02-01 09:29:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][300/1251]	eta 0:09:06 lr 0.000747	time 0.5592 (0.5750)	loss 3.2757 (3.3819)	grad_norm 1.5014 (1.3582)	mem 17417MB
[2023-02-01 09:30:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][350/1251]	eta 0:08:37 lr 0.000747	time 0.5694 (0.5745)	loss 3.3581 (3.3840)	grad_norm 1.2899 (1.3562)	mem 17417MB
[2023-02-01 09:30:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][400/1251]	eta 0:08:08 lr 0.000747	time 0.5570 (0.5737)	loss 3.0112 (3.3735)	grad_norm 1.5302 (1.3558)	mem 17417MB
[2023-02-01 09:31:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][450/1251]	eta 0:07:39 lr 0.000746	time 0.6193 (0.5736)	loss 2.5056 (3.3703)	grad_norm 1.4135 (1.3594)	mem 17417MB
[2023-02-01 09:31:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][500/1251]	eta 0:07:10 lr 0.000746	time 0.6186 (0.5728)	loss 2.7594 (3.3753)	grad_norm 1.2165 (1.3604)	mem 17417MB
[2023-02-01 09:31:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][550/1251]	eta 0:06:41 lr 0.000746	time 0.5558 (0.5727)	loss 3.3839 (3.3771)	grad_norm 1.4626 (1.3614)	mem 17417MB
[2023-02-01 09:32:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][600/1251]	eta 0:06:12 lr 0.000746	time 0.5548 (0.5726)	loss 3.1040 (3.3799)	grad_norm 1.3545 (1.3638)	mem 17417MB
[2023-02-01 09:32:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][650/1251]	eta 0:05:44 lr 0.000746	time 0.5606 (0.5725)	loss 3.8427 (3.3806)	grad_norm 1.3389 (1.3649)	mem 17417MB
[2023-02-01 09:33:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][700/1251]	eta 0:05:15 lr 0.000745	time 0.5660 (0.5723)	loss 3.9046 (3.3801)	grad_norm 1.2475 (1.3660)	mem 17417MB
[2023-02-01 09:33:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][750/1251]	eta 0:04:46 lr 0.000745	time 0.5567 (0.5720)	loss 3.4040 (3.3831)	grad_norm 1.3838 (1.3672)	mem 17417MB
[2023-02-01 09:34:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][800/1251]	eta 0:04:17 lr 0.000745	time 0.5532 (0.5720)	loss 3.4643 (3.3865)	grad_norm 1.3009 (1.3659)	mem 17417MB
[2023-02-01 09:34:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][850/1251]	eta 0:03:49 lr 0.000745	time 0.5554 (0.5721)	loss 3.8407 (3.3855)	grad_norm 1.3269 (1.3658)	mem 17417MB
[2023-02-01 09:35:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][900/1251]	eta 0:03:20 lr 0.000745	time 0.6207 (0.5719)	loss 3.3904 (3.3873)	grad_norm 1.2949 (1.3674)	mem 17417MB
[2023-02-01 09:35:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][950/1251]	eta 0:02:52 lr 0.000745	time 0.5576 (0.5720)	loss 2.6237 (3.3875)	grad_norm 1.3291 (1.3674)	mem 17417MB
[2023-02-01 09:36:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][1000/1251]	eta 0:02:23 lr 0.000744	time 0.5577 (0.5718)	loss 2.9522 (3.3857)	grad_norm 1.2332 (1.3645)	mem 17417MB
[2023-02-01 09:36:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][1050/1251]	eta 0:01:54 lr 0.000744	time 0.5672 (0.5717)	loss 4.0423 (3.3833)	grad_norm 1.2006 (1.3625)	mem 17417MB
[2023-02-01 09:37:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][1100/1251]	eta 0:01:26 lr 0.000744	time 0.5560 (0.5717)	loss 3.5925 (3.3841)	grad_norm 1.3775 (1.3631)	mem 17417MB
[2023-02-01 09:37:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][1150/1251]	eta 0:00:57 lr 0.000744	time 0.6293 (0.5716)	loss 4.0484 (3.3853)	grad_norm 1.4823 (1.3649)	mem 17417MB
[2023-02-01 09:38:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][1200/1251]	eta 0:00:29 lr 0.000744	time 0.5484 (0.5715)	loss 3.7363 (3.3875)	grad_norm 1.2162 (1.3657)	mem 17417MB
[2023-02-01 09:38:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [101/300][1250/1251]	eta 0:00:00 lr 0.000743	time 0.5485 (0.5714)	loss 4.0588 (3.3891)	grad_norm 1.3064 (nan)	mem 17417MB
[2023-02-01 09:38:38 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 101 training takes 0:11:54
[2023-02-01 09:38:38 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_101.pth saving......
[2023-02-01 09:38:40 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_101.pth saved !!!
[2023-02-01 09:38:41 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.862 (0.862)	Loss 0.9143 (0.9143)	Acc@1 78.516 (78.516)	Acc@5 95.801 (95.801)	Mem 17417MB
[2023-02-01 09:38:49 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.564 Acc@5 94.318
[2023-02-01 09:38:49 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.6%
[2023-02-01 09:38:50 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.229 (1.229)	Loss 0.8326 (0.8326)	Acc@1 80.273 (80.273)	Acc@5 95.117 (95.117)	Mem 17417MB
[2023-02-01 09:38:58 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.212 Acc@5 95.444
[2023-02-01 09:38:58 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.2%
[2023-02-01 09:38:58 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.21% at 101 epoch
[2023-02-01 09:39:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][0/1251]	eta 0:36:54 lr 0.000743	time 1.7704 (1.7704)	loss 3.6997 (3.6997)	grad_norm 1.3839 (1.3839)	mem 17417MB
[2023-02-01 09:39:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][50/1251]	eta 0:11:49 lr 0.000743	time 0.5522 (0.5909)	loss 3.8703 (3.3800)	grad_norm 1.5688 (1.3727)	mem 17417MB
[2023-02-01 09:39:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][100/1251]	eta 0:11:06 lr 0.000743	time 0.5560 (0.5793)	loss 4.3524 (3.3202)	grad_norm 1.4202 (1.4068)	mem 17417MB
[2023-02-01 09:40:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][150/1251]	eta 0:10:32 lr 0.000743	time 0.5581 (0.5747)	loss 2.0678 (3.2904)	grad_norm 1.4271 (1.3847)	mem 17417MB
[2023-02-01 09:40:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][200/1251]	eta 0:10:02 lr 0.000743	time 0.5614 (0.5737)	loss 3.5545 (3.2918)	grad_norm 1.4780 (1.3835)	mem 17417MB
[2023-02-01 09:41:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][250/1251]	eta 0:09:32 lr 0.000743	time 0.5552 (0.5724)	loss 3.7688 (3.3148)	grad_norm 1.5598 (1.3865)	mem 17417MB
[2023-02-01 09:41:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][300/1251]	eta 0:09:03 lr 0.000742	time 0.5626 (0.5719)	loss 3.4573 (3.3539)	grad_norm 1.4660 (1.3866)	mem 17417MB
[2023-02-01 09:42:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][350/1251]	eta 0:08:34 lr 0.000742	time 0.5619 (0.5709)	loss 2.7825 (3.3707)	grad_norm 1.3281 (1.3815)	mem 17417MB
[2023-02-01 09:42:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][400/1251]	eta 0:08:06 lr 0.000742	time 0.5582 (0.5712)	loss 3.7327 (3.3672)	grad_norm 1.4886 (1.3836)	mem 17417MB
[2023-02-01 09:43:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][450/1251]	eta 0:07:37 lr 0.000742	time 0.6203 (0.5708)	loss 3.1423 (3.3761)	grad_norm 1.4452 (1.3839)	mem 17417MB
[2023-02-01 09:43:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][500/1251]	eta 0:07:08 lr 0.000742	time 0.5511 (0.5708)	loss 3.0058 (3.3618)	grad_norm 1.1951 (1.3852)	mem 17417MB
[2023-02-01 09:44:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][550/1251]	eta 0:06:39 lr 0.000741	time 0.5488 (0.5704)	loss 3.5805 (3.3545)	grad_norm 1.4627 (1.3823)	mem 17417MB
[2023-02-01 09:44:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][600/1251]	eta 0:06:11 lr 0.000741	time 0.6365 (0.5705)	loss 2.9334 (3.3582)	grad_norm 1.3065 (1.3808)	mem 17417MB
[2023-02-01 09:45:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][650/1251]	eta 0:05:42 lr 0.000741	time 0.5629 (0.5702)	loss 2.9067 (3.3592)	grad_norm 1.2976 (1.3796)	mem 17417MB
[2023-02-01 09:45:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][700/1251]	eta 0:05:14 lr 0.000741	time 0.5576 (0.5705)	loss 3.8377 (3.3586)	grad_norm 1.3950 (1.3803)	mem 17417MB
[2023-02-01 09:46:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][750/1251]	eta 0:04:45 lr 0.000741	time 0.5560 (0.5701)	loss 3.5255 (3.3559)	grad_norm 1.3513 (1.3800)	mem 17417MB
[2023-02-01 09:46:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][800/1251]	eta 0:04:17 lr 0.000741	time 0.6500 (0.5701)	loss 3.3947 (3.3650)	grad_norm 1.2112 (1.3814)	mem 17417MB
[2023-02-01 09:47:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][850/1251]	eta 0:03:48 lr 0.000740	time 0.6216 (0.5698)	loss 2.4788 (3.3682)	grad_norm 1.3677 (1.3808)	mem 17417MB
[2023-02-01 09:47:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][900/1251]	eta 0:03:19 lr 0.000740	time 0.5496 (0.5697)	loss 4.0340 (3.3696)	grad_norm 1.4235 (1.3818)	mem 17417MB
[2023-02-01 09:48:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][950/1251]	eta 0:02:51 lr 0.000740	time 0.5565 (0.5696)	loss 3.5427 (3.3765)	grad_norm 1.4753 (1.3841)	mem 17417MB
[2023-02-01 09:48:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][1000/1251]	eta 0:02:22 lr 0.000740	time 0.5610 (0.5697)	loss 3.8945 (3.3738)	grad_norm 1.3695 (1.3833)	mem 17417MB
[2023-02-01 09:48:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][1050/1251]	eta 0:01:54 lr 0.000740	time 0.5643 (0.5695)	loss 4.1626 (3.3754)	grad_norm 1.2986 (1.3828)	mem 17417MB
[2023-02-01 09:49:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][1100/1251]	eta 0:01:25 lr 0.000739	time 0.6477 (0.5695)	loss 4.1091 (3.3741)	grad_norm 1.3214 (nan)	mem 17417MB
[2023-02-01 09:49:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][1150/1251]	eta 0:00:57 lr 0.000739	time 0.5615 (0.5694)	loss 3.5029 (3.3703)	grad_norm 1.2379 (nan)	mem 17417MB
[2023-02-01 09:50:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][1200/1251]	eta 0:00:29 lr 0.000739	time 0.6282 (0.5694)	loss 2.9397 (3.3694)	grad_norm 1.2673 (nan)	mem 17417MB
[2023-02-01 09:50:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [102/300][1250/1251]	eta 0:00:00 lr 0.000739	time 0.5490 (0.5692)	loss 3.7282 (3.3688)	grad_norm 1.4254 (nan)	mem 17417MB
[2023-02-01 09:50:50 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 102 training takes 0:11:52
[2023-02-01 09:50:50 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_102.pth saving......
[2023-02-01 09:50:52 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_102.pth saved !!!
[2023-02-01 09:50:53 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.911 (0.911)	Loss 0.9847 (0.9847)	Acc@1 76.660 (76.660)	Acc@5 93.750 (93.750)	Mem 17417MB
[2023-02-01 09:51:01 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.642 Acc@5 94.202
[2023-02-01 09:51:01 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.6%
[2023-02-01 09:51:02 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.280 (1.280)	Loss 0.7853 (0.7853)	Acc@1 81.055 (81.055)	Acc@5 95.801 (95.801)	Mem 17417MB
[2023-02-01 09:51:10 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.244 Acc@5 95.440
[2023-02-01 09:51:10 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.2%
[2023-02-01 09:51:10 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.24% at 102 epoch
[2023-02-01 09:51:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][0/1251]	eta 0:36:12 lr 0.000739	time 1.7364 (1.7364)	loss 3.5457 (3.5457)	grad_norm 1.4479 (1.4479)	mem 17417MB
[2023-02-01 09:51:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][50/1251]	eta 0:11:51 lr 0.000739	time 0.5550 (0.5921)	loss 4.0453 (3.2380)	grad_norm 1.5124 (1.3557)	mem 17417MB
[2023-02-01 09:52:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][100/1251]	eta 0:11:11 lr 0.000739	time 0.6366 (0.5833)	loss 3.8242 (3.3370)	grad_norm 1.3774 (1.3672)	mem 17417MB
[2023-02-01 09:52:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][150/1251]	eta 0:10:36 lr 0.000738	time 0.5537 (0.5780)	loss 3.8442 (3.3457)	grad_norm 1.4090 (1.3701)	mem 17417MB
[2023-02-01 09:53:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][200/1251]	eta 0:10:05 lr 0.000738	time 0.6298 (0.5759)	loss 3.9943 (3.3564)	grad_norm 1.3091 (1.3689)	mem 17417MB
[2023-02-01 09:53:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][250/1251]	eta 0:09:34 lr 0.000738	time 0.5576 (0.5744)	loss 2.6718 (3.3715)	grad_norm 1.4585 (1.3765)	mem 17417MB
[2023-02-01 09:54:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][300/1251]	eta 0:09:05 lr 0.000738	time 0.5580 (0.5736)	loss 3.1115 (3.3543)	grad_norm 1.2605 (1.3736)	mem 17417MB
[2023-02-01 09:54:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][350/1251]	eta 0:08:36 lr 0.000738	time 0.5536 (0.5731)	loss 2.8894 (3.3490)	grad_norm 1.3196 (1.3748)	mem 17417MB
[2023-02-01 09:55:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][400/1251]	eta 0:08:07 lr 0.000737	time 0.5614 (0.5730)	loss 3.8499 (3.3567)	grad_norm 1.2613 (1.3743)	mem 17417MB
[2023-02-01 09:55:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][450/1251]	eta 0:07:38 lr 0.000737	time 0.5511 (0.5723)	loss 3.5629 (3.3652)	grad_norm 1.2361 (1.3766)	mem 17417MB
[2023-02-01 09:55:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][500/1251]	eta 0:07:09 lr 0.000737	time 0.5463 (0.5718)	loss 3.4012 (3.3593)	grad_norm 1.2762 (1.3761)	mem 17417MB
[2023-02-01 09:56:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][550/1251]	eta 0:06:40 lr 0.000737	time 0.5559 (0.5716)	loss 3.1372 (3.3526)	grad_norm 1.5088 (1.3767)	mem 17417MB
[2023-02-01 09:56:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][600/1251]	eta 0:06:12 lr 0.000737	time 0.5593 (0.5715)	loss 2.2137 (3.3550)	grad_norm 1.1565 (1.3739)	mem 17417MB
[2023-02-01 09:57:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][650/1251]	eta 0:05:43 lr 0.000737	time 0.5590 (0.5713)	loss 2.9581 (3.3646)	grad_norm 1.3364 (1.3725)	mem 17417MB
[2023-02-01 09:57:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][700/1251]	eta 0:05:14 lr 0.000736	time 0.5562 (0.5712)	loss 2.7417 (3.3666)	grad_norm 1.3544 (1.3746)	mem 17417MB
[2023-02-01 09:58:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][750/1251]	eta 0:04:46 lr 0.000736	time 0.5657 (0.5710)	loss 3.6243 (3.3684)	grad_norm 1.4367 (1.3747)	mem 17417MB
[2023-02-01 09:58:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][800/1251]	eta 0:04:17 lr 0.000736	time 0.6171 (0.5709)	loss 4.1381 (3.3608)	grad_norm 1.4962 (1.3768)	mem 17417MB
[2023-02-01 09:59:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][850/1251]	eta 0:03:48 lr 0.000736	time 0.5514 (0.5707)	loss 3.6177 (3.3641)	grad_norm 1.4403 (1.3768)	mem 17417MB
[2023-02-01 09:59:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][900/1251]	eta 0:03:20 lr 0.000736	time 0.6293 (0.5708)	loss 3.7978 (3.3613)	grad_norm 1.2544 (1.3743)	mem 17417MB
[2023-02-01 10:00:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][950/1251]	eta 0:02:51 lr 0.000735	time 0.5557 (0.5708)	loss 3.7957 (3.3697)	grad_norm 1.3336 (1.3749)	mem 17417MB
[2023-02-01 10:00:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][1000/1251]	eta 0:02:23 lr 0.000735	time 0.5572 (0.5706)	loss 3.5349 (3.3737)	grad_norm 1.3900 (1.3773)	mem 17417MB
[2023-02-01 10:01:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][1050/1251]	eta 0:01:54 lr 0.000735	time 0.5611 (0.5706)	loss 4.3454 (3.3741)	grad_norm 1.4734 (1.3759)	mem 17417MB
[2023-02-01 10:01:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][1100/1251]	eta 0:01:26 lr 0.000735	time 0.6341 (0.5705)	loss 3.5832 (3.3726)	grad_norm 1.1989 (1.3773)	mem 17417MB
[2023-02-01 10:02:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][1150/1251]	eta 0:00:57 lr 0.000735	time 0.5640 (0.5704)	loss 3.2700 (3.3769)	grad_norm 1.4908 (1.3781)	mem 17417MB
[2023-02-01 10:02:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][1200/1251]	eta 0:00:29 lr 0.000735	time 0.5583 (0.5704)	loss 3.8726 (3.3767)	grad_norm 1.4707 (1.3783)	mem 17417MB
[2023-02-01 10:03:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [103/300][1250/1251]	eta 0:00:00 lr 0.000734	time 0.5527 (0.5704)	loss 3.5243 (3.3772)	grad_norm 1.5389 (1.3782)	mem 17417MB
[2023-02-01 10:03:04 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 103 training takes 0:11:53
[2023-02-01 10:03:04 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_103.pth saving......
[2023-02-01 10:03:06 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_103.pth saved !!!
[2023-02-01 10:03:07 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.862 (0.862)	Loss 0.9897 (0.9897)	Acc@1 76.562 (76.562)	Acc@5 94.141 (94.141)	Mem 17417MB
[2023-02-01 10:03:15 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.658 Acc@5 94.300
[2023-02-01 10:03:15 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.7%
[2023-02-01 10:03:16 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.357 (1.357)	Loss 0.7907 (0.7907)	Acc@1 81.934 (81.934)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-01 10:03:24 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.308 Acc@5 95.432
[2023-02-01 10:03:24 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.3%
[2023-02-01 10:03:24 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.31% at 103 epoch
[2023-02-01 10:03:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][0/1251]	eta 0:37:34 lr 0.000734	time 1.8023 (1.8023)	loss 3.1622 (3.1622)	grad_norm 1.3955 (1.3955)	mem 17417MB
[2023-02-01 10:03:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][50/1251]	eta 0:11:57 lr 0.000734	time 0.6357 (0.5974)	loss 3.7479 (3.2479)	grad_norm 1.3250 (1.4091)	mem 17417MB
[2023-02-01 10:04:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][100/1251]	eta 0:11:11 lr 0.000734	time 0.5732 (0.5831)	loss 3.8286 (3.3561)	grad_norm 1.5497 (1.4004)	mem 17417MB
[2023-02-01 10:04:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][150/1251]	eta 0:10:35 lr 0.000734	time 0.5575 (0.5775)	loss 3.1108 (3.3687)	grad_norm 1.2030 (1.3881)	mem 17417MB
[2023-02-01 10:05:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][200/1251]	eta 0:10:03 lr 0.000734	time 0.5514 (0.5745)	loss 3.3099 (3.3899)	grad_norm 1.2955 (1.3807)	mem 17417MB
[2023-02-01 10:05:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][250/1251]	eta 0:09:33 lr 0.000733	time 0.5593 (0.5731)	loss 3.4433 (3.3720)	grad_norm 1.2949 (1.3766)	mem 17417MB
[2023-02-01 10:06:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][300/1251]	eta 0:09:04 lr 0.000733	time 0.5567 (0.5724)	loss 4.2184 (3.3831)	grad_norm 1.3515 (1.3777)	mem 17417MB
[2023-02-01 10:06:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][350/1251]	eta 0:08:35 lr 0.000733	time 0.5520 (0.5717)	loss 2.8837 (3.3605)	grad_norm 1.2350 (1.3757)	mem 17417MB
[2023-02-01 10:07:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][400/1251]	eta 0:08:05 lr 0.000733	time 0.5493 (0.5711)	loss 3.3051 (3.3690)	grad_norm 1.2922 (1.3788)	mem 17417MB
[2023-02-01 10:07:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][450/1251]	eta 0:07:37 lr 0.000733	time 0.6373 (0.5707)	loss 3.7391 (3.3505)	grad_norm 1.3961 (1.3764)	mem 17417MB
[2023-02-01 10:08:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][500/1251]	eta 0:07:08 lr 0.000732	time 0.5532 (0.5703)	loss 3.8806 (3.3581)	grad_norm 1.5149 (1.3818)	mem 17417MB
[2023-02-01 10:08:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][550/1251]	eta 0:06:39 lr 0.000732	time 0.5549 (0.5699)	loss 3.3967 (3.3680)	grad_norm 1.4149 (1.3813)	mem 17417MB
[2023-02-01 10:09:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][600/1251]	eta 0:06:11 lr 0.000732	time 0.5569 (0.5701)	loss 3.3275 (3.3579)	grad_norm 1.3722 (1.3866)	mem 17417MB
[2023-02-01 10:09:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][650/1251]	eta 0:05:42 lr 0.000732	time 0.5565 (0.5699)	loss 2.1325 (3.3565)	grad_norm 1.4667 (1.3830)	mem 17417MB
[2023-02-01 10:10:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][700/1251]	eta 0:05:14 lr 0.000732	time 0.5519 (0.5699)	loss 3.6147 (3.3564)	grad_norm 1.2838 (1.3839)	mem 17417MB
[2023-02-01 10:10:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][750/1251]	eta 0:04:45 lr 0.000732	time 0.5618 (0.5694)	loss 3.4750 (3.3641)	grad_norm 1.4452 (1.3836)	mem 17417MB
[2023-02-01 10:11:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][800/1251]	eta 0:04:16 lr 0.000731	time 0.5549 (0.5696)	loss 3.7936 (3.3679)	grad_norm 1.4576 (1.3837)	mem 17417MB
[2023-02-01 10:11:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][850/1251]	eta 0:03:48 lr 0.000731	time 0.6368 (0.5695)	loss 4.0676 (3.3715)	grad_norm 1.4176 (1.3846)	mem 17417MB
[2023-02-01 10:11:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][900/1251]	eta 0:03:19 lr 0.000731	time 0.5551 (0.5696)	loss 3.8422 (3.3707)	grad_norm 1.5329 (1.3854)	mem 17417MB
[2023-02-01 10:12:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][950/1251]	eta 0:02:51 lr 0.000731	time 0.5566 (0.5695)	loss 2.8466 (3.3669)	grad_norm 1.4522 (1.3837)	mem 17417MB
[2023-02-01 10:12:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][1000/1251]	eta 0:02:22 lr 0.000731	time 0.6403 (0.5695)	loss 3.5434 (3.3667)	grad_norm 1.5394 (1.3851)	mem 17417MB
[2023-02-01 10:13:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][1050/1251]	eta 0:01:54 lr 0.000730	time 0.5642 (0.5694)	loss 3.5174 (3.3697)	grad_norm 1.3594 (1.3842)	mem 17417MB
[2023-02-01 10:13:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][1100/1251]	eta 0:01:25 lr 0.000730	time 0.5569 (0.5695)	loss 4.0150 (3.3676)	grad_norm 1.3000 (1.3839)	mem 17417MB
[2023-02-01 10:14:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][1150/1251]	eta 0:00:57 lr 0.000730	time 0.5544 (0.5695)	loss 3.7545 (3.3706)	grad_norm 1.4584 (1.3843)	mem 17417MB
[2023-02-01 10:14:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][1200/1251]	eta 0:00:29 lr 0.000730	time 0.5534 (0.5694)	loss 2.2832 (3.3698)	grad_norm 1.4104 (1.3840)	mem 17417MB
[2023-02-01 10:15:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [104/300][1250/1251]	eta 0:00:00 lr 0.000730	time 0.6384 (0.5693)	loss 3.7107 (3.3706)	grad_norm 1.3646 (1.3853)	mem 17417MB
[2023-02-01 10:15:16 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 104 training takes 0:11:52
[2023-02-01 10:15:17 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_104.pth saving......
[2023-02-01 10:15:18 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_104.pth saved !!!
[2023-02-01 10:15:19 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.855 (0.855)	Loss 0.9431 (0.9431)	Acc@1 78.027 (78.027)	Acc@5 94.727 (94.727)	Mem 17417MB
[2023-02-01 10:15:27 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.252 Acc@5 94.522
[2023-02-01 10:15:27 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.3%
[2023-02-01 10:15:28 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.212 (1.212)	Loss 0.8477 (0.8477)	Acc@1 80.078 (80.078)	Acc@5 95.410 (95.410)	Mem 17417MB
[2023-02-01 10:15:36 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.360 Acc@5 95.466
[2023-02-01 10:15:36 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.4%
[2023-02-01 10:15:36 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.36% at 104 epoch
[2023-02-01 10:15:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][0/1251]	eta 0:35:07 lr 0.000730	time 1.6844 (1.6844)	loss 3.5183 (3.5183)	grad_norm 1.3222 (1.3222)	mem 17417MB
[2023-02-01 10:16:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][50/1251]	eta 0:11:49 lr 0.000730	time 0.5528 (0.5905)	loss 3.7533 (3.3931)	grad_norm 1.2889 (1.3707)	mem 17417MB
[2023-02-01 10:16:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][100/1251]	eta 0:11:11 lr 0.000729	time 0.5575 (0.5834)	loss 3.6986 (3.3026)	grad_norm 1.5429 (1.3947)	mem 17417MB
[2023-02-01 10:17:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][150/1251]	eta 0:10:36 lr 0.000729	time 0.5546 (0.5785)	loss 3.8402 (3.3157)	grad_norm 1.4717 (1.3826)	mem 17417MB
[2023-02-01 10:17:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][200/1251]	eta 0:10:05 lr 0.000729	time 0.5556 (0.5765)	loss 3.5673 (3.3004)	grad_norm 1.4281 (1.3824)	mem 17417MB
[2023-02-01 10:18:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][250/1251]	eta 0:09:35 lr 0.000729	time 0.5552 (0.5749)	loss 3.3857 (3.3090)	grad_norm 1.3575 (1.3856)	mem 17417MB
[2023-02-01 10:18:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][300/1251]	eta 0:09:06 lr 0.000729	time 0.5599 (0.5747)	loss 3.4959 (3.3251)	grad_norm 1.5016 (1.3830)	mem 17417MB
[2023-02-01 10:18:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][350/1251]	eta 0:08:36 lr 0.000728	time 0.5559 (0.5737)	loss 3.3041 (3.3173)	grad_norm 1.2639 (1.3800)	mem 17417MB
[2023-02-01 10:19:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][400/1251]	eta 0:08:08 lr 0.000728	time 0.5532 (0.5735)	loss 2.9461 (3.3158)	grad_norm 1.4851 (1.3761)	mem 17417MB
[2023-02-01 10:19:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][450/1251]	eta 0:07:38 lr 0.000728	time 0.5558 (0.5726)	loss 3.6920 (3.3215)	grad_norm 1.4130 (nan)	mem 17417MB
[2023-02-01 10:20:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][500/1251]	eta 0:07:09 lr 0.000728	time 0.5530 (0.5723)	loss 2.8135 (3.3304)	grad_norm 1.3314 (nan)	mem 17417MB
[2023-02-01 10:20:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][550/1251]	eta 0:06:40 lr 0.000728	time 0.6321 (0.5720)	loss 3.6736 (3.3303)	grad_norm 1.2197 (nan)	mem 17417MB
[2023-02-01 10:21:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][600/1251]	eta 0:06:12 lr 0.000728	time 0.5574 (0.5720)	loss 2.7978 (3.3253)	grad_norm 1.3701 (nan)	mem 17417MB
[2023-02-01 10:21:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][650/1251]	eta 0:05:43 lr 0.000727	time 0.5550 (0.5718)	loss 3.8613 (3.3287)	grad_norm 1.3604 (nan)	mem 17417MB
[2023-02-01 10:22:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][700/1251]	eta 0:05:15 lr 0.000727	time 0.6293 (0.5719)	loss 3.8599 (3.3349)	grad_norm 1.3493 (nan)	mem 17417MB
[2023-02-01 10:22:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][750/1251]	eta 0:04:46 lr 0.000727	time 0.5553 (0.5717)	loss 3.8816 (3.3444)	grad_norm 1.3925 (nan)	mem 17417MB
[2023-02-01 10:23:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][800/1251]	eta 0:04:17 lr 0.000727	time 0.6286 (0.5718)	loss 3.8159 (3.3437)	grad_norm 1.2963 (nan)	mem 17417MB
[2023-02-01 10:23:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][850/1251]	eta 0:03:49 lr 0.000727	time 0.5643 (0.5716)	loss 2.6698 (3.3494)	grad_norm 1.3063 (nan)	mem 17417MB
[2023-02-01 10:24:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][900/1251]	eta 0:03:20 lr 0.000726	time 0.5554 (0.5716)	loss 3.0574 (3.3506)	grad_norm 1.4673 (nan)	mem 17417MB
[2023-02-01 10:24:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][950/1251]	eta 0:02:52 lr 0.000726	time 0.5765 (0.5715)	loss 3.5880 (3.3571)	grad_norm 1.4549 (nan)	mem 17417MB
[2023-02-01 10:25:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][1000/1251]	eta 0:02:23 lr 0.000726	time 0.6123 (0.5716)	loss 3.3323 (3.3536)	grad_norm 1.5084 (nan)	mem 17417MB
[2023-02-01 10:25:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][1050/1251]	eta 0:01:54 lr 0.000726	time 0.5586 (0.5715)	loss 3.3797 (3.3568)	grad_norm 1.3609 (nan)	mem 17417MB
[2023-02-01 10:26:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][1100/1251]	eta 0:01:26 lr 0.000726	time 0.5575 (0.5714)	loss 2.5133 (3.3581)	grad_norm 1.4070 (nan)	mem 17417MB
[2023-02-01 10:26:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][1150/1251]	eta 0:00:57 lr 0.000725	time 0.5589 (0.5714)	loss 3.6166 (3.3635)	grad_norm 1.2653 (nan)	mem 17417MB
[2023-02-01 10:27:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][1200/1251]	eta 0:00:29 lr 0.000725	time 0.5531 (0.5714)	loss 3.5338 (3.3656)	grad_norm 1.3010 (nan)	mem 17417MB
[2023-02-01 10:27:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [105/300][1250/1251]	eta 0:00:00 lr 0.000725	time 0.5481 (0.5713)	loss 2.8258 (3.3657)	grad_norm 1.3274 (nan)	mem 17417MB
[2023-02-01 10:27:31 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 105 training takes 0:11:54
[2023-02-01 10:27:32 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_105.pth saving......
[2023-02-01 10:27:33 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_105.pth saved !!!
[2023-02-01 10:27:34 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.865 (0.865)	Loss 0.9464 (0.9464)	Acc@1 78.809 (78.809)	Acc@5 93.750 (93.750)	Mem 17417MB
[2023-02-01 10:27:42 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.904 Acc@5 94.416
[2023-02-01 10:27:42 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 77.9%
[2023-02-01 10:27:43 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.231 (1.231)	Loss 0.6893 (0.6893)	Acc@1 83.008 (83.008)	Acc@5 97.168 (97.168)	Mem 17417MB
[2023-02-01 10:27:51 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.388 Acc@5 95.480
[2023-02-01 10:27:51 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.4%
[2023-02-01 10:27:51 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.39% at 105 epoch
[2023-02-01 10:27:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][0/1251]	eta 0:34:47 lr 0.000725	time 1.6685 (1.6685)	loss 3.5034 (3.5034)	grad_norm 1.3094 (1.3094)	mem 17417MB
[2023-02-01 10:28:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][50/1251]	eta 0:11:54 lr 0.000725	time 0.6413 (0.5951)	loss 3.9572 (3.3279)	grad_norm 1.3353 (1.3865)	mem 17417MB
[2023-02-01 10:28:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][100/1251]	eta 0:11:10 lr 0.000725	time 0.5519 (0.5830)	loss 3.1263 (3.3172)	grad_norm 1.2978 (1.3947)	mem 17417MB
[2023-02-01 10:29:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][150/1251]	eta 0:10:37 lr 0.000725	time 0.6214 (0.5794)	loss 2.9301 (3.2610)	grad_norm 1.2627 (1.3840)	mem 17417MB
[2023-02-01 10:29:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][200/1251]	eta 0:10:05 lr 0.000724	time 0.5571 (0.5761)	loss 3.6612 (3.3025)	grad_norm 1.3799 (1.3794)	mem 17417MB
[2023-02-01 10:30:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][250/1251]	eta 0:09:35 lr 0.000724	time 0.6251 (0.5751)	loss 3.0664 (3.3411)	grad_norm 1.2318 (1.3802)	mem 17417MB
[2023-02-01 10:30:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][300/1251]	eta 0:09:05 lr 0.000724	time 0.5578 (0.5740)	loss 3.0787 (3.3497)	grad_norm 1.4736 (1.3779)	mem 17417MB
[2023-02-01 10:31:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][350/1251]	eta 0:08:36 lr 0.000724	time 0.5661 (0.5732)	loss 3.1105 (3.3666)	grad_norm 1.4224 (1.3834)	mem 17417MB
[2023-02-01 10:31:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][400/1251]	eta 0:08:07 lr 0.000724	time 0.5591 (0.5726)	loss 3.3583 (3.3720)	grad_norm 1.4040 (1.3836)	mem 17417MB
[2023-02-01 10:32:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][450/1251]	eta 0:07:38 lr 0.000723	time 0.5555 (0.5723)	loss 3.7897 (3.3750)	grad_norm 1.2719 (1.3859)	mem 17417MB
[2023-02-01 10:32:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][500/1251]	eta 0:07:09 lr 0.000723	time 0.5516 (0.5718)	loss 3.7774 (3.3856)	grad_norm 1.4774 (1.3851)	mem 17417MB
[2023-02-01 10:33:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][550/1251]	eta 0:06:40 lr 0.000723	time 0.5589 (0.5718)	loss 3.1265 (3.3837)	grad_norm 1.9938 (1.3872)	mem 17417MB
[2023-02-01 10:33:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][600/1251]	eta 0:06:12 lr 0.000723	time 0.5484 (0.5717)	loss 2.8888 (3.3757)	grad_norm 1.4158 (1.3877)	mem 17417MB
[2023-02-01 10:34:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][650/1251]	eta 0:05:43 lr 0.000723	time 0.5561 (0.5716)	loss 3.2371 (3.3830)	grad_norm 1.2049 (1.3876)	mem 17417MB
[2023-02-01 10:34:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][700/1251]	eta 0:05:14 lr 0.000722	time 0.5597 (0.5714)	loss 2.3732 (3.3804)	grad_norm 1.4618 (1.3870)	mem 17417MB
[2023-02-01 10:35:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][750/1251]	eta 0:04:46 lr 0.000722	time 0.5584 (0.5710)	loss 3.7732 (3.3862)	grad_norm 1.5333 (1.3856)	mem 17417MB
[2023-02-01 10:35:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][800/1251]	eta 0:04:17 lr 0.000722	time 0.5587 (0.5709)	loss 3.7392 (3.3824)	grad_norm 1.3571 (1.3847)	mem 17417MB
[2023-02-01 10:35:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][850/1251]	eta 0:03:48 lr 0.000722	time 0.5610 (0.5710)	loss 3.9970 (3.3839)	grad_norm 1.5032 (1.3853)	mem 17417MB
[2023-02-01 10:36:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][900/1251]	eta 0:03:20 lr 0.000722	time 0.5545 (0.5709)	loss 3.4654 (3.3864)	grad_norm 1.3992 (1.3862)	mem 17417MB
[2023-02-01 10:36:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][950/1251]	eta 0:02:51 lr 0.000722	time 0.5482 (0.5709)	loss 4.1029 (3.3802)	grad_norm 1.3739 (1.3856)	mem 17417MB
[2023-02-01 10:37:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][1000/1251]	eta 0:02:23 lr 0.000721	time 0.5551 (0.5707)	loss 3.5110 (3.3845)	grad_norm 1.3407 (1.3846)	mem 17417MB
[2023-02-01 10:37:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][1050/1251]	eta 0:01:54 lr 0.000721	time 0.5539 (0.5706)	loss 2.6142 (3.3810)	grad_norm 1.2853 (1.3849)	mem 17417MB
[2023-02-01 10:38:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][1100/1251]	eta 0:01:26 lr 0.000721	time 0.5519 (0.5707)	loss 4.0316 (3.3829)	grad_norm 1.3817 (1.3836)	mem 17417MB
[2023-02-01 10:38:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][1150/1251]	eta 0:00:57 lr 0.000721	time 0.5581 (0.5705)	loss 3.5597 (3.3781)	grad_norm 1.5070 (1.3837)	mem 17417MB
[2023-02-01 10:39:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][1200/1251]	eta 0:00:29 lr 0.000721	time 0.5564 (0.5706)	loss 2.6270 (3.3740)	grad_norm 1.5732 (1.3843)	mem 17417MB
[2023-02-01 10:39:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [106/300][1250/1251]	eta 0:00:00 lr 0.000720	time 0.5522 (0.5705)	loss 3.2954 (3.3734)	grad_norm 1.3067 (1.3840)	mem 17417MB
[2023-02-01 10:39:45 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 106 training takes 0:11:53
[2023-02-01 10:39:45 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_106.pth saving......
[2023-02-01 10:39:47 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_106.pth saved !!!
[2023-02-01 10:39:48 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.866 (0.866)	Loss 1.0199 (1.0199)	Acc@1 76.367 (76.367)	Acc@5 93.555 (93.555)	Mem 17417MB
[2023-02-01 10:39:56 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.116 Acc@5 94.440
[2023-02-01 10:39:56 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.1%
[2023-02-01 10:39:57 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.318 (1.318)	Loss 0.8117 (0.8117)	Acc@1 79.590 (79.590)	Acc@5 95.801 (95.801)	Mem 17417MB
[2023-02-01 10:40:05 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.414 Acc@5 95.514
[2023-02-01 10:40:05 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.4%
[2023-02-01 10:40:05 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.41% at 106 epoch
[2023-02-01 10:40:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][0/1251]	eta 0:35:45 lr 0.000720	time 1.7154 (1.7154)	loss 2.0088 (2.0088)	grad_norm 1.3008 (1.3008)	mem 17417MB
[2023-02-01 10:40:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][50/1251]	eta 0:11:46 lr 0.000720	time 0.5535 (0.5885)	loss 3.1475 (3.2607)	grad_norm 1.4431 (1.3901)	mem 17417MB
[2023-02-01 10:41:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][100/1251]	eta 0:11:10 lr 0.000720	time 0.5567 (0.5823)	loss 3.9391 (3.3176)	grad_norm 1.3455 (1.3778)	mem 17417MB
[2023-02-01 10:41:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][150/1251]	eta 0:10:34 lr 0.000720	time 0.5602 (0.5767)	loss 3.0622 (3.3135)	grad_norm 1.5246 (1.3702)	mem 17417MB
[2023-02-01 10:42:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][200/1251]	eta 0:10:04 lr 0.000720	time 0.5577 (0.5749)	loss 2.8008 (3.3151)	grad_norm 1.5879 (1.3728)	mem 17417MB
[2023-02-01 10:42:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][250/1251]	eta 0:09:33 lr 0.000720	time 0.5580 (0.5731)	loss 3.5369 (3.3213)	grad_norm 1.4906 (1.3755)	mem 17417MB
[2023-02-01 10:42:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][300/1251]	eta 0:09:04 lr 0.000719	time 0.5598 (0.5724)	loss 3.8015 (3.3427)	grad_norm 1.3143 (1.3708)	mem 17417MB
[2023-02-01 10:43:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][350/1251]	eta 0:08:34 lr 0.000719	time 0.5550 (0.5713)	loss 3.7102 (3.3564)	grad_norm 1.3686 (1.3747)	mem 17417MB
[2023-02-01 10:43:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][400/1251]	eta 0:08:06 lr 0.000719	time 0.5611 (0.5716)	loss 3.8964 (3.3590)	grad_norm 1.2597 (1.3788)	mem 17417MB
[2023-02-01 10:44:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][450/1251]	eta 0:07:37 lr 0.000719	time 0.5555 (0.5708)	loss 3.0661 (3.3600)	grad_norm 1.2560 (1.3767)	mem 17417MB
[2023-02-01 10:44:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][500/1251]	eta 0:07:08 lr 0.000719	time 0.5581 (0.5705)	loss 2.5613 (3.3588)	grad_norm 1.2902 (1.3780)	mem 17417MB
[2023-02-01 10:45:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][550/1251]	eta 0:06:39 lr 0.000718	time 0.5501 (0.5704)	loss 4.1786 (3.3557)	grad_norm 1.5188 (1.3812)	mem 17417MB
[2023-02-01 10:45:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][600/1251]	eta 0:06:11 lr 0.000718	time 0.5543 (0.5701)	loss 2.7878 (3.3544)	grad_norm 1.2832 (1.3799)	mem 17417MB
[2023-02-01 10:46:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][650/1251]	eta 0:05:42 lr 0.000718	time 0.5728 (0.5702)	loss 2.7876 (3.3642)	grad_norm 1.4545 (1.3821)	mem 17417MB
[2023-02-01 10:46:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][700/1251]	eta 0:05:13 lr 0.000718	time 0.5481 (0.5698)	loss 3.7827 (3.3624)	grad_norm 1.4763 (1.3839)	mem 17417MB
[2023-02-01 10:47:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][750/1251]	eta 0:04:45 lr 0.000718	time 0.5513 (0.5697)	loss 2.5598 (3.3553)	grad_norm 1.3057 (1.3852)	mem 17417MB
[2023-02-01 10:47:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][800/1251]	eta 0:04:16 lr 0.000717	time 0.5587 (0.5695)	loss 3.8758 (3.3613)	grad_norm 1.3541 (1.3837)	mem 17417MB
[2023-02-01 10:48:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][850/1251]	eta 0:03:48 lr 0.000717	time 0.5565 (0.5692)	loss 4.0832 (3.3661)	grad_norm 1.3423 (1.3813)	mem 17417MB
[2023-02-01 10:48:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][900/1251]	eta 0:03:19 lr 0.000717	time 0.5604 (0.5693)	loss 2.8141 (3.3654)	grad_norm 1.2616 (1.3804)	mem 17417MB
[2023-02-01 10:49:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][950/1251]	eta 0:02:51 lr 0.000717	time 0.5627 (0.5694)	loss 2.6770 (3.3707)	grad_norm 1.2608 (1.3816)	mem 17417MB
[2023-02-01 10:49:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][1000/1251]	eta 0:02:22 lr 0.000717	time 0.5494 (0.5693)	loss 3.4273 (3.3716)	grad_norm 1.2798 (1.3826)	mem 17417MB
[2023-02-01 10:50:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][1050/1251]	eta 0:01:54 lr 0.000717	time 0.5722 (0.5694)	loss 3.2527 (3.3736)	grad_norm 1.3900 (1.3833)	mem 17417MB
[2023-02-01 10:50:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][1100/1251]	eta 0:01:25 lr 0.000716	time 0.6239 (0.5693)	loss 3.7879 (3.3769)	grad_norm 1.4895 (1.3812)	mem 17417MB
[2023-02-01 10:51:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][1150/1251]	eta 0:00:57 lr 0.000716	time 0.5508 (0.5692)	loss 2.8111 (3.3750)	grad_norm 1.3257 (1.3824)	mem 17417MB
[2023-02-01 10:51:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][1200/1251]	eta 0:00:29 lr 0.000716	time 0.5508 (0.5692)	loss 3.4930 (3.3748)	grad_norm 1.4273 (1.3816)	mem 17417MB
[2023-02-01 10:51:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [107/300][1250/1251]	eta 0:00:00 lr 0.000716	time 0.5504 (0.5692)	loss 2.4729 (3.3699)	grad_norm 1.5020 (1.3811)	mem 17417MB
[2023-02-01 10:51:57 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 107 training takes 0:11:52
[2023-02-01 10:51:57 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_107.pth saving......
[2023-02-01 10:51:59 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_107.pth saved !!!
[2023-02-01 10:52:00 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.021 (1.021)	Loss 0.9403 (0.9403)	Acc@1 77.051 (77.051)	Acc@5 94.434 (94.434)	Mem 17417MB
[2023-02-01 10:52:08 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.250 Acc@5 94.664
[2023-02-01 10:52:08 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.3%
[2023-02-01 10:52:09 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.260 (1.260)	Loss 0.8696 (0.8696)	Acc@1 79.004 (79.004)	Acc@5 94.824 (94.824)	Mem 17417MB
[2023-02-01 10:52:17 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.454 Acc@5 95.518
[2023-02-01 10:52:17 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.5%
[2023-02-01 10:52:17 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.45% at 107 epoch
[2023-02-01 10:52:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][0/1251]	eta 0:35:44 lr 0.000716	time 1.7142 (1.7142)	loss 3.5246 (3.5246)	grad_norm 1.2982 (1.2982)	mem 17417MB
[2023-02-01 10:52:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][50/1251]	eta 0:11:51 lr 0.000716	time 0.5750 (0.5928)	loss 2.6512 (3.4447)	grad_norm 1.4539 (1.4420)	mem 17417MB
[2023-02-01 10:53:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][100/1251]	eta 0:11:08 lr 0.000715	time 0.6469 (0.5804)	loss 3.9575 (3.3952)	grad_norm 1.4059 (1.4215)	mem 17417MB
[2023-02-01 10:53:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][150/1251]	eta 0:10:33 lr 0.000715	time 0.5571 (0.5758)	loss 2.0899 (3.4147)	grad_norm 1.3333 (1.4171)	mem 17417MB
[2023-02-01 10:54:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][200/1251]	eta 0:10:03 lr 0.000715	time 0.5544 (0.5741)	loss 3.8239 (3.4056)	grad_norm 1.3284 (1.4115)	mem 17417MB
[2023-02-01 10:54:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][250/1251]	eta 0:09:32 lr 0.000715	time 0.5644 (0.5724)	loss 2.8885 (3.4008)	grad_norm 1.3828 (1.4148)	mem 17417MB
[2023-02-01 10:55:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][300/1251]	eta 0:09:03 lr 0.000715	time 0.5574 (0.5720)	loss 3.8538 (3.4015)	grad_norm 1.3694 (1.4032)	mem 17417MB
[2023-02-01 10:55:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][350/1251]	eta 0:08:35 lr 0.000714	time 0.5565 (0.5717)	loss 3.3797 (3.4029)	grad_norm 1.3494 (1.4046)	mem 17417MB
[2023-02-01 10:56:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][400/1251]	eta 0:08:05 lr 0.000714	time 0.5541 (0.5709)	loss 3.2405 (3.3743)	grad_norm 1.4914 (1.3976)	mem 17417MB
[2023-02-01 10:56:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][450/1251]	eta 0:07:37 lr 0.000714	time 0.5593 (0.5707)	loss 3.7323 (3.3895)	grad_norm 1.2892 (1.3965)	mem 17417MB
[2023-02-01 10:57:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][500/1251]	eta 0:07:08 lr 0.000714	time 0.6427 (0.5701)	loss 2.1730 (3.3840)	grad_norm 1.5461 (1.3967)	mem 17417MB
[2023-02-01 10:57:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][550/1251]	eta 0:06:39 lr 0.000714	time 0.5551 (0.5701)	loss 3.6836 (3.3863)	grad_norm 1.2116 (1.3936)	mem 17417MB
[2023-02-01 10:58:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][600/1251]	eta 0:06:10 lr 0.000714	time 0.5558 (0.5698)	loss 2.5929 (3.3916)	grad_norm 1.3233 (1.3903)	mem 17417MB
[2023-02-01 10:58:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][650/1251]	eta 0:05:42 lr 0.000713	time 0.5559 (0.5698)	loss 3.9799 (3.3917)	grad_norm 1.2416 (1.3870)	mem 17417MB
[2023-02-01 10:58:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][700/1251]	eta 0:05:13 lr 0.000713	time 0.5620 (0.5695)	loss 2.5185 (3.3865)	grad_norm 1.4840 (nan)	mem 17417MB
[2023-02-01 10:59:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][750/1251]	eta 0:04:45 lr 0.000713	time 0.5545 (0.5694)	loss 3.7704 (3.3836)	grad_norm 1.3584 (nan)	mem 17417MB
[2023-02-01 10:59:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][800/1251]	eta 0:04:16 lr 0.000713	time 0.5560 (0.5690)	loss 3.7466 (3.3831)	grad_norm 1.4542 (nan)	mem 17417MB
[2023-02-01 11:00:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][850/1251]	eta 0:03:48 lr 0.000713	time 0.5545 (0.5691)	loss 3.9791 (3.3916)	grad_norm 1.3958 (nan)	mem 17417MB
[2023-02-01 11:00:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][900/1251]	eta 0:03:19 lr 0.000712	time 0.6430 (0.5689)	loss 2.8231 (3.3880)	grad_norm 1.5597 (nan)	mem 17417MB
[2023-02-01 11:01:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][950/1251]	eta 0:02:51 lr 0.000712	time 0.5579 (0.5689)	loss 3.8083 (3.3871)	grad_norm 1.3350 (nan)	mem 17417MB
[2023-02-01 11:01:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][1000/1251]	eta 0:02:22 lr 0.000712	time 0.5583 (0.5687)	loss 4.0940 (3.3923)	grad_norm 1.5180 (nan)	mem 17417MB
[2023-02-01 11:02:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][1050/1251]	eta 0:01:54 lr 0.000712	time 0.5547 (0.5688)	loss 2.8157 (3.3879)	grad_norm 1.3973 (nan)	mem 17417MB
[2023-02-01 11:02:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][1100/1251]	eta 0:01:25 lr 0.000712	time 0.5576 (0.5688)	loss 3.0571 (3.3910)	grad_norm 1.5575 (nan)	mem 17417MB
[2023-02-01 11:03:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][1150/1251]	eta 0:00:57 lr 0.000711	time 0.5589 (0.5686)	loss 3.6214 (3.3886)	grad_norm 1.3451 (nan)	mem 17417MB
[2023-02-01 11:03:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][1200/1251]	eta 0:00:28 lr 0.000711	time 0.6235 (0.5685)	loss 3.0636 (3.3930)	grad_norm 1.3620 (nan)	mem 17417MB
[2023-02-01 11:04:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [108/300][1250/1251]	eta 0:00:00 lr 0.000711	time 0.5503 (0.5686)	loss 3.9590 (3.3952)	grad_norm 1.2008 (nan)	mem 17417MB
[2023-02-01 11:04:09 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 108 training takes 0:11:51
[2023-02-01 11:04:09 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_108.pth saving......
[2023-02-01 11:04:11 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_108.pth saved !!!
[2023-02-01 11:04:11 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.836 (0.836)	Loss 0.9547 (0.9547)	Acc@1 76.465 (76.465)	Acc@5 94.336 (94.336)	Mem 17417MB
[2023-02-01 11:04:19 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 77.954 Acc@5 94.502
[2023-02-01 11:04:19 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.0%
[2023-02-01 11:04:21 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.207 (1.207)	Loss 0.7706 (0.7706)	Acc@1 81.543 (81.543)	Acc@5 96.582 (96.582)	Mem 17417MB
[2023-02-01 11:04:29 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.470 Acc@5 95.544
[2023-02-01 11:04:29 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.5%
[2023-02-01 11:04:29 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.47% at 108 epoch
[2023-02-01 11:04:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][0/1251]	eta 0:35:08 lr 0.000711	time 1.6852 (1.6852)	loss 3.1978 (3.1978)	grad_norm 1.2411 (1.2411)	mem 17417MB
[2023-02-01 11:04:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][50/1251]	eta 0:11:47 lr 0.000711	time 0.5584 (0.5894)	loss 3.6322 (3.3374)	grad_norm 1.3006 (1.3892)	mem 17417MB
[2023-02-01 11:05:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][100/1251]	eta 0:11:05 lr 0.000711	time 0.5484 (0.5786)	loss 3.3284 (3.3059)	grad_norm 1.5370 (1.3798)	mem 17417MB
[2023-02-01 11:05:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][150/1251]	eta 0:10:31 lr 0.000710	time 0.5596 (0.5733)	loss 3.7974 (3.3028)	grad_norm 1.3500 (1.3924)	mem 17417MB
[2023-02-01 11:06:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][200/1251]	eta 0:10:01 lr 0.000710	time 0.6134 (0.5726)	loss 3.1284 (3.2926)	grad_norm 1.4308 (1.3855)	mem 17417MB
[2023-02-01 11:06:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][250/1251]	eta 0:09:32 lr 0.000710	time 0.5570 (0.5715)	loss 2.6855 (3.3359)	grad_norm 1.3901 (1.3871)	mem 17417MB
[2023-02-01 11:07:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][300/1251]	eta 0:09:03 lr 0.000710	time 0.5549 (0.5713)	loss 3.3215 (3.3198)	grad_norm 1.1745 (1.3885)	mem 17417MB
[2023-02-01 11:07:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][350/1251]	eta 0:08:34 lr 0.000710	time 0.5532 (0.5710)	loss 3.7797 (3.3213)	grad_norm 1.5797 (1.3919)	mem 17417MB
[2023-02-01 11:08:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][400/1251]	eta 0:08:05 lr 0.000710	time 0.5507 (0.5706)	loss 2.1288 (3.3326)	grad_norm 1.4250 (1.3886)	mem 17417MB
[2023-02-01 11:08:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][450/1251]	eta 0:07:36 lr 0.000709	time 0.6566 (0.5703)	loss 3.3250 (3.3318)	grad_norm 1.4053 (1.3919)	mem 17417MB
[2023-02-01 11:09:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][500/1251]	eta 0:07:08 lr 0.000709	time 0.5580 (0.5700)	loss 4.2514 (3.3388)	grad_norm 1.3453 (1.3940)	mem 17417MB
[2023-02-01 11:09:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][550/1251]	eta 0:06:39 lr 0.000709	time 0.5505 (0.5697)	loss 3.7733 (3.3480)	grad_norm 1.8052 (1.3952)	mem 17417MB
[2023-02-01 11:10:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][600/1251]	eta 0:06:11 lr 0.000709	time 0.5557 (0.5699)	loss 3.3349 (3.3487)	grad_norm 1.4948 (1.3966)	mem 17417MB
[2023-02-01 11:10:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][650/1251]	eta 0:05:42 lr 0.000709	time 0.5537 (0.5696)	loss 3.9614 (3.3574)	grad_norm 1.4754 (1.3996)	mem 17417MB
[2023-02-01 11:11:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][700/1251]	eta 0:05:13 lr 0.000708	time 0.5516 (0.5695)	loss 3.6539 (3.3641)	grad_norm 1.4306 (1.4001)	mem 17417MB
[2023-02-01 11:11:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][750/1251]	eta 0:04:45 lr 0.000708	time 0.5576 (0.5691)	loss 3.1437 (3.3654)	grad_norm 1.5605 (1.4005)	mem 17417MB
[2023-02-01 11:12:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][800/1251]	eta 0:04:16 lr 0.000708	time 0.5527 (0.5692)	loss 3.8536 (3.3628)	grad_norm 1.4631 (1.3999)	mem 17417MB
[2023-02-01 11:12:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][850/1251]	eta 0:03:48 lr 0.000708	time 0.5557 (0.5688)	loss 3.0343 (3.3565)	grad_norm 1.4823 (1.3997)	mem 17417MB
[2023-02-01 11:13:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][900/1251]	eta 0:03:19 lr 0.000708	time 0.5550 (0.5690)	loss 2.9836 (3.3539)	grad_norm 1.5281 (1.3996)	mem 17417MB
[2023-02-01 11:13:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][950/1251]	eta 0:02:51 lr 0.000707	time 0.5608 (0.5687)	loss 3.5104 (3.3605)	grad_norm 1.3795 (1.4003)	mem 17417MB
[2023-02-01 11:13:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][1000/1251]	eta 0:02:22 lr 0.000707	time 0.5577 (0.5688)	loss 2.6426 (3.3587)	grad_norm 1.2761 (1.4016)	mem 17417MB
[2023-02-01 11:14:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][1050/1251]	eta 0:01:54 lr 0.000707	time 0.5574 (0.5687)	loss 3.0253 (3.3531)	grad_norm 1.3614 (1.4019)	mem 17417MB
[2023-02-01 11:14:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][1100/1251]	eta 0:01:25 lr 0.000707	time 0.5545 (0.5687)	loss 3.7070 (3.3539)	grad_norm 1.2188 (1.4010)	mem 17417MB
[2023-02-01 11:15:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][1150/1251]	eta 0:00:57 lr 0.000707	time 0.5608 (0.5688)	loss 3.7553 (3.3530)	grad_norm 1.5026 (1.3999)	mem 17417MB
[2023-02-01 11:15:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][1200/1251]	eta 0:00:29 lr 0.000707	time 0.6276 (0.5687)	loss 2.4912 (3.3515)	grad_norm 1.4005 (1.3999)	mem 17417MB
[2023-02-01 11:16:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [109/300][1250/1251]	eta 0:00:00 lr 0.000706	time 0.5511 (0.5686)	loss 3.0365 (3.3510)	grad_norm 1.3747 (1.3995)	mem 17417MB
[2023-02-01 11:16:20 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 109 training takes 0:11:51
[2023-02-01 11:16:20 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_109.pth saving......
[2023-02-01 11:16:22 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_109.pth saved !!!
[2023-02-01 11:16:23 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.897 (0.897)	Loss 0.8876 (0.8876)	Acc@1 79.102 (79.102)	Acc@5 95.215 (95.215)	Mem 17417MB
[2023-02-01 11:16:31 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.120 Acc@5 94.578
[2023-02-01 11:16:31 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.1%
[2023-02-01 11:16:32 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.228 (1.228)	Loss 0.7604 (0.7604)	Acc@1 81.543 (81.543)	Acc@5 95.605 (95.605)	Mem 17417MB
[2023-02-01 11:16:40 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.510 Acc@5 95.564
[2023-02-01 11:16:40 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.5%
[2023-02-01 11:16:40 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.51% at 109 epoch
[2023-02-01 11:16:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][0/1251]	eta 0:34:50 lr 0.000706	time 1.6713 (1.6713)	loss 4.0431 (4.0431)	grad_norm 1.1800 (1.1800)	mem 17417MB
[2023-02-01 11:17:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][50/1251]	eta 0:11:51 lr 0.000706	time 0.5583 (0.5926)	loss 3.2855 (3.3441)	grad_norm 1.2131 (1.3516)	mem 17417MB
[2023-02-01 11:17:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][100/1251]	eta 0:11:07 lr 0.000706	time 0.5574 (0.5803)	loss 3.1236 (3.3182)	grad_norm 1.3927 (1.3758)	mem 17417MB
[2023-02-01 11:18:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][150/1251]	eta 0:10:34 lr 0.000706	time 0.5525 (0.5760)	loss 3.6167 (3.3340)	grad_norm 1.5100 (1.3782)	mem 17417MB
[2023-02-01 11:18:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][200/1251]	eta 0:10:03 lr 0.000706	time 0.5612 (0.5742)	loss 3.6356 (3.3468)	grad_norm 1.3582 (1.3796)	mem 17417MB
[2023-02-01 11:19:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][250/1251]	eta 0:09:33 lr 0.000705	time 0.5568 (0.5734)	loss 2.4010 (3.3395)	grad_norm 1.4089 (1.3836)	mem 17417MB
[2023-02-01 11:19:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][300/1251]	eta 0:09:04 lr 0.000705	time 0.5541 (0.5722)	loss 1.9376 (3.3426)	grad_norm 1.2358 (1.3824)	mem 17417MB
[2023-02-01 11:20:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][350/1251]	eta 0:08:35 lr 0.000705	time 0.5462 (0.5719)	loss 3.6389 (3.3307)	grad_norm 1.3285 (1.3815)	mem 17417MB
[2023-02-01 11:20:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][400/1251]	eta 0:08:06 lr 0.000705	time 0.5635 (0.5711)	loss 3.0075 (3.3397)	grad_norm 1.4504 (1.3858)	mem 17417MB
[2023-02-01 11:20:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][450/1251]	eta 0:07:37 lr 0.000705	time 0.5494 (0.5707)	loss 2.6312 (3.3404)	grad_norm 1.5369 (1.3864)	mem 17417MB
[2023-02-01 11:21:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][500/1251]	eta 0:07:08 lr 0.000704	time 0.5501 (0.5703)	loss 3.4775 (3.3453)	grad_norm 1.3806 (1.3858)	mem 17417MB
[2023-02-01 11:21:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][550/1251]	eta 0:06:39 lr 0.000704	time 0.5597 (0.5701)	loss 2.9550 (3.3546)	grad_norm 1.2897 (1.3888)	mem 17417MB
[2023-02-01 11:22:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][600/1251]	eta 0:06:11 lr 0.000704	time 0.5595 (0.5699)	loss 3.5916 (3.3551)	grad_norm 1.4616 (1.3894)	mem 17417MB
[2023-02-01 11:22:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][650/1251]	eta 0:05:42 lr 0.000704	time 0.5582 (0.5700)	loss 3.9731 (3.3583)	grad_norm 1.2676 (1.3902)	mem 17417MB
[2023-02-01 11:23:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][700/1251]	eta 0:05:13 lr 0.000704	time 0.5587 (0.5699)	loss 3.5044 (3.3493)	grad_norm 1.5375 (1.3926)	mem 17417MB
[2023-02-01 11:23:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][750/1251]	eta 0:04:45 lr 0.000703	time 0.5557 (0.5698)	loss 3.4141 (3.3454)	grad_norm 1.2648 (1.3911)	mem 17417MB
[2023-02-01 11:24:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][800/1251]	eta 0:04:16 lr 0.000703	time 0.6400 (0.5696)	loss 2.5779 (3.3420)	grad_norm 1.4236 (1.3903)	mem 17417MB
[2023-02-01 11:24:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][850/1251]	eta 0:03:48 lr 0.000703	time 0.5662 (0.5695)	loss 3.5232 (3.3427)	grad_norm 1.3201 (1.3903)	mem 17417MB
[2023-02-01 11:25:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][900/1251]	eta 0:03:19 lr 0.000703	time 0.5562 (0.5694)	loss 4.0358 (3.3374)	grad_norm 1.3032 (1.3929)	mem 17417MB
[2023-02-01 11:25:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][950/1251]	eta 0:02:51 lr 0.000703	time 0.5674 (0.5694)	loss 2.6457 (3.3362)	grad_norm 1.3553 (1.3935)	mem 17417MB
[2023-02-01 11:26:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][1000/1251]	eta 0:02:22 lr 0.000703	time 0.5534 (0.5694)	loss 3.5698 (3.3370)	grad_norm 1.3102 (1.3940)	mem 17417MB
[2023-02-01 11:26:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][1050/1251]	eta 0:01:54 lr 0.000702	time 0.5621 (0.5694)	loss 4.1707 (3.3329)	grad_norm 1.4246 (1.3958)	mem 17417MB
[2023-02-01 11:27:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][1100/1251]	eta 0:01:25 lr 0.000702	time 0.6256 (0.5692)	loss 3.9927 (3.3317)	grad_norm 1.6517 (1.3948)	mem 17417MB
[2023-02-01 11:27:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][1150/1251]	eta 0:00:57 lr 0.000702	time 0.6239 (0.5692)	loss 2.8307 (3.3334)	grad_norm 1.3622 (1.3942)	mem 17417MB
[2023-02-01 11:28:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][1200/1251]	eta 0:00:29 lr 0.000702	time 0.5612 (0.5691)	loss 3.6862 (3.3311)	grad_norm 1.2879 (1.3932)	mem 17417MB
[2023-02-01 11:28:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [110/300][1250/1251]	eta 0:00:00 lr 0.000702	time 0.5554 (0.5691)	loss 3.6372 (3.3336)	grad_norm 1.3073 (1.3929)	mem 17417MB
[2023-02-01 11:28:32 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 110 training takes 0:11:52
[2023-02-01 11:28:32 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_110.pth saving......
[2023-02-01 11:28:34 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_110.pth saved !!!
[2023-02-01 11:28:35 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.892 (0.892)	Loss 0.9443 (0.9443)	Acc@1 78.906 (78.906)	Acc@5 93.848 (93.848)	Mem 17417MB
[2023-02-01 11:28:43 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.254 Acc@5 94.512
[2023-02-01 11:28:43 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.3%
[2023-02-01 11:28:44 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.253 (1.253)	Loss 0.8886 (0.8886)	Acc@1 79.297 (79.297)	Acc@5 94.629 (94.629)	Mem 17417MB
[2023-02-01 11:28:52 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.522 Acc@5 95.592
[2023-02-01 11:28:52 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.5%
[2023-02-01 11:28:52 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.52% at 110 epoch
[2023-02-01 11:28:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][0/1251]	eta 0:34:51 lr 0.000702	time 1.6717 (1.6717)	loss 3.0586 (3.0586)	grad_norm 1.4632 (1.4632)	mem 17417MB
[2023-02-01 11:29:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][50/1251]	eta 0:11:57 lr 0.000701	time 0.6476 (0.5970)	loss 3.6974 (3.2925)	grad_norm 1.4559 (1.4213)	mem 17417MB
[2023-02-01 11:29:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][100/1251]	eta 0:11:10 lr 0.000701	time 0.5540 (0.5825)	loss 3.1458 (3.3539)	grad_norm 1.4200 (1.4137)	mem 17417MB
[2023-02-01 11:30:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][150/1251]	eta 0:10:37 lr 0.000701	time 0.5573 (0.5786)	loss 2.6194 (3.3071)	grad_norm 1.3541 (1.4122)	mem 17417MB
[2023-02-01 11:30:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][200/1251]	eta 0:10:05 lr 0.000701	time 0.5522 (0.5757)	loss 3.3020 (3.3289)	grad_norm 1.2201 (1.4135)	mem 17417MB
[2023-02-01 11:31:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][250/1251]	eta 0:09:35 lr 0.000701	time 0.5512 (0.5746)	loss 4.1301 (3.3415)	grad_norm 1.4302 (1.4161)	mem 17417MB
[2023-02-01 11:31:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][300/1251]	eta 0:09:05 lr 0.000700	time 0.5595 (0.5737)	loss 2.3346 (3.3375)	grad_norm 1.4179 (nan)	mem 17417MB
[2023-02-01 11:32:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][350/1251]	eta 0:08:36 lr 0.000700	time 0.5595 (0.5729)	loss 3.6537 (3.3281)	grad_norm 1.3949 (nan)	mem 17417MB
[2023-02-01 11:32:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][400/1251]	eta 0:08:07 lr 0.000700	time 0.6224 (0.5724)	loss 2.5796 (3.3274)	grad_norm 1.5113 (nan)	mem 17417MB
[2023-02-01 11:33:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][450/1251]	eta 0:07:38 lr 0.000700	time 0.5847 (0.5723)	loss 2.3971 (3.3372)	grad_norm 1.4108 (nan)	mem 17417MB
[2023-02-01 11:33:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][500/1251]	eta 0:07:09 lr 0.000700	time 0.5527 (0.5715)	loss 3.2975 (3.3449)	grad_norm 1.3109 (nan)	mem 17417MB
[2023-02-01 11:34:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][550/1251]	eta 0:06:40 lr 0.000699	time 0.5541 (0.5714)	loss 3.2341 (3.3455)	grad_norm 1.4972 (nan)	mem 17417MB
[2023-02-01 11:34:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][600/1251]	eta 0:06:11 lr 0.000699	time 0.5558 (0.5709)	loss 3.5013 (3.3485)	grad_norm 1.2527 (nan)	mem 17417MB
[2023-02-01 11:35:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][650/1251]	eta 0:05:43 lr 0.000699	time 0.5566 (0.5710)	loss 3.9187 (3.3509)	grad_norm 1.3471 (nan)	mem 17417MB
[2023-02-01 11:35:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][700/1251]	eta 0:05:14 lr 0.000699	time 0.5566 (0.5706)	loss 3.9303 (3.3554)	grad_norm 1.4829 (nan)	mem 17417MB
[2023-02-01 11:36:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][750/1251]	eta 0:04:45 lr 0.000699	time 0.5582 (0.5705)	loss 4.0483 (3.3501)	grad_norm 1.5320 (nan)	mem 17417MB
[2023-02-01 11:36:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][800/1251]	eta 0:04:17 lr 0.000699	time 0.5535 (0.5705)	loss 2.7534 (3.3491)	grad_norm 1.2320 (nan)	mem 17417MB
[2023-02-01 11:36:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][850/1251]	eta 0:03:48 lr 0.000698	time 0.6209 (0.5704)	loss 3.4721 (3.3503)	grad_norm 1.2669 (nan)	mem 17417MB
[2023-02-01 11:37:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][900/1251]	eta 0:03:20 lr 0.000698	time 0.5586 (0.5703)	loss 3.9871 (3.3483)	grad_norm 1.3260 (nan)	mem 17417MB
[2023-02-01 11:37:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][950/1251]	eta 0:02:51 lr 0.000698	time 0.5597 (0.5702)	loss 2.4856 (3.3494)	grad_norm 1.4929 (nan)	mem 17417MB
[2023-02-01 11:38:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][1000/1251]	eta 0:02:23 lr 0.000698	time 0.5534 (0.5702)	loss 3.1980 (3.3567)	grad_norm 1.4382 (nan)	mem 17417MB
[2023-02-01 11:38:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][1050/1251]	eta 0:01:54 lr 0.000698	time 0.5520 (0.5702)	loss 2.6800 (3.3619)	grad_norm 1.2976 (nan)	mem 17417MB
[2023-02-01 11:39:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][1100/1251]	eta 0:01:26 lr 0.000697	time 0.5586 (0.5702)	loss 2.5485 (3.3569)	grad_norm 1.3441 (nan)	mem 17417MB
[2023-02-01 11:39:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][1150/1251]	eta 0:00:57 lr 0.000697	time 0.6184 (0.5699)	loss 3.4108 (3.3523)	grad_norm 1.3559 (nan)	mem 17417MB
[2023-02-01 11:40:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][1200/1251]	eta 0:00:29 lr 0.000697	time 0.6375 (0.5700)	loss 3.8031 (3.3585)	grad_norm 1.3589 (nan)	mem 17417MB
[2023-02-01 11:40:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [111/300][1250/1251]	eta 0:00:00 lr 0.000697	time 0.5565 (0.5699)	loss 2.7646 (3.3568)	grad_norm 1.2503 (nan)	mem 17417MB
[2023-02-01 11:40:45 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 111 training takes 0:11:53
[2023-02-01 11:40:45 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_111.pth saving......
[2023-02-01 11:40:47 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_111.pth saved !!!
[2023-02-01 11:40:48 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.877 (0.877)	Loss 1.0119 (1.0119)	Acc@1 76.758 (76.758)	Acc@5 93.262 (93.262)	Mem 17417MB
[2023-02-01 11:40:56 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.110 Acc@5 94.466
[2023-02-01 11:40:56 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.1%
[2023-02-01 11:40:57 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.198 (1.198)	Loss 0.8333 (0.8333)	Acc@1 80.859 (80.859)	Acc@5 95.410 (95.410)	Mem 17417MB
[2023-02-01 11:41:05 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.574 Acc@5 95.602
[2023-02-01 11:41:05 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.6%
[2023-02-01 11:41:05 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.57% at 111 epoch
[2023-02-01 11:41:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][0/1251]	eta 0:35:12 lr 0.000697	time 1.6888 (1.6888)	loss 3.5770 (3.5770)	grad_norm 1.3253 (1.3253)	mem 17417MB
[2023-02-01 11:41:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][50/1251]	eta 0:11:49 lr 0.000697	time 0.5629 (0.5909)	loss 3.3512 (3.3340)	grad_norm 1.2734 (1.4126)	mem 17417MB
[2023-02-01 11:42:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][100/1251]	eta 0:11:09 lr 0.000696	time 0.5569 (0.5817)	loss 3.4410 (3.3578)	grad_norm 1.2112 (1.3975)	mem 17417MB
[2023-02-01 11:42:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][150/1251]	eta 0:10:34 lr 0.000696	time 0.5603 (0.5765)	loss 3.3979 (3.3449)	grad_norm 1.2307 (1.4112)	mem 17417MB
[2023-02-01 11:43:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][200/1251]	eta 0:10:05 lr 0.000696	time 0.5498 (0.5763)	loss 3.5748 (3.3352)	grad_norm 1.4276 (1.4077)	mem 17417MB
[2023-02-01 11:43:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][250/1251]	eta 0:09:34 lr 0.000696	time 0.5819 (0.5740)	loss 2.9706 (3.3166)	grad_norm 1.4033 (1.4060)	mem 17417MB
[2023-02-01 11:43:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][300/1251]	eta 0:09:05 lr 0.000696	time 0.6158 (0.5738)	loss 3.8616 (3.3153)	grad_norm 1.5189 (1.4038)	mem 17417MB
[2023-02-01 11:44:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][350/1251]	eta 0:08:35 lr 0.000695	time 0.5619 (0.5726)	loss 4.2081 (3.3190)	grad_norm 1.4919 (1.4078)	mem 17417MB
[2023-02-01 11:44:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][400/1251]	eta 0:08:07 lr 0.000695	time 0.5580 (0.5725)	loss 3.6438 (3.3386)	grad_norm 1.6070 (1.4097)	mem 17417MB
[2023-02-01 11:45:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][450/1251]	eta 0:07:38 lr 0.000695	time 0.5564 (0.5720)	loss 3.5951 (3.3395)	grad_norm 1.4410 (1.4092)	mem 17417MB
[2023-02-01 11:45:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][500/1251]	eta 0:07:09 lr 0.000695	time 0.5595 (0.5718)	loss 3.7301 (3.3356)	grad_norm 1.2839 (1.4082)	mem 17417MB
[2023-02-01 11:46:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][550/1251]	eta 0:06:40 lr 0.000695	time 0.5556 (0.5714)	loss 3.7181 (3.3448)	grad_norm 1.2078 (1.4081)	mem 17417MB
[2023-02-01 11:46:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][600/1251]	eta 0:06:12 lr 0.000695	time 0.5548 (0.5714)	loss 3.8534 (3.3349)	grad_norm 1.1334 (1.4089)	mem 17417MB
[2023-02-01 11:47:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][650/1251]	eta 0:05:43 lr 0.000694	time 0.5591 (0.5710)	loss 3.8345 (3.3358)	grad_norm 1.4857 (1.4118)	mem 17417MB
[2023-02-01 11:47:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][700/1251]	eta 0:05:14 lr 0.000694	time 0.5531 (0.5709)	loss 3.1421 (3.3369)	grad_norm 1.2769 (1.4121)	mem 17417MB
[2023-02-01 11:48:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][750/1251]	eta 0:04:45 lr 0.000694	time 0.5602 (0.5708)	loss 3.8484 (3.3372)	grad_norm 1.2987 (1.4112)	mem 17417MB
[2023-02-01 11:48:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][800/1251]	eta 0:04:17 lr 0.000694	time 0.5580 (0.5706)	loss 2.8519 (3.3388)	grad_norm 1.4412 (1.4094)	mem 17417MB
[2023-02-01 11:49:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][850/1251]	eta 0:03:48 lr 0.000694	time 0.6193 (0.5704)	loss 3.6361 (3.3400)	grad_norm 1.2386 (1.4095)	mem 17417MB
[2023-02-01 11:49:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][900/1251]	eta 0:03:20 lr 0.000693	time 0.5614 (0.5705)	loss 2.5242 (3.3372)	grad_norm 1.4378 (1.4097)	mem 17417MB
[2023-02-01 11:50:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][950/1251]	eta 0:02:51 lr 0.000693	time 0.5557 (0.5704)	loss 2.2215 (3.3373)	grad_norm 1.3127 (1.4109)	mem 17417MB
[2023-02-01 11:50:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][1000/1251]	eta 0:02:23 lr 0.000693	time 0.5624 (0.5706)	loss 3.5615 (3.3466)	grad_norm 1.4778 (1.4104)	mem 17417MB
[2023-02-01 11:51:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][1050/1251]	eta 0:01:54 lr 0.000693	time 0.5571 (0.5704)	loss 2.5625 (3.3423)	grad_norm 1.4150 (1.4102)	mem 17417MB
[2023-02-01 11:51:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][1100/1251]	eta 0:01:26 lr 0.000693	time 0.6222 (0.5704)	loss 3.1902 (3.3404)	grad_norm 1.3280 (1.4095)	mem 17417MB
[2023-02-01 11:52:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][1150/1251]	eta 0:00:57 lr 0.000692	time 0.5579 (0.5705)	loss 3.0821 (3.3337)	grad_norm 1.2671 (1.4104)	mem 17417MB
[2023-02-01 11:52:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][1200/1251]	eta 0:00:29 lr 0.000692	time 0.5512 (0.5702)	loss 3.6938 (3.3346)	grad_norm 1.7700 (1.4108)	mem 17417MB
[2023-02-01 11:52:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [112/300][1250/1251]	eta 0:00:00 lr 0.000692	time 0.5525 (0.5703)	loss 3.2395 (3.3326)	grad_norm 1.2218 (1.4109)	mem 17417MB
[2023-02-01 11:52:59 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 112 training takes 0:11:53
[2023-02-01 11:52:59 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_112.pth saving......
[2023-02-01 11:53:01 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_112.pth saved !!!
[2023-02-01 11:53:02 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.829 (0.829)	Loss 0.9836 (0.9836)	Acc@1 77.637 (77.637)	Acc@5 92.676 (92.676)	Mem 17417MB
[2023-02-01 11:53:10 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.256 Acc@5 94.568
[2023-02-01 11:53:10 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.3%
[2023-02-01 11:53:11 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.319 (1.319)	Loss 0.7493 (0.7493)	Acc@1 81.934 (81.934)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-01 11:53:19 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.586 Acc@5 95.612
[2023-02-01 11:53:19 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.6%
[2023-02-01 11:53:19 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.59% at 112 epoch
[2023-02-01 11:53:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][0/1251]	eta 0:34:34 lr 0.000692	time 1.6582 (1.6582)	loss 2.5773 (2.5773)	grad_norm 1.4761 (1.4761)	mem 17417MB
[2023-02-01 11:53:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][50/1251]	eta 0:11:55 lr 0.000692	time 0.5634 (0.5960)	loss 3.6391 (3.2335)	grad_norm 1.4700 (1.4105)	mem 17417MB
[2023-02-01 11:54:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][100/1251]	eta 0:11:10 lr 0.000692	time 0.6178 (0.5829)	loss 3.7944 (3.3146)	grad_norm 1.4007 (1.4102)	mem 17417MB
[2023-02-01 11:54:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][150/1251]	eta 0:10:37 lr 0.000691	time 0.5573 (0.5788)	loss 2.6980 (3.3278)	grad_norm 1.2732 (1.4063)	mem 17417MB
[2023-02-01 11:55:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][200/1251]	eta 0:10:05 lr 0.000691	time 0.5495 (0.5760)	loss 3.7871 (3.3254)	grad_norm 1.3651 (1.4018)	mem 17417MB
[2023-02-01 11:55:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][250/1251]	eta 0:09:34 lr 0.000691	time 0.5509 (0.5744)	loss 3.1039 (3.3211)	grad_norm 1.3677 (1.4105)	mem 17417MB
[2023-02-01 11:56:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][300/1251]	eta 0:09:06 lr 0.000691	time 0.5725 (0.5742)	loss 3.5629 (3.3203)	grad_norm 1.3628 (1.4147)	mem 17417MB
[2023-02-01 11:56:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][350/1251]	eta 0:08:36 lr 0.000691	time 0.5575 (0.5738)	loss 2.5471 (3.3334)	grad_norm 1.3918 (1.4132)	mem 17417MB
[2023-02-01 11:57:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][400/1251]	eta 0:08:07 lr 0.000690	time 0.5533 (0.5730)	loss 3.7648 (3.3483)	grad_norm 1.3046 (1.4088)	mem 17417MB
[2023-02-01 11:57:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][450/1251]	eta 0:07:38 lr 0.000690	time 0.6236 (0.5729)	loss 3.6477 (3.3433)	grad_norm 1.3777 (1.4120)	mem 17417MB
[2023-02-01 11:58:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][500/1251]	eta 0:07:09 lr 0.000690	time 0.6180 (0.5721)	loss 4.1095 (3.3477)	grad_norm 1.3090 (1.4096)	mem 17417MB
[2023-02-01 11:58:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][550/1251]	eta 0:06:41 lr 0.000690	time 0.5598 (0.5722)	loss 3.1811 (3.3475)	grad_norm 1.4899 (1.4111)	mem 17417MB
[2023-02-01 11:59:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][600/1251]	eta 0:06:12 lr 0.000690	time 0.5541 (0.5721)	loss 3.1816 (3.3378)	grad_norm 1.3388 (1.4132)	mem 17417MB
[2023-02-01 11:59:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][650/1251]	eta 0:05:43 lr 0.000690	time 0.5628 (0.5720)	loss 4.0836 (3.3310)	grad_norm 1.2482 (1.4113)	mem 17417MB
[2023-02-01 12:00:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][700/1251]	eta 0:05:15 lr 0.000689	time 0.5556 (0.5719)	loss 3.7937 (3.3289)	grad_norm 1.4938 (1.4088)	mem 17417MB
[2023-02-01 12:00:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][750/1251]	eta 0:04:46 lr 0.000689	time 0.5510 (0.5716)	loss 4.2063 (3.3319)	grad_norm 1.3315 (1.4078)	mem 17417MB
[2023-02-01 12:00:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][800/1251]	eta 0:04:17 lr 0.000689	time 0.5604 (0.5716)	loss 3.6693 (3.3375)	grad_norm 1.8612 (1.4075)	mem 17417MB
[2023-02-01 12:01:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][850/1251]	eta 0:03:49 lr 0.000689	time 0.5578 (0.5717)	loss 2.8752 (3.3343)	grad_norm 1.2907 (1.4074)	mem 17417MB
[2023-02-01 12:01:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][900/1251]	eta 0:03:20 lr 0.000689	time 0.6195 (0.5716)	loss 3.8299 (3.3339)	grad_norm 1.3914 (nan)	mem 17417MB
[2023-02-01 12:02:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][950/1251]	eta 0:02:51 lr 0.000688	time 0.5648 (0.5714)	loss 3.0226 (3.3358)	grad_norm 1.5054 (nan)	mem 17417MB
[2023-02-01 12:02:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][1000/1251]	eta 0:02:23 lr 0.000688	time 0.6452 (0.5713)	loss 3.3265 (3.3305)	grad_norm 1.3966 (nan)	mem 17417MB
[2023-02-01 12:03:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][1050/1251]	eta 0:01:54 lr 0.000688	time 0.5607 (0.5710)	loss 3.0691 (3.3276)	grad_norm 1.2926 (nan)	mem 17417MB
[2023-02-01 12:03:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][1100/1251]	eta 0:01:26 lr 0.000688	time 0.5519 (0.5710)	loss 3.6696 (3.3291)	grad_norm 1.5176 (nan)	mem 17417MB
[2023-02-01 12:04:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][1150/1251]	eta 0:00:57 lr 0.000688	time 0.6260 (0.5709)	loss 2.5308 (3.3275)	grad_norm 1.3534 (nan)	mem 17417MB
[2023-02-01 12:04:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][1200/1251]	eta 0:00:29 lr 0.000687	time 0.5571 (0.5708)	loss 3.2089 (3.3303)	grad_norm 1.4351 (nan)	mem 17417MB
[2023-02-01 12:05:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [113/300][1250/1251]	eta 0:00:00 lr 0.000687	time 0.5497 (0.5708)	loss 3.4896 (3.3281)	grad_norm 1.4933 (nan)	mem 17417MB
[2023-02-01 12:05:13 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 113 training takes 0:11:54
[2023-02-01 12:05:13 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_113.pth saving......
[2023-02-01 12:05:15 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_113.pth saved !!!
[2023-02-01 12:05:16 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.879 (0.879)	Loss 0.9291 (0.9291)	Acc@1 77.051 (77.051)	Acc@5 95.410 (95.410)	Mem 17417MB
[2023-02-01 12:05:24 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.496 Acc@5 94.700
[2023-02-01 12:05:24 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.5%
[2023-02-01 12:05:25 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.281 (1.281)	Loss 0.7678 (0.7678)	Acc@1 82.324 (82.324)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-01 12:05:33 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.620 Acc@5 95.646
[2023-02-01 12:05:33 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.6%
[2023-02-01 12:05:33 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.62% at 113 epoch
[2023-02-01 12:05:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][0/1251]	eta 0:36:50 lr 0.000687	time 1.7669 (1.7669)	loss 4.1206 (4.1206)	grad_norm 1.2718 (1.2718)	mem 17417MB
[2023-02-01 12:06:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][50/1251]	eta 0:11:50 lr 0.000687	time 0.5589 (0.5919)	loss 3.4490 (3.2514)	grad_norm 1.5287 (1.4223)	mem 17417MB
[2023-02-01 12:06:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][100/1251]	eta 0:11:08 lr 0.000687	time 0.5628 (0.5812)	loss 3.9611 (3.2832)	grad_norm 1.7332 (1.4099)	mem 17417MB
[2023-02-01 12:07:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][150/1251]	eta 0:10:35 lr 0.000687	time 0.5523 (0.5776)	loss 3.2628 (3.3365)	grad_norm 1.5076 (1.4126)	mem 17417MB
[2023-02-01 12:07:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][200/1251]	eta 0:10:04 lr 0.000686	time 0.5550 (0.5749)	loss 3.8641 (3.3339)	grad_norm 1.6017 (1.4043)	mem 17417MB
[2023-02-01 12:07:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][250/1251]	eta 0:09:34 lr 0.000686	time 0.5679 (0.5743)	loss 3.0306 (3.3260)	grad_norm 1.2829 (1.4041)	mem 17417MB
[2023-02-01 12:08:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][300/1251]	eta 0:09:05 lr 0.000686	time 0.5538 (0.5735)	loss 3.2255 (3.3314)	grad_norm 1.3577 (1.4005)	mem 17417MB
[2023-02-01 12:08:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][350/1251]	eta 0:08:35 lr 0.000686	time 0.5648 (0.5722)	loss 3.9819 (3.3312)	grad_norm 1.5438 (1.3991)	mem 17417MB
[2023-02-01 12:09:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][400/1251]	eta 0:08:06 lr 0.000686	time 0.5626 (0.5721)	loss 3.8862 (3.3389)	grad_norm 1.5186 (1.3990)	mem 17417MB
[2023-02-01 12:09:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][450/1251]	eta 0:07:37 lr 0.000685	time 0.6237 (0.5712)	loss 2.5550 (3.3283)	grad_norm 1.3178 (1.4005)	mem 17417MB
[2023-02-01 12:10:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][500/1251]	eta 0:07:09 lr 0.000685	time 0.5570 (0.5713)	loss 2.9181 (3.3239)	grad_norm 1.7635 (1.4054)	mem 17417MB
[2023-02-01 12:10:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][550/1251]	eta 0:06:40 lr 0.000685	time 0.5582 (0.5708)	loss 2.7303 (3.3158)	grad_norm 1.3942 (1.4107)	mem 17417MB
[2023-02-01 12:11:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][600/1251]	eta 0:06:11 lr 0.000685	time 0.5595 (0.5708)	loss 4.0220 (3.3103)	grad_norm 1.3771 (1.4091)	mem 17417MB
[2023-02-01 12:11:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][650/1251]	eta 0:05:42 lr 0.000685	time 0.5670 (0.5705)	loss 2.1483 (3.3258)	grad_norm 1.3441 (1.4083)	mem 17417MB
[2023-02-01 12:12:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][700/1251]	eta 0:05:14 lr 0.000685	time 0.5505 (0.5706)	loss 2.1403 (3.3332)	grad_norm 1.3963 (1.4076)	mem 17417MB
[2023-02-01 12:12:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][750/1251]	eta 0:04:45 lr 0.000684	time 0.5535 (0.5702)	loss 3.0809 (3.3317)	grad_norm 1.5615 (1.4073)	mem 17417MB
[2023-02-01 12:13:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][800/1251]	eta 0:04:17 lr 0.000684	time 0.6081 (0.5702)	loss 3.9144 (3.3279)	grad_norm 1.3307 (1.4089)	mem 17417MB
[2023-02-01 12:13:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][850/1251]	eta 0:03:48 lr 0.000684	time 0.5554 (0.5698)	loss 3.5819 (3.3286)	grad_norm 1.3783 (1.4088)	mem 17417MB
[2023-02-01 12:14:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][900/1251]	eta 0:03:20 lr 0.000684	time 0.5497 (0.5698)	loss 3.4587 (3.3332)	grad_norm 1.3846 (1.4096)	mem 17417MB
[2023-02-01 12:14:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][950/1251]	eta 0:02:51 lr 0.000684	time 0.5624 (0.5698)	loss 3.3135 (3.3344)	grad_norm 1.5323 (1.4101)	mem 17417MB
[2023-02-01 12:15:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][1000/1251]	eta 0:02:23 lr 0.000683	time 0.5478 (0.5698)	loss 3.4365 (3.3313)	grad_norm 1.4249 (1.4102)	mem 17417MB
[2023-02-01 12:15:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][1050/1251]	eta 0:01:54 lr 0.000683	time 0.5818 (0.5697)	loss 3.5407 (3.3258)	grad_norm 1.3036 (1.4121)	mem 17417MB
[2023-02-01 12:16:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][1100/1251]	eta 0:01:26 lr 0.000683	time 0.6451 (0.5698)	loss 3.9370 (3.3236)	grad_norm 1.4000 (1.4111)	mem 17417MB
[2023-02-01 12:16:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][1150/1251]	eta 0:00:57 lr 0.000683	time 0.5571 (0.5695)	loss 3.1565 (3.3262)	grad_norm 1.2767 (1.4097)	mem 17417MB
[2023-02-01 12:16:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][1200/1251]	eta 0:00:29 lr 0.000683	time 0.5600 (0.5696)	loss 3.6562 (3.3229)	grad_norm 1.2308 (1.4098)	mem 17417MB
[2023-02-01 12:17:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [114/300][1250/1251]	eta 0:00:00 lr 0.000682	time 0.5516 (0.5694)	loss 3.5378 (3.3191)	grad_norm 1.4060 (1.4097)	mem 17417MB
[2023-02-01 12:17:25 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 114 training takes 0:11:52
[2023-02-01 12:17:25 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_114.pth saving......
[2023-02-01 12:17:27 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_114.pth saved !!!
[2023-02-01 12:17:28 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.899 (0.899)	Loss 0.9911 (0.9911)	Acc@1 77.441 (77.441)	Acc@5 93.652 (93.652)	Mem 17417MB
[2023-02-01 12:17:36 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.178 Acc@5 94.546
[2023-02-01 12:17:36 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.2%
[2023-02-01 12:17:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.237 (1.237)	Loss 0.7843 (0.7843)	Acc@1 80.957 (80.957)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-01 12:17:45 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.658 Acc@5 95.638
[2023-02-01 12:17:46 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.7%
[2023-02-01 12:17:46 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.66% at 114 epoch
[2023-02-01 12:17:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][0/1251]	eta 0:36:10 lr 0.000682	time 1.7354 (1.7354)	loss 4.1790 (4.1790)	grad_norm 1.4700 (1.4700)	mem 17417MB
[2023-02-01 12:18:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][50/1251]	eta 0:11:51 lr 0.000682	time 0.5477 (0.5921)	loss 2.7119 (3.2982)	grad_norm 1.4877 (1.3730)	mem 17417MB
[2023-02-01 12:18:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][100/1251]	eta 0:11:10 lr 0.000682	time 0.5569 (0.5826)	loss 2.0714 (3.2870)	grad_norm 1.3107 (1.3870)	mem 17417MB
[2023-02-01 12:19:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][150/1251]	eta 0:10:35 lr 0.000682	time 0.5492 (0.5772)	loss 3.6362 (3.2808)	grad_norm 1.4624 (1.3980)	mem 17417MB
[2023-02-01 12:19:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][200/1251]	eta 0:10:04 lr 0.000682	time 0.5608 (0.5755)	loss 3.7428 (3.2749)	grad_norm 1.3183 (1.4018)	mem 17417MB
[2023-02-01 12:20:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][250/1251]	eta 0:09:34 lr 0.000681	time 0.6229 (0.5743)	loss 3.5363 (3.3135)	grad_norm 1.3865 (1.4034)	mem 17417MB
[2023-02-01 12:20:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][300/1251]	eta 0:09:05 lr 0.000681	time 0.5574 (0.5735)	loss 3.6122 (3.3017)	grad_norm 1.5477 (1.4086)	mem 17417MB
[2023-02-01 12:21:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][350/1251]	eta 0:08:36 lr 0.000681	time 0.5535 (0.5727)	loss 3.0049 (3.3104)	grad_norm 1.3429 (1.4039)	mem 17417MB
[2023-02-01 12:21:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][400/1251]	eta 0:08:07 lr 0.000681	time 0.5543 (0.5728)	loss 2.3903 (3.2999)	grad_norm 1.3703 (1.4083)	mem 17417MB
[2023-02-01 12:22:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][450/1251]	eta 0:07:38 lr 0.000681	time 0.5533 (0.5723)	loss 3.9752 (3.3012)	grad_norm 1.3376 (nan)	mem 17417MB
[2023-02-01 12:22:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][500/1251]	eta 0:07:09 lr 0.000680	time 0.5527 (0.5716)	loss 2.3567 (3.3012)	grad_norm 1.5886 (nan)	mem 17417MB
[2023-02-01 12:23:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][550/1251]	eta 0:06:40 lr 0.000680	time 0.5511 (0.5714)	loss 3.5327 (3.3079)	grad_norm 1.3525 (nan)	mem 17417MB
[2023-02-01 12:23:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][600/1251]	eta 0:06:11 lr 0.000680	time 0.5571 (0.5714)	loss 3.7987 (3.3034)	grad_norm 1.3356 (nan)	mem 17417MB
[2023-02-01 12:23:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][650/1251]	eta 0:05:43 lr 0.000680	time 0.5597 (0.5715)	loss 3.8437 (3.2972)	grad_norm 1.7078 (nan)	mem 17417MB
[2023-02-01 12:24:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][700/1251]	eta 0:05:14 lr 0.000680	time 0.5579 (0.5714)	loss 3.4489 (3.3055)	grad_norm 1.4443 (nan)	mem 17417MB
[2023-02-01 12:24:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][750/1251]	eta 0:04:46 lr 0.000679	time 0.5463 (0.5713)	loss 3.1567 (3.3126)	grad_norm 1.2982 (nan)	mem 17417MB
[2023-02-01 12:25:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][800/1251]	eta 0:04:17 lr 0.000679	time 0.6141 (0.5708)	loss 3.4893 (3.3152)	grad_norm 1.6226 (nan)	mem 17417MB
[2023-02-01 12:25:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][850/1251]	eta 0:03:48 lr 0.000679	time 0.5563 (0.5709)	loss 3.3125 (3.3072)	grad_norm 1.4215 (nan)	mem 17417MB
[2023-02-01 12:26:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][900/1251]	eta 0:03:20 lr 0.000679	time 0.5523 (0.5708)	loss 4.2096 (3.3040)	grad_norm 1.4683 (nan)	mem 17417MB
[2023-02-01 12:26:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][950/1251]	eta 0:02:51 lr 0.000679	time 0.5528 (0.5710)	loss 3.9686 (3.3102)	grad_norm 1.4565 (nan)	mem 17417MB
[2023-02-01 12:27:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][1000/1251]	eta 0:02:23 lr 0.000679	time 0.5542 (0.5707)	loss 3.2378 (3.3090)	grad_norm 1.2422 (nan)	mem 17417MB
[2023-02-01 12:27:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][1050/1251]	eta 0:01:54 lr 0.000678	time 0.5535 (0.5707)	loss 3.5361 (3.3111)	grad_norm 1.3028 (nan)	mem 17417MB
[2023-02-01 12:28:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][1100/1251]	eta 0:01:26 lr 0.000678	time 0.6353 (0.5705)	loss 2.9358 (3.3064)	grad_norm 1.6573 (nan)	mem 17417MB
[2023-02-01 12:28:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][1150/1251]	eta 0:00:57 lr 0.000678	time 0.5563 (0.5703)	loss 2.9015 (3.3086)	grad_norm 1.4388 (nan)	mem 17417MB
[2023-02-01 12:29:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][1200/1251]	eta 0:00:29 lr 0.000678	time 0.5753 (0.5702)	loss 3.4093 (3.3055)	grad_norm 1.4458 (nan)	mem 17417MB
[2023-02-01 12:29:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [115/300][1250/1251]	eta 0:00:00 lr 0.000678	time 0.5512 (0.5703)	loss 3.8400 (3.3065)	grad_norm 1.5095 (nan)	mem 17417MB
[2023-02-01 12:29:39 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 115 training takes 0:11:53
[2023-02-01 12:29:39 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_115.pth saving......
[2023-02-01 12:29:41 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_115.pth saved !!!
[2023-02-01 12:29:42 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.870 (0.870)	Loss 0.9415 (0.9415)	Acc@1 78.711 (78.711)	Acc@5 95.215 (95.215)	Mem 17417MB
[2023-02-01 12:29:50 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.530 Acc@5 94.608
[2023-02-01 12:29:50 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.5%
[2023-02-01 12:29:51 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.258 (1.258)	Loss 0.7581 (0.7581)	Acc@1 81.641 (81.641)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-01 12:29:59 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.634 Acc@5 95.684
[2023-02-01 12:29:59 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.6%
[2023-02-01 12:29:59 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.66% at 114 epoch
[2023-02-01 12:30:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][0/1251]	eta 0:33:14 lr 0.000678	time 1.5945 (1.5945)	loss 3.1188 (3.1188)	grad_norm 1.3431 (1.3431)	mem 17417MB
[2023-02-01 12:30:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][50/1251]	eta 0:11:49 lr 0.000677	time 0.5627 (0.5911)	loss 3.1347 (3.3802)	grad_norm 1.3543 (1.4103)	mem 17417MB
[2023-02-01 12:30:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][100/1251]	eta 0:11:08 lr 0.000677	time 0.5676 (0.5811)	loss 3.9915 (3.3633)	grad_norm 1.3525 (1.4138)	mem 17417MB
[2023-02-01 12:31:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][150/1251]	eta 0:10:34 lr 0.000677	time 0.5623 (0.5761)	loss 3.7884 (3.3101)	grad_norm 1.3964 (1.4186)	mem 17417MB
[2023-02-01 12:31:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][200/1251]	eta 0:10:04 lr 0.000677	time 0.5615 (0.5750)	loss 3.2409 (3.3210)	grad_norm 1.3422 (1.4185)	mem 17417MB
[2023-02-01 12:32:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][250/1251]	eta 0:09:34 lr 0.000677	time 0.5627 (0.5735)	loss 2.8986 (3.3027)	grad_norm 1.3921 (1.4148)	mem 17417MB
[2023-02-01 12:32:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][300/1251]	eta 0:09:04 lr 0.000676	time 0.5613 (0.5730)	loss 3.6928 (3.2981)	grad_norm 1.3517 (1.4121)	mem 17417MB
[2023-02-01 12:33:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][350/1251]	eta 0:08:35 lr 0.000676	time 0.5558 (0.5724)	loss 2.3786 (3.3238)	grad_norm 1.4215 (1.4208)	mem 17417MB
[2023-02-01 12:33:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][400/1251]	eta 0:08:06 lr 0.000676	time 0.5568 (0.5719)	loss 2.4092 (3.3152)	grad_norm 1.4855 (1.4243)	mem 17417MB
[2023-02-01 12:34:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][450/1251]	eta 0:07:37 lr 0.000676	time 0.5592 (0.5716)	loss 3.2807 (3.3184)	grad_norm 1.2527 (1.4213)	mem 17417MB
[2023-02-01 12:34:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][500/1251]	eta 0:07:08 lr 0.000676	time 0.5620 (0.5710)	loss 3.5364 (3.3285)	grad_norm 1.3975 (1.4178)	mem 17417MB
[2023-02-01 12:35:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][550/1251]	eta 0:06:40 lr 0.000675	time 0.5574 (0.5711)	loss 2.2875 (3.3187)	grad_norm 1.3799 (1.4151)	mem 17417MB
[2023-02-01 12:35:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][600/1251]	eta 0:06:11 lr 0.000675	time 0.5614 (0.5710)	loss 3.2270 (3.3341)	grad_norm 1.5735 (1.4172)	mem 17417MB
[2023-02-01 12:36:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][650/1251]	eta 0:05:43 lr 0.000675	time 0.5543 (0.5708)	loss 3.7521 (3.3322)	grad_norm 1.3751 (1.4183)	mem 17417MB
[2023-02-01 12:36:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][700/1251]	eta 0:05:14 lr 0.000675	time 0.5567 (0.5707)	loss 2.8726 (3.3325)	grad_norm 1.4168 (1.4175)	mem 17417MB
[2023-02-01 12:37:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][750/1251]	eta 0:04:45 lr 0.000675	time 0.5560 (0.5703)	loss 4.1783 (3.3353)	grad_norm 1.5298 (1.4203)	mem 17417MB
[2023-02-01 12:37:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][800/1251]	eta 0:04:17 lr 0.000674	time 0.5621 (0.5704)	loss 3.3795 (3.3304)	grad_norm 1.5098 (1.4180)	mem 17417MB
[2023-02-01 12:38:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][850/1251]	eta 0:03:48 lr 0.000674	time 0.5765 (0.5704)	loss 3.1669 (3.3305)	grad_norm 1.3148 (1.4163)	mem 17417MB
[2023-02-01 12:38:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][900/1251]	eta 0:03:20 lr 0.000674	time 0.5596 (0.5705)	loss 3.6186 (3.3358)	grad_norm 1.2536 (1.4170)	mem 17417MB
[2023-02-01 12:39:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][950/1251]	eta 0:02:51 lr 0.000674	time 0.5515 (0.5702)	loss 2.9161 (3.3368)	grad_norm 1.4861 (1.4159)	mem 17417MB
[2023-02-01 12:39:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][1000/1251]	eta 0:02:23 lr 0.000674	time 0.5584 (0.5703)	loss 2.8601 (3.3391)	grad_norm 1.5384 (1.4154)	mem 17417MB
[2023-02-01 12:39:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][1050/1251]	eta 0:01:54 lr 0.000673	time 0.5620 (0.5701)	loss 3.1780 (3.3391)	grad_norm 1.4639 (1.4167)	mem 17417MB
[2023-02-01 12:40:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][1100/1251]	eta 0:01:26 lr 0.000673	time 0.5575 (0.5702)	loss 3.6102 (3.3432)	grad_norm 1.5191 (1.4159)	mem 17417MB
[2023-02-01 12:40:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][1150/1251]	eta 0:00:57 lr 0.000673	time 0.5601 (0.5701)	loss 3.1664 (3.3390)	grad_norm 1.4978 (1.4163)	mem 17417MB
[2023-02-01 12:41:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][1200/1251]	eta 0:00:29 lr 0.000673	time 0.5666 (0.5699)	loss 3.3916 (3.3375)	grad_norm 1.4349 (1.4167)	mem 17417MB
[2023-02-01 12:41:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [116/300][1250/1251]	eta 0:00:00 lr 0.000673	time 0.5481 (0.5700)	loss 2.6213 (3.3366)	grad_norm 1.4592 (1.4169)	mem 17417MB
[2023-02-01 12:41:52 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 116 training takes 0:11:53
[2023-02-01 12:41:52 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_116.pth saving......
[2023-02-01 12:41:54 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_116.pth saved !!!
[2023-02-01 12:41:55 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.869 (0.869)	Loss 1.0165 (1.0165)	Acc@1 76.562 (76.562)	Acc@5 93.359 (93.359)	Mem 17417MB
[2023-02-01 12:42:03 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.568 Acc@5 94.572
[2023-02-01 12:42:03 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.6%
[2023-02-01 12:42:04 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.167 (1.167)	Loss 0.8166 (0.8166)	Acc@1 80.664 (80.664)	Acc@5 95.898 (95.898)	Mem 17417MB
[2023-02-01 12:42:12 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.726 Acc@5 95.706
[2023-02-01 12:42:12 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.7%
[2023-02-01 12:42:12 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.73% at 116 epoch
[2023-02-01 12:42:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][0/1251]	eta 0:34:56 lr 0.000673	time 1.6755 (1.6755)	loss 3.4191 (3.4191)	grad_norm 1.3730 (1.3730)	mem 17417MB
[2023-02-01 12:42:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][50/1251]	eta 0:11:45 lr 0.000672	time 0.5542 (0.5878)	loss 3.1057 (3.3280)	grad_norm 1.4882 (nan)	mem 17417MB
[2023-02-01 12:43:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][100/1251]	eta 0:11:08 lr 0.000672	time 0.5496 (0.5808)	loss 3.6902 (3.3445)	grad_norm 1.8640 (nan)	mem 17417MB
[2023-02-01 12:43:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][150/1251]	eta 0:10:33 lr 0.000672	time 0.5570 (0.5757)	loss 3.6808 (3.3335)	grad_norm 1.2720 (nan)	mem 17417MB
[2023-02-01 12:44:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][200/1251]	eta 0:10:03 lr 0.000672	time 0.5531 (0.5744)	loss 3.0882 (3.3422)	grad_norm 1.4588 (nan)	mem 17417MB
[2023-02-01 12:44:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][250/1251]	eta 0:09:33 lr 0.000672	time 0.5505 (0.5726)	loss 2.6037 (3.3209)	grad_norm 1.4627 (nan)	mem 17417MB
[2023-02-01 12:45:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][300/1251]	eta 0:09:04 lr 0.000672	time 0.6307 (0.5725)	loss 1.9127 (3.3060)	grad_norm 1.3938 (nan)	mem 17417MB
[2023-02-01 12:45:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][350/1251]	eta 0:08:34 lr 0.000671	time 0.5544 (0.5714)	loss 3.6331 (3.3102)	grad_norm 1.4786 (nan)	mem 17417MB
[2023-02-01 12:46:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][400/1251]	eta 0:08:06 lr 0.000671	time 0.5506 (0.5714)	loss 2.3242 (3.3101)	grad_norm 1.2817 (nan)	mem 17417MB
[2023-02-01 12:46:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][450/1251]	eta 0:07:36 lr 0.000671	time 0.5631 (0.5704)	loss 3.9454 (3.3163)	grad_norm 1.6204 (nan)	mem 17417MB
[2023-02-01 12:46:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][500/1251]	eta 0:07:08 lr 0.000671	time 0.5603 (0.5703)	loss 3.3385 (3.3253)	grad_norm 1.4457 (nan)	mem 17417MB
[2023-02-01 12:47:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][550/1251]	eta 0:06:39 lr 0.000671	time 0.5674 (0.5698)	loss 3.1587 (3.3261)	grad_norm 1.4488 (nan)	mem 17417MB
[2023-02-01 12:47:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][600/1251]	eta 0:06:10 lr 0.000670	time 0.5537 (0.5697)	loss 3.1577 (3.3321)	grad_norm 1.3663 (nan)	mem 17417MB
[2023-02-01 12:48:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][650/1251]	eta 0:05:42 lr 0.000670	time 0.5598 (0.5695)	loss 3.4456 (3.3325)	grad_norm 1.4870 (nan)	mem 17417MB
[2023-02-01 12:48:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][700/1251]	eta 0:05:13 lr 0.000670	time 0.5564 (0.5695)	loss 3.5380 (3.3260)	grad_norm 1.4003 (nan)	mem 17417MB
[2023-02-01 12:49:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][750/1251]	eta 0:04:45 lr 0.000670	time 0.5550 (0.5692)	loss 3.3590 (3.3184)	grad_norm 1.5247 (nan)	mem 17417MB
[2023-02-01 12:49:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][800/1251]	eta 0:04:16 lr 0.000670	time 0.6243 (0.5693)	loss 4.1424 (3.3247)	grad_norm 1.6714 (nan)	mem 17417MB
[2023-02-01 12:50:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][850/1251]	eta 0:03:48 lr 0.000669	time 0.5547 (0.5690)	loss 3.6975 (3.3254)	grad_norm 1.3647 (nan)	mem 17417MB
[2023-02-01 12:50:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][900/1251]	eta 0:03:19 lr 0.000669	time 0.5729 (0.5691)	loss 3.9672 (3.3214)	grad_norm 1.3851 (nan)	mem 17417MB
[2023-02-01 12:51:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][950/1251]	eta 0:02:51 lr 0.000669	time 0.5600 (0.5689)	loss 3.8307 (3.3197)	grad_norm 1.4450 (nan)	mem 17417MB
[2023-02-01 12:51:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][1000/1251]	eta 0:02:22 lr 0.000669	time 0.6190 (0.5690)	loss 2.7635 (3.3251)	grad_norm 1.4125 (nan)	mem 17417MB
[2023-02-01 12:52:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][1050/1251]	eta 0:01:54 lr 0.000669	time 0.5541 (0.5689)	loss 3.7692 (3.3238)	grad_norm 1.3407 (nan)	mem 17417MB
[2023-02-01 12:52:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][1100/1251]	eta 0:01:25 lr 0.000668	time 0.5582 (0.5688)	loss 3.7696 (3.3231)	grad_norm 1.3296 (nan)	mem 17417MB
[2023-02-01 12:53:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][1150/1251]	eta 0:00:57 lr 0.000668	time 0.5558 (0.5688)	loss 3.6274 (3.3247)	grad_norm 1.5341 (nan)	mem 17417MB
[2023-02-01 12:53:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][1200/1251]	eta 0:00:29 lr 0.000668	time 0.6341 (0.5688)	loss 3.4220 (3.3238)	grad_norm 1.5316 (nan)	mem 17417MB
[2023-02-01 12:54:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [117/300][1250/1251]	eta 0:00:00 lr 0.000668	time 0.6087 (0.5687)	loss 3.3867 (3.3294)	grad_norm 1.4864 (nan)	mem 17417MB
[2023-02-01 12:54:04 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 117 training takes 0:11:51
[2023-02-01 12:54:04 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_117.pth saving......
[2023-02-01 12:54:06 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_117.pth saved !!!
[2023-02-01 12:54:07 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.875 (0.875)	Loss 0.8696 (0.8696)	Acc@1 79.590 (79.590)	Acc@5 94.531 (94.531)	Mem 17417MB
[2023-02-01 12:54:15 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.484 Acc@5 94.636
[2023-02-01 12:54:15 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.5%
[2023-02-01 12:54:16 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.231 (1.231)	Loss 0.8049 (0.8049)	Acc@1 81.934 (81.934)	Acc@5 95.703 (95.703)	Mem 17417MB
[2023-02-01 12:54:24 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.736 Acc@5 95.690
[2023-02-01 12:54:24 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.7%
[2023-02-01 12:54:24 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.74% at 117 epoch
[2023-02-01 12:54:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][0/1251]	eta 0:34:32 lr 0.000668	time 1.6569 (1.6569)	loss 2.1868 (2.1868)	grad_norm 1.2931 (1.2931)	mem 17417MB
[2023-02-01 12:54:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][50/1251]	eta 0:11:52 lr 0.000668	time 0.5562 (0.5936)	loss 3.7646 (3.3913)	grad_norm 1.3361 (1.4742)	mem 17417MB
[2023-02-01 12:55:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][100/1251]	eta 0:11:11 lr 0.000667	time 0.5570 (0.5831)	loss 3.3949 (3.3306)	grad_norm 1.4883 (1.4578)	mem 17417MB
[2023-02-01 12:55:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][150/1251]	eta 0:10:38 lr 0.000667	time 0.5571 (0.5796)	loss 3.4961 (3.3328)	grad_norm 1.3897 (1.4523)	mem 17417MB
[2023-02-01 12:56:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][200/1251]	eta 0:10:05 lr 0.000667	time 0.6269 (0.5759)	loss 2.5837 (3.3441)	grad_norm 1.3832 (1.4458)	mem 17417MB
[2023-02-01 12:56:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][250/1251]	eta 0:09:35 lr 0.000667	time 0.6163 (0.5747)	loss 2.8881 (3.3147)	grad_norm 1.3772 (1.4333)	mem 17417MB
[2023-02-01 12:57:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][300/1251]	eta 0:09:05 lr 0.000667	time 0.5553 (0.5735)	loss 3.5855 (3.2956)	grad_norm 1.3834 (1.4285)	mem 17417MB
[2023-02-01 12:57:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][350/1251]	eta 0:08:36 lr 0.000666	time 0.5729 (0.5733)	loss 3.5914 (3.2975)	grad_norm 1.2697 (1.4251)	mem 17417MB
[2023-02-01 12:58:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][400/1251]	eta 0:08:07 lr 0.000666	time 0.5559 (0.5728)	loss 2.9749 (3.3069)	grad_norm 1.5311 (1.4258)	mem 17417MB
[2023-02-01 12:58:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][450/1251]	eta 0:07:38 lr 0.000666	time 0.5609 (0.5727)	loss 2.5761 (3.3088)	grad_norm 1.4770 (1.4232)	mem 17417MB
[2023-02-01 12:59:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][500/1251]	eta 0:07:09 lr 0.000666	time 0.5514 (0.5721)	loss 2.9988 (3.3138)	grad_norm 1.3644 (1.4222)	mem 17417MB
[2023-02-01 12:59:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][550/1251]	eta 0:06:41 lr 0.000666	time 0.5546 (0.5721)	loss 3.1860 (3.3112)	grad_norm 1.5239 (1.4261)	mem 17417MB
[2023-02-01 13:00:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][600/1251]	eta 0:06:12 lr 0.000665	time 0.5571 (0.5719)	loss 4.0020 (3.3238)	grad_norm 1.5800 (1.4258)	mem 17417MB
[2023-02-01 13:00:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][650/1251]	eta 0:05:43 lr 0.000665	time 0.5598 (0.5718)	loss 3.3867 (3.3231)	grad_norm 1.4163 (1.4269)	mem 17417MB
[2023-02-01 13:01:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][700/1251]	eta 0:05:15 lr 0.000665	time 0.5592 (0.5717)	loss 3.3536 (3.3220)	grad_norm 1.2762 (1.4261)	mem 17417MB
[2023-02-01 13:01:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][750/1251]	eta 0:04:46 lr 0.000665	time 0.5538 (0.5714)	loss 3.8345 (3.3184)	grad_norm 1.4457 (1.4274)	mem 17417MB
[2023-02-01 13:02:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][800/1251]	eta 0:04:17 lr 0.000665	time 0.5561 (0.5713)	loss 3.3291 (3.3294)	grad_norm 1.4735 (1.4271)	mem 17417MB
[2023-02-01 13:02:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][850/1251]	eta 0:03:49 lr 0.000664	time 0.5649 (0.5712)	loss 3.0851 (3.3288)	grad_norm 1.4937 (1.4268)	mem 17417MB
[2023-02-01 13:02:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][900/1251]	eta 0:03:20 lr 0.000664	time 0.5601 (0.5712)	loss 3.5720 (3.3259)	grad_norm 1.3135 (1.4272)	mem 17417MB
[2023-02-01 13:03:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][950/1251]	eta 0:02:51 lr 0.000664	time 0.5578 (0.5714)	loss 3.3880 (3.3252)	grad_norm 1.4652 (1.4262)	mem 17417MB
[2023-02-01 13:03:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][1000/1251]	eta 0:02:23 lr 0.000664	time 0.6156 (0.5711)	loss 3.8497 (3.3254)	grad_norm 1.5311 (1.4278)	mem 17417MB
[2023-02-01 13:04:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][1050/1251]	eta 0:01:54 lr 0.000664	time 0.5531 (0.5711)	loss 3.7116 (3.3293)	grad_norm 1.4701 (1.4273)	mem 17417MB
[2023-02-01 13:04:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][1100/1251]	eta 0:01:26 lr 0.000663	time 0.5606 (0.5710)	loss 3.1418 (3.3262)	grad_norm 1.4129 (1.4277)	mem 17417MB
[2023-02-01 13:05:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][1150/1251]	eta 0:00:57 lr 0.000663	time 0.6365 (0.5710)	loss 4.1965 (3.3311)	grad_norm 1.4339 (1.4268)	mem 17417MB
[2023-02-01 13:05:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][1200/1251]	eta 0:00:29 lr 0.000663	time 0.5545 (0.5709)	loss 3.6586 (3.3286)	grad_norm 1.3638 (inf)	mem 17417MB
[2023-02-01 13:06:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [118/300][1250/1251]	eta 0:00:00 lr 0.000663	time 0.6049 (0.5708)	loss 3.4797 (3.3280)	grad_norm 1.4238 (inf)	mem 17417MB
[2023-02-01 13:06:18 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 118 training takes 0:11:54
[2023-02-01 13:06:18 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_118.pth saving......
[2023-02-01 13:06:20 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_118.pth saved !!!
[2023-02-01 13:06:21 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.859 (0.859)	Loss 0.9918 (0.9918)	Acc@1 76.562 (76.562)	Acc@5 93.945 (93.945)	Mem 17417MB
[2023-02-01 13:06:29 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.394 Acc@5 94.700
[2023-02-01 13:06:29 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.4%
[2023-02-01 13:06:30 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.267 (1.267)	Loss 0.8200 (0.8200)	Acc@1 79.785 (79.785)	Acc@5 95.312 (95.312)	Mem 17417MB
[2023-02-01 13:06:38 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.816 Acc@5 95.710
[2023-02-01 13:06:38 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.8%
[2023-02-01 13:06:38 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.82% at 118 epoch
[2023-02-01 13:06:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][0/1251]	eta 0:37:22 lr 0.000663	time 1.7923 (1.7923)	loss 3.8228 (3.8228)	grad_norm 1.4087 (1.4087)	mem 17417MB
[2023-02-01 13:07:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][50/1251]	eta 0:11:46 lr 0.000663	time 0.5558 (0.5880)	loss 3.9333 (3.3244)	grad_norm 1.4190 (1.4630)	mem 17417MB
[2023-02-01 13:07:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][100/1251]	eta 0:11:09 lr 0.000662	time 0.5670 (0.5814)	loss 3.4117 (3.2499)	grad_norm 1.3310 (1.4311)	mem 17417MB
[2023-02-01 13:08:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][150/1251]	eta 0:10:35 lr 0.000662	time 0.5567 (0.5769)	loss 3.1360 (3.2612)	grad_norm 1.2854 (1.4291)	mem 17417MB
[2023-02-01 13:08:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][200/1251]	eta 0:10:04 lr 0.000662	time 0.5622 (0.5747)	loss 3.8208 (3.2552)	grad_norm 1.4490 (1.4242)	mem 17417MB
[2023-02-01 13:09:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][250/1251]	eta 0:09:34 lr 0.000662	time 0.5625 (0.5738)	loss 3.1819 (3.2781)	grad_norm 1.3313 (1.4216)	mem 17417MB
[2023-02-01 13:09:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][300/1251]	eta 0:09:04 lr 0.000662	time 0.5586 (0.5729)	loss 3.3229 (3.2510)	grad_norm 1.3832 (1.4228)	mem 17417MB
[2023-02-01 13:09:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][350/1251]	eta 0:08:35 lr 0.000662	time 0.5570 (0.5717)	loss 3.2223 (3.2554)	grad_norm 1.3347 (1.4248)	mem 17417MB
[2023-02-01 13:10:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][400/1251]	eta 0:08:06 lr 0.000661	time 0.5594 (0.5716)	loss 2.8800 (3.2688)	grad_norm 1.2103 (1.4261)	mem 17417MB
[2023-02-01 13:10:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][450/1251]	eta 0:07:37 lr 0.000661	time 0.5583 (0.5711)	loss 3.7025 (3.2597)	grad_norm 1.2639 (1.4269)	mem 17417MB
[2023-02-01 13:11:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][500/1251]	eta 0:07:08 lr 0.000661	time 0.5587 (0.5711)	loss 3.3173 (3.2744)	grad_norm 1.3667 (1.4297)	mem 17417MB
[2023-02-01 13:11:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][550/1251]	eta 0:06:40 lr 0.000661	time 0.5545 (0.5710)	loss 2.9687 (3.2749)	grad_norm 1.3202 (1.4284)	mem 17417MB
[2023-02-01 13:12:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][600/1251]	eta 0:06:11 lr 0.000661	time 0.5577 (0.5706)	loss 2.9864 (3.2835)	grad_norm 1.7621 (1.4263)	mem 17417MB
[2023-02-01 13:12:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][650/1251]	eta 0:05:43 lr 0.000660	time 0.5573 (0.5708)	loss 3.6611 (3.2896)	grad_norm 1.4017 (1.4280)	mem 17417MB
[2023-02-01 13:13:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][700/1251]	eta 0:05:14 lr 0.000660	time 0.5503 (0.5706)	loss 1.9804 (3.2978)	grad_norm 1.2929 (1.4280)	mem 17417MB
[2023-02-01 13:13:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][750/1251]	eta 0:04:45 lr 0.000660	time 0.5653 (0.5703)	loss 2.7283 (3.2897)	grad_norm 1.3482 (1.4286)	mem 17417MB
[2023-02-01 13:14:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][800/1251]	eta 0:04:17 lr 0.000660	time 0.5584 (0.5703)	loss 3.4494 (3.2954)	grad_norm 1.4080 (1.4279)	mem 17417MB
[2023-02-01 13:14:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][850/1251]	eta 0:03:48 lr 0.000660	time 0.6405 (0.5701)	loss 3.7596 (3.2948)	grad_norm 1.4277 (1.4276)	mem 17417MB
[2023-02-01 13:15:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][900/1251]	eta 0:03:20 lr 0.000659	time 0.5593 (0.5701)	loss 2.4245 (3.2991)	grad_norm 1.3956 (1.4268)	mem 17417MB
[2023-02-01 13:15:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][950/1251]	eta 0:02:51 lr 0.000659	time 0.5603 (0.5700)	loss 2.7477 (3.2990)	grad_norm 1.3479 (1.4256)	mem 17417MB
[2023-02-01 13:16:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][1000/1251]	eta 0:02:23 lr 0.000659	time 0.5562 (0.5699)	loss 3.1247 (3.3003)	grad_norm 1.9366 (1.4272)	mem 17417MB
[2023-02-01 13:16:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][1050/1251]	eta 0:01:54 lr 0.000659	time 0.5545 (0.5700)	loss 3.8987 (3.3075)	grad_norm 1.4596 (1.4266)	mem 17417MB
[2023-02-01 13:17:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][1100/1251]	eta 0:01:26 lr 0.000659	time 0.6347 (0.5699)	loss 3.5571 (3.3109)	grad_norm 1.5252 (1.4267)	mem 17417MB
[2023-02-01 13:17:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][1150/1251]	eta 0:00:57 lr 0.000658	time 0.5518 (0.5697)	loss 2.6055 (3.3156)	grad_norm 1.6450 (1.4287)	mem 17417MB
[2023-02-01 13:18:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][1200/1251]	eta 0:00:29 lr 0.000658	time 0.5563 (0.5697)	loss 3.7214 (3.3168)	grad_norm 1.8994 (1.4295)	mem 17417MB
[2023-02-01 13:18:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [119/300][1250/1251]	eta 0:00:00 lr 0.000658	time 0.5512 (0.5696)	loss 3.5780 (3.3168)	grad_norm 1.4432 (1.4314)	mem 17417MB
[2023-02-01 13:18:31 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 119 training takes 0:11:52
[2023-02-01 13:18:31 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_119.pth saving......
[2023-02-01 13:18:33 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_119.pth saved !!!
[2023-02-01 13:18:33 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.842 (0.842)	Loss 0.8755 (0.8755)	Acc@1 77.148 (77.148)	Acc@5 95.801 (95.801)	Mem 17417MB
[2023-02-01 13:18:42 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.630 Acc@5 94.846
[2023-02-01 13:18:42 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.6%
[2023-02-01 13:18:43 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.187 (1.187)	Loss 0.8443 (0.8443)	Acc@1 80.957 (80.957)	Acc@5 95.801 (95.801)	Mem 17417MB
[2023-02-01 13:18:51 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.846 Acc@5 95.744
[2023-02-01 13:18:51 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.8%
[2023-02-01 13:18:51 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.85% at 119 epoch
[2023-02-01 13:18:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][0/1251]	eta 0:35:33 lr 0.000658	time 1.7054 (1.7054)	loss 2.9550 (2.9550)	grad_norm 1.3362 (1.3362)	mem 17417MB
[2023-02-01 13:19:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][50/1251]	eta 0:11:53 lr 0.000658	time 0.5651 (0.5942)	loss 2.5058 (3.3708)	grad_norm 1.4550 (1.4422)	mem 17417MB
[2023-02-01 13:19:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][100/1251]	eta 0:11:10 lr 0.000658	time 0.6425 (0.5825)	loss 3.6842 (3.3007)	grad_norm 1.2710 (1.4324)	mem 17417MB
[2023-02-01 13:20:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][150/1251]	eta 0:10:35 lr 0.000657	time 0.5536 (0.5777)	loss 3.3467 (3.2870)	grad_norm 1.3038 (1.4297)	mem 17417MB
[2023-02-01 13:20:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][200/1251]	eta 0:10:05 lr 0.000657	time 0.5551 (0.5766)	loss 3.1551 (3.2980)	grad_norm 1.3654 (1.4280)	mem 17417MB
[2023-02-01 13:21:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][250/1251]	eta 0:09:35 lr 0.000657	time 0.6371 (0.5752)	loss 2.6300 (3.3104)	grad_norm 1.4396 (1.4286)	mem 17417MB
[2023-02-01 13:21:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][300/1251]	eta 0:09:06 lr 0.000657	time 0.5553 (0.5741)	loss 2.2546 (3.3251)	grad_norm 1.5905 (1.4247)	mem 17417MB
[2023-02-01 13:22:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][350/1251]	eta 0:08:36 lr 0.000657	time 0.5633 (0.5738)	loss 3.9240 (3.3357)	grad_norm 1.3258 (1.4291)	mem 17417MB
[2023-02-01 13:22:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][400/1251]	eta 0:08:07 lr 0.000656	time 0.6278 (0.5730)	loss 2.3801 (3.3456)	grad_norm 1.2752 (1.4307)	mem 17417MB
[2023-02-01 13:23:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][450/1251]	eta 0:07:38 lr 0.000656	time 0.5590 (0.5728)	loss 2.7449 (3.3482)	grad_norm 1.4698 (1.4313)	mem 17417MB
[2023-02-01 13:23:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][500/1251]	eta 0:07:09 lr 0.000656	time 0.6413 (0.5723)	loss 3.0390 (3.3493)	grad_norm 1.3268 (1.4272)	mem 17417MB
[2023-02-01 13:24:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][550/1251]	eta 0:06:41 lr 0.000656	time 0.5574 (0.5722)	loss 3.6910 (3.3479)	grad_norm 1.2772 (1.4313)	mem 17417MB
[2023-02-01 13:24:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][600/1251]	eta 0:06:12 lr 0.000656	time 0.5605 (0.5721)	loss 3.4878 (3.3468)	grad_norm 1.3371 (1.4300)	mem 17417MB
[2023-02-01 13:25:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][650/1251]	eta 0:05:43 lr 0.000655	time 0.5595 (0.5721)	loss 3.9848 (3.3384)	grad_norm 1.4503 (1.4281)	mem 17417MB
[2023-02-01 13:25:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][700/1251]	eta 0:05:14 lr 0.000655	time 0.5533 (0.5717)	loss 2.3796 (3.3356)	grad_norm 1.3175 (1.4262)	mem 17417MB
[2023-02-01 13:26:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][750/1251]	eta 0:04:46 lr 0.000655	time 0.6252 (0.5718)	loss 4.0449 (3.3356)	grad_norm 1.4546 (1.4277)	mem 17417MB
[2023-02-01 13:26:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][800/1251]	eta 0:04:17 lr 0.000655	time 0.5546 (0.5714)	loss 2.5367 (3.3308)	grad_norm 1.5711 (1.4265)	mem 17417MB
[2023-02-01 13:26:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][850/1251]	eta 0:03:49 lr 0.000655	time 0.5498 (0.5713)	loss 2.5336 (3.3339)	grad_norm 1.4874 (1.4264)	mem 17417MB
[2023-02-01 13:27:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][900/1251]	eta 0:03:20 lr 0.000654	time 0.6406 (0.5714)	loss 3.2164 (3.3338)	grad_norm 1.4387 (1.4266)	mem 17417MB
[2023-02-01 13:27:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][950/1251]	eta 0:02:51 lr 0.000654	time 0.5561 (0.5714)	loss 2.3847 (3.3270)	grad_norm 1.3336 (1.4265)	mem 17417MB
[2023-02-01 13:28:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][1000/1251]	eta 0:02:23 lr 0.000654	time 0.5570 (0.5714)	loss 2.9462 (3.3315)	grad_norm 1.3851 (1.4261)	mem 17417MB
[2023-02-01 13:28:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][1050/1251]	eta 0:01:54 lr 0.000654	time 0.5563 (0.5715)	loss 3.5053 (3.3305)	grad_norm 1.4663 (1.4261)	mem 17417MB
[2023-02-01 13:29:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][1100/1251]	eta 0:01:26 lr 0.000654	time 0.5639 (0.5713)	loss 3.5087 (3.3296)	grad_norm 1.3177 (1.4245)	mem 17417MB
[2023-02-01 13:29:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][1150/1251]	eta 0:00:57 lr 0.000653	time 0.5509 (0.5712)	loss 3.7142 (3.3267)	grad_norm 1.5079 (1.4254)	mem 17417MB
[2023-02-01 13:30:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][1200/1251]	eta 0:00:29 lr 0.000653	time 0.6261 (0.5711)	loss 3.7278 (3.3257)	grad_norm 1.3258 (1.4258)	mem 17417MB
[2023-02-01 13:30:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [120/300][1250/1251]	eta 0:00:00 lr 0.000653	time 0.5511 (0.5711)	loss 2.2164 (3.3271)	grad_norm 1.4618 (1.4272)	mem 17417MB
[2023-02-01 13:30:45 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 120 training takes 0:11:54
[2023-02-01 13:30:45 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_120.pth saving......
[2023-02-01 13:30:47 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_120.pth saved !!!
[2023-02-01 13:30:48 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.842 (0.842)	Loss 0.8501 (0.8501)	Acc@1 79.004 (79.004)	Acc@5 95.703 (95.703)	Mem 17417MB
[2023-02-01 13:30:56 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.320 Acc@5 94.730
[2023-02-01 13:30:56 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.3%
[2023-02-01 13:30:57 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.364 (1.364)	Loss 0.7509 (0.7509)	Acc@1 81.055 (81.055)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-01 13:31:05 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.884 Acc@5 95.730
[2023-02-01 13:31:05 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.9%
[2023-02-01 13:31:05 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.88% at 120 epoch
[2023-02-01 13:31:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][0/1251]	eta 0:35:41 lr 0.000653	time 1.7117 (1.7117)	loss 2.6285 (2.6285)	grad_norm 1.3664 (1.3664)	mem 17417MB
[2023-02-01 13:31:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][50/1251]	eta 0:11:58 lr 0.000653	time 0.5546 (0.5982)	loss 2.4307 (3.3390)	grad_norm 1.5432 (1.4084)	mem 17417MB
[2023-02-01 13:32:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][100/1251]	eta 0:11:12 lr 0.000653	time 0.6205 (0.5847)	loss 2.8084 (3.2710)	grad_norm 1.6056 (1.4307)	mem 17417MB
[2023-02-01 13:32:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][150/1251]	eta 0:10:37 lr 0.000652	time 0.5571 (0.5792)	loss 3.6068 (3.2520)	grad_norm 1.4475 (1.4266)	mem 17417MB
[2023-02-01 13:33:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][200/1251]	eta 0:10:06 lr 0.000652	time 0.5571 (0.5766)	loss 3.3255 (3.2516)	grad_norm 1.4408 (nan)	mem 17417MB
[2023-02-01 13:33:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][250/1251]	eta 0:09:36 lr 0.000652	time 0.5561 (0.5756)	loss 3.4280 (3.2631)	grad_norm 1.3336 (nan)	mem 17417MB
[2023-02-01 13:33:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][300/1251]	eta 0:09:06 lr 0.000652	time 0.5561 (0.5742)	loss 3.1914 (3.2672)	grad_norm 1.5499 (nan)	mem 17417MB
[2023-02-01 13:34:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][350/1251]	eta 0:08:36 lr 0.000652	time 0.5537 (0.5735)	loss 2.6198 (3.2735)	grad_norm 1.3034 (nan)	mem 17417MB
[2023-02-01 13:34:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][400/1251]	eta 0:08:07 lr 0.000651	time 0.5660 (0.5728)	loss 3.3754 (3.2737)	grad_norm 1.4788 (nan)	mem 17417MB
[2023-02-01 13:35:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][450/1251]	eta 0:07:38 lr 0.000651	time 0.6433 (0.5728)	loss 3.7907 (3.2855)	grad_norm 1.3375 (nan)	mem 17417MB
[2023-02-01 13:35:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][500/1251]	eta 0:07:09 lr 0.000651	time 0.6124 (0.5722)	loss 3.5209 (3.2905)	grad_norm 1.4737 (nan)	mem 17417MB
[2023-02-01 13:36:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][550/1251]	eta 0:06:40 lr 0.000651	time 0.5598 (0.5719)	loss 2.1844 (3.2941)	grad_norm 1.4502 (nan)	mem 17417MB
[2023-02-01 13:36:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][600/1251]	eta 0:06:12 lr 0.000651	time 0.5482 (0.5722)	loss 3.0799 (3.2904)	grad_norm 1.4622 (nan)	mem 17417MB
[2023-02-01 13:37:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][650/1251]	eta 0:05:43 lr 0.000650	time 0.5569 (0.5718)	loss 3.4956 (3.2977)	grad_norm 1.4693 (nan)	mem 17417MB
[2023-02-01 13:37:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][700/1251]	eta 0:05:14 lr 0.000650	time 0.5587 (0.5715)	loss 3.7450 (3.2945)	grad_norm 1.2955 (nan)	mem 17417MB
[2023-02-01 13:38:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][750/1251]	eta 0:04:46 lr 0.000650	time 0.5630 (0.5715)	loss 3.4398 (3.3038)	grad_norm 1.2435 (nan)	mem 17417MB
[2023-02-01 13:38:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][800/1251]	eta 0:04:17 lr 0.000650	time 0.5534 (0.5714)	loss 2.7450 (3.3047)	grad_norm 1.3447 (nan)	mem 17417MB
[2023-02-01 13:39:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][850/1251]	eta 0:03:49 lr 0.000650	time 0.5661 (0.5712)	loss 3.0458 (3.3011)	grad_norm 1.3798 (nan)	mem 17417MB
[2023-02-01 13:39:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][900/1251]	eta 0:03:20 lr 0.000649	time 0.6173 (0.5714)	loss 3.6367 (3.3037)	grad_norm 1.4819 (nan)	mem 17417MB
[2023-02-01 13:40:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][950/1251]	eta 0:02:51 lr 0.000649	time 0.5560 (0.5711)	loss 3.4770 (3.3032)	grad_norm 1.5716 (nan)	mem 17417MB
[2023-02-01 13:40:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][1000/1251]	eta 0:02:23 lr 0.000649	time 0.5518 (0.5711)	loss 3.1310 (3.3065)	grad_norm 1.3947 (nan)	mem 17417MB
[2023-02-01 13:41:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][1050/1251]	eta 0:01:54 lr 0.000649	time 0.5540 (0.5711)	loss 3.9752 (3.3082)	grad_norm 1.4426 (nan)	mem 17417MB
[2023-02-01 13:41:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][1100/1251]	eta 0:01:26 lr 0.000649	time 0.5564 (0.5710)	loss 3.1595 (3.3054)	grad_norm 1.7340 (nan)	mem 17417MB
[2023-02-01 13:42:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][1150/1251]	eta 0:00:57 lr 0.000648	time 0.5564 (0.5710)	loss 3.5533 (3.3002)	grad_norm 1.2634 (nan)	mem 17417MB
[2023-02-01 13:42:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][1200/1251]	eta 0:00:29 lr 0.000648	time 0.5659 (0.5707)	loss 2.4429 (3.3016)	grad_norm 1.4265 (nan)	mem 17417MB
[2023-02-01 13:42:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [121/300][1250/1251]	eta 0:00:00 lr 0.000648	time 0.6171 (0.5706)	loss 2.5173 (3.3050)	grad_norm 1.1957 (nan)	mem 17417MB
[2023-02-01 13:42:59 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 121 training takes 0:11:53
[2023-02-01 13:43:00 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_121.pth saving......
[2023-02-01 13:43:01 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_121.pth saved !!!
[2023-02-01 13:43:02 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.863 (0.863)	Loss 0.8750 (0.8750)	Acc@1 79.102 (79.102)	Acc@5 95.215 (95.215)	Mem 17417MB
[2023-02-01 13:43:10 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.662 Acc@5 94.730
[2023-02-01 13:43:10 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.7%
[2023-02-01 13:43:11 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.324 (1.324)	Loss 0.8809 (0.8809)	Acc@1 78.711 (78.711)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-01 13:43:19 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.930 Acc@5 95.750
[2023-02-01 13:43:19 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 80.9%
[2023-02-01 13:43:19 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.93% at 121 epoch
[2023-02-01 13:43:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][0/1251]	eta 0:37:04 lr 0.000648	time 1.7779 (1.7779)	loss 3.6210 (3.6210)	grad_norm 1.3363 (1.3363)	mem 17417MB
[2023-02-01 13:43:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][50/1251]	eta 0:11:51 lr 0.000648	time 0.5498 (0.5926)	loss 2.9245 (3.2839)	grad_norm 1.3592 (1.3956)	mem 17417MB
[2023-02-01 13:44:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][100/1251]	eta 0:11:09 lr 0.000648	time 0.7333 (0.5817)	loss 2.0468 (3.1838)	grad_norm 1.5168 (1.4144)	mem 17417MB
[2023-02-01 13:44:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][150/1251]	eta 0:10:35 lr 0.000647	time 0.5508 (0.5770)	loss 3.0915 (3.1969)	grad_norm 1.4355 (1.4209)	mem 17417MB
[2023-02-01 13:45:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][200/1251]	eta 0:10:04 lr 0.000647	time 0.5733 (0.5752)	loss 2.9012 (3.1998)	grad_norm 1.4389 (1.4195)	mem 17417MB
[2023-02-01 13:45:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][250/1251]	eta 0:09:34 lr 0.000647	time 0.5530 (0.5743)	loss 3.7073 (3.2224)	grad_norm 1.3363 (1.4187)	mem 17417MB
[2023-02-01 13:46:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][300/1251]	eta 0:09:05 lr 0.000647	time 0.5586 (0.5731)	loss 3.0738 (3.2246)	grad_norm 1.3748 (1.4229)	mem 17417MB
[2023-02-01 13:46:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][350/1251]	eta 0:08:36 lr 0.000647	time 0.5564 (0.5732)	loss 3.1642 (3.2347)	grad_norm 1.3028 (1.4170)	mem 17417MB
[2023-02-01 13:47:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][400/1251]	eta 0:08:07 lr 0.000646	time 0.5640 (0.5724)	loss 3.7141 (3.2293)	grad_norm 1.6987 (1.4202)	mem 17417MB
[2023-02-01 13:47:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][450/1251]	eta 0:07:38 lr 0.000646	time 0.6161 (0.5725)	loss 2.5171 (3.2389)	grad_norm 1.3040 (1.4210)	mem 17417MB
[2023-02-01 13:48:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][500/1251]	eta 0:07:09 lr 0.000646	time 0.6331 (0.5719)	loss 3.4205 (3.2396)	grad_norm 1.4255 (1.4196)	mem 17417MB
[2023-02-01 13:48:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][550/1251]	eta 0:06:40 lr 0.000646	time 0.5550 (0.5716)	loss 3.0917 (3.2428)	grad_norm 1.4792 (1.4230)	mem 17417MB
[2023-02-01 13:49:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][600/1251]	eta 0:06:12 lr 0.000646	time 0.5621 (0.5715)	loss 2.5223 (3.2399)	grad_norm 1.3826 (1.4226)	mem 17417MB
[2023-02-01 13:49:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][650/1251]	eta 0:05:43 lr 0.000645	time 0.5546 (0.5714)	loss 3.7828 (3.2547)	grad_norm 1.6688 (1.4245)	mem 17417MB
[2023-02-01 13:50:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][700/1251]	eta 0:05:14 lr 0.000645	time 0.5515 (0.5713)	loss 3.6370 (3.2645)	grad_norm 1.3448 (1.4252)	mem 17417MB
[2023-02-01 13:50:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][750/1251]	eta 0:04:46 lr 0.000645	time 0.5547 (0.5712)	loss 2.9155 (3.2723)	grad_norm 1.4630 (1.4261)	mem 17417MB
[2023-02-01 13:50:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][800/1251]	eta 0:04:17 lr 0.000645	time 0.6520 (0.5712)	loss 3.2573 (3.2771)	grad_norm 1.3855 (1.4271)	mem 17417MB
[2023-02-01 13:51:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][850/1251]	eta 0:03:48 lr 0.000645	time 0.5567 (0.5711)	loss 3.6391 (3.2834)	grad_norm 1.3365 (1.4286)	mem 17417MB
[2023-02-01 13:51:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][900/1251]	eta 0:03:20 lr 0.000644	time 0.6160 (0.5711)	loss 3.2364 (3.2859)	grad_norm 1.5406 (1.4307)	mem 17417MB
[2023-02-01 13:52:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][950/1251]	eta 0:02:51 lr 0.000644	time 0.5550 (0.5708)	loss 3.1633 (3.2857)	grad_norm 1.3788 (1.4315)	mem 17417MB
[2023-02-01 13:52:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][1000/1251]	eta 0:02:23 lr 0.000644	time 0.5659 (0.5710)	loss 3.6565 (3.2855)	grad_norm 1.2942 (1.4323)	mem 17417MB
[2023-02-01 13:53:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][1050/1251]	eta 0:01:54 lr 0.000644	time 0.5563 (0.5707)	loss 3.4130 (3.2853)	grad_norm 1.3165 (nan)	mem 17417MB
[2023-02-01 13:53:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][1100/1251]	eta 0:01:26 lr 0.000644	time 0.6349 (0.5707)	loss 3.0929 (3.2837)	grad_norm 1.5394 (nan)	mem 17417MB
[2023-02-01 13:54:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][1150/1251]	eta 0:00:57 lr 0.000644	time 0.5601 (0.5706)	loss 3.5764 (3.2859)	grad_norm 1.3870 (nan)	mem 17417MB
[2023-02-01 13:54:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][1200/1251]	eta 0:00:29 lr 0.000643	time 0.6244 (0.5706)	loss 3.4832 (3.2859)	grad_norm 1.4179 (nan)	mem 17417MB
[2023-02-01 13:55:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [122/300][1250/1251]	eta 0:00:00 lr 0.000643	time 0.5517 (0.5705)	loss 3.4660 (3.2876)	grad_norm 1.6303 (nan)	mem 17417MB
[2023-02-01 13:55:13 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 122 training takes 0:11:53
[2023-02-01 13:55:13 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_122.pth saving......
[2023-02-01 13:55:15 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_122.pth saved !!!
[2023-02-01 13:55:16 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.915 (0.915)	Loss 0.8313 (0.8313)	Acc@1 79.688 (79.688)	Acc@5 95.410 (95.410)	Mem 17417MB
[2023-02-01 13:55:24 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.722 Acc@5 94.730
[2023-02-01 13:55:24 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.7%
[2023-02-01 13:55:25 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.178 (1.178)	Loss 0.8168 (0.8168)	Acc@1 79.688 (79.688)	Acc@5 95.703 (95.703)	Mem 17417MB
[2023-02-01 13:55:33 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.972 Acc@5 95.792
[2023-02-01 13:55:33 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.0%
[2023-02-01 13:55:33 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.97% at 122 epoch
[2023-02-01 13:55:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][0/1251]	eta 0:34:35 lr 0.000643	time 1.6590 (1.6590)	loss 3.4967 (3.4967)	grad_norm 1.5430 (1.5430)	mem 17417MB
[2023-02-01 13:56:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][50/1251]	eta 0:11:57 lr 0.000643	time 0.6376 (0.5970)	loss 4.1374 (3.3159)	grad_norm 1.5966 (1.4722)	mem 17417MB
[2023-02-01 13:56:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][100/1251]	eta 0:11:10 lr 0.000643	time 0.5510 (0.5825)	loss 3.5864 (3.2722)	grad_norm 1.4625 (1.4559)	mem 17417MB
[2023-02-01 13:57:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][150/1251]	eta 0:10:37 lr 0.000643	time 0.5548 (0.5789)	loss 2.9824 (3.2864)	grad_norm 1.3390 (1.4407)	mem 17417MB
[2023-02-01 13:57:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][200/1251]	eta 0:10:06 lr 0.000642	time 0.6236 (0.5770)	loss 3.6954 (3.3163)	grad_norm 1.3690 (1.4391)	mem 17417MB
[2023-02-01 13:57:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][250/1251]	eta 0:09:36 lr 0.000642	time 0.5541 (0.5757)	loss 3.1849 (3.3035)	grad_norm 1.4726 (1.4341)	mem 17417MB
[2023-02-01 13:58:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][300/1251]	eta 0:09:06 lr 0.000642	time 0.5546 (0.5742)	loss 3.4329 (3.2833)	grad_norm 1.5008 (1.4314)	mem 17417MB
[2023-02-01 13:58:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][350/1251]	eta 0:08:36 lr 0.000642	time 0.5536 (0.5737)	loss 3.7230 (3.3054)	grad_norm 2.0403 (1.4306)	mem 17417MB
[2023-02-01 13:59:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][400/1251]	eta 0:08:07 lr 0.000642	time 0.5554 (0.5731)	loss 3.4280 (3.3059)	grad_norm 1.7326 (1.4317)	mem 17417MB
[2023-02-01 13:59:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][450/1251]	eta 0:07:39 lr 0.000641	time 0.6183 (0.5731)	loss 3.4661 (3.3082)	grad_norm 1.3579 (1.4375)	mem 17417MB
[2023-02-01 14:00:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][500/1251]	eta 0:07:09 lr 0.000641	time 0.5556 (0.5723)	loss 3.4944 (3.3030)	grad_norm 1.4383 (1.4374)	mem 17417MB
[2023-02-01 14:00:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][550/1251]	eta 0:06:41 lr 0.000641	time 0.6230 (0.5722)	loss 3.0961 (3.3056)	grad_norm 1.6362 (1.4390)	mem 17417MB
[2023-02-01 14:01:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][600/1251]	eta 0:06:12 lr 0.000641	time 0.5573 (0.5720)	loss 3.9082 (3.3124)	grad_norm 1.3942 (1.4399)	mem 17417MB
[2023-02-01 14:01:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][650/1251]	eta 0:05:43 lr 0.000641	time 0.5631 (0.5716)	loss 2.8303 (3.3183)	grad_norm 1.5347 (1.4390)	mem 17417MB
[2023-02-01 14:02:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][700/1251]	eta 0:05:14 lr 0.000640	time 0.5543 (0.5714)	loss 3.2947 (3.3127)	grad_norm 1.2940 (1.4417)	mem 17417MB
[2023-02-01 14:02:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][750/1251]	eta 0:04:46 lr 0.000640	time 0.5631 (0.5710)	loss 3.8570 (3.3110)	grad_norm 1.3127 (1.4400)	mem 17417MB
[2023-02-01 14:03:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][800/1251]	eta 0:04:17 lr 0.000640	time 0.6067 (0.5710)	loss 3.9923 (3.3158)	grad_norm 1.4978 (1.4430)	mem 17417MB
[2023-02-01 14:03:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][850/1251]	eta 0:03:48 lr 0.000640	time 0.5529 (0.5707)	loss 3.2719 (3.3175)	grad_norm 1.3273 (1.4429)	mem 17417MB
[2023-02-01 14:04:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][900/1251]	eta 0:03:20 lr 0.000640	time 0.6251 (0.5707)	loss 3.5058 (3.3123)	grad_norm 1.5895 (1.4427)	mem 17417MB
[2023-02-01 14:04:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][950/1251]	eta 0:02:51 lr 0.000639	time 0.5528 (0.5707)	loss 3.2050 (3.3123)	grad_norm 1.4098 (1.4419)	mem 17417MB
[2023-02-01 14:05:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][1000/1251]	eta 0:02:23 lr 0.000639	time 0.5687 (0.5707)	loss 3.3098 (3.3117)	grad_norm 1.4223 (1.4430)	mem 17417MB
[2023-02-01 14:05:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][1050/1251]	eta 0:01:54 lr 0.000639	time 0.5562 (0.5705)	loss 3.5038 (3.3131)	grad_norm 1.5880 (1.4412)	mem 17417MB
[2023-02-01 14:06:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][1100/1251]	eta 0:01:26 lr 0.000639	time 0.5577 (0.5705)	loss 3.4288 (3.3148)	grad_norm 1.8991 (1.4425)	mem 17417MB
[2023-02-01 14:06:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][1150/1251]	eta 0:00:57 lr 0.000639	time 0.5617 (0.5703)	loss 3.9521 (3.3110)	grad_norm 1.7197 (1.4429)	mem 17417MB
[2023-02-01 14:06:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][1200/1251]	eta 0:00:29 lr 0.000638	time 0.5617 (0.5705)	loss 3.5166 (3.3111)	grad_norm 1.2981 (1.4434)	mem 17417MB
[2023-02-01 14:07:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [123/300][1250/1251]	eta 0:00:00 lr 0.000638	time 0.5501 (0.5705)	loss 3.5728 (3.3071)	grad_norm 1.3910 (1.4420)	mem 17417MB
[2023-02-01 14:07:27 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 123 training takes 0:11:53
[2023-02-01 14:07:27 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_123.pth saving......
[2023-02-01 14:07:29 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_123.pth saved !!!
[2023-02-01 14:07:30 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.873 (0.873)	Loss 0.8333 (0.8333)	Acc@1 79.883 (79.883)	Acc@5 95.215 (95.215)	Mem 17417MB
[2023-02-01 14:07:38 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.846 Acc@5 94.854
[2023-02-01 14:07:38 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.8%
[2023-02-01 14:07:39 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.262 (1.262)	Loss 0.8471 (0.8471)	Acc@1 80.371 (80.371)	Acc@5 95.312 (95.312)	Mem 17417MB
[2023-02-01 14:07:47 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.990 Acc@5 95.794
[2023-02-01 14:07:47 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.0%
[2023-02-01 14:07:47 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 80.99% at 123 epoch
[2023-02-01 14:07:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][0/1251]	eta 0:34:20 lr 0.000638	time 1.6473 (1.6473)	loss 3.1085 (3.1085)	grad_norm 1.3945 (1.3945)	mem 17417MB
[2023-02-01 14:08:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][50/1251]	eta 0:11:49 lr 0.000638	time 0.5561 (0.5904)	loss 3.6003 (3.2489)	grad_norm 1.5017 (1.4536)	mem 17417MB
[2023-02-01 14:08:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][100/1251]	eta 0:11:09 lr 0.000638	time 0.5625 (0.5816)	loss 4.1174 (3.2456)	grad_norm 1.6072 (1.4486)	mem 17417MB
[2023-02-01 14:09:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][150/1251]	eta 0:10:35 lr 0.000638	time 0.5595 (0.5772)	loss 3.6589 (3.2707)	grad_norm 1.3490 (1.4537)	mem 17417MB
[2023-02-01 14:09:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][200/1251]	eta 0:10:05 lr 0.000637	time 0.5497 (0.5764)	loss 4.0946 (3.2720)	grad_norm 1.4042 (1.4452)	mem 17417MB
[2023-02-01 14:10:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][250/1251]	eta 0:09:34 lr 0.000637	time 0.5619 (0.5741)	loss 3.5641 (3.2966)	grad_norm 1.3532 (1.4469)	mem 17417MB
[2023-02-01 14:10:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][300/1251]	eta 0:09:05 lr 0.000637	time 0.5649 (0.5739)	loss 2.7221 (3.2878)	grad_norm 1.5409 (1.4445)	mem 17417MB
[2023-02-01 14:11:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][350/1251]	eta 0:08:36 lr 0.000637	time 0.5582 (0.5729)	loss 2.7225 (3.3018)	grad_norm 1.4670 (1.4431)	mem 17417MB
[2023-02-01 14:11:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][400/1251]	eta 0:08:07 lr 0.000637	time 0.5550 (0.5723)	loss 3.5944 (3.3014)	grad_norm 1.3507 (1.4428)	mem 17417MB
[2023-02-01 14:12:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][450/1251]	eta 0:07:38 lr 0.000636	time 0.5550 (0.5720)	loss 2.2304 (3.3025)	grad_norm 1.3547 (1.4397)	mem 17417MB
[2023-02-01 14:12:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][500/1251]	eta 0:07:09 lr 0.000636	time 0.5548 (0.5717)	loss 3.1044 (3.3089)	grad_norm 1.3878 (1.4397)	mem 17417MB
[2023-02-01 14:13:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][550/1251]	eta 0:06:40 lr 0.000636	time 0.5611 (0.5711)	loss 3.2776 (3.3082)	grad_norm 1.4027 (nan)	mem 17417MB
[2023-02-01 14:13:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][600/1251]	eta 0:06:11 lr 0.000636	time 0.5561 (0.5713)	loss 3.9533 (3.3117)	grad_norm 1.5261 (nan)	mem 17417MB
[2023-02-01 14:13:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][650/1251]	eta 0:05:43 lr 0.000636	time 0.5625 (0.5709)	loss 2.8089 (3.3093)	grad_norm 1.3092 (nan)	mem 17417MB
[2023-02-01 14:14:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][700/1251]	eta 0:05:14 lr 0.000635	time 0.5511 (0.5710)	loss 3.4245 (3.3053)	grad_norm 1.4350 (nan)	mem 17417MB
[2023-02-01 14:14:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][750/1251]	eta 0:04:45 lr 0.000635	time 0.5630 (0.5708)	loss 3.1694 (3.3099)	grad_norm 1.4786 (nan)	mem 17417MB
[2023-02-01 14:15:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][800/1251]	eta 0:04:17 lr 0.000635	time 0.6204 (0.5706)	loss 4.3715 (3.3059)	grad_norm 1.5750 (nan)	mem 17417MB
[2023-02-01 14:15:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][850/1251]	eta 0:03:48 lr 0.000635	time 0.5527 (0.5703)	loss 2.2184 (3.3004)	grad_norm 1.4298 (nan)	mem 17417MB
[2023-02-01 14:16:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][900/1251]	eta 0:03:20 lr 0.000635	time 0.5517 (0.5703)	loss 4.0910 (3.3007)	grad_norm 1.6029 (nan)	mem 17417MB
[2023-02-01 14:16:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][950/1251]	eta 0:02:51 lr 0.000634	time 0.5616 (0.5701)	loss 3.5426 (3.3048)	grad_norm 1.5421 (nan)	mem 17417MB
[2023-02-01 14:17:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][1000/1251]	eta 0:02:23 lr 0.000634	time 0.5542 (0.5702)	loss 3.2432 (3.3028)	grad_norm 1.3817 (nan)	mem 17417MB
[2023-02-01 14:17:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][1050/1251]	eta 0:01:54 lr 0.000634	time 0.5547 (0.5700)	loss 3.7039 (3.2990)	grad_norm 1.3916 (nan)	mem 17417MB
[2023-02-01 14:18:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][1100/1251]	eta 0:01:26 lr 0.000634	time 0.6277 (0.5700)	loss 3.6163 (3.3066)	grad_norm 1.4307 (nan)	mem 17417MB
[2023-02-01 14:18:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][1150/1251]	eta 0:00:57 lr 0.000634	time 0.5613 (0.5700)	loss 2.8676 (3.3086)	grad_norm 1.6348 (nan)	mem 17417MB
[2023-02-01 14:19:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][1200/1251]	eta 0:00:29 lr 0.000633	time 0.5636 (0.5698)	loss 3.0184 (3.3119)	grad_norm 1.5606 (nan)	mem 17417MB
[2023-02-01 14:19:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [124/300][1250/1251]	eta 0:00:00 lr 0.000633	time 0.5534 (0.5699)	loss 2.6982 (3.3122)	grad_norm 1.3135 (nan)	mem 17417MB
[2023-02-01 14:19:40 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 124 training takes 0:11:53
[2023-02-01 14:19:40 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_124.pth saving......
[2023-02-01 14:19:42 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_124.pth saved !!!
[2023-02-01 14:19:43 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.880 (0.880)	Loss 0.8984 (0.8984)	Acc@1 79.395 (79.395)	Acc@5 94.531 (94.531)	Mem 17417MB
[2023-02-01 14:19:51 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.764 Acc@5 94.712
[2023-02-01 14:19:51 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.8%
[2023-02-01 14:19:52 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.198 (1.198)	Loss 0.8271 (0.8271)	Acc@1 81.055 (81.055)	Acc@5 95.410 (95.410)	Mem 17417MB
[2023-02-01 14:20:00 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.036 Acc@5 95.780
[2023-02-01 14:20:00 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.0%
[2023-02-01 14:20:00 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.04% at 124 epoch
[2023-02-01 14:20:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][0/1251]	eta 0:35:14 lr 0.000633	time 1.6901 (1.6901)	loss 3.1582 (3.1582)	grad_norm 1.3126 (1.3126)	mem 17417MB
[2023-02-01 14:20:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][50/1251]	eta 0:11:57 lr 0.000633	time 0.5550 (0.5971)	loss 3.9491 (3.2173)	grad_norm 1.4250 (1.4142)	mem 17417MB
[2023-02-01 14:20:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][100/1251]	eta 0:11:10 lr 0.000633	time 0.5532 (0.5828)	loss 3.3466 (3.2709)	grad_norm 1.4224 (1.4347)	mem 17417MB
[2023-02-01 14:21:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][150/1251]	eta 0:10:37 lr 0.000633	time 0.5560 (0.5788)	loss 3.1348 (3.3099)	grad_norm 1.3989 (1.4208)	mem 17417MB
[2023-02-01 14:21:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][200/1251]	eta 0:10:05 lr 0.000632	time 0.5582 (0.5757)	loss 3.6164 (3.2858)	grad_norm 1.5232 (1.4263)	mem 17417MB
[2023-02-01 14:22:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][250/1251]	eta 0:09:34 lr 0.000632	time 0.5551 (0.5735)	loss 3.1369 (3.2942)	grad_norm 1.5311 (1.4279)	mem 17417MB
[2023-02-01 14:22:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][300/1251]	eta 0:09:05 lr 0.000632	time 0.5608 (0.5736)	loss 3.0580 (3.3252)	grad_norm 1.2873 (1.4345)	mem 17417MB
[2023-02-01 14:23:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][350/1251]	eta 0:08:36 lr 0.000632	time 0.5771 (0.5727)	loss 2.5884 (3.3191)	grad_norm 1.4042 (1.4381)	mem 17417MB
[2023-02-01 14:23:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][400/1251]	eta 0:08:07 lr 0.000632	time 0.6324 (0.5723)	loss 3.7919 (3.3073)	grad_norm 1.3272 (1.4443)	mem 17417MB
[2023-02-01 14:24:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][450/1251]	eta 0:07:38 lr 0.000631	time 0.5579 (0.5721)	loss 2.9555 (3.3020)	grad_norm 1.4201 (1.4422)	mem 17417MB
[2023-02-01 14:24:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][500/1251]	eta 0:07:09 lr 0.000631	time 0.5576 (0.5714)	loss 3.8397 (3.2912)	grad_norm 1.6372 (1.4421)	mem 17417MB
[2023-02-01 14:25:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][550/1251]	eta 0:06:40 lr 0.000631	time 0.5592 (0.5715)	loss 3.1426 (3.2916)	grad_norm 1.3589 (1.4398)	mem 17417MB
[2023-02-01 14:25:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][600/1251]	eta 0:06:12 lr 0.000631	time 0.5587 (0.5714)	loss 2.8778 (3.2916)	grad_norm 1.4396 (1.4418)	mem 17417MB
[2023-02-01 14:26:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][650/1251]	eta 0:05:43 lr 0.000631	time 0.5495 (0.5712)	loss 1.9911 (3.2840)	grad_norm 1.4036 (1.4408)	mem 17417MB
[2023-02-01 14:26:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][700/1251]	eta 0:05:14 lr 0.000630	time 0.5657 (0.5711)	loss 3.7964 (3.2779)	grad_norm 1.5584 (1.4408)	mem 17417MB
[2023-02-01 14:27:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][750/1251]	eta 0:04:45 lr 0.000630	time 0.6282 (0.5707)	loss 2.2345 (3.2787)	grad_norm 1.3883 (1.4423)	mem 17417MB
[2023-02-01 14:27:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][800/1251]	eta 0:04:17 lr 0.000630	time 0.5668 (0.5706)	loss 3.2685 (3.2802)	grad_norm 1.2984 (1.4426)	mem 17417MB
[2023-02-01 14:28:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][850/1251]	eta 0:03:48 lr 0.000630	time 0.5571 (0.5706)	loss 3.5776 (3.2752)	grad_norm 1.5159 (1.4431)	mem 17417MB
[2023-02-01 14:28:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][900/1251]	eta 0:03:20 lr 0.000630	time 0.5598 (0.5705)	loss 3.7955 (3.2790)	grad_norm 1.5000 (1.4435)	mem 17417MB
[2023-02-01 14:29:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][950/1251]	eta 0:02:51 lr 0.000629	time 0.5557 (0.5704)	loss 3.0980 (3.2769)	grad_norm 1.4212 (1.4431)	mem 17417MB
[2023-02-01 14:29:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][1000/1251]	eta 0:02:23 lr 0.000629	time 0.6497 (0.5705)	loss 3.6327 (3.2789)	grad_norm 1.4839 (1.4439)	mem 17417MB
[2023-02-01 14:29:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][1050/1251]	eta 0:01:54 lr 0.000629	time 0.5556 (0.5703)	loss 3.4018 (3.2788)	grad_norm 1.3478 (1.4435)	mem 17417MB
[2023-02-01 14:30:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][1100/1251]	eta 0:01:26 lr 0.000629	time 0.5547 (0.5705)	loss 3.7470 (3.2769)	grad_norm 1.2958 (1.4437)	mem 17417MB
[2023-02-01 14:30:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][1150/1251]	eta 0:00:57 lr 0.000629	time 0.5594 (0.5704)	loss 3.8418 (3.2792)	grad_norm 1.4704 (1.4439)	mem 17417MB
[2023-02-01 14:31:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][1200/1251]	eta 0:00:29 lr 0.000628	time 0.5616 (0.5705)	loss 3.0802 (3.2849)	grad_norm 1.3743 (1.4442)	mem 17417MB
[2023-02-01 14:31:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [125/300][1250/1251]	eta 0:00:00 lr 0.000628	time 0.6396 (0.5705)	loss 3.0994 (3.2876)	grad_norm 1.3407 (1.4444)	mem 17417MB
[2023-02-01 14:31:54 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 125 training takes 0:11:53
[2023-02-01 14:31:54 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_125.pth saving......
[2023-02-01 14:31:56 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_125.pth saved !!!
[2023-02-01 14:31:57 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.832 (0.832)	Loss 0.8111 (0.8111)	Acc@1 79.883 (79.883)	Acc@5 95.410 (95.410)	Mem 17417MB
[2023-02-01 14:32:04 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.708 Acc@5 94.844
[2023-02-01 14:32:04 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.7%
[2023-02-01 14:32:06 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.162 (1.162)	Loss 0.7853 (0.7853)	Acc@1 81.543 (81.543)	Acc@5 95.508 (95.508)	Mem 17417MB
[2023-02-01 14:32:14 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.046 Acc@5 95.792
[2023-02-01 14:32:14 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.0%
[2023-02-01 14:32:14 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.05% at 125 epoch
[2023-02-01 14:32:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][0/1251]	eta 0:38:26 lr 0.000628	time 1.8435 (1.8435)	loss 3.9149 (3.9149)	grad_norm 1.3646 (1.3646)	mem 17417MB
[2023-02-01 14:32:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][50/1251]	eta 0:11:46 lr 0.000628	time 0.5801 (0.5881)	loss 3.1757 (3.3151)	grad_norm 1.5598 (1.4470)	mem 17417MB
[2023-02-01 14:33:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][100/1251]	eta 0:11:09 lr 0.000628	time 0.5563 (0.5816)	loss 4.1974 (3.3366)	grad_norm 1.3690 (1.4577)	mem 17417MB
[2023-02-01 14:33:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][150/1251]	eta 0:10:35 lr 0.000627	time 0.5526 (0.5769)	loss 2.8716 (3.3191)	grad_norm 1.2803 (1.4521)	mem 17417MB
[2023-02-01 14:34:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][200/1251]	eta 0:10:04 lr 0.000627	time 0.5657 (0.5755)	loss 4.2120 (3.3266)	grad_norm 1.4217 (1.4439)	mem 17417MB
[2023-02-01 14:34:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][250/1251]	eta 0:09:35 lr 0.000627	time 0.5574 (0.5747)	loss 3.6002 (3.3053)	grad_norm 1.6270 (1.4457)	mem 17417MB
[2023-02-01 14:35:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][300/1251]	eta 0:09:06 lr 0.000627	time 0.5576 (0.5745)	loss 2.1676 (3.3182)	grad_norm 1.3509 (1.4488)	mem 17417MB
[2023-02-01 14:35:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][350/1251]	eta 0:08:36 lr 0.000627	time 0.5604 (0.5736)	loss 3.6725 (3.3095)	grad_norm 1.4039 (1.4502)	mem 17417MB
[2023-02-01 14:36:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][400/1251]	eta 0:08:08 lr 0.000626	time 0.5540 (0.5735)	loss 3.2482 (3.3011)	grad_norm 1.4978 (nan)	mem 17417MB
[2023-02-01 14:36:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][450/1251]	eta 0:07:38 lr 0.000626	time 0.5559 (0.5725)	loss 3.3914 (3.2981)	grad_norm 1.4180 (nan)	mem 17417MB
[2023-02-01 14:37:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][500/1251]	eta 0:07:10 lr 0.000626	time 0.5554 (0.5729)	loss 3.1355 (3.2930)	grad_norm 1.4520 (nan)	mem 17417MB
[2023-02-01 14:37:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][550/1251]	eta 0:06:41 lr 0.000626	time 0.5566 (0.5723)	loss 3.2292 (3.2846)	grad_norm 1.4420 (nan)	mem 17417MB
[2023-02-01 14:37:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][600/1251]	eta 0:06:12 lr 0.000626	time 0.5643 (0.5726)	loss 2.8798 (3.2865)	grad_norm 1.5922 (nan)	mem 17417MB
[2023-02-01 14:38:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][650/1251]	eta 0:05:43 lr 0.000625	time 0.5571 (0.5722)	loss 3.6560 (3.2867)	grad_norm 1.6137 (nan)	mem 17417MB
[2023-02-01 14:38:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][700/1251]	eta 0:05:15 lr 0.000625	time 0.5569 (0.5723)	loss 3.4492 (3.2911)	grad_norm 1.3664 (nan)	mem 17417MB
[2023-02-01 14:39:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][750/1251]	eta 0:04:46 lr 0.000625	time 0.5607 (0.5719)	loss 3.1426 (3.2889)	grad_norm 1.4299 (nan)	mem 17417MB
[2023-02-01 14:39:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][800/1251]	eta 0:04:18 lr 0.000625	time 0.5577 (0.5721)	loss 3.9694 (3.2863)	grad_norm 1.3802 (nan)	mem 17417MB
[2023-02-01 14:40:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][850/1251]	eta 0:03:49 lr 0.000625	time 0.5567 (0.5716)	loss 3.1162 (3.2958)	grad_norm 1.5584 (nan)	mem 17417MB
[2023-02-01 14:40:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][900/1251]	eta 0:03:20 lr 0.000624	time 0.5543 (0.5718)	loss 3.4532 (3.2938)	grad_norm 1.6128 (nan)	mem 17417MB
[2023-02-01 14:41:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][950/1251]	eta 0:02:52 lr 0.000624	time 0.5575 (0.5715)	loss 2.6625 (3.2883)	grad_norm 1.4378 (nan)	mem 17417MB
[2023-02-01 14:41:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][1000/1251]	eta 0:02:23 lr 0.000624	time 0.6107 (0.5717)	loss 3.5190 (3.2894)	grad_norm 1.5247 (nan)	mem 17417MB
[2023-02-01 14:42:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][1050/1251]	eta 0:01:54 lr 0.000624	time 0.5554 (0.5716)	loss 3.0313 (3.2886)	grad_norm 1.5720 (nan)	mem 17417MB
[2023-02-01 14:42:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][1100/1251]	eta 0:01:26 lr 0.000624	time 0.6530 (0.5716)	loss 2.6471 (3.2878)	grad_norm 1.5684 (nan)	mem 17417MB
[2023-02-01 14:43:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][1150/1251]	eta 0:00:57 lr 0.000623	time 0.5540 (0.5716)	loss 3.2752 (3.2879)	grad_norm 1.4573 (nan)	mem 17417MB
[2023-02-01 14:43:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][1200/1251]	eta 0:00:29 lr 0.000623	time 0.5651 (0.5715)	loss 4.0269 (3.2837)	grad_norm 1.5379 (nan)	mem 17417MB
[2023-02-01 14:44:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [126/300][1250/1251]	eta 0:00:00 lr 0.000623	time 0.6126 (0.5713)	loss 3.6816 (3.2909)	grad_norm 1.4224 (nan)	mem 17417MB
[2023-02-01 14:44:09 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 126 training takes 0:11:54
[2023-02-01 14:44:09 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_126.pth saving......
[2023-02-01 14:44:11 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_126.pth saved !!!
[2023-02-01 14:44:11 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.860 (0.860)	Loss 0.9113 (0.9113)	Acc@1 79.980 (79.980)	Acc@5 93.750 (93.750)	Mem 17417MB
[2023-02-01 14:44:19 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.130 Acc@5 94.948
[2023-02-01 14:44:19 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.1%
[2023-02-01 14:44:21 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.324 (1.324)	Loss 0.8688 (0.8688)	Acc@1 79.102 (79.102)	Acc@5 94.727 (94.727)	Mem 17417MB
[2023-02-01 14:44:29 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.060 Acc@5 95.800
[2023-02-01 14:44:29 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.1%
[2023-02-01 14:44:29 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.06% at 126 epoch
[2023-02-01 14:44:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][0/1251]	eta 0:34:24 lr 0.000623	time 1.6500 (1.6500)	loss 4.3749 (4.3749)	grad_norm 1.3625 (1.3625)	mem 17417MB
[2023-02-01 14:44:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][50/1251]	eta 0:11:52 lr 0.000623	time 0.5574 (0.5933)	loss 2.4773 (3.2756)	grad_norm 1.4304 (1.4462)	mem 17417MB
[2023-02-01 14:45:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][100/1251]	eta 0:11:10 lr 0.000623	time 0.5515 (0.5822)	loss 3.5353 (3.2042)	grad_norm 1.8062 (1.4554)	mem 17417MB
[2023-02-01 14:45:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][150/1251]	eta 0:10:36 lr 0.000622	time 0.5514 (0.5780)	loss 2.7560 (3.2221)	grad_norm 1.2412 (1.4495)	mem 17417MB
[2023-02-01 14:46:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][200/1251]	eta 0:10:04 lr 0.000622	time 0.5597 (0.5751)	loss 3.6246 (3.2649)	grad_norm 1.7901 (1.4515)	mem 17417MB
[2023-02-01 14:46:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][250/1251]	eta 0:09:35 lr 0.000622	time 0.6302 (0.5750)	loss 3.5793 (3.2787)	grad_norm 1.4288 (1.4530)	mem 17417MB
[2023-02-01 14:47:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][300/1251]	eta 0:09:05 lr 0.000622	time 0.5545 (0.5734)	loss 3.7564 (3.2710)	grad_norm 1.6049 (1.4633)	mem 17417MB
[2023-02-01 14:47:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][350/1251]	eta 0:08:36 lr 0.000622	time 0.5563 (0.5733)	loss 3.3208 (3.2745)	grad_norm 1.3243 (1.4640)	mem 17417MB
[2023-02-01 14:48:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][400/1251]	eta 0:08:06 lr 0.000621	time 0.5524 (0.5722)	loss 3.2718 (3.2862)	grad_norm 1.3048 (1.4600)	mem 17417MB
[2023-02-01 14:48:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][450/1251]	eta 0:07:38 lr 0.000621	time 0.5567 (0.5722)	loss 2.8042 (3.2782)	grad_norm 1.3486 (1.4609)	mem 17417MB
[2023-02-01 14:49:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][500/1251]	eta 0:07:09 lr 0.000621	time 0.6569 (0.5719)	loss 3.1366 (3.2736)	grad_norm 1.3937 (1.4573)	mem 17417MB
[2023-02-01 14:49:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][550/1251]	eta 0:06:40 lr 0.000621	time 0.5569 (0.5716)	loss 4.0039 (3.2636)	grad_norm 1.4056 (1.4556)	mem 17417MB
[2023-02-01 14:50:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][600/1251]	eta 0:06:12 lr 0.000621	time 0.5596 (0.5715)	loss 3.7085 (3.2654)	grad_norm 1.4328 (1.4534)	mem 17417MB
[2023-02-01 14:50:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][650/1251]	eta 0:05:43 lr 0.000620	time 0.5499 (0.5717)	loss 3.5920 (3.2693)	grad_norm 1.5260 (1.4522)	mem 17417MB
[2023-02-01 14:51:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][700/1251]	eta 0:05:14 lr 0.000620	time 0.5603 (0.5714)	loss 3.3189 (3.2727)	grad_norm 1.3343 (1.4497)	mem 17417MB
[2023-02-01 14:51:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][750/1251]	eta 0:04:46 lr 0.000620	time 0.5641 (0.5712)	loss 2.9309 (3.2733)	grad_norm 1.2510 (1.4491)	mem 17417MB
[2023-02-01 14:52:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][800/1251]	eta 0:04:17 lr 0.000620	time 0.5581 (0.5709)	loss 2.8551 (3.2656)	grad_norm 1.3704 (1.4506)	mem 17417MB
[2023-02-01 14:52:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][850/1251]	eta 0:03:48 lr 0.000620	time 0.5489 (0.5709)	loss 2.8596 (3.2691)	grad_norm 1.3753 (1.4520)	mem 17417MB
[2023-02-01 14:53:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][900/1251]	eta 0:03:20 lr 0.000619	time 0.5550 (0.5709)	loss 3.6470 (3.2610)	grad_norm 1.6628 (1.4521)	mem 17417MB
[2023-02-01 14:53:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][950/1251]	eta 0:02:51 lr 0.000619	time 0.5569 (0.5707)	loss 3.8834 (3.2654)	grad_norm 1.5590 (1.4547)	mem 17417MB
[2023-02-01 14:54:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][1000/1251]	eta 0:02:23 lr 0.000619	time 0.6260 (0.5705)	loss 3.4745 (3.2682)	grad_norm 1.2843 (1.4563)	mem 17417MB
[2023-02-01 14:54:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][1050/1251]	eta 0:01:54 lr 0.000619	time 0.5564 (0.5706)	loss 2.5912 (3.2645)	grad_norm 1.7665 (1.4559)	mem 17417MB
[2023-02-01 14:54:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][1100/1251]	eta 0:01:26 lr 0.000619	time 0.5592 (0.5704)	loss 3.6799 (3.2646)	grad_norm 1.4294 (1.4559)	mem 17417MB
[2023-02-01 14:55:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][1150/1251]	eta 0:00:57 lr 0.000618	time 0.5654 (0.5704)	loss 3.6179 (3.2599)	grad_norm 2.0496 (1.4566)	mem 17417MB
[2023-02-01 14:55:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][1200/1251]	eta 0:00:29 lr 0.000618	time 0.5559 (0.5704)	loss 2.6069 (3.2619)	grad_norm 1.4606 (1.4579)	mem 17417MB
[2023-02-01 14:56:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [127/300][1250/1251]	eta 0:00:00 lr 0.000618	time 0.6003 (0.5704)	loss 3.9214 (3.2629)	grad_norm 1.4866 (1.4575)	mem 17417MB
[2023-02-01 14:56:22 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 127 training takes 0:11:53
[2023-02-01 14:56:23 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_127.pth saving......
[2023-02-01 14:56:24 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_127.pth saved !!!
[2023-02-01 14:56:25 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.905 (0.905)	Loss 0.8327 (0.8327)	Acc@1 79.785 (79.785)	Acc@5 95.410 (95.410)	Mem 17417MB
[2023-02-01 14:56:33 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.914 Acc@5 94.864
[2023-02-01 14:56:33 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.9%
[2023-02-01 14:56:34 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.223 (1.223)	Loss 0.7979 (0.7979)	Acc@1 82.715 (82.715)	Acc@5 95.117 (95.117)	Mem 17417MB
[2023-02-01 14:56:42 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.158 Acc@5 95.814
[2023-02-01 14:56:42 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.2%
[2023-02-01 14:56:42 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.16% at 127 epoch
[2023-02-01 14:56:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][0/1251]	eta 0:36:27 lr 0.000618	time 1.7485 (1.7485)	loss 2.9739 (2.9739)	grad_norm 1.4795 (1.4795)	mem 17417MB
[2023-02-01 14:57:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][50/1251]	eta 0:11:54 lr 0.000618	time 0.5598 (0.5951)	loss 3.3283 (3.1977)	grad_norm 1.3253 (1.4108)	mem 17417MB
[2023-02-01 14:57:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][100/1251]	eta 0:11:11 lr 0.000618	time 0.5576 (0.5831)	loss 3.8990 (3.2819)	grad_norm 1.2331 (1.4291)	mem 17417MB
[2023-02-01 14:58:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][150/1251]	eta 0:10:37 lr 0.000617	time 0.5589 (0.5788)	loss 3.4460 (3.2855)	grad_norm 1.6284 (1.4533)	mem 17417MB
[2023-02-01 14:58:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][200/1251]	eta 0:10:06 lr 0.000617	time 0.5686 (0.5769)	loss 4.1075 (3.3082)	grad_norm 1.5706 (1.4465)	mem 17417MB
[2023-02-01 14:59:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][250/1251]	eta 0:09:37 lr 0.000617	time 0.6293 (0.5765)	loss 3.5788 (3.2798)	grad_norm 1.3567 (1.4596)	mem 17417MB
[2023-02-01 14:59:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][300/1251]	eta 0:09:06 lr 0.000617	time 0.5653 (0.5749)	loss 3.5711 (3.2695)	grad_norm 1.5242 (1.4539)	mem 17417MB
[2023-02-01 15:00:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][350/1251]	eta 0:08:37 lr 0.000617	time 0.5561 (0.5743)	loss 3.2704 (3.2687)	grad_norm 1.3981 (1.4541)	mem 17417MB
[2023-02-01 15:00:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][400/1251]	eta 0:08:07 lr 0.000616	time 0.5827 (0.5732)	loss 3.9306 (3.2833)	grad_norm 1.3115 (1.4514)	mem 17417MB
[2023-02-01 15:01:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][450/1251]	eta 0:07:39 lr 0.000616	time 0.5554 (0.5731)	loss 2.3750 (3.2694)	grad_norm 1.3276 (1.4493)	mem 17417MB
[2023-02-01 15:01:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][500/1251]	eta 0:07:10 lr 0.000616	time 0.5584 (0.5729)	loss 3.6373 (3.2788)	grad_norm 1.4063 (1.4482)	mem 17417MB
[2023-02-01 15:01:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][550/1251]	eta 0:06:41 lr 0.000616	time 0.6301 (0.5727)	loss 3.2478 (3.2801)	grad_norm 1.7109 (1.4469)	mem 17417MB
[2023-02-01 15:02:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][600/1251]	eta 0:06:12 lr 0.000616	time 0.5665 (0.5724)	loss 2.9471 (3.2752)	grad_norm 1.4678 (1.4501)	mem 17417MB
[2023-02-01 15:02:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][650/1251]	eta 0:05:44 lr 0.000615	time 0.5530 (0.5725)	loss 3.5478 (3.2700)	grad_norm 1.3660 (1.4514)	mem 17417MB
[2023-02-01 15:03:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][700/1251]	eta 0:05:15 lr 0.000615	time 0.5575 (0.5722)	loss 3.5178 (3.2695)	grad_norm 1.6488 (1.4520)	mem 17417MB
[2023-02-01 15:03:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][750/1251]	eta 0:04:46 lr 0.000615	time 0.5546 (0.5722)	loss 3.0271 (3.2708)	grad_norm 1.4317 (1.4523)	mem 17417MB
[2023-02-01 15:04:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][800/1251]	eta 0:04:17 lr 0.000615	time 0.5618 (0.5720)	loss 2.9523 (3.2683)	grad_norm 1.5504 (1.4531)	mem 17417MB
[2023-02-01 15:04:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][850/1251]	eta 0:03:49 lr 0.000615	time 0.5651 (0.5718)	loss 3.0371 (3.2704)	grad_norm 1.4367 (1.4551)	mem 17417MB
[2023-02-01 15:05:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][900/1251]	eta 0:03:20 lr 0.000614	time 0.5587 (0.5719)	loss 3.4641 (3.2670)	grad_norm 1.3953 (1.4543)	mem 17417MB
[2023-02-01 15:05:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][950/1251]	eta 0:02:52 lr 0.000614	time 0.5506 (0.5717)	loss 3.1855 (3.2672)	grad_norm 1.3896 (1.4547)	mem 17417MB
[2023-02-01 15:06:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][1000/1251]	eta 0:02:23 lr 0.000614	time 0.5599 (0.5717)	loss 3.6808 (3.2695)	grad_norm 1.4724 (nan)	mem 17417MB
[2023-02-01 15:06:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][1050/1251]	eta 0:01:54 lr 0.000614	time 0.5605 (0.5717)	loss 2.9502 (3.2701)	grad_norm 1.4435 (nan)	mem 17417MB
[2023-02-01 15:07:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][1100/1251]	eta 0:01:26 lr 0.000614	time 0.5562 (0.5716)	loss 3.4476 (3.2696)	grad_norm 1.3480 (nan)	mem 17417MB
[2023-02-01 15:07:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][1150/1251]	eta 0:00:57 lr 0.000613	time 0.5597 (0.5713)	loss 3.9290 (3.2679)	grad_norm 1.5121 (nan)	mem 17417MB
[2023-02-01 15:08:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][1200/1251]	eta 0:00:29 lr 0.000613	time 0.5598 (0.5714)	loss 3.6164 (3.2680)	grad_norm 1.5863 (nan)	mem 17417MB
[2023-02-01 15:08:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [128/300][1250/1251]	eta 0:00:00 lr 0.000613	time 0.5529 (0.5713)	loss 2.5585 (3.2662)	grad_norm 1.4282 (nan)	mem 17417MB
[2023-02-01 15:08:37 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 128 training takes 0:11:54
[2023-02-01 15:08:37 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_128.pth saving......
[2023-02-01 15:08:39 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_128.pth saved !!!
[2023-02-01 15:08:40 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.987 (0.987)	Loss 0.8625 (0.8625)	Acc@1 79.785 (79.785)	Acc@5 94.141 (94.141)	Mem 17417MB
[2023-02-01 15:08:48 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.926 Acc@5 94.866
[2023-02-01 15:08:48 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 78.9%
[2023-02-01 15:08:50 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.304 (1.304)	Loss 0.8563 (0.8563)	Acc@1 81.738 (81.738)	Acc@5 94.434 (94.434)	Mem 17417MB
[2023-02-01 15:08:58 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.226 Acc@5 95.826
[2023-02-01 15:08:58 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.2%
[2023-02-01 15:08:58 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.23% at 128 epoch
[2023-02-01 15:08:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][0/1251]	eta 0:35:48 lr 0.000613	time 1.7178 (1.7178)	loss 4.2050 (4.2050)	grad_norm 1.3546 (1.3546)	mem 17417MB
[2023-02-01 15:09:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][50/1251]	eta 0:11:48 lr 0.000613	time 0.6305 (0.5903)	loss 3.3636 (3.2888)	grad_norm 1.3281 (1.4510)	mem 17417MB
[2023-02-01 15:09:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][100/1251]	eta 0:11:09 lr 0.000613	time 0.6484 (0.5815)	loss 3.5236 (3.2602)	grad_norm 1.2995 (1.4633)	mem 17417MB
[2023-02-01 15:10:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][150/1251]	eta 0:10:36 lr 0.000612	time 0.5566 (0.5779)	loss 3.8560 (3.2631)	grad_norm 1.4580 (1.4564)	mem 17417MB
[2023-02-01 15:10:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][200/1251]	eta 0:10:06 lr 0.000612	time 0.5762 (0.5769)	loss 3.7791 (3.2826)	grad_norm 1.3684 (1.4645)	mem 17417MB
[2023-02-01 15:11:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][250/1251]	eta 0:09:35 lr 0.000612	time 0.5517 (0.5751)	loss 3.0081 (3.2891)	grad_norm 1.4363 (1.4567)	mem 17417MB
[2023-02-01 15:11:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][300/1251]	eta 0:09:06 lr 0.000612	time 0.5572 (0.5748)	loss 3.4406 (3.2844)	grad_norm 1.4065 (1.4612)	mem 17417MB
[2023-02-01 15:12:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][350/1251]	eta 0:08:37 lr 0.000612	time 0.5628 (0.5740)	loss 3.2395 (3.2910)	grad_norm 1.5393 (1.4654)	mem 17417MB
[2023-02-01 15:12:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][400/1251]	eta 0:08:08 lr 0.000611	time 0.5583 (0.5737)	loss 2.9023 (3.3045)	grad_norm 1.5779 (1.4659)	mem 17417MB
[2023-02-01 15:13:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][450/1251]	eta 0:07:38 lr 0.000611	time 0.5518 (0.5729)	loss 2.3804 (3.2959)	grad_norm 1.3860 (1.4647)	mem 17417MB
[2023-02-01 15:13:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][500/1251]	eta 0:07:09 lr 0.000611	time 0.6549 (0.5723)	loss 3.7765 (3.2988)	grad_norm 1.4190 (1.4644)	mem 17417MB
[2023-02-01 15:14:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][550/1251]	eta 0:06:40 lr 0.000611	time 0.6259 (0.5719)	loss 3.4080 (3.2933)	grad_norm 1.4902 (1.4669)	mem 17417MB
[2023-02-01 15:14:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][600/1251]	eta 0:06:12 lr 0.000611	time 0.5538 (0.5719)	loss 3.0542 (3.2986)	grad_norm 1.4129 (1.4668)	mem 17417MB
[2023-02-01 15:15:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][650/1251]	eta 0:05:43 lr 0.000610	time 0.5554 (0.5719)	loss 3.1167 (3.2983)	grad_norm 1.4368 (1.4673)	mem 17417MB
[2023-02-01 15:15:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][700/1251]	eta 0:05:14 lr 0.000610	time 0.5546 (0.5716)	loss 3.4549 (3.2897)	grad_norm 1.3747 (1.4653)	mem 17417MB
[2023-02-01 15:16:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][750/1251]	eta 0:04:46 lr 0.000610	time 0.6296 (0.5718)	loss 3.4173 (3.2905)	grad_norm 1.3405 (1.4646)	mem 17417MB
[2023-02-01 15:16:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][800/1251]	eta 0:04:17 lr 0.000610	time 0.5584 (0.5715)	loss 3.8986 (3.2959)	grad_norm 1.3536 (1.4638)	mem 17417MB
[2023-02-01 15:17:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][850/1251]	eta 0:03:49 lr 0.000610	time 0.5536 (0.5714)	loss 3.7111 (3.2947)	grad_norm 1.3841 (1.4622)	mem 17417MB
[2023-02-01 15:17:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][900/1251]	eta 0:03:20 lr 0.000609	time 0.6436 (0.5714)	loss 3.4038 (3.2985)	grad_norm 1.4063 (1.4620)	mem 17417MB
[2023-02-01 15:18:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][950/1251]	eta 0:02:51 lr 0.000609	time 0.5643 (0.5713)	loss 2.0848 (3.2981)	grad_norm 1.3475 (1.4630)	mem 17417MB
[2023-02-01 15:18:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][1000/1251]	eta 0:02:23 lr 0.000609	time 0.5555 (0.5716)	loss 3.2960 (3.2978)	grad_norm 1.3702 (1.4637)	mem 17417MB
[2023-02-01 15:18:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][1050/1251]	eta 0:01:54 lr 0.000609	time 0.5624 (0.5714)	loss 3.4120 (3.2996)	grad_norm 1.3345 (1.4638)	mem 17417MB
[2023-02-01 15:19:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][1100/1251]	eta 0:01:26 lr 0.000609	time 0.5627 (0.5714)	loss 3.7819 (3.3008)	grad_norm 1.4488 (1.4647)	mem 17417MB
[2023-02-01 15:19:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][1150/1251]	eta 0:00:57 lr 0.000608	time 0.5556 (0.5713)	loss 2.3274 (3.2936)	grad_norm 1.5250 (1.4649)	mem 17417MB
[2023-02-01 15:20:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][1200/1251]	eta 0:00:29 lr 0.000608	time 0.6300 (0.5713)	loss 3.3097 (3.2972)	grad_norm 1.4609 (1.4638)	mem 17417MB
[2023-02-01 15:20:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [129/300][1250/1251]	eta 0:00:00 lr 0.000608	time 0.5501 (0.5712)	loss 3.2989 (3.2968)	grad_norm 1.4319 (1.4636)	mem 17417MB
[2023-02-01 15:20:52 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 129 training takes 0:11:54
[2023-02-01 15:20:52 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_129.pth saving......
[2023-02-01 15:20:54 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_129.pth saved !!!
[2023-02-01 15:20:55 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.885 (0.885)	Loss 0.8791 (0.8791)	Acc@1 79.102 (79.102)	Acc@5 95.410 (95.410)	Mem 17417MB
[2023-02-01 15:21:03 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.194 Acc@5 94.846
[2023-02-01 15:21:03 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.2%
[2023-02-01 15:21:04 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.187 (1.187)	Loss 0.8695 (0.8695)	Acc@1 79.785 (79.785)	Acc@5 95.312 (95.312)	Mem 17417MB
[2023-02-01 15:21:12 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.294 Acc@5 95.862
[2023-02-01 15:21:12 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.3%
[2023-02-01 15:21:12 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.29% at 129 epoch
[2023-02-01 15:21:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][0/1251]	eta 0:35:24 lr 0.000608	time 1.6979 (1.6979)	loss 3.6513 (3.6513)	grad_norm 1.3916 (1.3916)	mem 17417MB
[2023-02-01 15:21:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][50/1251]	eta 0:11:55 lr 0.000608	time 0.5580 (0.5954)	loss 2.1151 (3.4205)	grad_norm 1.5845 (1.4658)	mem 17417MB
[2023-02-01 15:22:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][100/1251]	eta 0:11:11 lr 0.000608	time 0.6145 (0.5836)	loss 2.8434 (3.3075)	grad_norm 1.5146 (1.4732)	mem 17417MB
[2023-02-01 15:22:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][150/1251]	eta 0:10:37 lr 0.000607	time 0.5585 (0.5787)	loss 3.2474 (3.3076)	grad_norm 1.5431 (1.4742)	mem 17417MB
[2023-02-01 15:23:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][200/1251]	eta 0:10:06 lr 0.000607	time 0.6293 (0.5767)	loss 3.6341 (3.3056)	grad_norm 1.6685 (1.4776)	mem 17417MB
[2023-02-01 15:23:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][250/1251]	eta 0:09:35 lr 0.000607	time 0.5543 (0.5746)	loss 2.0531 (3.2931)	grad_norm 1.3806 (1.4786)	mem 17417MB
[2023-02-01 15:24:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][300/1251]	eta 0:09:05 lr 0.000607	time 0.5590 (0.5741)	loss 3.6465 (3.3139)	grad_norm 1.4607 (1.4715)	mem 17417MB
[2023-02-01 15:24:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][350/1251]	eta 0:08:36 lr 0.000606	time 0.5476 (0.5737)	loss 2.7006 (3.2978)	grad_norm 1.4881 (1.4714)	mem 17417MB
[2023-02-01 15:25:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][400/1251]	eta 0:08:07 lr 0.000606	time 0.5548 (0.5733)	loss 3.3318 (3.2993)	grad_norm 1.3892 (1.4781)	mem 17417MB
[2023-02-01 15:25:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][450/1251]	eta 0:07:39 lr 0.000606	time 0.6428 (0.5731)	loss 3.3697 (3.2986)	grad_norm 1.3394 (1.4728)	mem 17417MB
[2023-02-01 15:25:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][500/1251]	eta 0:07:10 lr 0.000606	time 0.6235 (0.5728)	loss 4.0427 (3.3060)	grad_norm 1.4865 (1.4728)	mem 17417MB
[2023-02-01 15:26:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][550/1251]	eta 0:06:41 lr 0.000606	time 0.5565 (0.5724)	loss 3.4601 (3.3063)	grad_norm 1.5101 (1.4728)	mem 17417MB
[2023-02-01 15:26:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][600/1251]	eta 0:06:12 lr 0.000605	time 0.5572 (0.5726)	loss 3.0434 (3.3038)	grad_norm 1.3688 (1.4724)	mem 17417MB
[2023-02-01 15:27:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][650/1251]	eta 0:05:43 lr 0.000605	time 0.5561 (0.5720)	loss 2.9411 (3.2950)	grad_norm 1.6799 (1.4678)	mem 17417MB
[2023-02-01 15:27:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][700/1251]	eta 0:05:15 lr 0.000605	time 0.5599 (0.5721)	loss 3.1428 (3.2892)	grad_norm 1.5135 (1.4664)	mem 17417MB
[2023-02-01 15:28:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][750/1251]	eta 0:04:46 lr 0.000605	time 0.5854 (0.5719)	loss 3.7429 (3.2969)	grad_norm 1.4274 (1.4650)	mem 17417MB
[2023-02-01 15:28:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][800/1251]	eta 0:04:17 lr 0.000605	time 0.5558 (0.5718)	loss 3.6928 (3.2945)	grad_norm 1.6691 (1.4642)	mem 17417MB
[2023-02-01 15:29:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][850/1251]	eta 0:03:49 lr 0.000604	time 0.5559 (0.5717)	loss 2.6517 (3.2912)	grad_norm 1.5058 (nan)	mem 17417MB
[2023-02-01 15:29:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][900/1251]	eta 0:03:20 lr 0.000604	time 0.6176 (0.5719)	loss 2.9344 (3.2947)	grad_norm 1.3928 (nan)	mem 17417MB
[2023-02-01 15:30:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][950/1251]	eta 0:02:52 lr 0.000604	time 0.5551 (0.5717)	loss 3.4845 (3.2983)	grad_norm 1.4925 (nan)	mem 17417MB
[2023-02-01 15:30:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][1000/1251]	eta 0:02:23 lr 0.000604	time 0.5533 (0.5718)	loss 3.2754 (3.3021)	grad_norm 1.3505 (nan)	mem 17417MB
[2023-02-01 15:31:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][1050/1251]	eta 0:01:54 lr 0.000604	time 0.5577 (0.5715)	loss 3.4661 (3.3023)	grad_norm 1.4446 (nan)	mem 17417MB
[2023-02-01 15:31:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][1100/1251]	eta 0:01:26 lr 0.000603	time 0.5582 (0.5718)	loss 3.6418 (3.2971)	grad_norm 1.4186 (nan)	mem 17417MB
[2023-02-01 15:32:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][1150/1251]	eta 0:00:57 lr 0.000603	time 0.5581 (0.5714)	loss 3.9692 (3.2985)	grad_norm 1.5375 (nan)	mem 17417MB
[2023-02-01 15:32:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][1200/1251]	eta 0:00:29 lr 0.000603	time 0.6277 (0.5714)	loss 3.9822 (3.3005)	grad_norm 1.4427 (nan)	mem 17417MB
[2023-02-01 15:33:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [130/300][1250/1251]	eta 0:00:00 lr 0.000603	time 0.5495 (0.5712)	loss 2.9951 (3.3034)	grad_norm 1.6367 (nan)	mem 17417MB
[2023-02-01 15:33:07 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 130 training takes 0:11:54
[2023-02-01 15:33:07 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_130.pth saving......
[2023-02-01 15:33:09 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_130.pth saved !!!
[2023-02-01 15:33:10 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.877 (0.877)	Loss 0.8912 (0.8912)	Acc@1 79.199 (79.199)	Acc@5 95.020 (95.020)	Mem 17417MB
[2023-02-01 15:33:18 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.112 Acc@5 94.912
[2023-02-01 15:33:18 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.1%
[2023-02-01 15:33:19 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.149 (1.149)	Loss 0.8652 (0.8652)	Acc@1 80.273 (80.273)	Acc@5 94.727 (94.727)	Mem 17417MB
[2023-02-01 15:33:27 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.336 Acc@5 95.880
[2023-02-01 15:33:27 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.3%
[2023-02-01 15:33:27 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.34% at 130 epoch
[2023-02-01 15:33:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][0/1251]	eta 0:35:37 lr 0.000603	time 1.7089 (1.7089)	loss 3.4575 (3.4575)	grad_norm 1.5087 (1.5087)	mem 17417MB
[2023-02-01 15:33:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][50/1251]	eta 0:11:52 lr 0.000603	time 0.5719 (0.5932)	loss 3.9505 (3.2650)	grad_norm 1.4709 (1.4451)	mem 17417MB
[2023-02-01 15:34:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][100/1251]	eta 0:11:12 lr 0.000602	time 0.5560 (0.5841)	loss 3.3095 (3.2379)	grad_norm 1.6035 (1.4683)	mem 17417MB
[2023-02-01 15:34:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][150/1251]	eta 0:10:37 lr 0.000602	time 0.5627 (0.5788)	loss 3.7594 (3.2350)	grad_norm 1.4725 (1.4654)	mem 17417MB
[2023-02-01 15:35:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][200/1251]	eta 0:10:05 lr 0.000602	time 0.5572 (0.5765)	loss 2.5280 (3.2365)	grad_norm 1.4221 (1.4577)	mem 17417MB
[2023-02-01 15:35:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][250/1251]	eta 0:09:35 lr 0.000602	time 0.5601 (0.5754)	loss 3.2083 (3.2240)	grad_norm 1.3743 (1.4584)	mem 17417MB
[2023-02-01 15:36:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][300/1251]	eta 0:09:06 lr 0.000602	time 0.5557 (0.5744)	loss 2.8553 (3.2509)	grad_norm 1.3196 (1.4580)	mem 17417MB
[2023-02-01 15:36:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][350/1251]	eta 0:08:36 lr 0.000601	time 0.5576 (0.5735)	loss 4.1366 (3.2510)	grad_norm 1.8070 (1.4664)	mem 17417MB
[2023-02-01 15:37:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][400/1251]	eta 0:08:07 lr 0.000601	time 0.5570 (0.5728)	loss 3.0266 (3.2465)	grad_norm 1.3835 (1.4645)	mem 17417MB
[2023-02-01 15:37:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][450/1251]	eta 0:07:38 lr 0.000601	time 0.6217 (0.5723)	loss 3.2784 (3.2334)	grad_norm 1.4198 (1.4623)	mem 17417MB
[2023-02-01 15:38:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][500/1251]	eta 0:07:09 lr 0.000601	time 0.5557 (0.5719)	loss 4.0294 (3.2262)	grad_norm 1.5644 (1.4638)	mem 17417MB
[2023-02-01 15:38:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][550/1251]	eta 0:06:40 lr 0.000601	time 0.5548 (0.5715)	loss 3.5442 (3.2314)	grad_norm 1.4794 (1.4669)	mem 17417MB
[2023-02-01 15:39:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][600/1251]	eta 0:06:12 lr 0.000600	time 0.5651 (0.5715)	loss 3.5764 (3.2363)	grad_norm 1.4880 (1.4695)	mem 17417MB
[2023-02-01 15:39:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][650/1251]	eta 0:05:43 lr 0.000600	time 0.5594 (0.5715)	loss 2.7994 (3.2388)	grad_norm 1.3647 (1.4742)	mem 17417MB
[2023-02-01 15:40:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][700/1251]	eta 0:05:14 lr 0.000600	time 0.5555 (0.5713)	loss 3.6243 (3.2413)	grad_norm 1.5035 (1.4736)	mem 17417MB
[2023-02-01 15:40:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][750/1251]	eta 0:04:46 lr 0.000600	time 0.5613 (0.5710)	loss 2.3964 (3.2475)	grad_norm 1.4147 (1.4731)	mem 17417MB
[2023-02-01 15:41:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][800/1251]	eta 0:04:17 lr 0.000600	time 0.6393 (0.5711)	loss 3.0867 (3.2438)	grad_norm 1.5148 (1.4723)	mem 17417MB
[2023-02-01 15:41:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][850/1251]	eta 0:03:48 lr 0.000599	time 0.5594 (0.5707)	loss 3.7725 (3.2492)	grad_norm 1.4216 (1.4717)	mem 17417MB
[2023-02-01 15:42:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][900/1251]	eta 0:03:20 lr 0.000599	time 0.5642 (0.5708)	loss 4.0844 (3.2487)	grad_norm 1.3413 (1.4708)	mem 17417MB
[2023-02-01 15:42:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][950/1251]	eta 0:02:51 lr 0.000599	time 0.5543 (0.5706)	loss 3.5731 (3.2490)	grad_norm 1.3510 (1.4689)	mem 17417MB
[2023-02-01 15:42:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][1000/1251]	eta 0:02:23 lr 0.000599	time 0.5612 (0.5706)	loss 2.9192 (3.2488)	grad_norm 1.4866 (1.4692)	mem 17417MB
[2023-02-01 15:43:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][1050/1251]	eta 0:01:54 lr 0.000599	time 0.5556 (0.5706)	loss 3.3421 (3.2545)	grad_norm 1.6088 (1.4689)	mem 17417MB
[2023-02-01 15:43:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][1100/1251]	eta 0:01:26 lr 0.000598	time 0.6292 (0.5705)	loss 3.7968 (3.2567)	grad_norm 1.6551 (1.4691)	mem 17417MB
[2023-02-01 15:44:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][1150/1251]	eta 0:00:57 lr 0.000598	time 0.5490 (0.5704)	loss 3.4175 (3.2554)	grad_norm 1.4291 (1.4704)	mem 17417MB
[2023-02-01 15:44:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][1200/1251]	eta 0:00:29 lr 0.000598	time 0.5548 (0.5705)	loss 2.4978 (3.2599)	grad_norm 1.5734 (1.4699)	mem 17417MB
[2023-02-01 15:45:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [131/300][1250/1251]	eta 0:00:00 lr 0.000598	time 0.5492 (0.5702)	loss 2.5114 (3.2618)	grad_norm 1.4984 (1.4692)	mem 17417MB
[2023-02-01 15:45:20 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 131 training takes 0:11:53
[2023-02-01 15:45:21 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_131.pth saving......
[2023-02-01 15:45:22 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_131.pth saved !!!
[2023-02-01 15:45:23 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.926 (0.926)	Loss 0.8336 (0.8336)	Acc@1 79.785 (79.785)	Acc@5 95.605 (95.605)	Mem 17417MB
[2023-02-01 15:45:31 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 78.980 Acc@5 95.052
[2023-02-01 15:45:31 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.0%
[2023-02-01 15:45:33 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.556 (1.556)	Loss 0.7778 (0.7778)	Acc@1 83.105 (83.105)	Acc@5 95.801 (95.801)	Mem 17417MB
[2023-02-01 15:45:41 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.400 Acc@5 95.894
[2023-02-01 15:45:41 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.4%
[2023-02-01 15:45:41 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.40% at 131 epoch
[2023-02-01 15:45:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][0/1251]	eta 0:36:41 lr 0.000598	time 1.7597 (1.7597)	loss 3.2284 (3.2284)	grad_norm 1.5735 (1.5735)	mem 17417MB
[2023-02-01 15:46:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][50/1251]	eta 0:11:58 lr 0.000598	time 0.5561 (0.5983)	loss 3.5986 (3.1570)	grad_norm 1.3390 (1.4618)	mem 17417MB
[2023-02-01 15:46:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][100/1251]	eta 0:11:12 lr 0.000597	time 0.5610 (0.5844)	loss 2.0029 (3.1841)	grad_norm 1.4628 (1.4512)	mem 17417MB
[2023-02-01 15:47:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][150/1251]	eta 0:10:38 lr 0.000597	time 0.5550 (0.5796)	loss 2.3652 (3.1945)	grad_norm 1.4885 (1.4673)	mem 17417MB
[2023-02-01 15:47:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][200/1251]	eta 0:10:06 lr 0.000597	time 0.5670 (0.5768)	loss 2.6551 (3.2231)	grad_norm 1.4242 (1.4714)	mem 17417MB
[2023-02-01 15:48:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][250/1251]	eta 0:09:36 lr 0.000597	time 0.6257 (0.5757)	loss 3.3987 (3.2204)	grad_norm 1.4044 (1.4677)	mem 17417MB
[2023-02-01 15:48:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][300/1251]	eta 0:09:06 lr 0.000597	time 0.5726 (0.5746)	loss 2.7757 (3.2218)	grad_norm 1.4585 (1.4652)	mem 17417MB
[2023-02-01 15:49:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][350/1251]	eta 0:08:37 lr 0.000596	time 0.5538 (0.5741)	loss 3.6852 (3.2320)	grad_norm 1.4160 (1.4618)	mem 17417MB
[2023-02-01 15:49:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][400/1251]	eta 0:08:08 lr 0.000596	time 0.6284 (0.5736)	loss 3.9905 (3.2415)	grad_norm 1.4634 (1.4637)	mem 17417MB
[2023-02-01 15:49:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][450/1251]	eta 0:07:39 lr 0.000596	time 0.5533 (0.5733)	loss 3.5318 (3.2365)	grad_norm 1.4385 (1.4619)	mem 17417MB
[2023-02-01 15:50:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][500/1251]	eta 0:07:09 lr 0.000596	time 0.5594 (0.5724)	loss 3.7047 (3.2388)	grad_norm 1.5467 (1.4636)	mem 17417MB
[2023-02-01 15:50:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][550/1251]	eta 0:06:41 lr 0.000596	time 0.6143 (0.5724)	loss 3.9924 (3.2524)	grad_norm 1.4743 (1.4674)	mem 17417MB
[2023-02-01 15:51:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][600/1251]	eta 0:06:12 lr 0.000595	time 0.5557 (0.5721)	loss 3.9171 (3.2574)	grad_norm 1.3397 (1.4673)	mem 17417MB
[2023-02-01 15:51:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][650/1251]	eta 0:05:43 lr 0.000595	time 0.5623 (0.5721)	loss 3.9276 (3.2579)	grad_norm 1.4461 (1.4665)	mem 17417MB
[2023-02-01 15:52:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][700/1251]	eta 0:05:15 lr 0.000595	time 0.5621 (0.5719)	loss 3.3033 (3.2510)	grad_norm 1.3952 (1.4673)	mem 17417MB
[2023-02-01 15:52:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][750/1251]	eta 0:04:46 lr 0.000595	time 0.6186 (0.5718)	loss 3.4422 (3.2515)	grad_norm 1.5241 (1.4690)	mem 17417MB
[2023-02-01 15:53:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][800/1251]	eta 0:04:17 lr 0.000594	time 0.6191 (0.5716)	loss 2.6273 (3.2501)	grad_norm 1.3668 (1.4676)	mem 17417MB
[2023-02-01 15:53:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][850/1251]	eta 0:03:49 lr 0.000594	time 0.5644 (0.5718)	loss 4.0614 (3.2560)	grad_norm 1.4547 (1.4675)	mem 17417MB
[2023-02-01 15:54:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][900/1251]	eta 0:03:20 lr 0.000594	time 0.5609 (0.5714)	loss 3.3002 (3.2530)	grad_norm 1.4295 (1.4693)	mem 17417MB
[2023-02-01 15:54:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][950/1251]	eta 0:02:52 lr 0.000594	time 0.5595 (0.5717)	loss 2.9877 (3.2593)	grad_norm 1.7260 (1.4689)	mem 17417MB
[2023-02-01 15:55:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][1000/1251]	eta 0:02:23 lr 0.000594	time 0.5581 (0.5715)	loss 3.0767 (3.2576)	grad_norm 1.5361 (1.4693)	mem 17417MB
[2023-02-01 15:55:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][1050/1251]	eta 0:01:54 lr 0.000593	time 0.5543 (0.5715)	loss 4.1324 (3.2576)	grad_norm 1.5845 (1.4714)	mem 17417MB
[2023-02-01 15:56:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][1100/1251]	eta 0:01:26 lr 0.000593	time 0.5584 (0.5712)	loss 2.6092 (3.2581)	grad_norm 1.4038 (1.4694)	mem 17417MB
[2023-02-01 15:56:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][1150/1251]	eta 0:00:57 lr 0.000593	time 0.6286 (0.5713)	loss 3.5742 (3.2600)	grad_norm 1.4366 (1.4714)	mem 17417MB
[2023-02-01 15:57:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][1200/1251]	eta 0:00:29 lr 0.000593	time 0.5563 (0.5713)	loss 3.0750 (3.2657)	grad_norm 1.3269 (1.4710)	mem 17417MB
[2023-02-01 15:57:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [132/300][1250/1251]	eta 0:00:00 lr 0.000593	time 0.5501 (0.5713)	loss 3.4918 (3.2659)	grad_norm 1.2209 (1.4687)	mem 17417MB
[2023-02-01 15:57:36 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 132 training takes 0:11:54
[2023-02-01 15:57:36 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_132.pth saving......
[2023-02-01 15:57:38 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_132.pth saved !!!
[2023-02-01 15:57:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.865 (0.865)	Loss 0.8428 (0.8428)	Acc@1 80.078 (80.078)	Acc@5 95.801 (95.801)	Mem 17417MB
[2023-02-01 15:57:46 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.094 Acc@5 94.956
[2023-02-01 15:57:46 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.1%
[2023-02-01 15:57:48 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.497 (1.497)	Loss 0.8035 (0.8035)	Acc@1 81.152 (81.152)	Acc@5 95.898 (95.898)	Mem 17417MB
[2023-02-01 15:57:56 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.412 Acc@5 95.906
[2023-02-01 15:57:56 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.4%
[2023-02-01 15:57:56 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.41% at 132 epoch
[2023-02-01 15:57:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][0/1251]	eta 0:35:14 lr 0.000593	time 1.6905 (1.6905)	loss 3.5293 (3.5293)	grad_norm 1.4780 (1.4780)	mem 17417MB
[2023-02-01 15:58:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][50/1251]	eta 0:11:47 lr 0.000592	time 0.5586 (0.5894)	loss 3.6308 (3.1647)	grad_norm 1.4530 (1.4684)	mem 17417MB
[2023-02-01 15:58:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][100/1251]	eta 0:11:09 lr 0.000592	time 0.5606 (0.5821)	loss 3.9411 (3.1948)	grad_norm 1.4006 (1.4532)	mem 17417MB
[2023-02-01 15:59:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][150/1251]	eta 0:10:36 lr 0.000592	time 0.5531 (0.5780)	loss 4.0083 (3.2515)	grad_norm 1.8832 (nan)	mem 17417MB
[2023-02-01 15:59:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][200/1251]	eta 0:10:06 lr 0.000592	time 0.5593 (0.5775)	loss 3.8244 (3.2813)	grad_norm 1.4039 (nan)	mem 17417MB
[2023-02-01 16:00:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][250/1251]	eta 0:09:36 lr 0.000592	time 0.5561 (0.5757)	loss 2.9637 (3.2865)	grad_norm 1.4720 (nan)	mem 17417MB
[2023-02-01 16:00:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][300/1251]	eta 0:09:07 lr 0.000591	time 0.5648 (0.5755)	loss 2.0290 (3.2610)	grad_norm 1.4850 (nan)	mem 17417MB
[2023-02-01 16:01:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][350/1251]	eta 0:08:37 lr 0.000591	time 0.5602 (0.5740)	loss 2.6758 (3.2758)	grad_norm 1.3947 (nan)	mem 17417MB
[2023-02-01 16:01:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][400/1251]	eta 0:08:08 lr 0.000591	time 0.5543 (0.5736)	loss 2.1958 (3.2682)	grad_norm 1.4578 (nan)	mem 17417MB
[2023-02-01 16:02:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][450/1251]	eta 0:07:39 lr 0.000591	time 0.5638 (0.5731)	loss 2.3932 (3.2598)	grad_norm 1.6175 (nan)	mem 17417MB
[2023-02-01 16:02:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][500/1251]	eta 0:07:10 lr 0.000591	time 0.5606 (0.5732)	loss 2.9684 (3.2636)	grad_norm 1.6278 (nan)	mem 17417MB
[2023-02-01 16:03:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][550/1251]	eta 0:06:41 lr 0.000590	time 0.5627 (0.5729)	loss 4.2284 (3.2699)	grad_norm 1.5544 (nan)	mem 17417MB
[2023-02-01 16:03:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][600/1251]	eta 0:06:13 lr 0.000590	time 0.5535 (0.5731)	loss 4.0216 (3.2689)	grad_norm 1.5034 (nan)	mem 17417MB
[2023-02-01 16:04:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][650/1251]	eta 0:05:43 lr 0.000590	time 0.5585 (0.5724)	loss 2.6327 (3.2581)	grad_norm 1.4856 (nan)	mem 17417MB
[2023-02-01 16:04:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][700/1251]	eta 0:05:15 lr 0.000590	time 0.5514 (0.5726)	loss 3.3528 (3.2505)	grad_norm 1.3259 (nan)	mem 17417MB
[2023-02-01 16:05:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][750/1251]	eta 0:04:46 lr 0.000590	time 0.5590 (0.5722)	loss 3.4054 (3.2540)	grad_norm 1.5570 (nan)	mem 17417MB
[2023-02-01 16:05:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][800/1251]	eta 0:04:18 lr 0.000589	time 0.5564 (0.5725)	loss 3.8545 (3.2532)	grad_norm 1.3948 (nan)	mem 17417MB
[2023-02-01 16:06:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][850/1251]	eta 0:03:49 lr 0.000589	time 0.6223 (0.5723)	loss 3.8036 (3.2561)	grad_norm 1.3899 (nan)	mem 17417MB
[2023-02-01 16:06:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][900/1251]	eta 0:03:20 lr 0.000589	time 0.6126 (0.5722)	loss 3.9662 (3.2511)	grad_norm 1.4508 (nan)	mem 17417MB
[2023-02-01 16:07:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][950/1251]	eta 0:02:52 lr 0.000589	time 0.5525 (0.5721)	loss 3.2371 (3.2469)	grad_norm 1.5459 (nan)	mem 17417MB
[2023-02-01 16:07:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][1000/1251]	eta 0:02:23 lr 0.000589	time 0.5535 (0.5722)	loss 3.6352 (3.2495)	grad_norm 1.5607 (nan)	mem 17417MB
[2023-02-01 16:07:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][1050/1251]	eta 0:01:54 lr 0.000588	time 0.5524 (0.5721)	loss 3.0503 (3.2506)	grad_norm 1.2840 (nan)	mem 17417MB
[2023-02-01 16:08:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][1100/1251]	eta 0:01:26 lr 0.000588	time 0.5604 (0.5721)	loss 3.8997 (3.2509)	grad_norm 1.3718 (nan)	mem 17417MB
[2023-02-01 16:08:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][1150/1251]	eta 0:00:57 lr 0.000588	time 0.5572 (0.5720)	loss 3.0700 (3.2529)	grad_norm 1.3476 (nan)	mem 17417MB
[2023-02-01 16:09:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][1200/1251]	eta 0:00:29 lr 0.000588	time 0.5567 (0.5719)	loss 3.0805 (3.2518)	grad_norm 1.3264 (nan)	mem 17417MB
[2023-02-01 16:09:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [133/300][1250/1251]	eta 0:00:00 lr 0.000588	time 0.5547 (0.5718)	loss 2.5787 (3.2502)	grad_norm 1.4742 (nan)	mem 17417MB
[2023-02-01 16:09:51 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 133 training takes 0:11:55
[2023-02-01 16:09:51 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_133.pth saving......
[2023-02-01 16:09:53 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_133.pth saved !!!
[2023-02-01 16:09:54 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.852 (0.852)	Loss 0.8354 (0.8354)	Acc@1 79.688 (79.688)	Acc@5 95.703 (95.703)	Mem 17417MB
[2023-02-01 16:10:02 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.354 Acc@5 95.040
[2023-02-01 16:10:02 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.4%
[2023-02-01 16:10:03 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.192 (1.192)	Loss 0.8072 (0.8072)	Acc@1 81.641 (81.641)	Acc@5 95.801 (95.801)	Mem 17417MB
[2023-02-01 16:10:11 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.460 Acc@5 95.922
[2023-02-01 16:10:11 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.5%
[2023-02-01 16:10:11 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.46% at 133 epoch
[2023-02-01 16:10:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][0/1251]	eta 0:35:18 lr 0.000588	time 1.6935 (1.6935)	loss 3.1594 (3.1594)	grad_norm 1.5415 (1.5415)	mem 17417MB
[2023-02-01 16:10:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][50/1251]	eta 0:11:53 lr 0.000587	time 0.5553 (0.5937)	loss 3.7433 (3.2281)	grad_norm 1.3533 (1.4273)	mem 17417MB
[2023-02-01 16:11:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][100/1251]	eta 0:11:12 lr 0.000587	time 0.6211 (0.5845)	loss 2.7406 (3.1940)	grad_norm 1.5760 (1.4613)	mem 17417MB
[2023-02-01 16:11:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][150/1251]	eta 0:10:36 lr 0.000587	time 0.5548 (0.5781)	loss 2.6943 (3.1922)	grad_norm 1.3865 (1.4612)	mem 17417MB
[2023-02-01 16:12:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][200/1251]	eta 0:10:05 lr 0.000587	time 0.5617 (0.5764)	loss 3.6024 (3.1803)	grad_norm 1.6557 (1.4593)	mem 17417MB
[2023-02-01 16:12:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][250/1251]	eta 0:09:35 lr 0.000587	time 0.5560 (0.5745)	loss 3.0243 (3.1951)	grad_norm 1.4069 (1.4702)	mem 17417MB
[2023-02-01 16:13:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][300/1251]	eta 0:09:05 lr 0.000586	time 0.5542 (0.5741)	loss 3.5620 (3.2283)	grad_norm 1.5468 (1.4745)	mem 17417MB
[2023-02-01 16:13:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][350/1251]	eta 0:08:36 lr 0.000586	time 0.5603 (0.5733)	loss 1.9874 (3.2092)	grad_norm 1.5237 (1.4744)	mem 17417MB
[2023-02-01 16:14:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][400/1251]	eta 0:08:07 lr 0.000586	time 0.6270 (0.5728)	loss 3.8143 (3.2334)	grad_norm 1.4010 (1.4761)	mem 17417MB
[2023-02-01 16:14:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][450/1251]	eta 0:07:38 lr 0.000586	time 0.5555 (0.5725)	loss 3.5866 (3.2163)	grad_norm 1.5472 (1.4760)	mem 17417MB
[2023-02-01 16:14:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][500/1251]	eta 0:07:09 lr 0.000586	time 0.6159 (0.5720)	loss 3.4918 (3.2221)	grad_norm 1.4274 (1.4749)	mem 17417MB
[2023-02-01 16:15:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][550/1251]	eta 0:06:40 lr 0.000585	time 0.5676 (0.5716)	loss 3.6223 (3.2314)	grad_norm 1.3847 (1.4763)	mem 17417MB
[2023-02-01 16:15:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][600/1251]	eta 0:06:12 lr 0.000585	time 0.5557 (0.5715)	loss 3.2774 (3.2338)	grad_norm 1.4764 (1.4771)	mem 17417MB
[2023-02-01 16:16:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][650/1251]	eta 0:05:43 lr 0.000585	time 0.5625 (0.5713)	loss 3.2956 (3.2499)	grad_norm 1.3717 (1.4758)	mem 17417MB
[2023-02-01 16:16:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][700/1251]	eta 0:05:14 lr 0.000585	time 0.5555 (0.5712)	loss 2.3555 (3.2422)	grad_norm 1.4326 (1.4767)	mem 17417MB
[2023-02-01 16:17:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][750/1251]	eta 0:04:46 lr 0.000584	time 0.5633 (0.5710)	loss 2.5856 (3.2457)	grad_norm 1.5251 (1.4762)	mem 17417MB
[2023-02-01 16:17:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][800/1251]	eta 0:04:17 lr 0.000584	time 0.5565 (0.5709)	loss 2.2406 (3.2499)	grad_norm 1.6581 (1.4771)	mem 17417MB
[2023-02-01 16:18:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][850/1251]	eta 0:03:48 lr 0.000584	time 0.5489 (0.5708)	loss 3.2466 (3.2512)	grad_norm 1.4857 (1.4791)	mem 17417MB
[2023-02-01 16:18:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][900/1251]	eta 0:03:20 lr 0.000584	time 0.6097 (0.5710)	loss 3.7679 (3.2518)	grad_norm 1.4030 (1.4792)	mem 17417MB
[2023-02-01 16:19:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][950/1251]	eta 0:02:51 lr 0.000584	time 0.5537 (0.5707)	loss 3.3497 (3.2480)	grad_norm 1.7207 (nan)	mem 17417MB
[2023-02-01 16:19:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][1000/1251]	eta 0:02:23 lr 0.000583	time 0.6500 (0.5709)	loss 3.7119 (3.2450)	grad_norm 1.5067 (nan)	mem 17417MB
[2023-02-01 16:20:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][1050/1251]	eta 0:01:54 lr 0.000583	time 0.5505 (0.5707)	loss 2.8241 (3.2484)	grad_norm 1.4594 (nan)	mem 17417MB
[2023-02-01 16:20:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][1100/1251]	eta 0:01:26 lr 0.000583	time 0.6266 (0.5706)	loss 3.4609 (3.2490)	grad_norm 1.5677 (nan)	mem 17417MB
[2023-02-01 16:21:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][1150/1251]	eta 0:00:57 lr 0.000583	time 0.5556 (0.5705)	loss 3.5885 (3.2530)	grad_norm 1.5152 (nan)	mem 17417MB
[2023-02-01 16:21:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][1200/1251]	eta 0:00:29 lr 0.000583	time 0.6366 (0.5704)	loss 3.1531 (3.2507)	grad_norm 1.3600 (nan)	mem 17417MB
[2023-02-01 16:22:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [134/300][1250/1251]	eta 0:00:00 lr 0.000582	time 0.6378 (0.5705)	loss 3.5674 (3.2510)	grad_norm 1.3745 (nan)	mem 17417MB
[2023-02-01 16:22:05 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 134 training takes 0:11:53
[2023-02-01 16:22:05 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_134.pth saving......
[2023-02-01 16:22:07 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_134.pth saved !!!
[2023-02-01 16:22:08 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.974 (0.974)	Loss 0.9273 (0.9273)	Acc@1 78.320 (78.320)	Acc@5 94.531 (94.531)	Mem 17417MB
[2023-02-01 16:22:16 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.540 Acc@5 95.044
[2023-02-01 16:22:16 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.5%
[2023-02-01 16:22:17 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.232 (1.232)	Loss 0.7603 (0.7603)	Acc@1 81.543 (81.543)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-01 16:22:25 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.460 Acc@5 95.966
[2023-02-01 16:22:25 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.5%
[2023-02-01 16:22:25 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.46% at 134 epoch
[2023-02-01 16:22:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][0/1251]	eta 0:34:57 lr 0.000582	time 1.6770 (1.6770)	loss 3.7446 (3.7446)	grad_norm 1.4117 (1.4117)	mem 17417MB
[2023-02-01 16:22:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][50/1251]	eta 0:11:55 lr 0.000582	time 0.5622 (0.5957)	loss 3.8219 (3.2701)	grad_norm 1.4021 (1.4746)	mem 17417MB
[2023-02-01 16:23:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][100/1251]	eta 0:11:10 lr 0.000582	time 0.5558 (0.5825)	loss 3.6142 (3.2823)	grad_norm 1.5218 (1.4747)	mem 17417MB
[2023-02-01 16:23:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][150/1251]	eta 0:10:37 lr 0.000582	time 0.5533 (0.5789)	loss 3.5480 (3.2918)	grad_norm 1.4102 (1.4973)	mem 17417MB
[2023-02-01 16:24:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][200/1251]	eta 0:10:04 lr 0.000582	time 0.5545 (0.5750)	loss 3.7283 (3.3179)	grad_norm 1.3437 (1.4891)	mem 17417MB
[2023-02-01 16:24:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][250/1251]	eta 0:09:34 lr 0.000581	time 0.5578 (0.5743)	loss 2.7845 (3.3028)	grad_norm 1.4180 (1.4883)	mem 17417MB
[2023-02-01 16:25:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][300/1251]	eta 0:09:05 lr 0.000581	time 0.5589 (0.5734)	loss 2.9727 (3.2807)	grad_norm 1.4671 (1.4886)	mem 17417MB
[2023-02-01 16:25:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][350/1251]	eta 0:08:36 lr 0.000581	time 0.5643 (0.5730)	loss 3.4575 (3.2758)	grad_norm 1.2190 (1.4855)	mem 17417MB
[2023-02-01 16:26:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][400/1251]	eta 0:08:06 lr 0.000581	time 0.5609 (0.5721)	loss 3.4024 (3.2672)	grad_norm 1.3535 (1.4860)	mem 17417MB
[2023-02-01 16:26:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][450/1251]	eta 0:07:38 lr 0.000581	time 0.6354 (0.5722)	loss 2.1772 (3.2721)	grad_norm 1.7844 (1.4877)	mem 17417MB
[2023-02-01 16:27:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][500/1251]	eta 0:07:09 lr 0.000580	time 0.5562 (0.5715)	loss 3.0246 (3.2727)	grad_norm 1.3936 (1.4878)	mem 17417MB
[2023-02-01 16:27:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][550/1251]	eta 0:06:40 lr 0.000580	time 0.5570 (0.5717)	loss 3.7403 (3.2829)	grad_norm 1.5706 (1.4843)	mem 17417MB
[2023-02-01 16:28:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][600/1251]	eta 0:06:12 lr 0.000580	time 0.5665 (0.5715)	loss 3.2509 (3.2800)	grad_norm 1.5276 (1.4862)	mem 17417MB
[2023-02-01 16:28:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][650/1251]	eta 0:05:43 lr 0.000580	time 0.5618 (0.5715)	loss 3.2267 (3.2732)	grad_norm 1.7133 (1.4900)	mem 17417MB
[2023-02-01 16:29:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][700/1251]	eta 0:05:14 lr 0.000580	time 0.5604 (0.5714)	loss 4.0720 (3.2724)	grad_norm 1.5565 (1.4921)	mem 17417MB
[2023-02-01 16:29:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][750/1251]	eta 0:04:46 lr 0.000579	time 0.5580 (0.5713)	loss 3.8003 (3.2746)	grad_norm 1.4981 (1.4912)	mem 17417MB
[2023-02-01 16:30:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][800/1251]	eta 0:04:17 lr 0.000579	time 0.5575 (0.5711)	loss 3.6835 (3.2758)	grad_norm 1.4145 (1.4913)	mem 17417MB
[2023-02-01 16:30:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][850/1251]	eta 0:03:49 lr 0.000579	time 0.5544 (0.5713)	loss 3.4608 (3.2734)	grad_norm 1.3897 (1.4883)	mem 17417MB
[2023-02-01 16:31:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][900/1251]	eta 0:03:20 lr 0.000579	time 0.5570 (0.5714)	loss 2.8086 (3.2701)	grad_norm 1.3564 (1.4886)	mem 17417MB
[2023-02-01 16:31:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][950/1251]	eta 0:02:51 lr 0.000579	time 0.5586 (0.5713)	loss 3.5352 (3.2668)	grad_norm 1.3708 (1.4897)	mem 17417MB
[2023-02-01 16:31:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][1000/1251]	eta 0:02:23 lr 0.000578	time 0.6144 (0.5713)	loss 2.4572 (3.2666)	grad_norm 1.6002 (1.4908)	mem 17417MB
[2023-02-01 16:32:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][1050/1251]	eta 0:01:54 lr 0.000578	time 0.5548 (0.5711)	loss 4.1383 (3.2651)	grad_norm 1.3831 (1.4880)	mem 17417MB
[2023-02-01 16:32:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][1100/1251]	eta 0:01:26 lr 0.000578	time 0.5502 (0.5711)	loss 3.2415 (3.2649)	grad_norm 1.5239 (1.4870)	mem 17417MB
[2023-02-01 16:33:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][1150/1251]	eta 0:00:57 lr 0.000578	time 0.6406 (0.5710)	loss 3.5935 (3.2621)	grad_norm 1.8264 (1.4864)	mem 17417MB
[2023-02-01 16:33:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][1200/1251]	eta 0:00:29 lr 0.000578	time 0.5543 (0.5711)	loss 2.9596 (3.2605)	grad_norm 1.7546 (1.4856)	mem 17417MB
[2023-02-01 16:34:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [135/300][1250/1251]	eta 0:00:00 lr 0.000577	time 0.5501 (0.5709)	loss 2.3099 (3.2631)	grad_norm 1.3641 (1.4859)	mem 17417MB
[2023-02-01 16:34:19 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 135 training takes 0:11:54
[2023-02-01 16:34:19 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_135.pth saving......
[2023-02-01 16:34:21 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_135.pth saved !!!
[2023-02-01 16:34:22 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.893 (0.893)	Loss 0.8516 (0.8516)	Acc@1 80.371 (80.371)	Acc@5 95.605 (95.605)	Mem 17417MB
[2023-02-01 16:34:30 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.320 Acc@5 95.050
[2023-02-01 16:34:30 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.3%
[2023-02-01 16:34:31 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.194 (1.194)	Loss 0.7358 (0.7358)	Acc@1 83.496 (83.496)	Acc@5 96.484 (96.484)	Mem 17417MB
[2023-02-01 16:34:39 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.540 Acc@5 95.972
[2023-02-01 16:34:39 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.5%
[2023-02-01 16:34:39 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.54% at 135 epoch
[2023-02-01 16:34:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][0/1251]	eta 0:34:39 lr 0.000577	time 1.6621 (1.6621)	loss 2.8393 (2.8393)	grad_norm 1.3411 (1.3411)	mem 17417MB
[2023-02-01 16:35:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][50/1251]	eta 0:11:44 lr 0.000577	time 0.5558 (0.5865)	loss 3.1368 (3.2195)	grad_norm 1.3239 (1.4563)	mem 17417MB
[2023-02-01 16:35:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][100/1251]	eta 0:11:07 lr 0.000577	time 0.6427 (0.5799)	loss 4.0192 (3.1735)	grad_norm 1.5271 (1.4678)	mem 17417MB
[2023-02-01 16:36:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][150/1251]	eta 0:10:34 lr 0.000577	time 0.5630 (0.5766)	loss 3.8335 (3.2477)	grad_norm 1.7775 (1.4751)	mem 17417MB
[2023-02-01 16:36:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][200/1251]	eta 0:10:04 lr 0.000576	time 0.5702 (0.5751)	loss 3.2760 (3.2723)	grad_norm 1.3156 (1.4770)	mem 17417MB
[2023-02-01 16:37:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][250/1251]	eta 0:09:34 lr 0.000576	time 0.5517 (0.5740)	loss 3.4645 (3.2730)	grad_norm 1.4497 (1.4818)	mem 17417MB
[2023-02-01 16:37:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][300/1251]	eta 0:09:05 lr 0.000576	time 0.6286 (0.5731)	loss 3.4446 (3.2775)	grad_norm 1.6072 (1.4848)	mem 17417MB
[2023-02-01 16:38:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][350/1251]	eta 0:08:36 lr 0.000576	time 0.5707 (0.5729)	loss 3.6752 (3.2808)	grad_norm 1.7027 (1.4884)	mem 17417MB
[2023-02-01 16:38:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][400/1251]	eta 0:08:07 lr 0.000576	time 0.5532 (0.5729)	loss 2.1501 (3.2729)	grad_norm 1.5955 (1.4866)	mem 17417MB
[2023-02-01 16:38:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][450/1251]	eta 0:07:38 lr 0.000575	time 0.5593 (0.5723)	loss 1.8000 (3.2692)	grad_norm 1.4208 (1.4840)	mem 17417MB
[2023-02-01 16:39:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][500/1251]	eta 0:07:09 lr 0.000575	time 0.5645 (0.5723)	loss 3.5902 (3.2653)	grad_norm 1.5242 (1.4849)	mem 17417MB
[2023-02-01 16:39:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][550/1251]	eta 0:06:41 lr 0.000575	time 0.5703 (0.5722)	loss 2.0925 (3.2709)	grad_norm 1.7590 (1.4875)	mem 17417MB
[2023-02-01 16:40:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][600/1251]	eta 0:06:12 lr 0.000575	time 0.5589 (0.5720)	loss 3.3883 (3.2734)	grad_norm 1.5389 (1.4894)	mem 17417MB
[2023-02-01 16:40:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][650/1251]	eta 0:05:43 lr 0.000575	time 0.5711 (0.5722)	loss 2.2904 (3.2745)	grad_norm 1.4653 (1.4885)	mem 17417MB
[2023-02-01 16:41:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][700/1251]	eta 0:05:15 lr 0.000574	time 0.5679 (0.5720)	loss 4.1005 (3.2780)	grad_norm 1.5861 (1.4873)	mem 17417MB
[2023-02-01 16:41:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][750/1251]	eta 0:04:46 lr 0.000574	time 0.5519 (0.5720)	loss 3.6558 (3.2773)	grad_norm 1.3971 (1.4862)	mem 17417MB
[2023-02-01 16:42:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][800/1251]	eta 0:04:17 lr 0.000574	time 0.6105 (0.5718)	loss 3.7590 (3.2777)	grad_norm 1.4411 (1.4849)	mem 17417MB
[2023-02-01 16:42:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][850/1251]	eta 0:03:49 lr 0.000574	time 0.5632 (0.5717)	loss 2.6740 (3.2781)	grad_norm 1.4888 (1.4838)	mem 17417MB
[2023-02-01 16:43:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][900/1251]	eta 0:03:20 lr 0.000574	time 0.5576 (0.5716)	loss 3.8996 (3.2725)	grad_norm 1.4117 (nan)	mem 17417MB
[2023-02-01 16:43:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][950/1251]	eta 0:02:52 lr 0.000573	time 0.5580 (0.5715)	loss 2.1163 (3.2636)	grad_norm 1.4074 (nan)	mem 17417MB
[2023-02-01 16:44:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][1000/1251]	eta 0:02:23 lr 0.000573	time 0.5555 (0.5714)	loss 3.0769 (3.2601)	grad_norm 1.5241 (nan)	mem 17417MB
[2023-02-01 16:44:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][1050/1251]	eta 0:01:54 lr 0.000573	time 0.5555 (0.5715)	loss 2.5085 (3.2592)	grad_norm 1.2591 (nan)	mem 17417MB
[2023-02-01 16:45:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][1100/1251]	eta 0:01:26 lr 0.000573	time 0.6309 (0.5713)	loss 3.5382 (3.2592)	grad_norm 1.8093 (nan)	mem 17417MB
[2023-02-01 16:45:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][1150/1251]	eta 0:00:57 lr 0.000573	time 0.5535 (0.5712)	loss 3.4828 (3.2621)	grad_norm 1.4364 (nan)	mem 17417MB
[2023-02-01 16:46:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][1200/1251]	eta 0:00:29 lr 0.000572	time 0.5643 (0.5711)	loss 4.1123 (3.2599)	grad_norm 1.4783 (nan)	mem 17417MB
[2023-02-01 16:46:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [136/300][1250/1251]	eta 0:00:00 lr 0.000572	time 0.5525 (0.5710)	loss 3.6289 (3.2618)	grad_norm 1.5318 (nan)	mem 17417MB
[2023-02-01 16:46:34 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 136 training takes 0:11:54
[2023-02-01 16:46:34 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_136.pth saving......
[2023-02-01 16:46:36 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_136.pth saved !!!
[2023-02-01 16:46:37 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.884 (0.884)	Loss 0.8456 (0.8456)	Acc@1 80.859 (80.859)	Acc@5 94.727 (94.727)	Mem 17417MB
[2023-02-01 16:46:45 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.520 Acc@5 95.096
[2023-02-01 16:46:45 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.5%
[2023-02-01 16:46:46 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.227 (1.227)	Loss 0.8097 (0.8097)	Acc@1 80.176 (80.176)	Acc@5 95.215 (95.215)	Mem 17417MB
[2023-02-01 16:46:54 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.598 Acc@5 95.974
[2023-02-01 16:46:54 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.6%
[2023-02-01 16:46:54 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.60% at 136 epoch
[2023-02-01 16:46:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][0/1251]	eta 0:40:03 lr 0.000572	time 1.9216 (1.9216)	loss 2.9455 (2.9455)	grad_norm 1.3787 (1.3787)	mem 17417MB
[2023-02-01 16:47:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][50/1251]	eta 0:11:58 lr 0.000572	time 0.5589 (0.5983)	loss 3.0230 (3.1909)	grad_norm 1.3471 (1.4658)	mem 17417MB
[2023-02-01 16:47:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][100/1251]	eta 0:11:13 lr 0.000572	time 0.5623 (0.5848)	loss 2.1658 (3.2333)	grad_norm 1.4888 (1.4555)	mem 17417MB
[2023-02-01 16:48:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][150/1251]	eta 0:10:37 lr 0.000572	time 0.5575 (0.5791)	loss 3.9469 (3.2375)	grad_norm 1.6100 (1.4654)	mem 17417MB
[2023-02-01 16:48:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][200/1251]	eta 0:10:05 lr 0.000571	time 0.5583 (0.5764)	loss 3.6358 (3.2494)	grad_norm 1.3218 (1.4720)	mem 17417MB
[2023-02-01 16:49:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][250/1251]	eta 0:09:35 lr 0.000571	time 0.5605 (0.5750)	loss 2.9458 (3.2265)	grad_norm 1.5310 (1.4726)	mem 17417MB
[2023-02-01 16:49:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][300/1251]	eta 0:09:06 lr 0.000571	time 0.5633 (0.5741)	loss 3.0885 (3.2353)	grad_norm 1.9700 (1.4724)	mem 17417MB
[2023-02-01 16:50:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][350/1251]	eta 0:08:36 lr 0.000571	time 0.5557 (0.5735)	loss 2.5755 (3.2218)	grad_norm 1.5824 (1.4765)	mem 17417MB
[2023-02-01 16:50:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][400/1251]	eta 0:08:07 lr 0.000571	time 0.5590 (0.5727)	loss 3.3623 (3.2241)	grad_norm 1.3494 (1.4731)	mem 17417MB
[2023-02-01 16:51:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][450/1251]	eta 0:07:38 lr 0.000570	time 0.5508 (0.5727)	loss 2.3734 (3.2197)	grad_norm 1.4428 (1.4752)	mem 17417MB
[2023-02-01 16:51:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][500/1251]	eta 0:07:09 lr 0.000570	time 0.5593 (0.5720)	loss 2.8989 (3.2248)	grad_norm 1.3768 (1.4735)	mem 17417MB
[2023-02-01 16:52:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][550/1251]	eta 0:06:40 lr 0.000570	time 0.5660 (0.5719)	loss 3.6337 (3.2118)	grad_norm 1.4741 (1.4748)	mem 17417MB
[2023-02-01 16:52:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][600/1251]	eta 0:06:12 lr 0.000570	time 0.5495 (0.5718)	loss 3.7982 (3.2128)	grad_norm 1.4302 (1.4751)	mem 17417MB
[2023-02-01 16:53:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][650/1251]	eta 0:05:43 lr 0.000570	time 0.5641 (0.5714)	loss 2.8042 (3.2227)	grad_norm 1.5410 (1.4748)	mem 17417MB
[2023-02-01 16:53:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][700/1251]	eta 0:05:14 lr 0.000569	time 0.5528 (0.5714)	loss 2.3916 (3.2198)	grad_norm 1.3651 (1.4786)	mem 17417MB
[2023-02-01 16:54:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][750/1251]	eta 0:04:46 lr 0.000569	time 0.5599 (0.5712)	loss 2.5798 (3.2166)	grad_norm 1.4224 (1.4778)	mem 17417MB
[2023-02-01 16:54:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][800/1251]	eta 0:04:17 lr 0.000569	time 0.5649 (0.5710)	loss 2.8877 (3.2178)	grad_norm 1.5470 (1.4768)	mem 17417MB
[2023-02-01 16:55:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][850/1251]	eta 0:03:48 lr 0.000569	time 0.5651 (0.5709)	loss 3.7929 (3.2159)	grad_norm 1.3958 (1.4805)	mem 17417MB
[2023-02-01 16:55:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][900/1251]	eta 0:03:20 lr 0.000568	time 0.6264 (0.5708)	loss 3.7931 (3.2211)	grad_norm 1.4443 (1.4824)	mem 17417MB
[2023-02-01 16:55:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][950/1251]	eta 0:02:51 lr 0.000568	time 0.5630 (0.5707)	loss 3.1516 (3.2245)	grad_norm 1.3374 (1.4821)	mem 17417MB
[2023-02-01 16:56:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][1000/1251]	eta 0:02:23 lr 0.000568	time 0.6256 (0.5707)	loss 3.1512 (3.2351)	grad_norm 1.6319 (1.4828)	mem 17417MB
[2023-02-01 16:56:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][1050/1251]	eta 0:01:54 lr 0.000568	time 0.5606 (0.5706)	loss 3.5350 (3.2380)	grad_norm 1.3844 (1.4833)	mem 17417MB
[2023-02-01 16:57:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][1100/1251]	eta 0:01:26 lr 0.000568	time 0.5557 (0.5707)	loss 3.1869 (3.2423)	grad_norm 1.6107 (1.4839)	mem 17417MB
[2023-02-01 16:57:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][1150/1251]	eta 0:00:57 lr 0.000567	time 0.5521 (0.5706)	loss 3.5965 (3.2412)	grad_norm 1.5141 (1.4833)	mem 17417MB
[2023-02-01 16:58:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][1200/1251]	eta 0:00:29 lr 0.000567	time 0.5579 (0.5703)	loss 3.7074 (3.2384)	grad_norm 1.4245 (1.4843)	mem 17417MB
[2023-02-01 16:58:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [137/300][1250/1251]	eta 0:00:00 lr 0.000567	time 0.5491 (0.5703)	loss 2.7858 (3.2386)	grad_norm 1.5095 (1.4847)	mem 17417MB
[2023-02-01 16:58:47 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 137 training takes 0:11:53
[2023-02-01 16:58:48 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_137.pth saving......
[2023-02-01 16:58:49 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_137.pth saved !!!
[2023-02-01 16:58:50 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.961 (0.961)	Loss 0.8843 (0.8843)	Acc@1 78.027 (78.027)	Acc@5 95.703 (95.703)	Mem 17417MB
[2023-02-01 16:58:58 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.602 Acc@5 95.154
[2023-02-01 16:58:58 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.6%
[2023-02-01 16:58:59 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.150 (1.150)	Loss 0.8177 (0.8177)	Acc@1 79.785 (79.785)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-01 16:59:07 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.578 Acc@5 95.994
[2023-02-01 16:59:07 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.6%
[2023-02-01 16:59:07 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.60% at 136 epoch
[2023-02-01 16:59:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][0/1251]	eta 0:34:58 lr 0.000567	time 1.6772 (1.6772)	loss 3.8874 (3.8874)	grad_norm 1.5003 (1.5003)	mem 17417MB
[2023-02-01 16:59:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][50/1251]	eta 0:11:48 lr 0.000567	time 0.5556 (0.5902)	loss 3.2080 (3.1731)	grad_norm 1.3833 (1.5188)	mem 17417MB
[2023-02-01 17:00:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][100/1251]	eta 0:11:08 lr 0.000567	time 0.6477 (0.5810)	loss 2.4139 (3.2249)	grad_norm 1.3609 (1.4931)	mem 17417MB
[2023-02-01 17:00:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][150/1251]	eta 0:10:34 lr 0.000566	time 0.5645 (0.5761)	loss 3.4007 (3.2373)	grad_norm 1.3555 (1.4940)	mem 17417MB
[2023-02-01 17:01:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][200/1251]	eta 0:10:03 lr 0.000566	time 0.5602 (0.5740)	loss 3.7139 (3.2552)	grad_norm 1.4417 (1.4956)	mem 17417MB
[2023-02-01 17:01:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][250/1251]	eta 0:09:33 lr 0.000566	time 0.5531 (0.5731)	loss 2.6759 (3.2362)	grad_norm 1.4494 (1.4906)	mem 17417MB
[2023-02-01 17:02:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][300/1251]	eta 0:09:04 lr 0.000566	time 0.5566 (0.5726)	loss 2.6030 (3.2472)	grad_norm 1.4289 (1.4864)	mem 17417MB
[2023-02-01 17:02:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][350/1251]	eta 0:08:35 lr 0.000566	time 0.5600 (0.5716)	loss 3.5488 (3.2279)	grad_norm 1.4247 (1.4838)	mem 17417MB
[2023-02-01 17:02:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][400/1251]	eta 0:08:06 lr 0.000565	time 0.5520 (0.5712)	loss 3.1293 (3.2176)	grad_norm 1.4458 (1.4860)	mem 17417MB
[2023-02-01 17:03:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][450/1251]	eta 0:07:36 lr 0.000565	time 0.5580 (0.5704)	loss 3.5150 (3.2167)	grad_norm 1.3410 (1.4871)	mem 17417MB
[2023-02-01 17:03:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][500/1251]	eta 0:07:08 lr 0.000565	time 0.6337 (0.5707)	loss 3.2954 (3.2147)	grad_norm 1.7145 (1.4908)	mem 17417MB
[2023-02-01 17:04:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][550/1251]	eta 0:06:39 lr 0.000565	time 0.5611 (0.5702)	loss 2.1411 (3.2214)	grad_norm 1.3562 (1.4930)	mem 17417MB
[2023-02-01 17:04:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][600/1251]	eta 0:06:11 lr 0.000565	time 0.5588 (0.5700)	loss 3.0901 (3.2060)	grad_norm 1.6060 (1.4949)	mem 17417MB
[2023-02-01 17:05:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][650/1251]	eta 0:05:42 lr 0.000564	time 0.5494 (0.5697)	loss 3.6982 (3.2085)	grad_norm 1.4533 (1.4961)	mem 17417MB
[2023-02-01 17:05:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][700/1251]	eta 0:05:13 lr 0.000564	time 0.5557 (0.5695)	loss 3.4405 (3.2160)	grad_norm 1.3947 (1.4987)	mem 17417MB
[2023-02-01 17:06:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][750/1251]	eta 0:04:45 lr 0.000564	time 0.5525 (0.5693)	loss 2.4409 (3.2129)	grad_norm 1.4867 (1.4994)	mem 17417MB
[2023-02-01 17:06:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][800/1251]	eta 0:04:16 lr 0.000564	time 0.5626 (0.5692)	loss 2.5578 (3.2162)	grad_norm 1.3911 (1.5025)	mem 17417MB
[2023-02-01 17:07:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][850/1251]	eta 0:03:48 lr 0.000564	time 0.5579 (0.5691)	loss 4.1947 (3.2238)	grad_norm 1.5238 (1.5029)	mem 17417MB
[2023-02-01 17:07:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][900/1251]	eta 0:03:19 lr 0.000563	time 0.6414 (0.5692)	loss 2.5764 (3.2295)	grad_norm 1.5057 (1.5028)	mem 17417MB
[2023-02-01 17:08:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][950/1251]	eta 0:02:51 lr 0.000563	time 0.5579 (0.5690)	loss 3.4029 (3.2332)	grad_norm 1.4132 (1.5029)	mem 17417MB
[2023-02-01 17:08:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][1000/1251]	eta 0:02:22 lr 0.000563	time 0.5607 (0.5692)	loss 4.5685 (3.2337)	grad_norm 1.5631 (1.5012)	mem 17417MB
[2023-02-01 17:09:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][1050/1251]	eta 0:01:54 lr 0.000563	time 0.5637 (0.5691)	loss 2.2532 (3.2361)	grad_norm 1.6218 (1.5029)	mem 17417MB
[2023-02-01 17:09:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][1100/1251]	eta 0:01:25 lr 0.000563	time 0.6463 (0.5692)	loss 3.2378 (3.2372)	grad_norm 1.5322 (1.5016)	mem 17417MB
[2023-02-01 17:10:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][1150/1251]	eta 0:00:57 lr 0.000562	time 0.5702 (0.5691)	loss 4.0563 (3.2400)	grad_norm 1.9584 (1.5010)	mem 17417MB
[2023-02-01 17:10:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][1200/1251]	eta 0:00:29 lr 0.000562	time 0.5582 (0.5691)	loss 3.7258 (3.2361)	grad_norm 1.5724 (1.5018)	mem 17417MB
[2023-02-01 17:10:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [138/300][1250/1251]	eta 0:00:00 lr 0.000562	time 0.5514 (0.5689)	loss 3.1167 (3.2413)	grad_norm 1.4847 (1.5022)	mem 17417MB
[2023-02-01 17:10:59 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 138 training takes 0:11:51
[2023-02-01 17:10:59 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_138.pth saving......
[2023-02-01 17:11:01 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_138.pth saved !!!
[2023-02-01 17:11:02 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.938 (0.938)	Loss 0.8804 (0.8804)	Acc@1 79.785 (79.785)	Acc@5 95.020 (95.020)	Mem 17417MB
[2023-02-01 17:11:10 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.554 Acc@5 95.204
[2023-02-01 17:11:10 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.6%
[2023-02-01 17:11:11 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.142 (1.142)	Loss 0.8221 (0.8221)	Acc@1 80.859 (80.859)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-01 17:11:19 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.646 Acc@5 96.030
[2023-02-01 17:11:19 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.6%
[2023-02-01 17:11:19 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.65% at 138 epoch
[2023-02-01 17:11:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][0/1251]	eta 0:37:44 lr 0.000562	time 1.8104 (1.8104)	loss 2.5744 (2.5744)	grad_norm 1.3559 (1.3559)	mem 17417MB
[2023-02-01 17:11:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][50/1251]	eta 0:11:54 lr 0.000562	time 0.5548 (0.5948)	loss 3.6955 (3.1485)	grad_norm 1.5856 (1.5094)	mem 17417MB
[2023-02-01 17:12:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][100/1251]	eta 0:11:10 lr 0.000561	time 0.5519 (0.5828)	loss 3.2995 (3.1568)	grad_norm 1.5959 (1.5133)	mem 17417MB
[2023-02-01 17:12:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][150/1251]	eta 0:10:36 lr 0.000561	time 0.5553 (0.5783)	loss 3.8534 (3.2059)	grad_norm 1.5453 (1.5100)	mem 17417MB
[2023-02-01 17:13:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][200/1251]	eta 0:10:04 lr 0.000561	time 0.5649 (0.5753)	loss 2.0391 (3.2013)	grad_norm 1.5271 (1.5129)	mem 17417MB
[2023-02-01 17:13:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][250/1251]	eta 0:09:34 lr 0.000561	time 0.6245 (0.5741)	loss 3.1914 (3.2122)	grad_norm 1.5902 (1.5137)	mem 17417MB
[2023-02-01 17:14:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][300/1251]	eta 0:09:04 lr 0.000561	time 0.5592 (0.5726)	loss 3.8503 (3.2076)	grad_norm 1.7112 (1.5117)	mem 17417MB
[2023-02-01 17:14:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][350/1251]	eta 0:08:35 lr 0.000560	time 0.5581 (0.5725)	loss 3.1760 (3.2004)	grad_norm 1.5573 (1.5073)	mem 17417MB
[2023-02-01 17:15:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][400/1251]	eta 0:08:06 lr 0.000560	time 0.6312 (0.5718)	loss 3.1177 (3.2182)	grad_norm 1.5746 (1.5098)	mem 17417MB
[2023-02-01 17:15:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][450/1251]	eta 0:07:37 lr 0.000560	time 0.6440 (0.5714)	loss 2.6633 (3.2256)	grad_norm 1.6137 (1.5130)	mem 17417MB
[2023-02-01 17:16:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][500/1251]	eta 0:07:08 lr 0.000560	time 0.5545 (0.5705)	loss 3.0711 (3.2243)	grad_norm 1.6367 (1.5105)	mem 17417MB
[2023-02-01 17:16:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][550/1251]	eta 0:06:39 lr 0.000560	time 0.5529 (0.5701)	loss 3.2663 (3.2232)	grad_norm 1.5393 (nan)	mem 17417MB
[2023-02-01 17:17:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][600/1251]	eta 0:06:10 lr 0.000559	time 0.5530 (0.5697)	loss 3.2137 (3.2241)	grad_norm 1.3034 (nan)	mem 17417MB
[2023-02-01 17:17:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][650/1251]	eta 0:05:42 lr 0.000559	time 0.5602 (0.5696)	loss 2.2656 (3.2242)	grad_norm 1.7182 (nan)	mem 17417MB
[2023-02-01 17:17:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][700/1251]	eta 0:05:13 lr 0.000559	time 0.5528 (0.5695)	loss 3.8745 (3.2278)	grad_norm 1.5418 (nan)	mem 17417MB
[2023-02-01 17:18:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][750/1251]	eta 0:04:45 lr 0.000559	time 0.5534 (0.5695)	loss 3.4947 (3.2242)	grad_norm 1.4347 (nan)	mem 17417MB
[2023-02-01 17:18:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][800/1251]	eta 0:04:16 lr 0.000559	time 0.5542 (0.5691)	loss 3.1858 (3.2194)	grad_norm 1.3757 (nan)	mem 17417MB
[2023-02-01 17:19:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][850/1251]	eta 0:03:48 lr 0.000558	time 0.5592 (0.5690)	loss 3.4670 (3.2170)	grad_norm 1.4185 (nan)	mem 17417MB
[2023-02-01 17:19:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][900/1251]	eta 0:03:19 lr 0.000558	time 0.5570 (0.5690)	loss 3.9427 (3.2208)	grad_norm 1.5201 (nan)	mem 17417MB
[2023-02-01 17:20:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][950/1251]	eta 0:02:51 lr 0.000558	time 0.5520 (0.5689)	loss 3.8346 (3.2219)	grad_norm 1.5808 (nan)	mem 17417MB
[2023-02-01 17:20:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][1000/1251]	eta 0:02:22 lr 0.000558	time 0.6193 (0.5690)	loss 3.8438 (3.2198)	grad_norm 1.3789 (nan)	mem 17417MB
[2023-02-01 17:21:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][1050/1251]	eta 0:01:54 lr 0.000558	time 0.5596 (0.5691)	loss 2.8853 (3.2161)	grad_norm 1.5170 (nan)	mem 17417MB
[2023-02-01 17:21:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][1100/1251]	eta 0:01:25 lr 0.000557	time 0.5528 (0.5688)	loss 3.4346 (3.2181)	grad_norm 1.6191 (nan)	mem 17417MB
[2023-02-01 17:22:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][1150/1251]	eta 0:00:57 lr 0.000557	time 0.5574 (0.5689)	loss 3.2947 (3.2166)	grad_norm 1.4652 (nan)	mem 17417MB
[2023-02-01 17:22:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][1200/1251]	eta 0:00:29 lr 0.000557	time 0.5574 (0.5689)	loss 3.8701 (3.2144)	grad_norm 1.3739 (nan)	mem 17417MB
[2023-02-01 17:23:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [139/300][1250/1251]	eta 0:00:00 lr 0.000557	time 0.6097 (0.5689)	loss 3.6574 (3.2199)	grad_norm 1.6102 (nan)	mem 17417MB
[2023-02-01 17:23:11 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 139 training takes 0:11:51
[2023-02-01 17:23:11 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_139.pth saving......
[2023-02-01 17:23:13 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_139.pth saved !!!
[2023-02-01 17:23:14 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.911 (0.911)	Loss 0.9489 (0.9489)	Acc@1 77.734 (77.734)	Acc@5 94.531 (94.531)	Mem 17417MB
[2023-02-01 17:23:22 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.594 Acc@5 95.036
[2023-02-01 17:23:22 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.6%
[2023-02-01 17:23:23 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.213 (1.213)	Loss 0.7525 (0.7525)	Acc@1 82.617 (82.617)	Acc@5 95.898 (95.898)	Mem 17417MB
[2023-02-01 17:23:31 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.656 Acc@5 96.024
[2023-02-01 17:23:31 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.7%
[2023-02-01 17:23:31 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.66% at 139 epoch
[2023-02-01 17:23:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][0/1251]	eta 0:34:37 lr 0.000557	time 1.6607 (1.6607)	loss 3.7497 (3.7497)	grad_norm 1.6041 (1.6041)	mem 17417MB
[2023-02-01 17:24:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][50/1251]	eta 0:11:47 lr 0.000557	time 0.5620 (0.5893)	loss 3.6241 (3.2198)	grad_norm 1.5227 (1.4833)	mem 17417MB
[2023-02-01 17:24:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][100/1251]	eta 0:11:06 lr 0.000556	time 0.5577 (0.5790)	loss 2.5518 (3.2585)	grad_norm 1.4731 (1.4871)	mem 17417MB
[2023-02-01 17:24:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][150/1251]	eta 0:10:33 lr 0.000556	time 0.5537 (0.5754)	loss 3.3957 (3.2109)	grad_norm 1.4209 (1.4875)	mem 17417MB
[2023-02-01 17:25:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][200/1251]	eta 0:10:03 lr 0.000556	time 0.5539 (0.5737)	loss 3.1535 (3.2386)	grad_norm 1.4529 (1.4807)	mem 17417MB
[2023-02-01 17:25:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][250/1251]	eta 0:09:33 lr 0.000556	time 0.5513 (0.5728)	loss 3.1185 (3.2248)	grad_norm 1.3597 (1.4839)	mem 17417MB
[2023-02-01 17:26:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][300/1251]	eta 0:09:03 lr 0.000556	time 0.5549 (0.5720)	loss 3.4074 (3.2285)	grad_norm 1.4975 (1.4920)	mem 17417MB
[2023-02-01 17:26:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][350/1251]	eta 0:08:34 lr 0.000555	time 0.5575 (0.5714)	loss 3.2221 (3.2268)	grad_norm 1.3359 (1.4926)	mem 17417MB
[2023-02-01 17:27:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][400/1251]	eta 0:08:05 lr 0.000555	time 0.5591 (0.5709)	loss 3.0534 (3.2375)	grad_norm 1.6538 (1.4927)	mem 17417MB
[2023-02-01 17:27:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][450/1251]	eta 0:07:36 lr 0.000555	time 0.5612 (0.5705)	loss 2.9624 (3.2386)	grad_norm 1.4085 (1.4957)	mem 17417MB
[2023-02-01 17:28:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][500/1251]	eta 0:07:08 lr 0.000555	time 0.5590 (0.5704)	loss 3.5198 (3.2452)	grad_norm 1.3883 (1.5019)	mem 17417MB
[2023-02-01 17:28:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][550/1251]	eta 0:06:39 lr 0.000554	time 0.5593 (0.5702)	loss 3.4894 (3.2441)	grad_norm 1.3656 (1.5000)	mem 17417MB
[2023-02-01 17:29:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][600/1251]	eta 0:06:11 lr 0.000554	time 0.5519 (0.5702)	loss 2.4610 (3.2435)	grad_norm 1.3019 (1.4995)	mem 17417MB
[2023-02-01 17:29:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][650/1251]	eta 0:05:42 lr 0.000554	time 0.5697 (0.5700)	loss 3.7642 (3.2488)	grad_norm 1.4952 (1.5029)	mem 17417MB
[2023-02-01 17:30:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][700/1251]	eta 0:05:13 lr 0.000554	time 0.5623 (0.5697)	loss 3.0872 (3.2462)	grad_norm 1.5717 (1.5025)	mem 17417MB
[2023-02-01 17:30:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][750/1251]	eta 0:04:45 lr 0.000554	time 0.5529 (0.5696)	loss 3.7465 (3.2418)	grad_norm 1.5737 (1.5019)	mem 17417MB
[2023-02-01 17:31:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][800/1251]	eta 0:04:16 lr 0.000553	time 0.6543 (0.5697)	loss 4.0193 (3.2357)	grad_norm 1.4679 (1.5019)	mem 17417MB
[2023-02-01 17:31:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][850/1251]	eta 0:03:48 lr 0.000553	time 0.5602 (0.5695)	loss 3.3565 (3.2374)	grad_norm 1.8405 (1.5038)	mem 17417MB
[2023-02-01 17:32:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][900/1251]	eta 0:03:19 lr 0.000553	time 0.5558 (0.5694)	loss 2.7163 (3.2379)	grad_norm 1.6660 (1.5040)	mem 17417MB
[2023-02-01 17:32:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][950/1251]	eta 0:02:51 lr 0.000553	time 0.5567 (0.5693)	loss 3.5478 (3.2319)	grad_norm 1.8351 (1.5027)	mem 17417MB
[2023-02-01 17:33:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][1000/1251]	eta 0:02:22 lr 0.000553	time 0.5528 (0.5694)	loss 3.0445 (3.2329)	grad_norm 1.4706 (1.5044)	mem 17417MB
[2023-02-01 17:33:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][1050/1251]	eta 0:01:54 lr 0.000552	time 0.5592 (0.5692)	loss 3.5037 (3.2321)	grad_norm 1.4802 (1.5037)	mem 17417MB
[2023-02-01 17:33:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][1100/1251]	eta 0:01:25 lr 0.000552	time 0.5540 (0.5691)	loss 3.8691 (3.2336)	grad_norm 1.5676 (1.5065)	mem 17417MB
[2023-02-01 17:34:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][1150/1251]	eta 0:00:57 lr 0.000552	time 0.6198 (0.5691)	loss 3.6162 (3.2371)	grad_norm 1.6841 (1.5075)	mem 17417MB
[2023-02-01 17:34:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][1200/1251]	eta 0:00:29 lr 0.000552	time 0.5533 (0.5691)	loss 3.7804 (3.2386)	grad_norm 1.7005 (1.5059)	mem 17417MB
[2023-02-01 17:35:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [140/300][1250/1251]	eta 0:00:00 lr 0.000552	time 0.5520 (0.5691)	loss 3.4595 (3.2443)	grad_norm 1.5448 (1.5075)	mem 17417MB
[2023-02-01 17:35:23 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 140 training takes 0:11:52
[2023-02-01 17:35:23 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_140.pth saving......
[2023-02-01 17:35:25 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_140.pth saved !!!
[2023-02-01 17:35:26 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.982 (0.982)	Loss 0.8909 (0.8909)	Acc@1 79.590 (79.590)	Acc@5 94.531 (94.531)	Mem 17417MB
[2023-02-01 17:35:34 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.584 Acc@5 95.192
[2023-02-01 17:35:34 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.6%
[2023-02-01 17:35:35 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.163 (1.163)	Loss 0.7190 (0.7190)	Acc@1 83.887 (83.887)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-01 17:35:43 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.720 Acc@5 96.058
[2023-02-01 17:35:43 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.7%
[2023-02-01 17:35:43 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.72% at 140 epoch
[2023-02-01 17:35:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][0/1251]	eta 0:36:19 lr 0.000552	time 1.7421 (1.7421)	loss 2.5546 (2.5546)	grad_norm 1.4728 (1.4728)	mem 17417MB
[2023-02-01 17:36:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][50/1251]	eta 0:11:51 lr 0.000551	time 0.5577 (0.5927)	loss 3.4632 (3.2324)	grad_norm 1.6957 (1.4849)	mem 17417MB
[2023-02-01 17:36:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][100/1251]	eta 0:11:08 lr 0.000551	time 0.5532 (0.5810)	loss 2.8229 (3.1674)	grad_norm 1.3647 (1.4942)	mem 17417MB
[2023-02-01 17:37:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][150/1251]	eta 0:10:34 lr 0.000551	time 0.5563 (0.5767)	loss 2.2710 (3.1222)	grad_norm 1.4694 (1.4905)	mem 17417MB
[2023-02-01 17:37:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][200/1251]	eta 0:10:04 lr 0.000551	time 0.5598 (0.5750)	loss 3.6943 (3.1184)	grad_norm 1.3833 (1.4942)	mem 17417MB
[2023-02-01 17:38:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][250/1251]	eta 0:09:34 lr 0.000551	time 0.6206 (0.5736)	loss 2.6942 (3.1389)	grad_norm 1.4574 (1.4967)	mem 17417MB
[2023-02-01 17:38:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][300/1251]	eta 0:09:04 lr 0.000550	time 0.5515 (0.5726)	loss 2.2185 (3.1410)	grad_norm 1.6353 (nan)	mem 17417MB
[2023-02-01 17:39:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][350/1251]	eta 0:08:35 lr 0.000550	time 0.5515 (0.5720)	loss 3.5008 (3.1362)	grad_norm 1.4446 (nan)	mem 17417MB
[2023-02-01 17:39:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][400/1251]	eta 0:08:06 lr 0.000550	time 0.5592 (0.5716)	loss 3.4807 (3.1433)	grad_norm 1.4984 (nan)	mem 17417MB
[2023-02-01 17:40:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][450/1251]	eta 0:07:37 lr 0.000550	time 0.5534 (0.5713)	loss 3.5916 (3.1496)	grad_norm 1.3692 (nan)	mem 17417MB
[2023-02-01 17:40:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][500/1251]	eta 0:07:08 lr 0.000550	time 0.5759 (0.5707)	loss 2.9754 (3.1509)	grad_norm 1.6452 (nan)	mem 17417MB
[2023-02-01 17:40:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][550/1251]	eta 0:06:39 lr 0.000549	time 0.5513 (0.5705)	loss 3.6820 (3.1580)	grad_norm 1.4210 (nan)	mem 17417MB
[2023-02-01 17:41:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][600/1251]	eta 0:06:11 lr 0.000549	time 0.5583 (0.5706)	loss 3.6772 (3.1669)	grad_norm 1.3176 (nan)	mem 17417MB
[2023-02-01 17:41:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][650/1251]	eta 0:05:42 lr 0.000549	time 0.5624 (0.5704)	loss 3.1357 (3.1752)	grad_norm 1.4030 (nan)	mem 17417MB
[2023-02-01 17:42:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][700/1251]	eta 0:05:14 lr 0.000549	time 0.5659 (0.5702)	loss 3.4625 (3.1804)	grad_norm 1.5534 (nan)	mem 17417MB
[2023-02-01 17:42:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][750/1251]	eta 0:04:45 lr 0.000548	time 0.5595 (0.5699)	loss 2.7501 (3.1854)	grad_norm 1.6998 (nan)	mem 17417MB
[2023-02-01 17:43:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][800/1251]	eta 0:04:16 lr 0.000548	time 0.5568 (0.5698)	loss 3.1495 (3.1823)	grad_norm 1.5791 (nan)	mem 17417MB
[2023-02-01 17:43:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][850/1251]	eta 0:03:48 lr 0.000548	time 0.6278 (0.5699)	loss 2.8482 (3.1946)	grad_norm 1.7024 (nan)	mem 17417MB
[2023-02-01 17:44:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][900/1251]	eta 0:03:19 lr 0.000548	time 0.5530 (0.5697)	loss 2.8092 (3.1966)	grad_norm 1.7229 (nan)	mem 17417MB
[2023-02-01 17:44:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][950/1251]	eta 0:02:51 lr 0.000548	time 0.5544 (0.5696)	loss 2.6897 (3.1986)	grad_norm 1.6288 (nan)	mem 17417MB
[2023-02-01 17:45:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][1000/1251]	eta 0:02:23 lr 0.000547	time 0.5580 (0.5697)	loss 3.7714 (3.2040)	grad_norm 1.4972 (nan)	mem 17417MB
[2023-02-01 17:45:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][1050/1251]	eta 0:01:54 lr 0.000547	time 0.5589 (0.5697)	loss 3.5754 (3.2134)	grad_norm 1.5458 (nan)	mem 17417MB
[2023-02-01 17:46:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][1100/1251]	eta 0:01:26 lr 0.000547	time 0.5520 (0.5696)	loss 3.2351 (3.2181)	grad_norm 1.5423 (nan)	mem 17417MB
[2023-02-01 17:46:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][1150/1251]	eta 0:00:57 lr 0.000547	time 0.5492 (0.5696)	loss 2.2833 (3.2258)	grad_norm 1.5679 (nan)	mem 17417MB
[2023-02-01 17:47:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][1200/1251]	eta 0:00:29 lr 0.000547	time 0.6356 (0.5697)	loss 2.6886 (3.2265)	grad_norm 1.4285 (nan)	mem 17417MB
[2023-02-01 17:47:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [141/300][1250/1251]	eta 0:00:00 lr 0.000546	time 0.5502 (0.5697)	loss 3.3441 (3.2291)	grad_norm 1.5967 (nan)	mem 17417MB
[2023-02-01 17:47:36 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 141 training takes 0:11:52
[2023-02-01 17:47:36 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_141.pth saving......
[2023-02-01 17:47:38 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_141.pth saved !!!
[2023-02-01 17:47:39 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.911 (0.911)	Loss 0.8783 (0.8783)	Acc@1 78.613 (78.613)	Acc@5 95.508 (95.508)	Mem 17417MB
[2023-02-01 17:47:47 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.502 Acc@5 95.196
[2023-02-01 17:47:47 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.5%
[2023-02-01 17:47:48 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.371 (1.371)	Loss 0.8598 (0.8598)	Acc@1 79.492 (79.492)	Acc@5 95.996 (95.996)	Mem 17417MB
[2023-02-01 17:47:56 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.732 Acc@5 96.074
[2023-02-01 17:47:56 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.7%
[2023-02-01 17:47:56 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.73% at 141 epoch
[2023-02-01 17:47:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][0/1251]	eta 0:39:45 lr 0.000546	time 1.9068 (1.9068)	loss 2.3812 (2.3812)	grad_norm 1.5024 (1.5024)	mem 17417MB
[2023-02-01 17:48:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][50/1251]	eta 0:11:58 lr 0.000546	time 0.5577 (0.5987)	loss 3.5600 (3.2901)	grad_norm 1.6169 (1.5678)	mem 17417MB
[2023-02-01 17:48:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][100/1251]	eta 0:11:11 lr 0.000546	time 0.6247 (0.5834)	loss 3.1229 (3.2441)	grad_norm 1.5089 (1.5354)	mem 17417MB
[2023-02-01 17:49:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][150/1251]	eta 0:10:37 lr 0.000546	time 0.5603 (0.5787)	loss 3.0014 (3.2234)	grad_norm 1.3984 (1.5296)	mem 17417MB
[2023-02-01 17:49:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][200/1251]	eta 0:10:05 lr 0.000546	time 0.5554 (0.5763)	loss 3.5025 (3.2032)	grad_norm 1.5023 (1.5219)	mem 17417MB
[2023-02-01 17:50:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][250/1251]	eta 0:09:34 lr 0.000545	time 0.5538 (0.5743)	loss 3.3606 (3.2032)	grad_norm 1.4508 (1.5239)	mem 17417MB
[2023-02-01 17:50:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][300/1251]	eta 0:09:05 lr 0.000545	time 0.5514 (0.5741)	loss 3.3159 (3.2071)	grad_norm 1.6279 (1.5281)	mem 17417MB
[2023-02-01 17:51:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][350/1251]	eta 0:08:36 lr 0.000545	time 0.5626 (0.5729)	loss 2.4743 (3.1998)	grad_norm 1.3368 (1.5230)	mem 17417MB
[2023-02-01 17:51:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][400/1251]	eta 0:08:07 lr 0.000545	time 0.5617 (0.5724)	loss 3.2537 (3.1962)	grad_norm 1.5820 (1.5269)	mem 17417MB
[2023-02-01 17:52:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][450/1251]	eta 0:07:38 lr 0.000545	time 0.5497 (0.5721)	loss 3.0073 (3.1903)	grad_norm 1.4586 (1.5230)	mem 17417MB
[2023-02-01 17:52:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][500/1251]	eta 0:07:08 lr 0.000544	time 0.6140 (0.5712)	loss 3.2406 (3.1985)	grad_norm 1.4840 (1.5213)	mem 17417MB
[2023-02-01 17:53:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][550/1251]	eta 0:06:40 lr 0.000544	time 0.5594 (0.5711)	loss 3.1310 (3.1900)	grad_norm 1.3768 (1.5228)	mem 17417MB
[2023-02-01 17:53:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][600/1251]	eta 0:06:11 lr 0.000544	time 0.5623 (0.5706)	loss 3.2771 (3.1972)	grad_norm 1.4924 (1.5230)	mem 17417MB
[2023-02-01 17:54:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][650/1251]	eta 0:05:42 lr 0.000544	time 0.5574 (0.5701)	loss 3.4191 (3.2009)	grad_norm 1.4995 (1.5225)	mem 17417MB
[2023-02-01 17:54:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][700/1251]	eta 0:05:14 lr 0.000544	time 0.5586 (0.5700)	loss 2.7265 (3.1999)	grad_norm 1.6551 (1.5229)	mem 17417MB
[2023-02-01 17:55:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][750/1251]	eta 0:04:45 lr 0.000543	time 0.5582 (0.5699)	loss 2.8730 (3.1990)	grad_norm 1.3877 (1.5222)	mem 17417MB
[2023-02-01 17:55:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][800/1251]	eta 0:04:17 lr 0.000543	time 0.5502 (0.5700)	loss 3.4970 (3.2012)	grad_norm 1.4630 (1.5187)	mem 17417MB
[2023-02-01 17:56:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][850/1251]	eta 0:03:48 lr 0.000543	time 0.5672 (0.5696)	loss 3.6929 (3.2009)	grad_norm 1.3853 (1.5169)	mem 17417MB
[2023-02-01 17:56:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][900/1251]	eta 0:03:19 lr 0.000543	time 0.6290 (0.5696)	loss 3.1933 (3.2112)	grad_norm 1.5055 (1.5162)	mem 17417MB
[2023-02-01 17:56:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][950/1251]	eta 0:02:51 lr 0.000542	time 0.5584 (0.5696)	loss 3.5516 (3.2148)	grad_norm 1.3324 (1.5139)	mem 17417MB
[2023-02-01 17:57:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][1000/1251]	eta 0:02:22 lr 0.000542	time 0.5525 (0.5696)	loss 3.5561 (3.2171)	grad_norm 1.4461 (1.5147)	mem 17417MB
[2023-02-01 17:57:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][1050/1251]	eta 0:01:54 lr 0.000542	time 0.5544 (0.5695)	loss 2.9073 (3.2151)	grad_norm 1.5611 (1.5156)	mem 17417MB
[2023-02-01 17:58:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][1100/1251]	eta 0:01:25 lr 0.000542	time 0.6285 (0.5695)	loss 3.3859 (3.2151)	grad_norm 1.6392 (1.5175)	mem 17417MB
[2023-02-01 17:58:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][1150/1251]	eta 0:00:57 lr 0.000542	time 0.5495 (0.5692)	loss 3.1334 (3.2117)	grad_norm 1.7526 (1.5186)	mem 17417MB
[2023-02-01 17:59:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][1200/1251]	eta 0:00:29 lr 0.000541	time 0.5620 (0.5692)	loss 2.2122 (3.2132)	grad_norm 1.3450 (1.5153)	mem 17417MB
[2023-02-01 17:59:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [142/300][1250/1251]	eta 0:00:00 lr 0.000541	time 0.5634 (0.5692)	loss 3.5948 (3.2132)	grad_norm 1.5101 (1.5155)	mem 17417MB
[2023-02-01 17:59:48 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 142 training takes 0:11:52
[2023-02-01 17:59:49 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_142.pth saving......
[2023-02-01 17:59:50 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_142.pth saved !!!
[2023-02-01 17:59:51 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.920 (0.920)	Loss 0.8726 (0.8726)	Acc@1 79.395 (79.395)	Acc@5 94.434 (94.434)	Mem 17417MB
[2023-02-01 17:59:59 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.390 Acc@5 95.222
[2023-02-01 17:59:59 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.4%
[2023-02-01 18:00:01 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.191 (1.191)	Loss 0.7337 (0.7337)	Acc@1 83.008 (83.008)	Acc@5 96.484 (96.484)	Mem 17417MB
[2023-02-01 18:00:09 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.750 Acc@5 96.104
[2023-02-01 18:00:09 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.7%
[2023-02-01 18:00:09 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.75% at 142 epoch
[2023-02-01 18:00:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][0/1251]	eta 0:34:36 lr 0.000541	time 1.6598 (1.6598)	loss 2.7507 (2.7507)	grad_norm 1.4417 (1.4417)	mem 17417MB
[2023-02-01 18:00:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][50/1251]	eta 0:11:46 lr 0.000541	time 0.5576 (0.5885)	loss 3.3687 (3.2336)	grad_norm 1.5583 (1.4914)	mem 17417MB
[2023-02-01 18:01:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][100/1251]	eta 0:11:08 lr 0.000541	time 0.6394 (0.5807)	loss 3.1815 (3.2500)	grad_norm 1.2894 (1.4686)	mem 17417MB
[2023-02-01 18:01:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][150/1251]	eta 0:10:34 lr 0.000541	time 0.5614 (0.5761)	loss 3.2342 (3.2235)	grad_norm 1.5729 (1.4928)	mem 17417MB
[2023-02-01 18:02:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][200/1251]	eta 0:10:03 lr 0.000540	time 0.5599 (0.5742)	loss 2.9199 (3.2406)	grad_norm 1.3236 (nan)	mem 17417MB
[2023-02-01 18:02:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][250/1251]	eta 0:09:33 lr 0.000540	time 0.5561 (0.5728)	loss 3.7377 (3.2484)	grad_norm 1.6489 (nan)	mem 17417MB
[2023-02-01 18:03:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][300/1251]	eta 0:09:03 lr 0.000540	time 0.5594 (0.5719)	loss 3.2232 (3.2259)	grad_norm 1.4839 (nan)	mem 17417MB
[2023-02-01 18:03:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][350/1251]	eta 0:08:34 lr 0.000540	time 0.5592 (0.5713)	loss 2.3019 (3.2282)	grad_norm 1.3280 (nan)	mem 17417MB
[2023-02-01 18:03:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][400/1251]	eta 0:08:05 lr 0.000540	time 0.5613 (0.5709)	loss 3.8835 (3.2273)	grad_norm 1.3724 (nan)	mem 17417MB
[2023-02-01 18:04:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][450/1251]	eta 0:07:36 lr 0.000539	time 0.6253 (0.5705)	loss 3.6552 (3.2157)	grad_norm 1.8174 (nan)	mem 17417MB
[2023-02-01 18:04:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][500/1251]	eta 0:07:08 lr 0.000539	time 0.6112 (0.5701)	loss 3.1272 (3.2086)	grad_norm 1.5670 (nan)	mem 17417MB
[2023-02-01 18:05:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][550/1251]	eta 0:06:39 lr 0.000539	time 0.6243 (0.5700)	loss 3.2098 (3.2100)	grad_norm 1.6092 (nan)	mem 17417MB
[2023-02-01 18:05:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][600/1251]	eta 0:06:10 lr 0.000539	time 0.5524 (0.5698)	loss 3.5586 (3.2156)	grad_norm 1.3863 (nan)	mem 17417MB
[2023-02-01 18:06:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][650/1251]	eta 0:05:42 lr 0.000539	time 0.5613 (0.5697)	loss 3.7454 (3.2091)	grad_norm 1.5792 (nan)	mem 17417MB
[2023-02-01 18:06:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][700/1251]	eta 0:05:13 lr 0.000538	time 0.5605 (0.5697)	loss 3.4883 (3.2098)	grad_norm 1.7583 (nan)	mem 17417MB
[2023-02-01 18:07:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][750/1251]	eta 0:04:45 lr 0.000538	time 0.5578 (0.5696)	loss 2.7485 (3.2015)	grad_norm 1.5992 (nan)	mem 17417MB
[2023-02-01 18:07:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][800/1251]	eta 0:04:16 lr 0.000538	time 0.5604 (0.5693)	loss 3.5460 (3.1986)	grad_norm 1.6000 (nan)	mem 17417MB
[2023-02-01 18:08:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][850/1251]	eta 0:03:48 lr 0.000538	time 0.5546 (0.5692)	loss 3.0222 (3.2030)	grad_norm 1.5137 (nan)	mem 17417MB
[2023-02-01 18:08:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][900/1251]	eta 0:03:19 lr 0.000538	time 0.6119 (0.5692)	loss 3.8155 (3.2017)	grad_norm 1.4497 (nan)	mem 17417MB
[2023-02-01 18:09:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][950/1251]	eta 0:02:51 lr 0.000537	time 0.5512 (0.5692)	loss 2.3376 (3.2057)	grad_norm 1.3328 (nan)	mem 17417MB
[2023-02-01 18:09:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][1000/1251]	eta 0:02:22 lr 0.000537	time 0.6548 (0.5692)	loss 1.9474 (3.1988)	grad_norm 1.4423 (nan)	mem 17417MB
[2023-02-01 18:10:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][1050/1251]	eta 0:01:54 lr 0.000537	time 0.5562 (0.5692)	loss 3.1653 (3.1953)	grad_norm 1.4503 (nan)	mem 17417MB
[2023-02-01 18:10:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][1100/1251]	eta 0:01:25 lr 0.000537	time 0.6245 (0.5692)	loss 3.4207 (3.1960)	grad_norm 1.4305 (nan)	mem 17417MB
[2023-02-01 18:11:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][1150/1251]	eta 0:00:57 lr 0.000536	time 0.5671 (0.5692)	loss 2.7083 (3.1975)	grad_norm 1.3969 (nan)	mem 17417MB
[2023-02-01 18:11:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][1200/1251]	eta 0:00:29 lr 0.000536	time 0.6248 (0.5692)	loss 3.7486 (3.2019)	grad_norm 1.6023 (nan)	mem 17417MB
[2023-02-01 18:12:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [143/300][1250/1251]	eta 0:00:00 lr 0.000536	time 0.5495 (0.5693)	loss 2.8743 (3.2050)	grad_norm 1.4404 (nan)	mem 17417MB
[2023-02-01 18:12:01 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 143 training takes 0:11:52
[2023-02-01 18:12:01 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_143.pth saving......
[2023-02-01 18:12:03 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_143.pth saved !!!
[2023-02-01 18:12:04 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.960 (0.960)	Loss 0.7401 (0.7401)	Acc@1 82.910 (82.910)	Acc@5 95.703 (95.703)	Mem 17417MB
[2023-02-01 18:12:12 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.628 Acc@5 95.118
[2023-02-01 18:12:12 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.6%
[2023-02-01 18:12:13 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.300 (1.300)	Loss 0.7677 (0.7677)	Acc@1 82.129 (82.129)	Acc@5 96.973 (96.973)	Mem 17417MB
[2023-02-01 18:12:21 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.760 Acc@5 96.114
[2023-02-01 18:12:21 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.8%
[2023-02-01 18:12:21 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.76% at 143 epoch
[2023-02-01 18:12:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][0/1251]	eta 0:33:45 lr 0.000536	time 1.6193 (1.6193)	loss 3.0405 (3.0405)	grad_norm 1.4630 (1.4630)	mem 17417MB
[2023-02-01 18:12:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][50/1251]	eta 0:11:51 lr 0.000536	time 0.5488 (0.5923)	loss 3.4460 (3.0521)	grad_norm 1.5662 (1.5248)	mem 17417MB
[2023-02-01 18:13:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][100/1251]	eta 0:11:09 lr 0.000536	time 0.5586 (0.5815)	loss 3.9138 (3.1430)	grad_norm 1.3851 (1.5429)	mem 17417MB
[2023-02-01 18:13:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][150/1251]	eta 0:10:35 lr 0.000535	time 0.5580 (0.5769)	loss 3.6583 (3.1456)	grad_norm 1.4715 (1.5210)	mem 17417MB
[2023-02-01 18:14:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][200/1251]	eta 0:10:04 lr 0.000535	time 0.6222 (0.5752)	loss 3.3113 (3.1438)	grad_norm 1.3941 (1.5187)	mem 17417MB
[2023-02-01 18:14:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][250/1251]	eta 0:09:34 lr 0.000535	time 0.5550 (0.5736)	loss 3.3321 (3.1567)	grad_norm 1.7467 (1.5225)	mem 17417MB
[2023-02-01 18:15:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][300/1251]	eta 0:09:05 lr 0.000535	time 0.5607 (0.5733)	loss 3.0905 (3.1560)	grad_norm 1.5638 (1.5215)	mem 17417MB
[2023-02-01 18:15:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][350/1251]	eta 0:08:35 lr 0.000535	time 0.5518 (0.5726)	loss 3.3046 (3.1719)	grad_norm 1.5272 (1.5164)	mem 17417MB
[2023-02-01 18:16:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][400/1251]	eta 0:08:06 lr 0.000534	time 0.5518 (0.5720)	loss 3.8747 (3.1765)	grad_norm 1.5490 (1.5218)	mem 17417MB
[2023-02-01 18:16:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][450/1251]	eta 0:07:38 lr 0.000534	time 0.6101 (0.5721)	loss 3.9384 (3.1844)	grad_norm 1.6541 (1.5232)	mem 17417MB
[2023-02-01 18:17:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][500/1251]	eta 0:07:09 lr 0.000534	time 0.5661 (0.5717)	loss 2.6860 (3.1750)	grad_norm 1.5561 (1.5201)	mem 17417MB
[2023-02-01 18:17:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][550/1251]	eta 0:06:40 lr 0.000534	time 0.5543 (0.5715)	loss 3.6931 (3.1823)	grad_norm 1.4010 (1.5232)	mem 17417MB
[2023-02-01 18:18:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][600/1251]	eta 0:06:12 lr 0.000534	time 0.5598 (0.5715)	loss 2.7374 (3.1905)	grad_norm 1.4199 (1.5227)	mem 17417MB
[2023-02-01 18:18:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][650/1251]	eta 0:05:43 lr 0.000533	time 0.5546 (0.5712)	loss 3.7733 (3.1832)	grad_norm 1.6289 (1.5227)	mem 17417MB
[2023-02-01 18:19:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][700/1251]	eta 0:05:14 lr 0.000533	time 0.5686 (0.5710)	loss 3.1637 (3.1772)	grad_norm 1.4838 (1.5251)	mem 17417MB
[2023-02-01 18:19:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][750/1251]	eta 0:04:45 lr 0.000533	time 0.5541 (0.5707)	loss 2.1825 (3.1749)	grad_norm 1.4369 (1.5252)	mem 17417MB
[2023-02-01 18:19:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][800/1251]	eta 0:04:17 lr 0.000533	time 0.6115 (0.5707)	loss 3.8143 (3.1875)	grad_norm 1.4099 (1.5259)	mem 17417MB
[2023-02-01 18:20:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][850/1251]	eta 0:03:48 lr 0.000533	time 0.5621 (0.5706)	loss 2.5577 (3.1846)	grad_norm 1.4733 (1.5237)	mem 17417MB
[2023-02-01 18:20:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][900/1251]	eta 0:03:20 lr 0.000532	time 0.6266 (0.5707)	loss 3.2533 (3.1906)	grad_norm 1.5707 (1.5235)	mem 17417MB
[2023-02-01 18:21:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][950/1251]	eta 0:02:51 lr 0.000532	time 0.5586 (0.5705)	loss 2.6076 (3.1989)	grad_norm 1.5410 (1.5236)	mem 17417MB
[2023-02-01 18:21:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][1000/1251]	eta 0:02:23 lr 0.000532	time 0.6245 (0.5706)	loss 3.0894 (3.1912)	grad_norm 1.5145 (1.5229)	mem 17417MB
[2023-02-01 18:22:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][1050/1251]	eta 0:01:54 lr 0.000532	time 0.5644 (0.5705)	loss 3.1651 (3.1894)	grad_norm 1.5269 (1.5226)	mem 17417MB
[2023-02-01 18:22:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][1100/1251]	eta 0:01:26 lr 0.000532	time 0.5607 (0.5705)	loss 3.1457 (3.1940)	grad_norm 1.4542 (1.5230)	mem 17417MB
[2023-02-01 18:23:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][1150/1251]	eta 0:00:57 lr 0.000531	time 0.5519 (0.5706)	loss 3.5569 (3.1923)	grad_norm 1.4158 (1.5249)	mem 17417MB
[2023-02-01 18:23:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][1200/1251]	eta 0:00:29 lr 0.000531	time 0.5626 (0.5705)	loss 3.4212 (3.1941)	grad_norm 1.5343 (1.5247)	mem 17417MB
[2023-02-01 18:24:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [144/300][1250/1251]	eta 0:00:00 lr 0.000531	time 0.5564 (0.5706)	loss 2.7511 (3.1946)	grad_norm 1.6645 (1.5236)	mem 17417MB
[2023-02-01 18:24:15 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 144 training takes 0:11:53
[2023-02-01 18:24:15 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_144.pth saving......
[2023-02-01 18:24:17 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_144.pth saved !!!
[2023-02-01 18:24:18 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.852 (0.852)	Loss 0.8632 (0.8632)	Acc@1 79.199 (79.199)	Acc@5 95.508 (95.508)	Mem 17417MB
[2023-02-01 18:24:25 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.786 Acc@5 95.148
[2023-02-01 18:24:25 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.8%
[2023-02-01 18:24:27 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.284 (1.284)	Loss 0.7748 (0.7748)	Acc@1 83.105 (83.105)	Acc@5 95.801 (95.801)	Mem 17417MB
[2023-02-01 18:24:35 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.802 Acc@5 96.122
[2023-02-01 18:24:35 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.8%
[2023-02-01 18:24:35 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.80% at 144 epoch
[2023-02-01 18:24:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][0/1251]	eta 0:34:50 lr 0.000531	time 1.6708 (1.6708)	loss 2.1077 (2.1077)	grad_norm 1.5788 (1.5788)	mem 17417MB
[2023-02-01 18:25:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][50/1251]	eta 0:11:49 lr 0.000531	time 0.5716 (0.5908)	loss 3.2035 (3.1142)	grad_norm 1.6205 (1.5221)	mem 17417MB
[2023-02-01 18:25:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][100/1251]	eta 0:11:08 lr 0.000530	time 0.5557 (0.5811)	loss 2.5327 (3.1427)	grad_norm 1.5119 (nan)	mem 17417MB
[2023-02-01 18:26:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][150/1251]	eta 0:10:35 lr 0.000530	time 0.5584 (0.5770)	loss 2.6762 (3.2016)	grad_norm 1.4596 (nan)	mem 17417MB
[2023-02-01 18:26:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][200/1251]	eta 0:10:05 lr 0.000530	time 0.5562 (0.5758)	loss 2.6688 (3.2021)	grad_norm 1.4357 (nan)	mem 17417MB
[2023-02-01 18:26:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][250/1251]	eta 0:09:34 lr 0.000530	time 0.5626 (0.5743)	loss 2.5731 (3.2036)	grad_norm 1.7340 (nan)	mem 17417MB
[2023-02-01 18:27:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][300/1251]	eta 0:09:05 lr 0.000530	time 0.5555 (0.5735)	loss 3.4418 (3.2206)	grad_norm 1.3826 (nan)	mem 17417MB
[2023-02-01 18:27:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][350/1251]	eta 0:08:35 lr 0.000529	time 0.5518 (0.5721)	loss 3.3895 (3.2101)	grad_norm 1.4501 (nan)	mem 17417MB
[2023-02-01 18:28:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][400/1251]	eta 0:08:06 lr 0.000529	time 0.5661 (0.5719)	loss 3.4459 (3.2183)	grad_norm 1.3958 (nan)	mem 17417MB
[2023-02-01 18:28:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][450/1251]	eta 0:07:37 lr 0.000529	time 0.5539 (0.5713)	loss 2.7377 (3.2073)	grad_norm 1.7318 (nan)	mem 17417MB
[2023-02-01 18:29:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][500/1251]	eta 0:07:08 lr 0.000529	time 0.5586 (0.5712)	loss 2.8341 (3.1996)	grad_norm 1.4373 (nan)	mem 17417MB
[2023-02-01 18:29:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][550/1251]	eta 0:06:40 lr 0.000529	time 0.5644 (0.5709)	loss 3.5902 (3.2114)	grad_norm 1.3679 (nan)	mem 17417MB
[2023-02-01 18:30:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][600/1251]	eta 0:06:11 lr 0.000528	time 0.5565 (0.5707)	loss 3.6555 (3.2084)	grad_norm 1.4457 (nan)	mem 17417MB
[2023-02-01 18:30:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][650/1251]	eta 0:05:43 lr 0.000528	time 0.5574 (0.5707)	loss 3.9334 (3.2119)	grad_norm 1.5346 (nan)	mem 17417MB
[2023-02-01 18:31:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][700/1251]	eta 0:05:14 lr 0.000528	time 0.5693 (0.5705)	loss 3.5802 (3.2110)	grad_norm 1.5734 (nan)	mem 17417MB
[2023-02-01 18:31:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][750/1251]	eta 0:04:45 lr 0.000528	time 0.5562 (0.5701)	loss 3.5794 (3.2090)	grad_norm 1.6705 (nan)	mem 17417MB
[2023-02-01 18:32:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][800/1251]	eta 0:04:17 lr 0.000528	time 0.6167 (0.5701)	loss 2.1310 (3.2101)	grad_norm 1.4316 (nan)	mem 17417MB
[2023-02-01 18:32:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][850/1251]	eta 0:03:48 lr 0.000527	time 0.5602 (0.5700)	loss 3.0986 (3.2082)	grad_norm 1.4476 (nan)	mem 17417MB
[2023-02-01 18:33:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][900/1251]	eta 0:03:20 lr 0.000527	time 0.5622 (0.5701)	loss 3.2717 (3.2034)	grad_norm 1.4935 (nan)	mem 17417MB
[2023-02-01 18:33:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][950/1251]	eta 0:02:51 lr 0.000527	time 0.5540 (0.5700)	loss 3.2818 (3.2036)	grad_norm 1.4486 (nan)	mem 17417MB
[2023-02-01 18:34:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][1000/1251]	eta 0:02:23 lr 0.000527	time 0.5619 (0.5701)	loss 2.8093 (3.2023)	grad_norm 1.6717 (nan)	mem 17417MB
[2023-02-01 18:34:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][1050/1251]	eta 0:01:54 lr 0.000527	time 0.5562 (0.5700)	loss 3.5674 (3.1975)	grad_norm 1.6541 (nan)	mem 17417MB
[2023-02-01 18:35:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][1100/1251]	eta 0:01:26 lr 0.000526	time 0.5581 (0.5699)	loss 3.5526 (3.2007)	grad_norm 1.5098 (nan)	mem 17417MB
[2023-02-01 18:35:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][1150/1251]	eta 0:00:57 lr 0.000526	time 0.5562 (0.5698)	loss 3.3676 (3.2009)	grad_norm 1.4624 (nan)	mem 17417MB
[2023-02-01 18:35:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][1200/1251]	eta 0:00:29 lr 0.000526	time 0.5631 (0.5699)	loss 3.7090 (3.2079)	grad_norm 1.5594 (nan)	mem 17417MB
[2023-02-01 18:36:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [145/300][1250/1251]	eta 0:00:00 lr 0.000526	time 0.5555 (0.5698)	loss 3.4336 (3.2081)	grad_norm 1.6512 (nan)	mem 17417MB
[2023-02-01 18:36:28 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 145 training takes 0:11:52
[2023-02-01 18:36:28 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_145.pth saving......
[2023-02-01 18:36:30 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_145.pth saved !!!
[2023-02-01 18:36:31 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.858 (0.858)	Loss 0.8352 (0.8352)	Acc@1 80.859 (80.859)	Acc@5 94.629 (94.629)	Mem 17417MB
[2023-02-01 18:36:38 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.790 Acc@5 95.186
[2023-02-01 18:36:38 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.8%
[2023-02-01 18:36:40 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.291 (1.291)	Loss 0.7988 (0.7988)	Acc@1 80.762 (80.762)	Acc@5 95.898 (95.898)	Mem 17417MB
[2023-02-01 18:36:48 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.850 Acc@5 96.120
[2023-02-01 18:36:48 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.8%
[2023-02-01 18:36:48 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.85% at 145 epoch
[2023-02-01 18:36:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][0/1251]	eta 0:34:37 lr 0.000526	time 1.6605 (1.6605)	loss 3.5644 (3.5644)	grad_norm 1.5921 (1.5921)	mem 17417MB
[2023-02-01 18:37:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][50/1251]	eta 0:11:49 lr 0.000526	time 0.5572 (0.5906)	loss 3.6587 (3.1303)	grad_norm 1.4833 (1.5278)	mem 17417MB
[2023-02-01 18:37:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][100/1251]	eta 0:11:06 lr 0.000525	time 0.5599 (0.5791)	loss 2.1885 (3.1368)	grad_norm 1.4597 (1.5273)	mem 17417MB
[2023-02-01 18:38:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][150/1251]	eta 0:10:33 lr 0.000525	time 0.5619 (0.5758)	loss 2.6669 (3.1256)	grad_norm 1.4233 (1.5320)	mem 17417MB
[2023-02-01 18:38:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][200/1251]	eta 0:10:02 lr 0.000525	time 0.5621 (0.5735)	loss 2.1556 (3.1502)	grad_norm 1.6378 (nan)	mem 17417MB
[2023-02-01 18:39:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][250/1251]	eta 0:09:32 lr 0.000525	time 0.5600 (0.5720)	loss 3.1711 (3.1675)	grad_norm 1.4399 (nan)	mem 17417MB
[2023-02-01 18:39:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][300/1251]	eta 0:09:03 lr 0.000524	time 0.5564 (0.5716)	loss 2.5614 (3.1615)	grad_norm 1.4410 (nan)	mem 17417MB
[2023-02-01 18:40:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][350/1251]	eta 0:08:34 lr 0.000524	time 0.5606 (0.5706)	loss 2.1309 (3.1676)	grad_norm 1.5195 (nan)	mem 17417MB
[2023-02-01 18:40:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][400/1251]	eta 0:08:05 lr 0.000524	time 0.6196 (0.5701)	loss 4.0297 (3.1687)	grad_norm 1.6796 (nan)	mem 17417MB
[2023-02-01 18:41:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][450/1251]	eta 0:07:36 lr 0.000524	time 0.5544 (0.5698)	loss 2.7092 (3.1749)	grad_norm 1.4594 (nan)	mem 17417MB
[2023-02-01 18:41:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][500/1251]	eta 0:07:07 lr 0.000524	time 0.5743 (0.5692)	loss 2.0669 (3.1883)	grad_norm 1.4270 (nan)	mem 17417MB
[2023-02-01 18:42:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][550/1251]	eta 0:06:39 lr 0.000523	time 0.5612 (0.5693)	loss 2.7809 (3.1829)	grad_norm 1.6692 (nan)	mem 17417MB
[2023-02-01 18:42:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][600/1251]	eta 0:06:10 lr 0.000523	time 0.5536 (0.5691)	loss 3.8577 (3.1812)	grad_norm 1.4673 (nan)	mem 17417MB
[2023-02-01 18:42:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][650/1251]	eta 0:05:42 lr 0.000523	time 0.5495 (0.5692)	loss 3.6385 (3.1838)	grad_norm 1.4665 (nan)	mem 17417MB
[2023-02-01 18:43:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][700/1251]	eta 0:05:13 lr 0.000523	time 0.5545 (0.5690)	loss 2.2766 (3.1825)	grad_norm 1.6049 (nan)	mem 17417MB
[2023-02-01 18:43:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][750/1251]	eta 0:04:45 lr 0.000523	time 0.6232 (0.5690)	loss 3.2235 (3.1834)	grad_norm 1.3672 (nan)	mem 17417MB
[2023-02-01 18:44:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][800/1251]	eta 0:04:16 lr 0.000522	time 0.6369 (0.5688)	loss 3.6061 (3.1836)	grad_norm 1.5627 (nan)	mem 17417MB
[2023-02-01 18:44:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][850/1251]	eta 0:03:48 lr 0.000522	time 0.5541 (0.5688)	loss 2.8517 (3.1810)	grad_norm 1.6429 (nan)	mem 17417MB
[2023-02-01 18:45:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][900/1251]	eta 0:03:19 lr 0.000522	time 0.5554 (0.5687)	loss 2.7029 (3.1835)	grad_norm 1.4045 (nan)	mem 17417MB
[2023-02-01 18:45:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][950/1251]	eta 0:02:51 lr 0.000522	time 0.5623 (0.5687)	loss 2.1181 (3.1861)	grad_norm 1.8623 (nan)	mem 17417MB
[2023-02-01 18:46:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][1000/1251]	eta 0:02:22 lr 0.000522	time 0.5552 (0.5687)	loss 3.7721 (3.1873)	grad_norm 1.4329 (nan)	mem 17417MB
[2023-02-01 18:46:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][1050/1251]	eta 0:01:54 lr 0.000521	time 0.5592 (0.5687)	loss 3.5515 (3.1876)	grad_norm 1.6639 (nan)	mem 17417MB
[2023-02-01 18:47:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][1100/1251]	eta 0:01:25 lr 0.000521	time 0.6350 (0.5687)	loss 1.9589 (3.1877)	grad_norm 1.4741 (nan)	mem 17417MB
[2023-02-01 18:47:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][1150/1251]	eta 0:00:57 lr 0.000521	time 0.5533 (0.5686)	loss 3.1839 (3.1899)	grad_norm 1.4098 (nan)	mem 17417MB
[2023-02-01 18:48:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][1200/1251]	eta 0:00:29 lr 0.000521	time 0.5848 (0.5688)	loss 3.9653 (3.1891)	grad_norm 1.6346 (nan)	mem 17417MB
[2023-02-01 18:48:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [146/300][1250/1251]	eta 0:00:00 lr 0.000521	time 0.5531 (0.5687)	loss 3.3082 (3.1889)	grad_norm 1.3800 (nan)	mem 17417MB
[2023-02-01 18:48:39 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 146 training takes 0:11:51
[2023-02-01 18:48:39 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_146.pth saving......
[2023-02-01 18:48:41 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_146.pth saved !!!
[2023-02-01 18:48:42 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.900 (0.900)	Loss 0.9261 (0.9261)	Acc@1 78.906 (78.906)	Acc@5 94.531 (94.531)	Mem 17417MB
[2023-02-01 18:48:50 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.692 Acc@5 95.252
[2023-02-01 18:48:50 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.7%
[2023-02-01 18:48:52 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.308 (1.308)	Loss 0.8108 (0.8108)	Acc@1 82.324 (82.324)	Acc@5 95.410 (95.410)	Mem 17417MB
[2023-02-01 18:49:00 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.868 Acc@5 96.124
[2023-02-01 18:49:00 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.9%
[2023-02-01 18:49:00 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.87% at 146 epoch
[2023-02-01 18:49:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][0/1251]	eta 0:36:05 lr 0.000521	time 1.7308 (1.7308)	loss 3.1017 (3.1017)	grad_norm 1.4785 (1.4785)	mem 17417MB
[2023-02-01 18:49:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][50/1251]	eta 0:11:43 lr 0.000520	time 0.5579 (0.5862)	loss 2.6108 (3.1197)	grad_norm 1.2790 (1.4916)	mem 17417MB
[2023-02-01 18:49:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][100/1251]	eta 0:11:08 lr 0.000520	time 0.5505 (0.5811)	loss 3.6922 (3.1891)	grad_norm 1.5194 (1.5089)	mem 17417MB
[2023-02-01 18:50:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][150/1251]	eta 0:10:33 lr 0.000520	time 0.5578 (0.5757)	loss 3.2305 (3.1484)	grad_norm 1.3442 (1.5159)	mem 17417MB
[2023-02-01 18:50:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][200/1251]	eta 0:10:03 lr 0.000520	time 0.5540 (0.5738)	loss 2.8975 (3.1794)	grad_norm 1.4909 (1.5280)	mem 17417MB
[2023-02-01 18:51:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][250/1251]	eta 0:09:33 lr 0.000520	time 0.5602 (0.5730)	loss 3.0962 (3.1772)	grad_norm 1.4827 (1.5228)	mem 17417MB
[2023-02-01 18:51:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][300/1251]	eta 0:09:04 lr 0.000519	time 0.5504 (0.5721)	loss 3.0173 (3.1675)	grad_norm 1.5336 (1.5252)	mem 17417MB
[2023-02-01 18:52:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][350/1251]	eta 0:08:35 lr 0.000519	time 0.5508 (0.5717)	loss 3.0929 (3.1621)	grad_norm 1.6212 (1.5317)	mem 17417MB
[2023-02-01 18:52:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][400/1251]	eta 0:08:06 lr 0.000519	time 0.5534 (0.5714)	loss 1.9367 (3.1546)	grad_norm 1.4281 (1.5297)	mem 17417MB
[2023-02-01 18:53:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][450/1251]	eta 0:07:37 lr 0.000519	time 0.5556 (0.5707)	loss 3.4584 (3.1793)	grad_norm 1.3977 (1.5264)	mem 17417MB
[2023-02-01 18:53:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][500/1251]	eta 0:07:08 lr 0.000518	time 0.5537 (0.5705)	loss 2.9288 (3.1749)	grad_norm 1.6563 (1.5287)	mem 17417MB
[2023-02-01 18:54:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][550/1251]	eta 0:06:39 lr 0.000518	time 0.5512 (0.5704)	loss 3.7139 (3.1785)	grad_norm 1.5980 (1.5311)	mem 17417MB
[2023-02-01 18:54:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][600/1251]	eta 0:06:11 lr 0.000518	time 0.5514 (0.5702)	loss 2.2007 (3.1791)	grad_norm 1.5412 (1.5311)	mem 17417MB
[2023-02-01 18:55:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][650/1251]	eta 0:05:42 lr 0.000518	time 0.5549 (0.5702)	loss 2.5239 (3.1804)	grad_norm 1.6858 (1.5319)	mem 17417MB
[2023-02-01 18:55:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][700/1251]	eta 0:05:14 lr 0.000518	time 0.5576 (0.5701)	loss 3.5401 (3.1701)	grad_norm 1.3095 (1.5281)	mem 17417MB
[2023-02-01 18:56:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][750/1251]	eta 0:04:45 lr 0.000517	time 0.5520 (0.5699)	loss 2.9876 (3.1816)	grad_norm 1.4400 (1.5273)	mem 17417MB
[2023-02-01 18:56:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][800/1251]	eta 0:04:17 lr 0.000517	time 0.5540 (0.5700)	loss 3.7598 (3.1828)	grad_norm 1.4263 (1.5288)	mem 17417MB
[2023-02-01 18:57:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][850/1251]	eta 0:03:48 lr 0.000517	time 0.5687 (0.5698)	loss 3.6051 (3.1892)	grad_norm 1.3867 (1.5294)	mem 17417MB
[2023-02-01 18:57:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][900/1251]	eta 0:03:20 lr 0.000517	time 0.5590 (0.5699)	loss 3.8314 (3.1895)	grad_norm 1.9467 (1.5298)	mem 17417MB
[2023-02-01 18:58:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][950/1251]	eta 0:02:51 lr 0.000517	time 0.5542 (0.5699)	loss 2.3942 (3.1870)	grad_norm 1.4977 (1.5307)	mem 17417MB
[2023-02-01 18:58:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][1000/1251]	eta 0:02:23 lr 0.000516	time 0.6317 (0.5699)	loss 2.7209 (3.1824)	grad_norm 1.4218 (1.5314)	mem 17417MB
[2023-02-01 18:58:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][1050/1251]	eta 0:01:54 lr 0.000516	time 0.5558 (0.5700)	loss 3.2166 (3.1834)	grad_norm 1.5004 (1.5315)	mem 17417MB
[2023-02-01 18:59:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][1100/1251]	eta 0:01:26 lr 0.000516	time 0.5578 (0.5699)	loss 3.3634 (3.1818)	grad_norm 1.7117 (1.5305)	mem 17417MB
[2023-02-01 18:59:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][1150/1251]	eta 0:00:57 lr 0.000516	time 0.5551 (0.5700)	loss 3.2138 (3.1827)	grad_norm 1.4683 (1.5308)	mem 17417MB
[2023-02-01 19:00:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][1200/1251]	eta 0:00:29 lr 0.000516	time 0.5648 (0.5701)	loss 2.9031 (3.1850)	grad_norm 1.6097 (1.5311)	mem 17417MB
[2023-02-01 19:00:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [147/300][1250/1251]	eta 0:00:00 lr 0.000515	time 0.5549 (0.5699)	loss 3.3182 (3.1868)	grad_norm 1.4145 (1.5308)	mem 17417MB
[2023-02-01 19:00:53 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 147 training takes 0:11:53
[2023-02-01 19:00:53 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_147.pth saving......
[2023-02-01 19:00:54 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_147.pth saved !!!
[2023-02-01 19:00:55 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.847 (0.847)	Loss 0.8436 (0.8436)	Acc@1 80.664 (80.664)	Acc@5 94.531 (94.531)	Mem 17417MB
[2023-02-01 19:01:03 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.752 Acc@5 95.210
[2023-02-01 19:01:03 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.8%
[2023-02-01 19:01:05 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.297 (1.297)	Loss 0.8370 (0.8370)	Acc@1 79.590 (79.590)	Acc@5 95.801 (95.801)	Mem 17417MB
[2023-02-01 19:01:13 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.894 Acc@5 96.130
[2023-02-01 19:01:13 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.9%
[2023-02-01 19:01:13 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.89% at 147 epoch
[2023-02-01 19:01:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][0/1251]	eta 0:35:09 lr 0.000515	time 1.6861 (1.6861)	loss 3.2553 (3.2553)	grad_norm 1.4356 (1.4356)	mem 17417MB
[2023-02-01 19:01:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][50/1251]	eta 0:11:49 lr 0.000515	time 0.5506 (0.5904)	loss 3.1149 (3.2997)	grad_norm 1.4764 (1.5302)	mem 17417MB
[2023-02-01 19:02:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][100/1251]	eta 0:11:09 lr 0.000515	time 0.5583 (0.5821)	loss 2.2405 (3.2204)	grad_norm 1.4769 (1.5430)	mem 17417MB
[2023-02-01 19:02:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][150/1251]	eta 0:10:35 lr 0.000515	time 0.5549 (0.5772)	loss 2.1077 (3.1877)	grad_norm 1.5904 (1.5382)	mem 17417MB
[2023-02-01 19:03:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][200/1251]	eta 0:10:04 lr 0.000515	time 0.5607 (0.5751)	loss 3.4497 (3.1691)	grad_norm 1.5808 (1.5411)	mem 17417MB
[2023-02-01 19:03:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][250/1251]	eta 0:09:34 lr 0.000514	time 0.5654 (0.5739)	loss 4.0516 (3.1610)	grad_norm 1.5010 (1.5499)	mem 17417MB
[2023-02-01 19:04:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][300/1251]	eta 0:09:05 lr 0.000514	time 0.5523 (0.5733)	loss 3.4133 (3.1613)	grad_norm 1.5023 (1.5402)	mem 17417MB
[2023-02-01 19:04:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][350/1251]	eta 0:08:35 lr 0.000514	time 0.5539 (0.5725)	loss 3.4389 (3.1764)	grad_norm 1.5002 (1.5349)	mem 17417MB
[2023-02-01 19:05:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][400/1251]	eta 0:08:06 lr 0.000514	time 0.6295 (0.5720)	loss 3.7069 (3.1707)	grad_norm 1.8922 (1.5390)	mem 17417MB
[2023-02-01 19:05:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][450/1251]	eta 0:07:37 lr 0.000514	time 0.5552 (0.5714)	loss 3.5815 (3.1626)	grad_norm 1.8236 (1.5395)	mem 17417MB
[2023-02-01 19:05:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][500/1251]	eta 0:07:08 lr 0.000513	time 0.5802 (0.5710)	loss 3.3249 (3.1736)	grad_norm 1.5983 (1.5376)	mem 17417MB
[2023-02-01 19:06:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][550/1251]	eta 0:06:40 lr 0.000513	time 0.5651 (0.5710)	loss 2.2004 (3.1796)	grad_norm 1.2954 (1.5388)	mem 17417MB
[2023-02-01 19:06:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][600/1251]	eta 0:06:11 lr 0.000513	time 0.5580 (0.5707)	loss 3.6544 (3.1950)	grad_norm 1.5934 (1.5378)	mem 17417MB
[2023-02-01 19:07:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][650/1251]	eta 0:05:43 lr 0.000513	time 0.5483 (0.5709)	loss 3.9316 (3.1943)	grad_norm 1.7938 (1.5362)	mem 17417MB
[2023-02-01 19:07:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][700/1251]	eta 0:05:14 lr 0.000512	time 0.5576 (0.5706)	loss 3.3174 (3.1965)	grad_norm 1.6624 (1.5403)	mem 17417MB
[2023-02-01 19:08:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][750/1251]	eta 0:04:45 lr 0.000512	time 0.5524 (0.5706)	loss 3.6749 (3.1972)	grad_norm 1.3904 (1.5374)	mem 17417MB
[2023-02-01 19:08:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][800/1251]	eta 0:04:17 lr 0.000512	time 0.5590 (0.5706)	loss 3.6614 (3.1902)	grad_norm 1.4075 (1.5380)	mem 17417MB
[2023-02-01 19:09:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][850/1251]	eta 0:03:48 lr 0.000512	time 0.5596 (0.5704)	loss 3.3138 (3.1972)	grad_norm 1.7277 (1.5368)	mem 17417MB
[2023-02-01 19:09:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][900/1251]	eta 0:03:20 lr 0.000512	time 0.5571 (0.5704)	loss 3.0286 (3.1994)	grad_norm 1.6913 (1.5370)	mem 17417MB
[2023-02-01 19:10:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][950/1251]	eta 0:02:51 lr 0.000511	time 0.5558 (0.5703)	loss 3.0313 (3.1966)	grad_norm 1.7567 (1.5379)	mem 17417MB
[2023-02-01 19:10:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][1000/1251]	eta 0:02:23 lr 0.000511	time 0.6199 (0.5702)	loss 2.1378 (3.1999)	grad_norm 1.4358 (1.5391)	mem 17417MB
[2023-02-01 19:11:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][1050/1251]	eta 0:01:54 lr 0.000511	time 0.5690 (0.5702)	loss 3.5174 (3.2025)	grad_norm 1.6848 (1.5392)	mem 17417MB
[2023-02-01 19:11:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][1100/1251]	eta 0:01:26 lr 0.000511	time 0.5606 (0.5701)	loss 3.4599 (3.2017)	grad_norm 1.7874 (1.5395)	mem 17417MB
[2023-02-01 19:12:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][1150/1251]	eta 0:00:57 lr 0.000511	time 0.6616 (0.5702)	loss 2.9768 (3.1991)	grad_norm 1.5497 (1.5395)	mem 17417MB
[2023-02-01 19:12:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][1200/1251]	eta 0:00:29 lr 0.000510	time 0.6352 (0.5701)	loss 3.3881 (3.2029)	grad_norm 1.5660 (1.5406)	mem 17417MB
[2023-02-01 19:13:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [148/300][1250/1251]	eta 0:00:00 lr 0.000510	time 0.6266 (0.5699)	loss 3.8269 (3.2039)	grad_norm 1.5401 (1.5417)	mem 17417MB
[2023-02-01 19:13:06 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 148 training takes 0:11:53
[2023-02-01 19:13:06 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_148.pth saving......
[2023-02-01 19:13:08 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_148.pth saved !!!
[2023-02-01 19:13:09 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.917 (0.917)	Loss 0.8544 (0.8544)	Acc@1 80.273 (80.273)	Acc@5 94.824 (94.824)	Mem 17417MB
[2023-02-01 19:13:17 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.962 Acc@5 95.328
[2023-02-01 19:13:17 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.0%
[2023-02-01 19:13:18 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.251 (1.251)	Loss 0.7629 (0.7629)	Acc@1 82.617 (82.617)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-01 19:13:26 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.908 Acc@5 96.140
[2023-02-01 19:13:26 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.9%
[2023-02-01 19:13:26 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.91% at 148 epoch
[2023-02-01 19:13:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][0/1251]	eta 0:37:14 lr 0.000510	time 1.7864 (1.7864)	loss 3.6239 (3.6239)	grad_norm 1.7798 (1.7798)	mem 17417MB
[2023-02-01 19:13:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][50/1251]	eta 0:11:55 lr 0.000510	time 0.5553 (0.5954)	loss 3.3801 (3.1255)	grad_norm 1.4870 (1.5660)	mem 17417MB
[2023-02-01 19:14:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][100/1251]	eta 0:11:12 lr 0.000510	time 0.5645 (0.5840)	loss 3.3003 (3.1902)	grad_norm 1.4417 (1.5434)	mem 17417MB
[2023-02-01 19:14:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][150/1251]	eta 0:10:38 lr 0.000510	time 0.5581 (0.5801)	loss 2.7925 (3.1897)	grad_norm 1.4720 (1.5415)	mem 17417MB
[2023-02-01 19:15:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][200/1251]	eta 0:10:06 lr 0.000509	time 0.5534 (0.5770)	loss 3.1992 (3.1979)	grad_norm 1.3605 (1.5348)	mem 17417MB
[2023-02-01 19:15:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][250/1251]	eta 0:09:36 lr 0.000509	time 0.5551 (0.5759)	loss 3.4445 (3.2125)	grad_norm 1.4157 (1.5387)	mem 17417MB
[2023-02-01 19:16:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][300/1251]	eta 0:09:06 lr 0.000509	time 0.5483 (0.5751)	loss 2.9087 (3.2089)	grad_norm 1.7351 (1.5481)	mem 17417MB
[2023-02-01 19:16:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][350/1251]	eta 0:08:36 lr 0.000509	time 0.5576 (0.5737)	loss 3.7928 (3.2042)	grad_norm 1.5027 (1.5460)	mem 17417MB
[2023-02-01 19:17:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][400/1251]	eta 0:08:07 lr 0.000509	time 0.6301 (0.5734)	loss 3.6406 (3.2114)	grad_norm 1.8038 (1.5507)	mem 17417MB
[2023-02-01 19:17:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][450/1251]	eta 0:07:39 lr 0.000508	time 0.5532 (0.5731)	loss 2.2712 (3.2157)	grad_norm 1.5786 (1.5533)	mem 17417MB
[2023-02-01 19:18:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][500/1251]	eta 0:07:10 lr 0.000508	time 0.5560 (0.5727)	loss 3.8265 (3.2176)	grad_norm 1.6042 (1.5606)	mem 17417MB
[2023-02-01 19:18:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][550/1251]	eta 0:06:41 lr 0.000508	time 0.5562 (0.5730)	loss 3.4963 (3.2114)	grad_norm 1.5897 (1.5607)	mem 17417MB
[2023-02-01 19:19:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][600/1251]	eta 0:06:12 lr 0.000508	time 0.5584 (0.5726)	loss 3.2346 (3.2031)	grad_norm 1.4056 (1.5596)	mem 17417MB
[2023-02-01 19:19:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][650/1251]	eta 0:05:44 lr 0.000507	time 0.5699 (0.5726)	loss 2.2858 (3.2007)	grad_norm 1.5254 (1.5573)	mem 17417MB
[2023-02-01 19:20:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][700/1251]	eta 0:05:15 lr 0.000507	time 0.5597 (0.5722)	loss 2.1998 (3.1965)	grad_norm 1.3963 (nan)	mem 17417MB
[2023-02-01 19:20:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][750/1251]	eta 0:04:46 lr 0.000507	time 0.5571 (0.5721)	loss 3.8667 (3.1916)	grad_norm 1.6309 (nan)	mem 17417MB
[2023-02-01 19:21:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][800/1251]	eta 0:04:17 lr 0.000507	time 0.5580 (0.5720)	loss 2.9918 (3.1820)	grad_norm 1.6907 (nan)	mem 17417MB
[2023-02-01 19:21:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][850/1251]	eta 0:03:49 lr 0.000507	time 0.6454 (0.5721)	loss 2.0822 (3.1801)	grad_norm 1.5928 (nan)	mem 17417MB
[2023-02-01 19:22:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][900/1251]	eta 0:03:20 lr 0.000506	time 0.5589 (0.5718)	loss 3.8025 (3.1799)	grad_norm 1.4621 (nan)	mem 17417MB
[2023-02-01 19:22:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][950/1251]	eta 0:02:52 lr 0.000506	time 0.5626 (0.5719)	loss 3.1469 (3.1853)	grad_norm 1.4349 (nan)	mem 17417MB
[2023-02-01 19:22:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][1000/1251]	eta 0:02:23 lr 0.000506	time 0.5666 (0.5716)	loss 2.9713 (3.1861)	grad_norm 1.4997 (nan)	mem 17417MB
[2023-02-01 19:23:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][1050/1251]	eta 0:01:54 lr 0.000506	time 0.5669 (0.5717)	loss 3.7169 (3.1848)	grad_norm 1.3781 (nan)	mem 17417MB
[2023-02-01 19:23:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][1100/1251]	eta 0:01:26 lr 0.000506	time 0.5497 (0.5715)	loss 2.7153 (3.1829)	grad_norm 1.4666 (nan)	mem 17417MB
[2023-02-01 19:24:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][1150/1251]	eta 0:00:57 lr 0.000505	time 0.5623 (0.5714)	loss 3.9406 (3.1867)	grad_norm 1.5203 (nan)	mem 17417MB
[2023-02-01 19:24:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][1200/1251]	eta 0:00:29 lr 0.000505	time 0.5544 (0.5713)	loss 2.9507 (3.1820)	grad_norm 1.5530 (nan)	mem 17417MB
[2023-02-01 19:25:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [149/300][1250/1251]	eta 0:00:00 lr 0.000505	time 0.5538 (0.5712)	loss 3.4948 (3.1812)	grad_norm 1.5357 (nan)	mem 17417MB
[2023-02-01 19:25:21 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 149 training takes 0:11:54
[2023-02-01 19:25:21 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_149.pth saving......
[2023-02-01 19:25:23 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_149.pth saved !!!
[2023-02-01 19:25:24 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.869 (0.869)	Loss 0.8770 (0.8770)	Acc@1 79.297 (79.297)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-01 19:25:32 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.724 Acc@5 95.254
[2023-02-01 19:25:32 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.7%
[2023-02-01 19:25:33 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.290 (1.290)	Loss 0.7094 (0.7094)	Acc@1 83.887 (83.887)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-01 19:25:41 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.914 Acc@5 96.134
[2023-02-01 19:25:41 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.9%
[2023-02-01 19:25:41 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.91% at 149 epoch
[2023-02-01 19:25:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][0/1251]	eta 0:35:02 lr 0.000505	time 1.6803 (1.6803)	loss 3.5289 (3.5289)	grad_norm 1.4476 (1.4476)	mem 17417MB
[2023-02-01 19:26:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][50/1251]	eta 0:11:48 lr 0.000505	time 0.6329 (0.5900)	loss 3.8586 (3.2390)	grad_norm 1.5761 (1.5182)	mem 17417MB
[2023-02-01 19:26:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][100/1251]	eta 0:11:11 lr 0.000505	time 0.6519 (0.5832)	loss 2.2924 (3.1989)	grad_norm 1.4410 (1.5331)	mem 17417MB
[2023-02-01 19:27:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][150/1251]	eta 0:10:34 lr 0.000504	time 0.5592 (0.5767)	loss 2.8325 (3.1599)	grad_norm 1.6816 (1.5370)	mem 17417MB
[2023-02-01 19:27:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][200/1251]	eta 0:10:04 lr 0.000504	time 0.5511 (0.5751)	loss 2.5808 (3.1738)	grad_norm 1.7174 (1.5446)	mem 17417MB
[2023-02-01 19:28:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][250/1251]	eta 0:09:35 lr 0.000504	time 0.5559 (0.5746)	loss 2.9171 (3.1584)	grad_norm 1.5028 (1.5375)	mem 17417MB
[2023-02-01 19:28:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][300/1251]	eta 0:09:05 lr 0.000504	time 0.5595 (0.5735)	loss 3.6523 (3.1506)	grad_norm 1.5787 (1.5390)	mem 17417MB
[2023-02-01 19:29:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][350/1251]	eta 0:08:36 lr 0.000504	time 0.5659 (0.5731)	loss 3.5577 (3.1630)	grad_norm 1.7165 (1.5387)	mem 17417MB
[2023-02-01 19:29:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][400/1251]	eta 0:08:06 lr 0.000503	time 0.5639 (0.5722)	loss 2.9073 (3.1491)	grad_norm 1.4818 (1.5376)	mem 17417MB
[2023-02-01 19:29:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][450/1251]	eta 0:07:37 lr 0.000503	time 0.5561 (0.5717)	loss 3.0536 (3.1437)	grad_norm 1.5136 (1.5404)	mem 17417MB
[2023-02-01 19:30:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][500/1251]	eta 0:07:09 lr 0.000503	time 0.6404 (0.5719)	loss 3.7981 (3.1266)	grad_norm 1.5009 (1.5393)	mem 17417MB
[2023-02-01 19:30:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][550/1251]	eta 0:06:40 lr 0.000503	time 0.5645 (0.5713)	loss 3.3780 (3.1326)	grad_norm 1.5156 (1.5372)	mem 17417MB
[2023-02-01 19:31:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][600/1251]	eta 0:06:11 lr 0.000503	time 0.5572 (0.5712)	loss 1.9861 (3.1342)	grad_norm 1.4763 (1.5374)	mem 17417MB
[2023-02-01 19:31:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][650/1251]	eta 0:05:43 lr 0.000502	time 0.5579 (0.5712)	loss 3.8186 (3.1407)	grad_norm 1.6288 (1.5366)	mem 17417MB
[2023-02-01 19:32:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][700/1251]	eta 0:05:14 lr 0.000502	time 0.5576 (0.5708)	loss 2.5521 (3.1425)	grad_norm 1.5287 (1.5373)	mem 17417MB
[2023-02-01 19:32:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][750/1251]	eta 0:04:45 lr 0.000502	time 0.5583 (0.5708)	loss 3.3522 (3.1481)	grad_norm 1.3287 (1.5391)	mem 17417MB
[2023-02-01 19:33:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][800/1251]	eta 0:04:17 lr 0.000502	time 0.5600 (0.5707)	loss 2.4165 (3.1495)	grad_norm 1.5462 (1.5391)	mem 17417MB
[2023-02-01 19:33:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][850/1251]	eta 0:03:48 lr 0.000501	time 0.5631 (0.5706)	loss 2.7692 (3.1521)	grad_norm 1.6734 (1.5408)	mem 17417MB
[2023-02-01 19:34:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][900/1251]	eta 0:03:20 lr 0.000501	time 0.6475 (0.5708)	loss 3.4412 (3.1536)	grad_norm 1.3752 (1.5408)	mem 17417MB
[2023-02-01 19:34:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][950/1251]	eta 0:02:51 lr 0.000501	time 0.5540 (0.5705)	loss 2.9049 (3.1546)	grad_norm 1.5744 (1.5411)	mem 17417MB
[2023-02-01 19:35:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][1000/1251]	eta 0:02:23 lr 0.000501	time 0.5541 (0.5706)	loss 3.1023 (3.1547)	grad_norm 1.5833 (1.5419)	mem 17417MB
[2023-02-01 19:35:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][1050/1251]	eta 0:01:54 lr 0.000501	time 0.5836 (0.5707)	loss 2.0158 (3.1541)	grad_norm 1.4711 (1.5403)	mem 17417MB
[2023-02-01 19:36:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][1100/1251]	eta 0:01:26 lr 0.000500	time 0.6444 (0.5705)	loss 3.0120 (3.1622)	grad_norm 1.4811 (1.5417)	mem 17417MB
[2023-02-01 19:36:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][1150/1251]	eta 0:00:57 lr 0.000500	time 0.5491 (0.5703)	loss 2.8386 (3.1525)	grad_norm 1.6446 (1.5412)	mem 17417MB
[2023-02-01 19:37:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][1200/1251]	eta 0:00:29 lr 0.000500	time 0.6153 (0.5703)	loss 3.2598 (3.1574)	grad_norm 1.5138 (1.5402)	mem 17417MB
[2023-02-01 19:37:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [150/300][1250/1251]	eta 0:00:00 lr 0.000500	time 0.5510 (0.5703)	loss 3.5888 (3.1585)	grad_norm 1.3805 (1.5391)	mem 17417MB
[2023-02-01 19:37:35 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 150 training takes 0:11:53
[2023-02-01 19:37:35 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_150.pth saving......
[2023-02-01 19:37:36 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_150.pth saved !!!
[2023-02-01 19:37:37 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.951 (0.951)	Loss 0.8083 (0.8083)	Acc@1 80.859 (80.859)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-01 19:37:45 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.992 Acc@5 95.438
[2023-02-01 19:37:45 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.0%
[2023-02-01 19:37:47 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.244 (1.244)	Loss 0.7565 (0.7565)	Acc@1 82.129 (82.129)	Acc@5 96.582 (96.582)	Mem 17417MB
[2023-02-01 19:37:55 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.942 Acc@5 96.136
[2023-02-01 19:37:55 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 81.9%
[2023-02-01 19:37:55 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.94% at 150 epoch
[2023-02-01 19:37:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][0/1251]	eta 0:35:03 lr 0.000500	time 1.6811 (1.6811)	loss 3.2399 (3.2399)	grad_norm 1.4598 (1.4598)	mem 17417MB
[2023-02-01 19:38:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][50/1251]	eta 0:11:56 lr 0.000500	time 0.5709 (0.5966)	loss 3.2441 (3.1299)	grad_norm 1.7135 (1.5212)	mem 17417MB
[2023-02-01 19:38:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][100/1251]	eta 0:11:10 lr 0.000499	time 0.5520 (0.5822)	loss 2.9601 (3.1786)	grad_norm 2.0086 (1.5665)	mem 17417MB
[2023-02-01 19:39:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][150/1251]	eta 0:10:36 lr 0.000499	time 0.5596 (0.5785)	loss 3.2164 (3.2043)	grad_norm 1.5266 (1.5614)	mem 17417MB
[2023-02-01 19:39:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][200/1251]	eta 0:10:05 lr 0.000499	time 0.5574 (0.5761)	loss 2.5024 (3.1847)	grad_norm 1.5255 (1.5614)	mem 17417MB
[2023-02-01 19:40:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][250/1251]	eta 0:09:35 lr 0.000499	time 0.5532 (0.5752)	loss 3.8388 (3.2037)	grad_norm 1.5607 (1.5564)	mem 17417MB
[2023-02-01 19:40:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][300/1251]	eta 0:09:05 lr 0.000499	time 0.5589 (0.5738)	loss 3.6122 (3.1918)	grad_norm 1.4955 (1.5629)	mem 17417MB
[2023-02-01 19:41:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][350/1251]	eta 0:08:37 lr 0.000498	time 0.5604 (0.5740)	loss 3.3672 (3.1899)	grad_norm 1.5650 (1.5671)	mem 17417MB
[2023-02-01 19:41:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][400/1251]	eta 0:08:07 lr 0.000498	time 0.5727 (0.5726)	loss 2.2465 (3.1998)	grad_norm 1.6837 (1.5663)	mem 17417MB
[2023-02-01 19:42:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][450/1251]	eta 0:07:38 lr 0.000498	time 0.6421 (0.5727)	loss 3.5223 (3.1910)	grad_norm 1.4668 (1.5652)	mem 17417MB
[2023-02-01 19:42:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][500/1251]	eta 0:07:09 lr 0.000498	time 0.5588 (0.5719)	loss 3.3782 (3.1906)	grad_norm 1.4145 (1.5638)	mem 17417MB
[2023-02-01 19:43:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][550/1251]	eta 0:06:40 lr 0.000498	time 0.5631 (0.5717)	loss 3.8703 (3.2017)	grad_norm 1.9700 (1.5669)	mem 17417MB
[2023-02-01 19:43:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][600/1251]	eta 0:06:12 lr 0.000497	time 0.5642 (0.5716)	loss 2.8831 (3.1960)	grad_norm 1.4561 (nan)	mem 17417MB
[2023-02-01 19:44:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][650/1251]	eta 0:05:43 lr 0.000497	time 0.5607 (0.5714)	loss 3.4523 (3.1934)	grad_norm 1.4552 (nan)	mem 17417MB
[2023-02-01 19:44:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][700/1251]	eta 0:05:14 lr 0.000497	time 0.5542 (0.5711)	loss 2.8520 (3.1881)	grad_norm 1.4827 (nan)	mem 17417MB
[2023-02-01 19:45:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][750/1251]	eta 0:04:46 lr 0.000497	time 0.5551 (0.5712)	loss 3.1465 (3.1923)	grad_norm 1.6534 (nan)	mem 17417MB
[2023-02-01 19:45:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][800/1251]	eta 0:04:17 lr 0.000497	time 0.5607 (0.5707)	loss 3.2248 (3.1931)	grad_norm 1.5692 (nan)	mem 17417MB
[2023-02-01 19:46:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][850/1251]	eta 0:03:48 lr 0.000496	time 0.5553 (0.5707)	loss 2.7574 (3.1923)	grad_norm 1.5845 (nan)	mem 17417MB
[2023-02-01 19:46:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][900/1251]	eta 0:03:20 lr 0.000496	time 0.6296 (0.5706)	loss 3.3494 (3.2002)	grad_norm 1.6822 (nan)	mem 17417MB
[2023-02-01 19:46:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][950/1251]	eta 0:02:51 lr 0.000496	time 0.5554 (0.5706)	loss 3.0857 (3.1983)	grad_norm 1.5248 (nan)	mem 17417MB
[2023-02-01 19:47:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][1000/1251]	eta 0:02:23 lr 0.000496	time 0.5557 (0.5706)	loss 3.4790 (3.1967)	grad_norm 1.4450 (nan)	mem 17417MB
[2023-02-01 19:47:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][1050/1251]	eta 0:01:54 lr 0.000495	time 0.5650 (0.5705)	loss 3.1044 (3.2020)	grad_norm 1.4667 (nan)	mem 17417MB
[2023-02-01 19:48:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][1100/1251]	eta 0:01:26 lr 0.000495	time 0.5564 (0.5705)	loss 3.0484 (3.2044)	grad_norm 1.7234 (nan)	mem 17417MB
[2023-02-01 19:48:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][1150/1251]	eta 0:00:57 lr 0.000495	time 0.5632 (0.5705)	loss 3.2969 (3.2007)	grad_norm 1.5414 (nan)	mem 17417MB
[2023-02-01 19:49:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][1200/1251]	eta 0:00:29 lr 0.000495	time 0.5591 (0.5705)	loss 2.0774 (3.2052)	grad_norm 1.4142 (nan)	mem 17417MB
[2023-02-01 19:49:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [151/300][1250/1251]	eta 0:00:00 lr 0.000495	time 0.5505 (0.5705)	loss 3.4625 (3.2054)	grad_norm 1.6283 (nan)	mem 17417MB
[2023-02-01 19:49:48 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 151 training takes 0:11:53
[2023-02-01 19:49:49 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_151.pth saving......
[2023-02-01 19:49:50 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_151.pth saved !!!
[2023-02-01 19:49:51 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.901 (0.901)	Loss 0.8346 (0.8346)	Acc@1 80.371 (80.371)	Acc@5 95.410 (95.410)	Mem 17417MB
[2023-02-01 19:49:59 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 79.868 Acc@5 95.268
[2023-02-01 19:49:59 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 79.9%
[2023-02-01 19:50:00 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.289 (1.289)	Loss 0.8293 (0.8293)	Acc@1 81.445 (81.445)	Acc@5 94.629 (94.629)	Mem 17417MB
[2023-02-01 19:50:08 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.960 Acc@5 96.166
[2023-02-01 19:50:08 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.0%
[2023-02-01 19:50:08 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 81.96% at 151 epoch
[2023-02-01 19:50:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][0/1251]	eta 0:37:23 lr 0.000495	time 1.7933 (1.7933)	loss 3.7680 (3.7680)	grad_norm 1.5439 (1.5439)	mem 17417MB
[2023-02-01 19:50:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][50/1251]	eta 0:11:54 lr 0.000494	time 0.5583 (0.5946)	loss 2.6824 (3.1700)	grad_norm 1.5788 (1.5701)	mem 17417MB
[2023-02-01 19:51:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][100/1251]	eta 0:11:10 lr 0.000494	time 0.7176 (0.5825)	loss 3.7427 (3.1620)	grad_norm 1.6315 (1.5695)	mem 17417MB
[2023-02-01 19:51:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][150/1251]	eta 0:10:35 lr 0.000494	time 0.5564 (0.5776)	loss 3.5528 (3.1647)	grad_norm 1.9937 (1.5986)	mem 17417MB
[2023-02-01 19:52:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][200/1251]	eta 0:10:05 lr 0.000494	time 0.6287 (0.5760)	loss 2.0790 (3.1683)	grad_norm 1.3565 (1.5868)	mem 17417MB
[2023-02-01 19:52:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][250/1251]	eta 0:09:35 lr 0.000494	time 0.5600 (0.5748)	loss 3.6762 (3.1596)	grad_norm 1.3969 (1.5773)	mem 17417MB
[2023-02-01 19:53:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][300/1251]	eta 0:09:05 lr 0.000493	time 0.5564 (0.5738)	loss 2.5641 (3.1787)	grad_norm 1.6845 (1.5708)	mem 17417MB
[2023-02-01 19:53:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][350/1251]	eta 0:08:36 lr 0.000493	time 0.5634 (0.5729)	loss 2.8982 (3.1827)	grad_norm 1.7064 (1.5682)	mem 17417MB
[2023-02-01 19:53:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][400/1251]	eta 0:08:06 lr 0.000493	time 0.5559 (0.5721)	loss 3.3846 (3.1714)	grad_norm 1.7905 (1.5693)	mem 17417MB
[2023-02-01 19:54:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][450/1251]	eta 0:07:38 lr 0.000493	time 0.5539 (0.5719)	loss 2.9192 (3.1636)	grad_norm 1.4672 (1.5730)	mem 17417MB
[2023-02-01 19:54:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][500/1251]	eta 0:07:09 lr 0.000493	time 0.6145 (0.5718)	loss 3.5921 (3.1682)	grad_norm 1.5371 (1.5693)	mem 17417MB
[2023-02-01 19:55:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][550/1251]	eta 0:06:40 lr 0.000492	time 0.5583 (0.5715)	loss 3.1166 (3.1619)	grad_norm 1.8344 (1.5693)	mem 17417MB
[2023-02-01 19:55:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][600/1251]	eta 0:06:12 lr 0.000492	time 0.6237 (0.5715)	loss 3.5446 (3.1523)	grad_norm 1.6550 (1.5707)	mem 17417MB
[2023-02-01 19:56:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][650/1251]	eta 0:05:43 lr 0.000492	time 0.5537 (0.5713)	loss 2.6963 (3.1561)	grad_norm 1.5750 (1.5672)	mem 17417MB
[2023-02-01 19:56:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][700/1251]	eta 0:05:14 lr 0.000492	time 0.5520 (0.5712)	loss 2.2826 (3.1607)	grad_norm 1.7385 (1.5666)	mem 17417MB
[2023-02-01 19:57:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][750/1251]	eta 0:04:46 lr 0.000492	time 0.5586 (0.5711)	loss 3.4045 (3.1623)	grad_norm 1.6800 (nan)	mem 17417MB
[2023-02-01 19:57:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][800/1251]	eta 0:04:17 lr 0.000491	time 0.6554 (0.5709)	loss 3.2665 (3.1632)	grad_norm 1.5576 (nan)	mem 17417MB
[2023-02-01 19:58:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][850/1251]	eta 0:03:48 lr 0.000491	time 0.5593 (0.5710)	loss 3.0044 (3.1709)	grad_norm 1.5458 (nan)	mem 17417MB
[2023-02-01 19:58:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][900/1251]	eta 0:03:20 lr 0.000491	time 0.6172 (0.5708)	loss 3.1887 (3.1774)	grad_norm 1.6708 (nan)	mem 17417MB
[2023-02-01 19:59:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][950/1251]	eta 0:02:51 lr 0.000491	time 0.5558 (0.5707)	loss 2.8871 (3.1799)	grad_norm 1.5845 (nan)	mem 17417MB
[2023-02-01 19:59:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][1000/1251]	eta 0:02:23 lr 0.000490	time 0.6204 (0.5709)	loss 3.1599 (3.1815)	grad_norm 1.7113 (nan)	mem 17417MB
[2023-02-01 20:00:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][1050/1251]	eta 0:01:54 lr 0.000490	time 0.5577 (0.5708)	loss 3.2437 (3.1720)	grad_norm 1.5955 (nan)	mem 17417MB
[2023-02-01 20:00:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][1100/1251]	eta 0:01:26 lr 0.000490	time 0.5544 (0.5707)	loss 3.8601 (3.1741)	grad_norm 1.5533 (nan)	mem 17417MB
[2023-02-01 20:01:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][1150/1251]	eta 0:00:57 lr 0.000490	time 0.6159 (0.5706)	loss 2.9225 (3.1766)	grad_norm 1.3861 (nan)	mem 17417MB
[2023-02-01 20:01:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][1200/1251]	eta 0:00:29 lr 0.000490	time 0.5484 (0.5705)	loss 3.9424 (3.1815)	grad_norm 1.6500 (nan)	mem 17417MB
[2023-02-01 20:02:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [152/300][1250/1251]	eta 0:00:00 lr 0.000489	time 0.5493 (0.5705)	loss 2.9805 (3.1804)	grad_norm 1.5931 (nan)	mem 17417MB
[2023-02-01 20:02:02 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 152 training takes 0:11:53
[2023-02-01 20:02:02 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_152.pth saving......
[2023-02-01 20:02:04 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_152.pth saved !!!
[2023-02-01 20:02:05 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.857 (0.857)	Loss 0.8722 (0.8722)	Acc@1 78.516 (78.516)	Acc@5 94.824 (94.824)	Mem 17417MB
[2023-02-01 20:02:13 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.158 Acc@5 95.544
[2023-02-01 20:02:13 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.2%
[2023-02-01 20:02:14 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.384 (1.384)	Loss 0.7600 (0.7600)	Acc@1 81.348 (81.348)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-01 20:02:22 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.012 Acc@5 96.188
[2023-02-01 20:02:22 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.0%
[2023-02-01 20:02:22 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.01% at 152 epoch
[2023-02-01 20:02:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][0/1251]	eta 0:34:49 lr 0.000489	time 1.6706 (1.6706)	loss 2.6526 (2.6526)	grad_norm 1.4820 (1.4820)	mem 17417MB
[2023-02-01 20:02:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][50/1251]	eta 0:11:51 lr 0.000489	time 0.6427 (0.5927)	loss 3.6969 (2.9793)	grad_norm 1.6885 (1.5329)	mem 17417MB
[2023-02-01 20:03:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][100/1251]	eta 0:11:08 lr 0.000489	time 0.5622 (0.5810)	loss 2.2346 (3.0571)	grad_norm 1.4657 (1.5575)	mem 17417MB
[2023-02-01 20:03:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][150/1251]	eta 0:10:35 lr 0.000489	time 0.6706 (0.5773)	loss 3.6536 (3.0924)	grad_norm 1.6717 (1.5519)	mem 17417MB
[2023-02-01 20:04:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][200/1251]	eta 0:10:05 lr 0.000489	time 0.5537 (0.5757)	loss 2.9012 (3.0978)	grad_norm 1.3717 (1.5474)	mem 17417MB
[2023-02-01 20:04:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][250/1251]	eta 0:09:34 lr 0.000488	time 0.6281 (0.5739)	loss 3.0242 (3.1195)	grad_norm 1.3995 (1.5541)	mem 17417MB
[2023-02-01 20:05:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][300/1251]	eta 0:09:05 lr 0.000488	time 0.5531 (0.5736)	loss 3.2285 (3.1282)	grad_norm 1.6417 (1.5610)	mem 17417MB
[2023-02-01 20:05:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][350/1251]	eta 0:08:35 lr 0.000488	time 0.5594 (0.5726)	loss 3.2249 (3.1286)	grad_norm 1.8817 (1.5594)	mem 17417MB
[2023-02-01 20:06:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][400/1251]	eta 0:08:07 lr 0.000488	time 0.5565 (0.5723)	loss 3.3970 (3.1365)	grad_norm 1.5779 (1.5567)	mem 17417MB
[2023-02-01 20:06:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][450/1251]	eta 0:07:38 lr 0.000488	time 0.6257 (0.5720)	loss 3.9922 (3.1432)	grad_norm 1.6181 (1.5611)	mem 17417MB
[2023-02-01 20:07:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][500/1251]	eta 0:07:09 lr 0.000487	time 0.5571 (0.5716)	loss 2.9563 (3.1410)	grad_norm 1.5152 (1.5605)	mem 17417MB
[2023-02-01 20:07:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][550/1251]	eta 0:06:40 lr 0.000487	time 0.5636 (0.5711)	loss 3.3664 (3.1439)	grad_norm 1.6125 (1.5566)	mem 17417MB
[2023-02-01 20:08:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][600/1251]	eta 0:06:11 lr 0.000487	time 0.5587 (0.5712)	loss 2.6046 (3.1535)	grad_norm 1.5636 (1.5607)	mem 17417MB
[2023-02-01 20:08:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][650/1251]	eta 0:05:42 lr 0.000487	time 0.5611 (0.5706)	loss 3.4054 (3.1544)	grad_norm 1.4337 (1.5579)	mem 17417MB
[2023-02-01 20:09:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][700/1251]	eta 0:05:14 lr 0.000487	time 0.5589 (0.5710)	loss 2.8798 (3.1513)	grad_norm 1.5639 (1.5611)	mem 17417MB
[2023-02-01 20:09:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][750/1251]	eta 0:04:45 lr 0.000486	time 0.5567 (0.5707)	loss 3.0258 (3.1587)	grad_norm 1.5547 (1.5633)	mem 17417MB
[2023-02-01 20:09:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][800/1251]	eta 0:04:17 lr 0.000486	time 0.5547 (0.5705)	loss 3.4572 (3.1562)	grad_norm 1.7136 (1.5672)	mem 17417MB
[2023-02-01 20:10:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][850/1251]	eta 0:03:48 lr 0.000486	time 0.6186 (0.5704)	loss 3.0540 (3.1566)	grad_norm 1.9667 (1.5679)	mem 17417MB
[2023-02-01 20:10:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][900/1251]	eta 0:03:20 lr 0.000486	time 0.5639 (0.5702)	loss 3.5040 (3.1496)	grad_norm 1.6688 (1.5699)	mem 17417MB
[2023-02-01 20:11:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][950/1251]	eta 0:02:51 lr 0.000486	time 0.5651 (0.5701)	loss 3.4551 (3.1561)	grad_norm 1.5451 (1.5703)	mem 17417MB
[2023-02-01 20:11:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][1000/1251]	eta 0:02:23 lr 0.000485	time 0.5549 (0.5703)	loss 3.1665 (3.1561)	grad_norm 1.4629 (1.5722)	mem 17417MB
[2023-02-01 20:12:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][1050/1251]	eta 0:01:54 lr 0.000485	time 0.5684 (0.5701)	loss 3.7794 (3.1606)	grad_norm 1.7437 (1.5735)	mem 17417MB
[2023-02-01 20:12:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][1100/1251]	eta 0:01:26 lr 0.000485	time 0.6278 (0.5706)	loss 3.2886 (3.1613)	grad_norm 1.4758 (1.5732)	mem 17417MB
[2023-02-01 20:13:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][1150/1251]	eta 0:00:57 lr 0.000485	time 0.5600 (0.5706)	loss 3.9052 (3.1599)	grad_norm 1.5501 (1.5727)	mem 17417MB
[2023-02-01 20:13:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][1200/1251]	eta 0:00:29 lr 0.000484	time 0.5563 (0.5706)	loss 2.8931 (3.1521)	grad_norm 1.7674 (1.5719)	mem 17417MB
[2023-02-01 20:14:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [153/300][1250/1251]	eta 0:00:00 lr 0.000484	time 0.5482 (0.5706)	loss 2.9726 (3.1577)	grad_norm 1.5620 (1.5722)	mem 17417MB
[2023-02-01 20:14:16 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 153 training takes 0:11:53
[2023-02-01 20:14:16 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_153.pth saving......
[2023-02-01 20:14:18 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_153.pth saved !!!
[2023-02-01 20:14:19 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.917 (0.917)	Loss 0.7851 (0.7851)	Acc@1 81.836 (81.836)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-01 20:14:27 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.142 Acc@5 95.312
[2023-02-01 20:14:27 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.1%
[2023-02-01 20:14:28 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.238 (1.238)	Loss 0.9068 (0.9068)	Acc@1 78.613 (78.613)	Acc@5 95.215 (95.215)	Mem 17417MB
[2023-02-01 20:14:36 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.020 Acc@5 96.182
[2023-02-01 20:14:36 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.0%
[2023-02-01 20:14:36 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.02% at 153 epoch
[2023-02-01 20:14:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][0/1251]	eta 0:35:44 lr 0.000484	time 1.7140 (1.7140)	loss 2.9021 (2.9021)	grad_norm 1.5345 (1.5345)	mem 17417MB
[2023-02-01 20:15:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][50/1251]	eta 0:11:51 lr 0.000484	time 0.5557 (0.5920)	loss 3.5825 (3.0026)	grad_norm 1.4645 (1.6015)	mem 17417MB
[2023-02-01 20:15:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][100/1251]	eta 0:11:10 lr 0.000484	time 0.6104 (0.5823)	loss 3.9569 (3.1049)	grad_norm 1.5632 (1.5786)	mem 17417MB
[2023-02-01 20:16:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][150/1251]	eta 0:10:36 lr 0.000484	time 0.5585 (0.5782)	loss 3.4660 (3.1399)	grad_norm 1.6174 (1.5805)	mem 17417MB
[2023-02-01 20:16:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][200/1251]	eta 0:10:05 lr 0.000483	time 0.5582 (0.5758)	loss 3.3565 (3.1487)	grad_norm 1.5869 (1.5782)	mem 17417MB
[2023-02-01 20:17:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][250/1251]	eta 0:09:34 lr 0.000483	time 0.5556 (0.5743)	loss 3.6643 (3.1394)	grad_norm 1.4820 (1.5870)	mem 17417MB
[2023-02-01 20:17:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][300/1251]	eta 0:09:05 lr 0.000483	time 0.5528 (0.5735)	loss 3.0562 (3.1261)	grad_norm 1.6058 (1.5904)	mem 17417MB
[2023-02-01 20:17:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][350/1251]	eta 0:08:36 lr 0.000483	time 0.5549 (0.5728)	loss 3.3253 (3.1176)	grad_norm 1.4274 (1.5897)	mem 17417MB
[2023-02-01 20:18:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][400/1251]	eta 0:08:07 lr 0.000483	time 0.5607 (0.5728)	loss 3.3444 (3.1334)	grad_norm 1.6066 (1.5871)	mem 17417MB
[2023-02-01 20:18:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][450/1251]	eta 0:07:38 lr 0.000482	time 0.6286 (0.5725)	loss 3.8417 (3.1359)	grad_norm 1.5735 (1.5839)	mem 17417MB
[2023-02-01 20:19:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][500/1251]	eta 0:07:09 lr 0.000482	time 0.6087 (0.5723)	loss 3.2539 (3.1276)	grad_norm 1.8295 (1.5838)	mem 17417MB
[2023-02-01 20:19:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][550/1251]	eta 0:06:40 lr 0.000482	time 0.5515 (0.5720)	loss 3.1601 (3.1276)	grad_norm 1.7072 (1.5800)	mem 17417MB
[2023-02-01 20:20:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][600/1251]	eta 0:06:12 lr 0.000482	time 0.5577 (0.5718)	loss 2.6792 (3.1278)	grad_norm 1.6476 (1.5820)	mem 17417MB
[2023-02-01 20:20:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][650/1251]	eta 0:05:43 lr 0.000482	time 0.5587 (0.5716)	loss 3.0275 (3.1377)	grad_norm 1.5792 (1.5811)	mem 17417MB
[2023-02-01 20:21:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][700/1251]	eta 0:05:14 lr 0.000481	time 0.5547 (0.5716)	loss 3.3546 (3.1426)	grad_norm 1.5161 (1.5767)	mem 17417MB
[2023-02-01 20:21:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][750/1251]	eta 0:04:46 lr 0.000481	time 0.5511 (0.5712)	loss 3.4021 (3.1471)	grad_norm 1.8138 (1.5744)	mem 17417MB
[2023-02-01 20:22:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][800/1251]	eta 0:04:17 lr 0.000481	time 0.6235 (0.5714)	loss 3.9429 (3.1440)	grad_norm 1.7455 (1.5745)	mem 17417MB
[2023-02-01 20:22:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][850/1251]	eta 0:03:48 lr 0.000481	time 0.5501 (0.5710)	loss 3.7733 (3.1437)	grad_norm 1.4921 (1.5738)	mem 17417MB
[2023-02-01 20:23:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][900/1251]	eta 0:03:20 lr 0.000481	time 0.6163 (0.5712)	loss 2.3078 (3.1356)	grad_norm 1.4266 (1.5755)	mem 17417MB
[2023-02-01 20:23:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][950/1251]	eta 0:02:51 lr 0.000480	time 0.5603 (0.5711)	loss 3.8187 (3.1347)	grad_norm 1.4680 (1.5742)	mem 17417MB
[2023-02-01 20:24:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][1000/1251]	eta 0:02:23 lr 0.000480	time 0.5525 (0.5709)	loss 4.2905 (3.1335)	grad_norm 1.5839 (1.5737)	mem 17417MB
[2023-02-01 20:24:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][1050/1251]	eta 0:01:54 lr 0.000480	time 0.5603 (0.5707)	loss 3.4048 (3.1357)	grad_norm 1.4775 (1.5745)	mem 17417MB
[2023-02-01 20:25:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][1100/1251]	eta 0:01:26 lr 0.000480	time 0.6285 (0.5708)	loss 3.7729 (3.1388)	grad_norm 1.6380 (1.5746)	mem 17417MB
[2023-02-01 20:25:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][1150/1251]	eta 0:00:57 lr 0.000480	time 0.5571 (0.5705)	loss 3.0231 (3.1413)	grad_norm 1.6679 (1.5741)	mem 17417MB
[2023-02-01 20:26:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][1200/1251]	eta 0:00:29 lr 0.000479	time 0.5593 (0.5706)	loss 2.6806 (3.1426)	grad_norm 1.5080 (1.5751)	mem 17417MB
[2023-02-01 20:26:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [154/300][1250/1251]	eta 0:00:00 lr 0.000479	time 0.6128 (0.5707)	loss 2.5104 (3.1452)	grad_norm 1.4497 (1.5766)	mem 17417MB
[2023-02-01 20:26:30 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 154 training takes 0:11:53
[2023-02-01 20:26:30 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_154.pth saving......
[2023-02-01 20:26:32 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_154.pth saved !!!
[2023-02-01 20:26:33 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.902 (0.902)	Loss 0.9422 (0.9422)	Acc@1 77.051 (77.051)	Acc@5 93.945 (93.945)	Mem 17417MB
[2023-02-01 20:26:41 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.068 Acc@5 95.452
[2023-02-01 20:26:41 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.1%
[2023-02-01 20:26:42 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.177 (1.177)	Loss 0.7659 (0.7659)	Acc@1 82.715 (82.715)	Acc@5 95.605 (95.605)	Mem 17417MB
[2023-02-01 20:26:50 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.054 Acc@5 96.170
[2023-02-01 20:26:50 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.1%
[2023-02-01 20:26:50 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.05% at 154 epoch
[2023-02-01 20:26:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][0/1251]	eta 0:35:10 lr 0.000479	time 1.6872 (1.6872)	loss 3.2864 (3.2864)	grad_norm 1.4123 (1.4123)	mem 17417MB
[2023-02-01 20:27:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][50/1251]	eta 0:11:48 lr 0.000479	time 0.5587 (0.5900)	loss 4.0976 (3.2106)	grad_norm 1.4616 (1.6131)	mem 17417MB
[2023-02-01 20:27:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][100/1251]	eta 0:11:09 lr 0.000479	time 0.5552 (0.5820)	loss 3.2230 (3.1360)	grad_norm 1.5658 (1.6176)	mem 17417MB
[2023-02-01 20:28:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][150/1251]	eta 0:10:35 lr 0.000478	time 0.5564 (0.5772)	loss 3.3128 (3.1567)	grad_norm 1.5635 (1.6076)	mem 17417MB
[2023-02-01 20:28:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][200/1251]	eta 0:10:04 lr 0.000478	time 0.5554 (0.5756)	loss 3.3031 (3.1523)	grad_norm 1.5827 (1.5904)	mem 17417MB
[2023-02-01 20:29:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][250/1251]	eta 0:09:34 lr 0.000478	time 0.6221 (0.5739)	loss 2.2356 (3.1390)	grad_norm 1.5652 (1.5972)	mem 17417MB
[2023-02-01 20:29:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][300/1251]	eta 0:09:05 lr 0.000478	time 0.5613 (0.5731)	loss 2.8032 (3.1431)	grad_norm 1.4024 (1.5950)	mem 17417MB
[2023-02-01 20:30:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][350/1251]	eta 0:08:35 lr 0.000478	time 0.5634 (0.5721)	loss 2.8807 (3.1408)	grad_norm 1.4448 (1.5900)	mem 17417MB
[2023-02-01 20:30:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][400/1251]	eta 0:08:06 lr 0.000477	time 0.5522 (0.5720)	loss 3.2913 (3.1372)	grad_norm 1.7413 (1.5881)	mem 17417MB
[2023-02-01 20:31:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][450/1251]	eta 0:07:37 lr 0.000477	time 0.6276 (0.5715)	loss 3.4922 (3.1314)	grad_norm 1.5649 (1.5841)	mem 17417MB
[2023-02-01 20:31:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][500/1251]	eta 0:07:08 lr 0.000477	time 0.5540 (0.5712)	loss 2.6534 (3.1380)	grad_norm 1.4971 (1.5812)	mem 17417MB
[2023-02-01 20:32:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][550/1251]	eta 0:06:40 lr 0.000477	time 0.5671 (0.5709)	loss 2.7142 (3.1320)	grad_norm 1.5396 (1.5850)	mem 17417MB
[2023-02-01 20:32:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][600/1251]	eta 0:06:11 lr 0.000477	time 0.5670 (0.5706)	loss 3.0767 (3.1386)	grad_norm 1.6589 (1.5840)	mem 17417MB
[2023-02-01 20:33:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][650/1251]	eta 0:05:42 lr 0.000476	time 0.5504 (0.5706)	loss 3.1355 (3.1396)	grad_norm 1.6192 (1.5788)	mem 17417MB
[2023-02-01 20:33:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][700/1251]	eta 0:05:14 lr 0.000476	time 0.5658 (0.5704)	loss 2.9419 (3.1452)	grad_norm 1.4657 (1.5785)	mem 17417MB
[2023-02-01 20:33:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][750/1251]	eta 0:04:45 lr 0.000476	time 0.5619 (0.5703)	loss 2.2513 (3.1556)	grad_norm 1.5375 (1.5759)	mem 17417MB
[2023-02-01 20:34:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][800/1251]	eta 0:04:17 lr 0.000476	time 0.5654 (0.5701)	loss 2.7448 (3.1549)	grad_norm 1.5451 (1.5757)	mem 17417MB
[2023-02-01 20:34:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][850/1251]	eta 0:03:48 lr 0.000476	time 0.5569 (0.5699)	loss 3.3617 (3.1583)	grad_norm 1.7456 (1.5775)	mem 17417MB
[2023-02-01 20:35:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][900/1251]	eta 0:03:20 lr 0.000475	time 0.5531 (0.5701)	loss 2.3203 (3.1618)	grad_norm 1.5591 (1.5793)	mem 17417MB
[2023-02-01 20:35:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][950/1251]	eta 0:02:51 lr 0.000475	time 0.5546 (0.5699)	loss 3.2926 (3.1592)	grad_norm 1.6666 (1.5837)	mem 17417MB
[2023-02-01 20:36:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][1000/1251]	eta 0:02:23 lr 0.000475	time 0.6488 (0.5700)	loss 3.2330 (3.1649)	grad_norm 1.4919 (1.5826)	mem 17417MB
[2023-02-01 20:36:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][1050/1251]	eta 0:01:54 lr 0.000475	time 0.5602 (0.5698)	loss 3.9077 (3.1701)	grad_norm 1.6493 (1.5816)	mem 17417MB
[2023-02-01 20:37:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][1100/1251]	eta 0:01:26 lr 0.000475	time 0.6238 (0.5698)	loss 2.5952 (3.1665)	grad_norm 1.5549 (1.5819)	mem 17417MB
[2023-02-01 20:37:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][1150/1251]	eta 0:00:57 lr 0.000474	time 0.5615 (0.5698)	loss 3.6620 (3.1656)	grad_norm 1.6073 (1.5815)	mem 17417MB
[2023-02-01 20:38:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][1200/1251]	eta 0:00:29 lr 0.000474	time 0.6301 (0.5698)	loss 2.4830 (3.1676)	grad_norm 1.7442 (1.5816)	mem 17417MB
[2023-02-01 20:38:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [155/300][1250/1251]	eta 0:00:00 lr 0.000474	time 0.5493 (0.5697)	loss 3.3961 (3.1634)	grad_norm 1.6305 (1.5800)	mem 17417MB
[2023-02-01 20:38:43 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 155 training takes 0:11:52
[2023-02-01 20:38:43 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_155.pth saving......
[2023-02-01 20:38:45 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_155.pth saved !!!
[2023-02-01 20:38:46 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.855 (0.855)	Loss 0.8212 (0.8212)	Acc@1 81.445 (81.445)	Acc@5 95.508 (95.508)	Mem 17417MB
[2023-02-01 20:38:54 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.436 Acc@5 95.506
[2023-02-01 20:38:54 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.4%
[2023-02-01 20:38:55 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.301 (1.301)	Loss 0.7828 (0.7828)	Acc@1 81.738 (81.738)	Acc@5 95.898 (95.898)	Mem 17417MB
[2023-02-01 20:39:03 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.102 Acc@5 96.164
[2023-02-01 20:39:03 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.1%
[2023-02-01 20:39:03 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.10% at 155 epoch
[2023-02-01 20:39:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][0/1251]	eta 0:35:22 lr 0.000474	time 1.6969 (1.6969)	loss 3.5381 (3.5381)	grad_norm 1.6123 (1.6123)	mem 17417MB
[2023-02-01 20:39:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][50/1251]	eta 0:11:56 lr 0.000474	time 0.5565 (0.5967)	loss 3.4771 (3.3030)	grad_norm 1.6374 (1.5776)	mem 17417MB
[2023-02-01 20:40:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][100/1251]	eta 0:11:14 lr 0.000474	time 0.5548 (0.5859)	loss 3.5731 (3.2369)	grad_norm 1.9139 (1.5827)	mem 17417MB
[2023-02-01 20:40:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][150/1251]	eta 0:10:40 lr 0.000473	time 0.5588 (0.5818)	loss 3.0869 (3.2239)	grad_norm 1.4766 (1.5809)	mem 17417MB
[2023-02-01 20:41:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][200/1251]	eta 0:10:08 lr 0.000473	time 0.6215 (0.5791)	loss 3.3934 (3.1905)	grad_norm 1.6090 (1.5787)	mem 17417MB
[2023-02-01 20:41:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][250/1251]	eta 0:09:38 lr 0.000473	time 0.5529 (0.5777)	loss 2.5129 (3.1611)	grad_norm 1.6643 (1.5841)	mem 17417MB
[2023-02-01 20:41:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][300/1251]	eta 0:09:08 lr 0.000473	time 0.6397 (0.5772)	loss 3.0321 (3.1587)	grad_norm 1.4498 (1.5808)	mem 17417MB
[2023-02-01 20:42:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][350/1251]	eta 0:08:39 lr 0.000472	time 0.5641 (0.5764)	loss 3.3959 (3.1514)	grad_norm 1.5757 (1.5873)	mem 17417MB
[2023-02-01 20:42:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][400/1251]	eta 0:08:09 lr 0.000472	time 0.5786 (0.5756)	loss 3.5033 (3.1433)	grad_norm 1.4552 (1.5876)	mem 17417MB
[2023-02-01 20:43:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][450/1251]	eta 0:07:40 lr 0.000472	time 0.5594 (0.5754)	loss 3.4831 (3.1667)	grad_norm 1.5880 (1.5941)	mem 17417MB
[2023-02-01 20:43:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][500/1251]	eta 0:07:11 lr 0.000472	time 0.5619 (0.5749)	loss 3.0339 (3.1577)	grad_norm 1.5057 (1.5966)	mem 17417MB
[2023-02-01 20:44:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][550/1251]	eta 0:06:42 lr 0.000472	time 0.5570 (0.5747)	loss 3.7374 (3.1544)	grad_norm 1.6943 (1.5914)	mem 17417MB
[2023-02-01 20:44:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][600/1251]	eta 0:06:13 lr 0.000471	time 0.5572 (0.5744)	loss 3.1026 (3.1556)	grad_norm 1.5171 (nan)	mem 17417MB
[2023-02-01 20:45:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][650/1251]	eta 0:05:45 lr 0.000471	time 0.5565 (0.5744)	loss 3.3044 (3.1510)	grad_norm 1.5608 (nan)	mem 17417MB
[2023-02-01 20:45:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][700/1251]	eta 0:05:16 lr 0.000471	time 0.5616 (0.5741)	loss 3.3999 (3.1521)	grad_norm 1.4388 (nan)	mem 17417MB
[2023-02-01 20:46:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][750/1251]	eta 0:04:47 lr 0.000471	time 0.5694 (0.5738)	loss 2.5154 (3.1581)	grad_norm 1.4765 (nan)	mem 17417MB
[2023-02-01 20:46:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][800/1251]	eta 0:04:18 lr 0.000471	time 0.6181 (0.5739)	loss 3.4955 (3.1559)	grad_norm 1.5547 (nan)	mem 17417MB
[2023-02-01 20:47:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][850/1251]	eta 0:03:50 lr 0.000470	time 0.5542 (0.5737)	loss 3.7126 (3.1636)	grad_norm 1.5342 (nan)	mem 17417MB
[2023-02-01 20:47:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][900/1251]	eta 0:03:21 lr 0.000470	time 0.5527 (0.5737)	loss 3.3694 (3.1633)	grad_norm 1.4138 (nan)	mem 17417MB
[2023-02-01 20:48:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][950/1251]	eta 0:02:52 lr 0.000470	time 0.5525 (0.5737)	loss 2.5000 (3.1694)	grad_norm 1.6961 (nan)	mem 17417MB
[2023-02-01 20:48:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][1000/1251]	eta 0:02:23 lr 0.000470	time 0.5563 (0.5736)	loss 3.7701 (3.1676)	grad_norm 1.4907 (nan)	mem 17417MB
[2023-02-01 20:49:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][1050/1251]	eta 0:01:55 lr 0.000470	time 0.5546 (0.5734)	loss 3.7529 (3.1663)	grad_norm 1.4386 (nan)	mem 17417MB
[2023-02-01 20:49:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][1100/1251]	eta 0:01:26 lr 0.000469	time 0.5629 (0.5733)	loss 3.4248 (3.1657)	grad_norm 1.5004 (nan)	mem 17417MB
[2023-02-01 20:50:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][1150/1251]	eta 0:00:57 lr 0.000469	time 0.5575 (0.5731)	loss 2.3525 (3.1607)	grad_norm 1.4454 (nan)	mem 17417MB
[2023-02-01 20:50:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][1200/1251]	eta 0:00:29 lr 0.000469	time 0.5561 (0.5730)	loss 2.3264 (3.1601)	grad_norm 1.6438 (nan)	mem 17417MB
[2023-02-01 20:51:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [156/300][1250/1251]	eta 0:00:00 lr 0.000469	time 0.5505 (0.5730)	loss 2.7648 (3.1646)	grad_norm 1.9396 (nan)	mem 17417MB
[2023-02-01 20:51:00 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 156 training takes 0:11:56
[2023-02-01 20:51:00 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_156.pth saving......
[2023-02-01 20:51:02 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_156.pth saved !!!
[2023-02-01 20:51:03 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.894 (0.894)	Loss 0.8136 (0.8136)	Acc@1 80.566 (80.566)	Acc@5 95.215 (95.215)	Mem 17417MB
[2023-02-01 20:51:11 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.114 Acc@5 95.392
[2023-02-01 20:51:11 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.1%
[2023-02-01 20:51:12 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.194 (1.194)	Loss 0.7542 (0.7542)	Acc@1 81.934 (81.934)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-01 20:51:20 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.112 Acc@5 96.198
[2023-02-01 20:51:20 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.1%
[2023-02-01 20:51:20 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.11% at 156 epoch
[2023-02-01 20:51:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][0/1251]	eta 0:35:45 lr 0.000469	time 1.7154 (1.7154)	loss 2.1083 (2.1083)	grad_norm 1.6082 (1.6082)	mem 17417MB
[2023-02-01 20:51:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][50/1251]	eta 0:11:52 lr 0.000469	time 0.5516 (0.5930)	loss 3.3025 (3.1692)	grad_norm 1.6747 (1.5753)	mem 17417MB
[2023-02-01 20:52:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][100/1251]	eta 0:11:11 lr 0.000468	time 0.6393 (0.5836)	loss 3.0734 (3.1630)	grad_norm 1.3521 (1.5724)	mem 17417MB
[2023-02-01 20:52:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][150/1251]	eta 0:10:36 lr 0.000468	time 0.5530 (0.5786)	loss 2.5147 (3.1400)	grad_norm 1.4945 (1.5670)	mem 17417MB
[2023-02-01 20:53:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][200/1251]	eta 0:10:05 lr 0.000468	time 0.5498 (0.5760)	loss 3.6727 (3.1482)	grad_norm 1.5763 (1.5700)	mem 17417MB
[2023-02-01 20:53:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][250/1251]	eta 0:09:35 lr 0.000468	time 0.5514 (0.5747)	loss 3.7752 (3.1745)	grad_norm 1.4989 (1.5707)	mem 17417MB
[2023-02-01 20:54:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][300/1251]	eta 0:09:05 lr 0.000468	time 0.5497 (0.5741)	loss 2.2243 (3.1592)	grad_norm 1.6087 (1.5740)	mem 17417MB
[2023-02-01 20:54:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][350/1251]	eta 0:08:36 lr 0.000467	time 0.5594 (0.5731)	loss 3.0736 (3.1536)	grad_norm 1.7583 (1.5808)	mem 17417MB
[2023-02-01 20:55:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][400/1251]	eta 0:08:07 lr 0.000467	time 0.5541 (0.5731)	loss 3.5522 (3.1568)	grad_norm 1.5504 (1.5817)	mem 17417MB
[2023-02-01 20:55:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][450/1251]	eta 0:07:38 lr 0.000467	time 0.5838 (0.5727)	loss 2.3284 (3.1453)	grad_norm 1.5804 (1.5794)	mem 17417MB
[2023-02-01 20:56:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][500/1251]	eta 0:07:09 lr 0.000467	time 0.5552 (0.5721)	loss 3.5522 (3.1490)	grad_norm 1.4707 (1.5770)	mem 17417MB
[2023-02-01 20:56:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][550/1251]	eta 0:06:40 lr 0.000466	time 0.5710 (0.5720)	loss 3.1491 (3.1479)	grad_norm 1.6231 (1.5785)	mem 17417MB
[2023-02-01 20:57:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][600/1251]	eta 0:06:12 lr 0.000466	time 0.5619 (0.5720)	loss 3.2608 (3.1521)	grad_norm 1.4953 (1.5798)	mem 17417MB
[2023-02-01 20:57:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][650/1251]	eta 0:05:43 lr 0.000466	time 0.5573 (0.5720)	loss 3.6605 (3.1535)	grad_norm 1.7370 (1.5795)	mem 17417MB
[2023-02-01 20:58:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][700/1251]	eta 0:05:15 lr 0.000466	time 0.5504 (0.5719)	loss 3.2389 (3.1565)	grad_norm 1.5010 (1.5817)	mem 17417MB
[2023-02-01 20:58:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][750/1251]	eta 0:04:46 lr 0.000466	time 0.5565 (0.5717)	loss 3.6566 (3.1526)	grad_norm 1.3384 (1.5811)	mem 17417MB
[2023-02-01 20:58:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][800/1251]	eta 0:04:17 lr 0.000465	time 0.5568 (0.5715)	loss 2.1257 (3.1476)	grad_norm 1.4371 (1.5810)	mem 17417MB
[2023-02-01 20:59:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][850/1251]	eta 0:03:49 lr 0.000465	time 0.5568 (0.5713)	loss 3.6425 (3.1510)	grad_norm 1.6842 (1.5815)	mem 17417MB
[2023-02-01 20:59:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][900/1251]	eta 0:03:20 lr 0.000465	time 0.5594 (0.5713)	loss 3.2255 (3.1534)	grad_norm 1.4558 (1.5794)	mem 17417MB
[2023-02-01 21:00:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][950/1251]	eta 0:02:51 lr 0.000465	time 0.5599 (0.5712)	loss 3.4206 (3.1528)	grad_norm 1.4534 (1.5781)	mem 17417MB
[2023-02-01 21:00:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][1000/1251]	eta 0:02:23 lr 0.000465	time 0.6224 (0.5712)	loss 3.6458 (3.1476)	grad_norm 1.5367 (1.5813)	mem 17417MB
[2023-02-01 21:01:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][1050/1251]	eta 0:01:54 lr 0.000464	time 0.5551 (0.5711)	loss 3.1188 (3.1466)	grad_norm 1.5170 (1.5815)	mem 17417MB
[2023-02-01 21:01:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][1100/1251]	eta 0:01:26 lr 0.000464	time 0.5713 (0.5710)	loss 3.4557 (3.1400)	grad_norm 1.9996 (1.5832)	mem 17417MB
[2023-02-01 21:02:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][1150/1251]	eta 0:00:57 lr 0.000464	time 0.5554 (0.5709)	loss 2.7965 (3.1419)	grad_norm 1.7161 (1.5848)	mem 17417MB
[2023-02-01 21:02:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][1200/1251]	eta 0:00:29 lr 0.000464	time 0.6271 (0.5709)	loss 3.2441 (3.1420)	grad_norm 1.6209 (1.5856)	mem 17417MB
[2023-02-01 21:03:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [157/300][1250/1251]	eta 0:00:00 lr 0.000464	time 0.6106 (0.5708)	loss 2.7445 (3.1412)	grad_norm 1.5439 (1.5857)	mem 17417MB
[2023-02-01 21:03:14 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 157 training takes 0:11:54
[2023-02-01 21:03:14 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_157.pth saving......
[2023-02-01 21:03:16 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_157.pth saved !!!
[2023-02-01 21:03:17 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.858 (0.858)	Loss 0.7933 (0.7933)	Acc@1 80.957 (80.957)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-01 21:03:25 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.304 Acc@5 95.484
[2023-02-01 21:03:25 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.3%
[2023-02-01 21:03:27 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.278 (1.278)	Loss 0.7845 (0.7845)	Acc@1 81.445 (81.445)	Acc@5 95.898 (95.898)	Mem 17417MB
[2023-02-01 21:03:34 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.122 Acc@5 96.204
[2023-02-01 21:03:34 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.1%
[2023-02-01 21:03:34 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.12% at 157 epoch
[2023-02-01 21:03:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][0/1251]	eta 0:35:46 lr 0.000464	time 1.7155 (1.7155)	loss 2.5561 (2.5561)	grad_norm 1.6050 (1.6050)	mem 17417MB
[2023-02-01 21:04:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][50/1251]	eta 0:11:50 lr 0.000463	time 0.5554 (0.5918)	loss 3.7272 (3.1070)	grad_norm 1.5408 (1.5365)	mem 17417MB
[2023-02-01 21:04:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][100/1251]	eta 0:11:10 lr 0.000463	time 0.6311 (0.5829)	loss 3.9428 (3.2087)	grad_norm 1.5152 (1.5629)	mem 17417MB
[2023-02-01 21:05:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][150/1251]	eta 0:10:35 lr 0.000463	time 0.5576 (0.5774)	loss 3.8416 (3.2010)	grad_norm 1.5275 (1.5591)	mem 17417MB
[2023-02-01 21:05:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][200/1251]	eta 0:10:04 lr 0.000463	time 0.5560 (0.5748)	loss 3.0740 (3.1876)	grad_norm 1.4894 (1.5661)	mem 17417MB
[2023-02-01 21:05:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][250/1251]	eta 0:09:34 lr 0.000463	time 0.5539 (0.5740)	loss 2.6764 (3.1683)	grad_norm 1.5241 (1.5742)	mem 17417MB
[2023-02-01 21:06:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][300/1251]	eta 0:09:05 lr 0.000462	time 0.5805 (0.5738)	loss 3.3849 (3.1396)	grad_norm 1.6077 (nan)	mem 17417MB
[2023-02-01 21:06:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][350/1251]	eta 0:08:35 lr 0.000462	time 0.5529 (0.5724)	loss 3.3418 (3.1412)	grad_norm 1.7228 (nan)	mem 17417MB
[2023-02-01 21:07:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][400/1251]	eta 0:08:06 lr 0.000462	time 0.6254 (0.5719)	loss 2.7390 (3.1384)	grad_norm 1.5962 (nan)	mem 17417MB
[2023-02-01 21:07:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][450/1251]	eta 0:07:37 lr 0.000462	time 0.5573 (0.5715)	loss 3.4383 (3.1316)	grad_norm 1.6764 (nan)	mem 17417MB
[2023-02-01 21:08:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][500/1251]	eta 0:07:09 lr 0.000462	time 0.6207 (0.5712)	loss 2.8922 (3.1450)	grad_norm 1.6354 (nan)	mem 17417MB
[2023-02-01 21:08:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][550/1251]	eta 0:06:40 lr 0.000461	time 0.5664 (0.5712)	loss 3.3771 (3.1412)	grad_norm 1.7021 (nan)	mem 17417MB
[2023-02-01 21:09:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][600/1251]	eta 0:06:11 lr 0.000461	time 0.5594 (0.5709)	loss 3.4387 (3.1503)	grad_norm 1.5124 (nan)	mem 17417MB
[2023-02-01 21:09:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][650/1251]	eta 0:05:43 lr 0.000461	time 0.5537 (0.5707)	loss 3.5287 (3.1669)	grad_norm 1.5635 (nan)	mem 17417MB
[2023-02-01 21:10:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][700/1251]	eta 0:05:14 lr 0.000461	time 0.5589 (0.5707)	loss 2.8566 (3.1642)	grad_norm 1.5180 (nan)	mem 17417MB
[2023-02-01 21:10:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][750/1251]	eta 0:04:45 lr 0.000460	time 0.5544 (0.5705)	loss 2.7844 (3.1558)	grad_norm 1.3446 (nan)	mem 17417MB
[2023-02-01 21:11:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][800/1251]	eta 0:04:17 lr 0.000460	time 0.5573 (0.5705)	loss 2.3287 (3.1584)	grad_norm 1.5226 (nan)	mem 17417MB
[2023-02-01 21:11:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][850/1251]	eta 0:03:48 lr 0.000460	time 0.5547 (0.5704)	loss 3.4690 (3.1605)	grad_norm 1.6800 (nan)	mem 17417MB
[2023-02-01 21:12:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][900/1251]	eta 0:03:20 lr 0.000460	time 0.6529 (0.5704)	loss 3.6316 (3.1620)	grad_norm 1.6771 (nan)	mem 17417MB
[2023-02-01 21:12:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][950/1251]	eta 0:02:51 lr 0.000460	time 0.5595 (0.5703)	loss 3.4285 (3.1604)	grad_norm 1.4796 (nan)	mem 17417MB
[2023-02-01 21:13:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][1000/1251]	eta 0:02:23 lr 0.000459	time 0.5543 (0.5702)	loss 3.6037 (3.1662)	grad_norm 1.7656 (nan)	mem 17417MB
[2023-02-01 21:13:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][1050/1251]	eta 0:01:54 lr 0.000459	time 0.5515 (0.5702)	loss 2.4154 (3.1634)	grad_norm 1.6044 (nan)	mem 17417MB
[2023-02-01 21:14:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][1100/1251]	eta 0:01:26 lr 0.000459	time 0.6243 (0.5703)	loss 3.6589 (3.1686)	grad_norm 1.5165 (nan)	mem 17417MB
[2023-02-01 21:14:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][1150/1251]	eta 0:00:57 lr 0.000459	time 0.5487 (0.5703)	loss 2.5745 (3.1661)	grad_norm 1.6579 (nan)	mem 17417MB
[2023-02-01 21:14:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][1200/1251]	eta 0:00:29 lr 0.000459	time 0.5523 (0.5701)	loss 3.5850 (3.1675)	grad_norm 1.3863 (nan)	mem 17417MB
[2023-02-01 21:15:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [158/300][1250/1251]	eta 0:00:00 lr 0.000458	time 0.5504 (0.5701)	loss 3.7263 (3.1656)	grad_norm 1.5075 (nan)	mem 17417MB
[2023-02-01 21:15:28 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 158 training takes 0:11:53
[2023-02-01 21:15:28 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_158.pth saving......
[2023-02-01 21:15:30 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_158.pth saved !!!
[2023-02-01 21:15:31 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.921 (0.921)	Loss 0.7926 (0.7926)	Acc@1 81.152 (81.152)	Acc@5 95.508 (95.508)	Mem 17417MB
[2023-02-01 21:15:39 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.406 Acc@5 95.522
[2023-02-01 21:15:39 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.4%
[2023-02-01 21:15:40 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.262 (1.262)	Loss 0.7333 (0.7333)	Acc@1 83.008 (83.008)	Acc@5 97.363 (97.363)	Mem 17417MB
[2023-02-01 21:15:48 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.148 Acc@5 96.216
[2023-02-01 21:15:48 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.1%
[2023-02-01 21:15:48 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.15% at 158 epoch
[2023-02-01 21:15:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][0/1251]	eta 0:37:19 lr 0.000458	time 1.7902 (1.7902)	loss 3.2776 (3.2776)	grad_norm 1.6022 (1.6022)	mem 17417MB
[2023-02-01 21:16:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][50/1251]	eta 0:11:56 lr 0.000458	time 0.5582 (0.5963)	loss 3.3679 (3.2121)	grad_norm 1.7891 (1.6332)	mem 17417MB
[2023-02-01 21:16:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][100/1251]	eta 0:11:13 lr 0.000458	time 0.5544 (0.5856)	loss 3.1899 (3.1625)	grad_norm 1.6545 (1.6167)	mem 17417MB
[2023-02-01 21:17:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][150/1251]	eta 0:10:37 lr 0.000458	time 0.5564 (0.5788)	loss 3.7829 (3.1193)	grad_norm 1.5013 (1.6137)	mem 17417MB
[2023-02-01 21:17:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][200/1251]	eta 0:10:05 lr 0.000458	time 0.5534 (0.5765)	loss 3.1515 (3.1236)	grad_norm 1.6910 (1.6049)	mem 17417MB
[2023-02-01 21:18:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][250/1251]	eta 0:09:35 lr 0.000457	time 0.6227 (0.5750)	loss 2.7583 (3.1170)	grad_norm 1.6968 (1.6187)	mem 17417MB
[2023-02-01 21:18:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][300/1251]	eta 0:09:05 lr 0.000457	time 0.5567 (0.5737)	loss 4.0679 (3.1398)	grad_norm 1.6522 (1.6126)	mem 17417MB
[2023-02-01 21:19:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][350/1251]	eta 0:08:36 lr 0.000457	time 0.5548 (0.5733)	loss 3.5613 (3.1479)	grad_norm 1.5221 (1.6066)	mem 17417MB
[2023-02-01 21:19:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][400/1251]	eta 0:08:07 lr 0.000457	time 0.5521 (0.5727)	loss 2.6196 (3.1264)	grad_norm 1.3825 (1.6045)	mem 17417MB
[2023-02-01 21:20:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][450/1251]	eta 0:07:38 lr 0.000457	time 0.6244 (0.5726)	loss 2.8886 (3.1179)	grad_norm 1.4844 (1.6046)	mem 17417MB
[2023-02-01 21:20:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][500/1251]	eta 0:07:09 lr 0.000456	time 0.5651 (0.5724)	loss 2.0882 (3.1120)	grad_norm 1.4955 (1.6076)	mem 17417MB
[2023-02-01 21:21:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][550/1251]	eta 0:06:41 lr 0.000456	time 0.5505 (0.5721)	loss 3.0159 (3.1126)	grad_norm 1.3590 (1.6049)	mem 17417MB
[2023-02-01 21:21:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][600/1251]	eta 0:06:12 lr 0.000456	time 0.5549 (0.5720)	loss 2.6059 (3.1079)	grad_norm 1.6599 (1.6024)	mem 17417MB
[2023-02-01 21:22:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][650/1251]	eta 0:05:43 lr 0.000456	time 0.5558 (0.5721)	loss 2.9568 (3.1126)	grad_norm 1.4045 (1.6055)	mem 17417MB
[2023-02-01 21:22:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][700/1251]	eta 0:05:14 lr 0.000456	time 0.5629 (0.5716)	loss 2.9201 (3.1138)	grad_norm 1.6358 (1.6049)	mem 17417MB
[2023-02-01 21:22:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][750/1251]	eta 0:04:46 lr 0.000455	time 0.5563 (0.5715)	loss 3.1043 (3.1214)	grad_norm 1.5966 (1.6032)	mem 17417MB
[2023-02-01 21:23:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][800/1251]	eta 0:04:17 lr 0.000455	time 0.5568 (0.5712)	loss 3.6057 (3.1203)	grad_norm 1.6214 (1.6032)	mem 17417MB
[2023-02-01 21:23:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][850/1251]	eta 0:03:49 lr 0.000455	time 0.5575 (0.5713)	loss 3.0745 (3.1190)	grad_norm 1.5661 (1.6047)	mem 17417MB
[2023-02-01 21:24:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][900/1251]	eta 0:03:20 lr 0.000455	time 0.5540 (0.5712)	loss 3.6059 (3.1282)	grad_norm 1.7054 (1.6050)	mem 17417MB
[2023-02-01 21:24:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][950/1251]	eta 0:02:51 lr 0.000454	time 0.5577 (0.5711)	loss 3.6738 (3.1263)	grad_norm 1.5761 (1.6066)	mem 17417MB
[2023-02-01 21:25:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][1000/1251]	eta 0:02:23 lr 0.000454	time 0.6383 (0.5711)	loss 3.6218 (3.1314)	grad_norm 1.5483 (1.6052)	mem 17417MB
[2023-02-01 21:25:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][1050/1251]	eta 0:01:54 lr 0.000454	time 0.5545 (0.5712)	loss 1.9946 (3.1255)	grad_norm 1.6139 (1.6038)	mem 17417MB
[2023-02-01 21:26:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][1100/1251]	eta 0:01:26 lr 0.000454	time 0.5615 (0.5710)	loss 3.6020 (3.1319)	grad_norm 1.5010 (1.6035)	mem 17417MB
[2023-02-01 21:26:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][1150/1251]	eta 0:00:57 lr 0.000454	time 0.5608 (0.5711)	loss 2.0313 (3.1331)	grad_norm 1.5364 (1.6040)	mem 17417MB
[2023-02-01 21:27:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][1200/1251]	eta 0:00:29 lr 0.000453	time 0.5589 (0.5711)	loss 2.8213 (3.1301)	grad_norm 1.4142 (1.6031)	mem 17417MB
[2023-02-01 21:27:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [159/300][1250/1251]	eta 0:00:00 lr 0.000453	time 0.6082 (0.5710)	loss 2.7816 (3.1320)	grad_norm 1.5507 (nan)	mem 17417MB
[2023-02-01 21:27:42 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 159 training takes 0:11:54
[2023-02-01 21:27:42 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_159.pth saving......
[2023-02-01 21:27:44 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_159.pth saved !!!
[2023-02-01 21:27:45 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.880 (0.880)	Loss 0.8262 (0.8262)	Acc@1 80.957 (80.957)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-01 21:27:53 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.528 Acc@5 95.450
[2023-02-01 21:27:53 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.5%
[2023-02-01 21:27:54 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.273 (1.273)	Loss 0.7716 (0.7716)	Acc@1 82.617 (82.617)	Acc@5 95.215 (95.215)	Mem 17417MB
[2023-02-01 21:28:02 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.172 Acc@5 96.220
[2023-02-01 21:28:02 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.2%
[2023-02-01 21:28:02 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.17% at 159 epoch
[2023-02-01 21:28:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][0/1251]	eta 0:35:22 lr 0.000453	time 1.6966 (1.6966)	loss 3.9015 (3.9015)	grad_norm 1.4473 (1.4473)	mem 17417MB
[2023-02-01 21:28:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][50/1251]	eta 0:11:51 lr 0.000453	time 0.5708 (0.5926)	loss 3.4721 (3.1906)	grad_norm 1.6178 (1.6452)	mem 17417MB
[2023-02-01 21:29:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][100/1251]	eta 0:11:09 lr 0.000453	time 0.5562 (0.5814)	loss 3.3380 (3.1494)	grad_norm 1.9242 (1.6116)	mem 17417MB
[2023-02-01 21:29:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][150/1251]	eta 0:10:35 lr 0.000453	time 0.5600 (0.5769)	loss 3.3194 (3.1179)	grad_norm 1.7094 (1.6072)	mem 17417MB
[2023-02-01 21:29:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][200/1251]	eta 0:10:04 lr 0.000452	time 0.5583 (0.5755)	loss 3.1554 (3.1178)	grad_norm 1.9095 (1.6071)	mem 17417MB
[2023-02-01 21:30:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][250/1251]	eta 0:09:35 lr 0.000452	time 0.5570 (0.5749)	loss 2.6741 (3.1289)	grad_norm 1.5357 (1.6146)	mem 17417MB
[2023-02-01 21:30:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][300/1251]	eta 0:09:05 lr 0.000452	time 0.5555 (0.5739)	loss 2.4467 (3.1213)	grad_norm 1.6092 (1.6148)	mem 17417MB
[2023-02-01 21:31:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][350/1251]	eta 0:08:36 lr 0.000452	time 0.5655 (0.5729)	loss 3.1522 (3.1263)	grad_norm 1.5998 (1.6198)	mem 17417MB
[2023-02-01 21:31:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][400/1251]	eta 0:08:06 lr 0.000452	time 0.5510 (0.5722)	loss 3.5687 (3.1211)	grad_norm 1.6130 (1.6145)	mem 17417MB
[2023-02-01 21:32:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][450/1251]	eta 0:07:37 lr 0.000451	time 0.5529 (0.5716)	loss 2.8957 (3.1203)	grad_norm 1.6196 (1.6167)	mem 17417MB
[2023-02-01 21:32:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][500/1251]	eta 0:07:09 lr 0.000451	time 0.5607 (0.5714)	loss 2.3659 (3.1071)	grad_norm 1.3250 (1.6146)	mem 17417MB
[2023-02-01 21:33:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][550/1251]	eta 0:06:40 lr 0.000451	time 0.5618 (0.5712)	loss 2.9698 (3.1076)	grad_norm 1.4621 (1.6122)	mem 17417MB
[2023-02-01 21:33:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][600/1251]	eta 0:06:11 lr 0.000451	time 0.5593 (0.5713)	loss 3.5842 (3.1096)	grad_norm 1.6174 (1.6146)	mem 17417MB
[2023-02-01 21:34:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][650/1251]	eta 0:05:43 lr 0.000451	time 0.5592 (0.5710)	loss 2.2428 (3.1115)	grad_norm 1.4948 (1.6142)	mem 17417MB
[2023-02-01 21:34:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][700/1251]	eta 0:05:14 lr 0.000450	time 0.5567 (0.5707)	loss 2.0968 (3.1079)	grad_norm 1.6401 (1.6140)	mem 17417MB
[2023-02-01 21:35:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][750/1251]	eta 0:04:45 lr 0.000450	time 0.5527 (0.5707)	loss 2.7559 (3.1000)	grad_norm 1.6025 (1.6142)	mem 17417MB
[2023-02-01 21:35:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][800/1251]	eta 0:04:17 lr 0.000450	time 0.6194 (0.5707)	loss 3.4270 (3.1007)	grad_norm 1.4994 (1.6171)	mem 17417MB
[2023-02-01 21:36:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][850/1251]	eta 0:03:48 lr 0.000450	time 0.5541 (0.5706)	loss 3.0831 (3.1000)	grad_norm 1.6219 (1.6137)	mem 17417MB
[2023-02-01 21:36:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][900/1251]	eta 0:03:20 lr 0.000450	time 0.6286 (0.5705)	loss 3.5377 (3.1039)	grad_norm 1.5256 (1.6152)	mem 17417MB
[2023-02-01 21:37:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][950/1251]	eta 0:02:51 lr 0.000449	time 0.5570 (0.5703)	loss 3.2590 (3.1062)	grad_norm 1.4940 (1.6147)	mem 17417MB
[2023-02-01 21:37:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][1000/1251]	eta 0:02:23 lr 0.000449	time 0.5581 (0.5704)	loss 3.6172 (3.1088)	grad_norm 1.6710 (1.6132)	mem 17417MB
[2023-02-01 21:38:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][1050/1251]	eta 0:01:54 lr 0.000449	time 0.5551 (0.5705)	loss 3.4239 (3.1045)	grad_norm 1.5570 (1.6115)	mem 17417MB
[2023-02-01 21:38:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][1100/1251]	eta 0:01:26 lr 0.000449	time 0.6274 (0.5703)	loss 3.9642 (3.1023)	grad_norm 1.6648 (1.6103)	mem 17417MB
[2023-02-01 21:38:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][1150/1251]	eta 0:00:57 lr 0.000449	time 0.6461 (0.5705)	loss 2.5446 (3.1060)	grad_norm 1.5926 (1.6102)	mem 17417MB
[2023-02-01 21:39:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][1200/1251]	eta 0:00:29 lr 0.000448	time 0.5598 (0.5703)	loss 3.4062 (3.1067)	grad_norm 1.7302 (1.6092)	mem 17417MB
[2023-02-01 21:39:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [160/300][1250/1251]	eta 0:00:00 lr 0.000448	time 0.5498 (0.5703)	loss 3.2155 (3.0994)	grad_norm 1.6416 (1.6082)	mem 17417MB
[2023-02-01 21:39:56 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 160 training takes 0:11:53
[2023-02-01 21:39:56 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_160.pth saving......
[2023-02-01 21:39:58 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_160.pth saved !!!
[2023-02-01 21:39:59 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.085 (1.085)	Loss 0.8831 (0.8831)	Acc@1 79.492 (79.492)	Acc@5 94.043 (94.043)	Mem 17417MB
[2023-02-01 21:40:07 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.182 Acc@5 95.444
[2023-02-01 21:40:07 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.2%
[2023-02-01 21:40:08 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.227 (1.227)	Loss 0.7389 (0.7389)	Acc@1 82.910 (82.910)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-01 21:40:16 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.184 Acc@5 96.236
[2023-02-01 21:40:16 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.2%
[2023-02-01 21:40:16 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.18% at 160 epoch
[2023-02-01 21:40:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][0/1251]	eta 0:35:34 lr 0.000448	time 1.7064 (1.7064)	loss 3.1710 (3.1710)	grad_norm 1.9801 (1.9801)	mem 17417MB
[2023-02-01 21:40:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][50/1251]	eta 0:11:54 lr 0.000448	time 0.5672 (0.5947)	loss 3.5172 (3.0760)	grad_norm 1.4374 (1.6151)	mem 17417MB
[2023-02-01 21:41:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][100/1251]	eta 0:11:11 lr 0.000448	time 0.5585 (0.5831)	loss 2.8148 (3.0500)	grad_norm 1.4460 (1.6131)	mem 17417MB
[2023-02-01 21:41:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][150/1251]	eta 0:10:37 lr 0.000447	time 0.5537 (0.5789)	loss 2.7297 (3.0616)	grad_norm 1.7597 (1.6150)	mem 17417MB
[2023-02-01 21:42:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][200/1251]	eta 0:10:06 lr 0.000447	time 0.5740 (0.5767)	loss 3.0128 (3.0530)	grad_norm 1.4485 (1.6082)	mem 17417MB
[2023-02-01 21:42:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][250/1251]	eta 0:09:36 lr 0.000447	time 0.5503 (0.5756)	loss 2.6373 (3.0826)	grad_norm 1.6009 (1.6191)	mem 17417MB
[2023-02-01 21:43:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][300/1251]	eta 0:09:06 lr 0.000447	time 0.5559 (0.5744)	loss 3.3087 (3.0846)	grad_norm 1.3593 (1.6133)	mem 17417MB
[2023-02-01 21:43:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][350/1251]	eta 0:08:37 lr 0.000447	time 0.5531 (0.5741)	loss 3.7013 (3.1001)	grad_norm 1.4096 (1.6129)	mem 17417MB
[2023-02-01 21:44:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][400/1251]	eta 0:08:07 lr 0.000446	time 0.5506 (0.5733)	loss 4.0039 (3.1121)	grad_norm 1.5925 (1.6126)	mem 17417MB
[2023-02-01 21:44:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][450/1251]	eta 0:07:39 lr 0.000446	time 0.5712 (0.5732)	loss 3.0330 (3.1241)	grad_norm 1.6058 (1.6121)	mem 17417MB
[2023-02-01 21:45:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][500/1251]	eta 0:07:09 lr 0.000446	time 0.5539 (0.5724)	loss 2.8218 (3.1188)	grad_norm 1.5409 (1.6161)	mem 17417MB
[2023-02-01 21:45:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][550/1251]	eta 0:06:41 lr 0.000446	time 0.5532 (0.5724)	loss 3.3630 (3.1159)	grad_norm 1.6733 (1.6143)	mem 17417MB
[2023-02-01 21:46:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][600/1251]	eta 0:06:12 lr 0.000446	time 0.5714 (0.5723)	loss 3.5136 (3.1088)	grad_norm 1.8234 (1.6124)	mem 17417MB
[2023-02-01 21:46:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][650/1251]	eta 0:05:43 lr 0.000445	time 0.5578 (0.5722)	loss 3.5070 (3.1163)	grad_norm 1.7062 (1.6152)	mem 17417MB
[2023-02-01 21:46:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][700/1251]	eta 0:05:15 lr 0.000445	time 0.5526 (0.5719)	loss 4.1272 (3.1116)	grad_norm 1.7332 (1.6172)	mem 17417MB
[2023-02-01 21:47:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][750/1251]	eta 0:04:46 lr 0.000445	time 0.5507 (0.5716)	loss 2.9420 (3.1172)	grad_norm 1.4403 (1.6159)	mem 17417MB
[2023-02-01 21:47:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][800/1251]	eta 0:04:17 lr 0.000445	time 0.5593 (0.5714)	loss 3.4265 (3.1197)	grad_norm 2.0436 (inf)	mem 17417MB
[2023-02-01 21:48:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][850/1251]	eta 0:03:49 lr 0.000445	time 0.6343 (0.5713)	loss 3.3770 (3.1203)	grad_norm 1.6810 (inf)	mem 17417MB
[2023-02-01 21:48:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][900/1251]	eta 0:03:20 lr 0.000444	time 0.5520 (0.5712)	loss 3.3862 (3.1234)	grad_norm 1.8201 (inf)	mem 17417MB
[2023-02-01 21:49:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][950/1251]	eta 0:02:51 lr 0.000444	time 0.5572 (0.5711)	loss 3.5501 (3.1256)	grad_norm 1.7795 (inf)	mem 17417MB
[2023-02-01 21:49:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][1000/1251]	eta 0:02:23 lr 0.000444	time 0.5527 (0.5710)	loss 3.2564 (3.1291)	grad_norm 1.5583 (inf)	mem 17417MB
[2023-02-01 21:50:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][1050/1251]	eta 0:01:54 lr 0.000444	time 0.5597 (0.5711)	loss 3.7478 (3.1311)	grad_norm 1.5714 (inf)	mem 17417MB
[2023-02-01 21:50:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][1100/1251]	eta 0:01:26 lr 0.000444	time 0.6451 (0.5710)	loss 3.3626 (3.1274)	grad_norm 1.7276 (inf)	mem 17417MB
[2023-02-01 21:51:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][1150/1251]	eta 0:00:57 lr 0.000443	time 0.5593 (0.5708)	loss 3.0639 (3.1289)	grad_norm 1.4709 (inf)	mem 17417MB
[2023-02-01 21:51:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][1200/1251]	eta 0:00:29 lr 0.000443	time 0.5523 (0.5707)	loss 3.3802 (3.1260)	grad_norm 1.5446 (inf)	mem 17417MB
[2023-02-01 21:52:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [161/300][1250/1251]	eta 0:00:00 lr 0.000443	time 0.5499 (0.5708)	loss 3.2136 (3.1286)	grad_norm 1.5618 (inf)	mem 17417MB
[2023-02-01 21:52:11 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 161 training takes 0:11:54
[2023-02-01 21:52:11 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_161.pth saving......
[2023-02-01 21:52:13 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_161.pth saved !!!
[2023-02-01 21:52:13 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.907 (0.907)	Loss 0.8077 (0.8077)	Acc@1 80.762 (80.762)	Acc@5 95.117 (95.117)	Mem 17417MB
[2023-02-01 21:52:21 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.472 Acc@5 95.512
[2023-02-01 21:52:21 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.5%
[2023-02-01 21:52:23 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.203 (1.203)	Loss 0.7566 (0.7566)	Acc@1 81.934 (81.934)	Acc@5 96.484 (96.484)	Mem 17417MB
[2023-02-01 21:52:31 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.202 Acc@5 96.244
[2023-02-01 21:52:31 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.2%
[2023-02-01 21:52:31 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.20% at 161 epoch
[2023-02-01 21:52:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][0/1251]	eta 0:35:47 lr 0.000443	time 1.7163 (1.7163)	loss 2.5116 (2.5116)	grad_norm 1.7846 (1.7846)	mem 17417MB
[2023-02-01 21:53:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][50/1251]	eta 0:11:52 lr 0.000443	time 0.5570 (0.5935)	loss 2.6643 (3.0679)	grad_norm 1.7070 (1.6316)	mem 17417MB
[2023-02-01 21:53:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][100/1251]	eta 0:11:10 lr 0.000443	time 0.6444 (0.5827)	loss 2.5194 (3.0528)	grad_norm 1.4934 (1.6227)	mem 17417MB
[2023-02-01 21:53:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][150/1251]	eta 0:10:36 lr 0.000442	time 0.5493 (0.5778)	loss 2.9081 (3.0872)	grad_norm 1.5096 (1.6147)	mem 17417MB
[2023-02-01 21:54:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][200/1251]	eta 0:10:04 lr 0.000442	time 0.5608 (0.5756)	loss 2.6383 (3.0806)	grad_norm 1.8082 (1.6012)	mem 17417MB
[2023-02-01 21:54:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][250/1251]	eta 0:09:35 lr 0.000442	time 0.5570 (0.5746)	loss 2.8296 (3.0800)	grad_norm 1.5752 (1.6002)	mem 17417MB
[2023-02-01 21:55:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][300/1251]	eta 0:09:05 lr 0.000442	time 0.5521 (0.5737)	loss 3.1603 (3.0857)	grad_norm 1.4952 (1.6006)	mem 17417MB
[2023-02-01 21:55:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][350/1251]	eta 0:08:36 lr 0.000442	time 0.5576 (0.5732)	loss 3.2946 (3.0947)	grad_norm 1.7242 (1.5958)	mem 17417MB
[2023-02-01 21:56:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][400/1251]	eta 0:08:07 lr 0.000441	time 0.5514 (0.5730)	loss 3.0981 (3.1018)	grad_norm 1.4173 (1.5994)	mem 17417MB
[2023-02-01 21:56:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][450/1251]	eta 0:07:38 lr 0.000441	time 0.5568 (0.5727)	loss 3.7766 (3.1131)	grad_norm 1.8022 (1.6000)	mem 17417MB
[2023-02-01 21:57:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][500/1251]	eta 0:07:10 lr 0.000441	time 0.6654 (0.5726)	loss 3.5927 (3.1084)	grad_norm 1.5038 (1.6045)	mem 17417MB
[2023-02-01 21:57:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][550/1251]	eta 0:06:41 lr 0.000441	time 0.5612 (0.5723)	loss 3.7412 (3.1228)	grad_norm 1.8305 (1.6050)	mem 17417MB
[2023-02-01 21:58:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][600/1251]	eta 0:06:12 lr 0.000440	time 0.5534 (0.5718)	loss 2.5988 (3.1160)	grad_norm 1.3569 (1.6027)	mem 17417MB
[2023-02-01 21:58:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][650/1251]	eta 0:05:43 lr 0.000440	time 0.5554 (0.5718)	loss 3.7177 (3.1176)	grad_norm 1.4816 (1.6066)	mem 17417MB
[2023-02-01 21:59:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][700/1251]	eta 0:05:14 lr 0.000440	time 0.5557 (0.5717)	loss 3.7936 (3.1171)	grad_norm 1.7537 (1.6051)	mem 17417MB
[2023-02-01 21:59:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][750/1251]	eta 0:04:46 lr 0.000440	time 0.5538 (0.5716)	loss 2.7765 (3.1174)	grad_norm 1.5573 (1.6105)	mem 17417MB
[2023-02-01 22:00:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][800/1251]	eta 0:04:17 lr 0.000440	time 0.5634 (0.5715)	loss 3.0899 (3.1218)	grad_norm 1.6453 (1.6082)	mem 17417MB
[2023-02-01 22:00:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][850/1251]	eta 0:03:49 lr 0.000439	time 0.5530 (0.5712)	loss 3.3121 (3.1228)	grad_norm 1.3728 (1.6051)	mem 17417MB
[2023-02-01 22:01:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][900/1251]	eta 0:03:20 lr 0.000439	time 0.6409 (0.5713)	loss 3.3144 (3.1225)	grad_norm 1.5342 (1.6039)	mem 17417MB
[2023-02-01 22:01:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][950/1251]	eta 0:02:51 lr 0.000439	time 0.5610 (0.5711)	loss 2.6424 (3.1231)	grad_norm 1.7495 (1.6045)	mem 17417MB
[2023-02-01 22:02:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][1000/1251]	eta 0:02:23 lr 0.000439	time 0.5524 (0.5712)	loss 2.4116 (3.1199)	grad_norm 1.5888 (1.6055)	mem 17417MB
[2023-02-01 22:02:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][1050/1251]	eta 0:01:54 lr 0.000439	time 0.5547 (0.5711)	loss 2.3661 (3.1259)	grad_norm 1.4691 (1.6053)	mem 17417MB
[2023-02-01 22:02:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][1100/1251]	eta 0:01:26 lr 0.000438	time 0.6454 (0.5711)	loss 3.8356 (3.1281)	grad_norm 1.5679 (1.6059)	mem 17417MB
[2023-02-01 22:03:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][1150/1251]	eta 0:00:57 lr 0.000438	time 0.6249 (0.5710)	loss 3.6052 (3.1297)	grad_norm 1.5392 (1.6085)	mem 17417MB
[2023-02-01 22:03:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][1200/1251]	eta 0:00:29 lr 0.000438	time 0.5795 (0.5709)	loss 3.5295 (3.1387)	grad_norm 1.5746 (1.6084)	mem 17417MB
[2023-02-01 22:04:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [162/300][1250/1251]	eta 0:00:00 lr 0.000438	time 0.5542 (0.5710)	loss 3.2104 (3.1403)	grad_norm 1.6022 (1.6107)	mem 17417MB
[2023-02-01 22:04:25 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 162 training takes 0:11:54
[2023-02-01 22:04:25 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_162.pth saving......
[2023-02-01 22:04:27 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_162.pth saved !!!
[2023-02-01 22:04:28 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.878 (0.878)	Loss 0.8090 (0.8090)	Acc@1 81.738 (81.738)	Acc@5 95.508 (95.508)	Mem 17417MB
[2023-02-01 22:04:36 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.462 Acc@5 95.476
[2023-02-01 22:04:36 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.5%
[2023-02-01 22:04:37 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.201 (1.201)	Loss 0.7255 (0.7255)	Acc@1 81.348 (81.348)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-01 22:04:45 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.274 Acc@5 96.264
[2023-02-01 22:04:45 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.3%
[2023-02-01 22:04:45 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.27% at 162 epoch
[2023-02-01 22:04:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][0/1251]	eta 0:34:41 lr 0.000438	time 1.6637 (1.6637)	loss 3.5585 (3.5585)	grad_norm 1.5992 (1.5992)	mem 17417MB
[2023-02-01 22:05:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][50/1251]	eta 0:11:56 lr 0.000438	time 0.5657 (0.5969)	loss 3.5723 (3.1710)	grad_norm 1.4732 (1.6485)	mem 17417MB
[2023-02-01 22:05:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][100/1251]	eta 0:11:12 lr 0.000437	time 0.5594 (0.5845)	loss 2.1658 (3.1579)	grad_norm 1.6593 (1.6181)	mem 17417MB
[2023-02-01 22:06:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][150/1251]	eta 0:10:38 lr 0.000437	time 0.5618 (0.5802)	loss 3.4491 (3.1573)	grad_norm 1.8123 (1.6336)	mem 17417MB
[2023-02-01 22:06:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][200/1251]	eta 0:10:07 lr 0.000437	time 0.5529 (0.5776)	loss 3.0058 (3.1365)	grad_norm 1.6723 (1.6243)	mem 17417MB
[2023-02-01 22:07:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][250/1251]	eta 0:09:36 lr 0.000437	time 0.5563 (0.5759)	loss 3.8315 (3.1478)	grad_norm 1.4738 (1.6253)	mem 17417MB
[2023-02-01 22:07:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][300/1251]	eta 0:09:07 lr 0.000437	time 0.5559 (0.5754)	loss 1.9840 (3.1239)	grad_norm 1.7829 (1.6233)	mem 17417MB
[2023-02-01 22:08:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][350/1251]	eta 0:08:38 lr 0.000436	time 0.5561 (0.5749)	loss 3.3020 (3.1343)	grad_norm 1.6135 (1.6183)	mem 17417MB
[2023-02-01 22:08:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][400/1251]	eta 0:08:08 lr 0.000436	time 0.5603 (0.5742)	loss 2.9730 (3.1407)	grad_norm 1.4639 (1.6124)	mem 17417MB
[2023-02-01 22:09:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][450/1251]	eta 0:07:39 lr 0.000436	time 0.6495 (0.5742)	loss 2.7998 (3.1327)	grad_norm 1.5279 (1.6084)	mem 17417MB
[2023-02-01 22:09:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][500/1251]	eta 0:07:10 lr 0.000436	time 0.5605 (0.5733)	loss 2.2226 (3.1300)	grad_norm 1.5095 (nan)	mem 17417MB
[2023-02-01 22:10:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][550/1251]	eta 0:06:41 lr 0.000436	time 0.5527 (0.5733)	loss 3.1878 (3.1354)	grad_norm 1.5393 (nan)	mem 17417MB
[2023-02-01 22:10:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][600/1251]	eta 0:06:13 lr 0.000435	time 0.5585 (0.5732)	loss 2.9444 (3.1293)	grad_norm 1.6762 (nan)	mem 17417MB
[2023-02-01 22:10:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][650/1251]	eta 0:05:44 lr 0.000435	time 0.5547 (0.5728)	loss 2.7272 (3.1268)	grad_norm 1.5187 (nan)	mem 17417MB
[2023-02-01 22:11:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][700/1251]	eta 0:05:15 lr 0.000435	time 0.5594 (0.5728)	loss 3.4968 (3.1267)	grad_norm 1.4937 (nan)	mem 17417MB
[2023-02-01 22:11:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][750/1251]	eta 0:04:46 lr 0.000435	time 0.5595 (0.5725)	loss 3.0445 (3.1226)	grad_norm 1.4486 (nan)	mem 17417MB
[2023-02-01 22:12:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][800/1251]	eta 0:04:18 lr 0.000435	time 0.5671 (0.5723)	loss 3.2970 (3.1180)	grad_norm 1.5692 (nan)	mem 17417MB
[2023-02-01 22:12:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][850/1251]	eta 0:03:49 lr 0.000434	time 0.6223 (0.5723)	loss 3.3184 (3.1253)	grad_norm 1.7315 (nan)	mem 17417MB
[2023-02-01 22:13:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][900/1251]	eta 0:03:20 lr 0.000434	time 0.5558 (0.5723)	loss 3.5696 (3.1234)	grad_norm 1.5501 (nan)	mem 17417MB
[2023-02-01 22:13:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][950/1251]	eta 0:02:52 lr 0.000434	time 0.5543 (0.5722)	loss 3.7048 (3.1254)	grad_norm 1.5420 (nan)	mem 17417MB
[2023-02-01 22:14:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][1000/1251]	eta 0:02:23 lr 0.000434	time 0.6375 (0.5722)	loss 2.0887 (3.1277)	grad_norm 1.5449 (nan)	mem 17417MB
[2023-02-01 22:14:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][1050/1251]	eta 0:01:54 lr 0.000434	time 0.5674 (0.5721)	loss 3.9405 (3.1250)	grad_norm 1.6307 (nan)	mem 17417MB
[2023-02-01 22:15:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][1100/1251]	eta 0:01:26 lr 0.000433	time 0.5562 (0.5720)	loss 3.1454 (3.1237)	grad_norm 1.6307 (nan)	mem 17417MB
[2023-02-01 22:15:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][1150/1251]	eta 0:00:57 lr 0.000433	time 0.5695 (0.5719)	loss 3.4156 (3.1240)	grad_norm 1.6145 (nan)	mem 17417MB
[2023-02-01 22:16:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][1200/1251]	eta 0:00:29 lr 0.000433	time 0.5518 (0.5718)	loss 3.4655 (3.1250)	grad_norm 1.5836 (nan)	mem 17417MB
[2023-02-01 22:16:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [163/300][1250/1251]	eta 0:00:00 lr 0.000433	time 0.6163 (0.5719)	loss 2.8738 (3.1250)	grad_norm 2.0585 (nan)	mem 17417MB
[2023-02-01 22:16:41 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 163 training takes 0:11:55
[2023-02-01 22:16:41 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_163.pth saving......
[2023-02-01 22:16:43 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_163.pth saved !!!
[2023-02-01 22:16:44 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.059 (1.059)	Loss 0.8003 (0.8003)	Acc@1 82.227 (82.227)	Acc@5 95.312 (95.312)	Mem 17417MB
[2023-02-01 22:16:52 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.520 Acc@5 95.596
[2023-02-01 22:16:52 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.5%
[2023-02-01 22:16:53 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.280 (1.280)	Loss 0.7967 (0.7967)	Acc@1 80.859 (80.859)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-01 22:17:01 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.298 Acc@5 96.286
[2023-02-01 22:17:01 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.3%
[2023-02-01 22:17:01 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.30% at 163 epoch
[2023-02-01 22:17:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][0/1251]	eta 0:35:57 lr 0.000433	time 1.7244 (1.7244)	loss 3.2844 (3.2844)	grad_norm 1.6784 (1.6784)	mem 17417MB
[2023-02-01 22:17:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][50/1251]	eta 0:11:54 lr 0.000432	time 0.5647 (0.5948)	loss 3.8322 (3.2144)	grad_norm 1.5389 (1.6241)	mem 17417MB
[2023-02-01 22:18:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][100/1251]	eta 0:11:12 lr 0.000432	time 0.6139 (0.5840)	loss 2.3843 (3.2018)	grad_norm 1.6527 (1.6365)	mem 17417MB
[2023-02-01 22:18:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][150/1251]	eta 0:10:38 lr 0.000432	time 0.5692 (0.5797)	loss 3.7700 (3.1889)	grad_norm 1.7517 (1.6333)	mem 17417MB
[2023-02-01 22:18:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][200/1251]	eta 0:10:05 lr 0.000432	time 0.5610 (0.5765)	loss 3.7533 (3.1919)	grad_norm 1.6318 (1.6244)	mem 17417MB
[2023-02-01 22:19:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][250/1251]	eta 0:09:36 lr 0.000432	time 0.6297 (0.5757)	loss 3.1484 (3.1730)	grad_norm 1.4615 (1.6243)	mem 17417MB
[2023-02-01 22:19:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][300/1251]	eta 0:09:06 lr 0.000431	time 0.5526 (0.5751)	loss 2.2442 (3.1450)	grad_norm 1.6953 (1.6174)	mem 17417MB
[2023-02-01 22:20:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][350/1251]	eta 0:08:37 lr 0.000431	time 0.5584 (0.5742)	loss 3.0971 (3.1451)	grad_norm 1.5570 (1.6147)	mem 17417MB
[2023-02-01 22:20:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][400/1251]	eta 0:08:08 lr 0.000431	time 0.5570 (0.5737)	loss 3.1743 (3.1419)	grad_norm 1.5929 (1.6204)	mem 17417MB
[2023-02-01 22:21:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][450/1251]	eta 0:07:39 lr 0.000431	time 0.5648 (0.5730)	loss 2.2360 (3.1462)	grad_norm 1.6886 (1.6168)	mem 17417MB
[2023-02-01 22:21:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][500/1251]	eta 0:07:10 lr 0.000431	time 0.6214 (0.5729)	loss 3.6621 (3.1367)	grad_norm 1.8302 (1.6148)	mem 17417MB
[2023-02-01 22:22:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][550/1251]	eta 0:06:41 lr 0.000430	time 0.5507 (0.5725)	loss 3.7887 (3.1346)	grad_norm 1.6062 (1.6146)	mem 17417MB
[2023-02-01 22:22:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][600/1251]	eta 0:06:12 lr 0.000430	time 0.5547 (0.5726)	loss 3.7348 (3.1383)	grad_norm 1.4087 (1.6157)	mem 17417MB
[2023-02-01 22:23:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][650/1251]	eta 0:05:43 lr 0.000430	time 0.5539 (0.5722)	loss 3.4018 (3.1418)	grad_norm 1.6082 (1.6158)	mem 17417MB
[2023-02-01 22:23:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][700/1251]	eta 0:05:15 lr 0.000430	time 0.5551 (0.5722)	loss 3.0429 (3.1387)	grad_norm 1.6159 (1.6149)	mem 17417MB
[2023-02-01 22:24:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][750/1251]	eta 0:04:46 lr 0.000430	time 0.5549 (0.5719)	loss 3.2148 (3.1450)	grad_norm 1.9633 (1.6165)	mem 17417MB
[2023-02-01 22:24:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][800/1251]	eta 0:04:17 lr 0.000429	time 0.5538 (0.5719)	loss 3.2548 (3.1440)	grad_norm 1.7954 (1.6175)	mem 17417MB
[2023-02-01 22:25:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][850/1251]	eta 0:03:49 lr 0.000429	time 0.5582 (0.5717)	loss 3.5507 (3.1411)	grad_norm 1.6740 (1.6201)	mem 17417MB
[2023-02-01 22:25:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][900/1251]	eta 0:03:20 lr 0.000429	time 0.6153 (0.5717)	loss 3.7992 (3.1452)	grad_norm 1.6103 (1.6182)	mem 17417MB
[2023-02-01 22:26:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][950/1251]	eta 0:02:52 lr 0.000429	time 0.5594 (0.5717)	loss 2.3520 (3.1442)	grad_norm 1.6034 (1.6185)	mem 17417MB
[2023-02-01 22:26:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][1000/1251]	eta 0:02:23 lr 0.000429	time 0.5576 (0.5716)	loss 2.1435 (3.1396)	grad_norm 1.7857 (1.6180)	mem 17417MB
[2023-02-01 22:27:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][1050/1251]	eta 0:01:54 lr 0.000428	time 0.5597 (0.5714)	loss 2.3514 (3.1392)	grad_norm 1.7017 (1.6197)	mem 17417MB
[2023-02-01 22:27:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][1100/1251]	eta 0:01:26 lr 0.000428	time 0.5529 (0.5715)	loss 3.5953 (3.1381)	grad_norm 1.6586 (1.6175)	mem 17417MB
[2023-02-01 22:27:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][1150/1251]	eta 0:00:57 lr 0.000428	time 0.5627 (0.5714)	loss 2.9298 (3.1419)	grad_norm 1.5186 (1.6194)	mem 17417MB
[2023-02-01 22:28:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][1200/1251]	eta 0:00:29 lr 0.000428	time 0.5672 (0.5713)	loss 2.6259 (3.1391)	grad_norm 2.0492 (1.6181)	mem 17417MB
[2023-02-01 22:28:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [164/300][1250/1251]	eta 0:00:00 lr 0.000428	time 0.6204 (0.5712)	loss 2.5675 (3.1423)	grad_norm 1.4703 (1.6203)	mem 17417MB
[2023-02-01 22:28:55 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 164 training takes 0:11:54
[2023-02-01 22:28:56 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_164.pth saving......
[2023-02-01 22:28:57 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_164.pth saved !!!
[2023-02-01 22:28:58 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.860 (0.860)	Loss 0.7957 (0.7957)	Acc@1 80.078 (80.078)	Acc@5 95.996 (95.996)	Mem 17417MB
[2023-02-01 22:29:06 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.548 Acc@5 95.662
[2023-02-01 22:29:06 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.5%
[2023-02-01 22:29:07 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.213 (1.213)	Loss 0.6419 (0.6419)	Acc@1 85.156 (85.156)	Acc@5 97.266 (97.266)	Mem 17417MB
[2023-02-01 22:29:15 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.274 Acc@5 96.288
[2023-02-01 22:29:15 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.3%
[2023-02-01 22:29:15 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.30% at 163 epoch
[2023-02-01 22:29:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][0/1251]	eta 0:34:39 lr 0.000428	time 1.6620 (1.6620)	loss 2.9023 (2.9023)	grad_norm 1.7364 (1.7364)	mem 17417MB
[2023-02-01 22:29:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][50/1251]	eta 0:11:50 lr 0.000427	time 0.5498 (0.5919)	loss 2.9002 (3.0786)	grad_norm 1.6513 (1.6405)	mem 17417MB
[2023-02-01 22:30:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][100/1251]	eta 0:11:10 lr 0.000427	time 0.5560 (0.5825)	loss 3.0377 (3.1649)	grad_norm 1.6498 (1.6241)	mem 17417MB
[2023-02-01 22:30:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][150/1251]	eta 0:10:38 lr 0.000427	time 0.5544 (0.5796)	loss 2.4193 (3.1114)	grad_norm 1.7339 (1.6341)	mem 17417MB
[2023-02-01 22:31:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][200/1251]	eta 0:10:07 lr 0.000427	time 0.5573 (0.5777)	loss 3.0031 (3.1187)	grad_norm 1.4945 (nan)	mem 17417MB
[2023-02-01 22:31:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][250/1251]	eta 0:09:36 lr 0.000427	time 0.6229 (0.5762)	loss 3.3296 (3.1350)	grad_norm 1.7175 (nan)	mem 17417MB
[2023-02-01 22:32:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][300/1251]	eta 0:09:07 lr 0.000426	time 0.5547 (0.5754)	loss 2.1715 (3.1256)	grad_norm 1.3522 (nan)	mem 17417MB
[2023-02-01 22:32:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][350/1251]	eta 0:08:37 lr 0.000426	time 0.5705 (0.5747)	loss 3.1964 (3.1191)	grad_norm 1.4869 (nan)	mem 17417MB
[2023-02-01 22:33:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][400/1251]	eta 0:08:08 lr 0.000426	time 0.5529 (0.5742)	loss 2.9151 (3.1181)	grad_norm 1.4515 (nan)	mem 17417MB
[2023-02-01 22:33:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][450/1251]	eta 0:07:39 lr 0.000426	time 0.6188 (0.5740)	loss 2.3433 (3.1175)	grad_norm 1.6945 (nan)	mem 17417MB
[2023-02-01 22:34:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][500/1251]	eta 0:07:10 lr 0.000426	time 0.5591 (0.5737)	loss 3.6996 (3.1253)	grad_norm 1.5984 (nan)	mem 17417MB
[2023-02-01 22:34:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][550/1251]	eta 0:06:41 lr 0.000425	time 0.5559 (0.5733)	loss 3.6097 (3.1253)	grad_norm 1.6057 (nan)	mem 17417MB
[2023-02-01 22:35:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][600/1251]	eta 0:06:13 lr 0.000425	time 0.5555 (0.5733)	loss 3.6177 (3.1303)	grad_norm 1.5117 (nan)	mem 17417MB
[2023-02-01 22:35:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][650/1251]	eta 0:05:44 lr 0.000425	time 0.5602 (0.5729)	loss 2.6130 (3.1334)	grad_norm 1.8029 (nan)	mem 17417MB
[2023-02-01 22:35:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][700/1251]	eta 0:05:15 lr 0.000425	time 0.5588 (0.5731)	loss 3.2614 (3.1454)	grad_norm 1.4006 (nan)	mem 17417MB
[2023-02-01 22:36:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][750/1251]	eta 0:04:47 lr 0.000424	time 0.6291 (0.5729)	loss 2.7625 (3.1456)	grad_norm 1.5057 (nan)	mem 17417MB
[2023-02-01 22:36:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][800/1251]	eta 0:04:18 lr 0.000424	time 0.5569 (0.5728)	loss 2.7776 (3.1436)	grad_norm 1.4795 (nan)	mem 17417MB
[2023-02-01 22:37:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][850/1251]	eta 0:03:49 lr 0.000424	time 0.5520 (0.5728)	loss 3.0497 (3.1392)	grad_norm 1.5425 (nan)	mem 17417MB
[2023-02-01 22:37:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][900/1251]	eta 0:03:21 lr 0.000424	time 0.5595 (0.5728)	loss 2.8299 (3.1355)	grad_norm 1.5358 (nan)	mem 17417MB
[2023-02-01 22:38:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][950/1251]	eta 0:02:52 lr 0.000424	time 0.5776 (0.5726)	loss 3.3563 (3.1294)	grad_norm 1.6685 (nan)	mem 17417MB
[2023-02-01 22:38:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][1000/1251]	eta 0:02:23 lr 0.000423	time 0.5576 (0.5726)	loss 3.1551 (3.1281)	grad_norm 1.7452 (nan)	mem 17417MB
[2023-02-01 22:39:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][1050/1251]	eta 0:01:55 lr 0.000423	time 0.5635 (0.5726)	loss 3.4474 (3.1309)	grad_norm 1.4741 (nan)	mem 17417MB
[2023-02-01 22:39:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][1100/1251]	eta 0:01:26 lr 0.000423	time 0.6318 (0.5725)	loss 3.3819 (3.1239)	grad_norm 1.4947 (nan)	mem 17417MB
[2023-02-01 22:40:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][1150/1251]	eta 0:00:57 lr 0.000423	time 0.5542 (0.5725)	loss 3.6489 (3.1258)	grad_norm 1.4183 (nan)	mem 17417MB
[2023-02-01 22:40:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][1200/1251]	eta 0:00:29 lr 0.000423	time 0.5550 (0.5724)	loss 3.3472 (3.1296)	grad_norm 1.5160 (nan)	mem 17417MB
[2023-02-01 22:41:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [165/300][1250/1251]	eta 0:00:00 lr 0.000422	time 0.5524 (0.5723)	loss 3.8962 (3.1240)	grad_norm 1.6023 (nan)	mem 17417MB
[2023-02-01 22:41:12 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 165 training takes 0:11:56
[2023-02-01 22:41:12 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_165.pth saving......
[2023-02-01 22:41:13 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_165.pth saved !!!
[2023-02-01 22:41:14 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.893 (0.893)	Loss 0.8558 (0.8558)	Acc@1 80.566 (80.566)	Acc@5 94.336 (94.336)	Mem 17417MB
[2023-02-01 22:41:22 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.742 Acc@5 95.646
[2023-02-01 22:41:22 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.7%
[2023-02-01 22:41:24 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.404 (1.404)	Loss 0.6959 (0.6959)	Acc@1 84.277 (84.277)	Acc@5 96.973 (96.973)	Mem 17417MB
[2023-02-01 22:41:32 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.270 Acc@5 96.298
[2023-02-01 22:41:32 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.3%
[2023-02-01 22:41:32 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.30% at 163 epoch
[2023-02-01 22:41:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][0/1251]	eta 0:34:16 lr 0.000422	time 1.6437 (1.6437)	loss 3.7549 (3.7549)	grad_norm 1.7541 (1.7541)	mem 17417MB
[2023-02-01 22:42:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][50/1251]	eta 0:11:53 lr 0.000422	time 0.6389 (0.5944)	loss 3.5915 (3.0911)	grad_norm 1.4109 (1.6668)	mem 17417MB
[2023-02-01 22:42:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][100/1251]	eta 0:11:11 lr 0.000422	time 0.5650 (0.5836)	loss 3.5372 (3.1415)	grad_norm 1.5833 (1.6430)	mem 17417MB
[2023-02-01 22:42:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][150/1251]	eta 0:10:36 lr 0.000422	time 0.5577 (0.5783)	loss 2.5369 (3.0936)	grad_norm 1.6825 (1.6351)	mem 17417MB
[2023-02-01 22:43:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][200/1251]	eta 0:10:06 lr 0.000422	time 0.5568 (0.5767)	loss 3.0273 (3.0800)	grad_norm 1.5743 (1.6355)	mem 17417MB
[2023-02-01 22:43:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][250/1251]	eta 0:09:35 lr 0.000421	time 0.5540 (0.5751)	loss 3.5634 (3.0705)	grad_norm 1.6633 (1.6432)	mem 17417MB
[2023-02-01 22:44:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][300/1251]	eta 0:09:06 lr 0.000421	time 0.5628 (0.5746)	loss 3.4901 (3.0905)	grad_norm 1.5923 (1.6497)	mem 17417MB
[2023-02-01 22:44:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][350/1251]	eta 0:08:36 lr 0.000421	time 0.5566 (0.5736)	loss 3.5897 (3.1056)	grad_norm 1.4979 (1.6458)	mem 17417MB
[2023-02-01 22:45:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][400/1251]	eta 0:08:07 lr 0.000421	time 0.5545 (0.5732)	loss 2.8130 (3.1006)	grad_norm 1.6101 (1.6479)	mem 17417MB
[2023-02-01 22:45:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][450/1251]	eta 0:07:38 lr 0.000421	time 0.5592 (0.5730)	loss 3.5137 (3.0976)	grad_norm 1.6286 (1.6474)	mem 17417MB
[2023-02-01 22:46:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][500/1251]	eta 0:07:09 lr 0.000420	time 0.5544 (0.5722)	loss 3.1521 (3.0973)	grad_norm 1.5264 (1.6436)	mem 17417MB
[2023-02-01 22:46:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][550/1251]	eta 0:06:41 lr 0.000420	time 0.5516 (0.5723)	loss 2.3939 (3.0994)	grad_norm 1.7830 (1.6436)	mem 17417MB
[2023-02-01 22:47:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][600/1251]	eta 0:06:12 lr 0.000420	time 0.5576 (0.5723)	loss 2.9124 (3.1050)	grad_norm 1.5084 (1.6439)	mem 17417MB
[2023-02-01 22:47:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][650/1251]	eta 0:05:43 lr 0.000420	time 0.5515 (0.5721)	loss 3.3040 (3.1053)	grad_norm 1.7660 (1.6412)	mem 17417MB
[2023-02-01 22:48:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][700/1251]	eta 0:05:15 lr 0.000420	time 0.5556 (0.5720)	loss 3.5464 (3.1101)	grad_norm 1.9079 (1.6403)	mem 17417MB
[2023-02-01 22:48:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][750/1251]	eta 0:04:46 lr 0.000419	time 0.5521 (0.5715)	loss 3.2837 (3.1105)	grad_norm 1.5259 (1.6390)	mem 17417MB
[2023-02-01 22:49:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][800/1251]	eta 0:04:17 lr 0.000419	time 0.6212 (0.5717)	loss 2.5690 (3.1023)	grad_norm 1.6823 (1.6400)	mem 17417MB
[2023-02-01 22:49:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][850/1251]	eta 0:03:49 lr 0.000419	time 0.5551 (0.5714)	loss 3.8239 (3.1002)	grad_norm 1.6764 (1.6387)	mem 17417MB
[2023-02-01 22:50:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][900/1251]	eta 0:03:20 lr 0.000419	time 0.5593 (0.5714)	loss 3.6175 (3.1027)	grad_norm 1.9601 (1.6388)	mem 17417MB
[2023-02-01 22:50:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][950/1251]	eta 0:02:51 lr 0.000419	time 0.5548 (0.5713)	loss 3.0151 (3.1094)	grad_norm 1.5121 (1.6409)	mem 17417MB
[2023-02-01 22:51:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][1000/1251]	eta 0:02:23 lr 0.000418	time 0.5508 (0.5712)	loss 3.5285 (3.1091)	grad_norm 1.5833 (1.6416)	mem 17417MB
[2023-02-01 22:51:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][1050/1251]	eta 0:01:54 lr 0.000418	time 0.5542 (0.5712)	loss 3.4044 (3.1005)	grad_norm 1.7368 (1.6392)	mem 17417MB
[2023-02-01 22:52:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][1100/1251]	eta 0:01:26 lr 0.000418	time 0.6333 (0.5712)	loss 3.3187 (3.1032)	grad_norm 1.7629 (1.6387)	mem 17417MB
[2023-02-01 22:52:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][1150/1251]	eta 0:00:57 lr 0.000418	time 0.5615 (0.5709)	loss 3.0204 (3.1067)	grad_norm 1.6628 (1.6384)	mem 17417MB
[2023-02-01 22:52:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][1200/1251]	eta 0:00:29 lr 0.000418	time 0.5585 (0.5709)	loss 3.4464 (3.1126)	grad_norm 1.6823 (1.6374)	mem 17417MB
[2023-02-01 22:53:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [166/300][1250/1251]	eta 0:00:00 lr 0.000417	time 0.5511 (0.5709)	loss 3.4507 (3.1148)	grad_norm 1.5286 (1.6377)	mem 17417MB
[2023-02-01 22:53:26 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 166 training takes 0:11:54
[2023-02-01 22:53:26 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_166.pth saving......
[2023-02-01 22:53:28 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_166.pth saved !!!
[2023-02-01 22:53:29 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.883 (0.883)	Loss 0.8015 (0.8015)	Acc@1 79.980 (79.980)	Acc@5 95.312 (95.312)	Mem 17417MB
[2023-02-01 22:53:37 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.628 Acc@5 95.608
[2023-02-01 22:53:37 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.6%
[2023-02-01 22:53:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.191 (1.191)	Loss 0.7486 (0.7486)	Acc@1 82.812 (82.812)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-01 22:53:46 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.300 Acc@5 96.318
[2023-02-01 22:53:46 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.3%
[2023-02-01 22:53:46 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.30% at 166 epoch
[2023-02-01 22:53:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][0/1251]	eta 0:35:13 lr 0.000417	time 1.6892 (1.6892)	loss 3.7612 (3.7612)	grad_norm 1.6382 (1.6382)	mem 17417MB
[2023-02-01 22:54:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][50/1251]	eta 0:11:54 lr 0.000417	time 0.5576 (0.5947)	loss 3.4026 (3.1221)	grad_norm 1.6515 (1.6403)	mem 17417MB
[2023-02-01 22:54:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][100/1251]	eta 0:11:12 lr 0.000417	time 0.6276 (0.5845)	loss 3.0958 (3.1197)	grad_norm 1.4666 (nan)	mem 17417MB
[2023-02-01 22:55:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][150/1251]	eta 0:10:36 lr 0.000417	time 0.5551 (0.5779)	loss 2.4055 (3.1429)	grad_norm 1.5957 (nan)	mem 17417MB
[2023-02-01 22:55:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][200/1251]	eta 0:10:06 lr 0.000417	time 0.5638 (0.5770)	loss 3.4951 (3.1817)	grad_norm 1.6335 (nan)	mem 17417MB
[2023-02-01 22:56:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][250/1251]	eta 0:09:35 lr 0.000416	time 0.5617 (0.5745)	loss 2.3850 (3.1928)	grad_norm 1.6751 (nan)	mem 17417MB
[2023-02-01 22:56:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][300/1251]	eta 0:09:05 lr 0.000416	time 0.5585 (0.5739)	loss 3.5425 (3.1885)	grad_norm 1.6893 (nan)	mem 17417MB
[2023-02-01 22:57:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][350/1251]	eta 0:08:36 lr 0.000416	time 0.5573 (0.5731)	loss 3.2324 (3.1599)	grad_norm 1.4668 (nan)	mem 17417MB
[2023-02-01 22:57:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][400/1251]	eta 0:08:07 lr 0.000416	time 0.5603 (0.5731)	loss 3.6704 (3.1544)	grad_norm 1.6996 (nan)	mem 17417MB
[2023-02-01 22:58:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][450/1251]	eta 0:07:38 lr 0.000416	time 0.5569 (0.5726)	loss 3.4399 (3.1524)	grad_norm 1.5207 (nan)	mem 17417MB
[2023-02-01 22:58:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][500/1251]	eta 0:07:09 lr 0.000415	time 0.6232 (0.5725)	loss 3.7280 (3.1535)	grad_norm 1.5357 (nan)	mem 17417MB
[2023-02-01 22:59:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][550/1251]	eta 0:06:40 lr 0.000415	time 0.6213 (0.5719)	loss 3.2741 (3.1568)	grad_norm 1.4953 (nan)	mem 17417MB
[2023-02-01 22:59:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][600/1251]	eta 0:06:12 lr 0.000415	time 0.5534 (0.5720)	loss 3.8492 (3.1576)	grad_norm 1.9859 (nan)	mem 17417MB
[2023-02-01 22:59:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][650/1251]	eta 0:05:43 lr 0.000415	time 0.5535 (0.5719)	loss 3.4092 (3.1585)	grad_norm 1.4298 (nan)	mem 17417MB
[2023-02-01 23:00:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][700/1251]	eta 0:05:15 lr 0.000414	time 0.5562 (0.5718)	loss 3.5935 (3.1545)	grad_norm 1.7100 (nan)	mem 17417MB
[2023-02-01 23:00:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][750/1251]	eta 0:04:46 lr 0.000414	time 0.5624 (0.5717)	loss 3.2072 (3.1436)	grad_norm 1.5701 (nan)	mem 17417MB
[2023-02-01 23:01:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][800/1251]	eta 0:04:17 lr 0.000414	time 0.5616 (0.5716)	loss 2.8543 (3.1481)	grad_norm 1.4468 (nan)	mem 17417MB
[2023-02-01 23:01:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][850/1251]	eta 0:03:49 lr 0.000414	time 0.5537 (0.5714)	loss 3.2822 (3.1435)	grad_norm 1.6174 (nan)	mem 17417MB
[2023-02-01 23:02:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][900/1251]	eta 0:03:20 lr 0.000414	time 0.5511 (0.5713)	loss 2.2948 (3.1387)	grad_norm 1.6705 (nan)	mem 17417MB
[2023-02-01 23:02:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][950/1251]	eta 0:02:51 lr 0.000413	time 0.5486 (0.5711)	loss 2.2759 (3.1377)	grad_norm 1.9631 (nan)	mem 17417MB
[2023-02-01 23:03:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][1000/1251]	eta 0:02:23 lr 0.000413	time 0.5542 (0.5712)	loss 2.1851 (3.1372)	grad_norm 1.5666 (nan)	mem 17417MB
[2023-02-01 23:03:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][1050/1251]	eta 0:01:54 lr 0.000413	time 0.5589 (0.5711)	loss 2.3826 (3.1337)	grad_norm 1.6283 (nan)	mem 17417MB
[2023-02-01 23:04:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][1100/1251]	eta 0:01:26 lr 0.000413	time 0.6146 (0.5709)	loss 3.3419 (3.1338)	grad_norm 1.5236 (nan)	mem 17417MB
[2023-02-01 23:04:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][1150/1251]	eta 0:00:57 lr 0.000413	time 0.5569 (0.5708)	loss 2.8603 (3.1319)	grad_norm 2.0751 (nan)	mem 17417MB
[2023-02-01 23:05:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][1200/1251]	eta 0:00:29 lr 0.000412	time 0.6340 (0.5707)	loss 3.8208 (3.1292)	grad_norm 1.9699 (nan)	mem 17417MB
[2023-02-01 23:05:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [167/300][1250/1251]	eta 0:00:00 lr 0.000412	time 0.5475 (0.5707)	loss 2.5905 (3.1254)	grad_norm 1.6074 (nan)	mem 17417MB
[2023-02-01 23:05:40 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 167 training takes 0:11:54
[2023-02-01 23:05:40 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_167.pth saving......
[2023-02-01 23:05:42 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_167.pth saved !!!
[2023-02-01 23:05:43 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.834 (0.834)	Loss 0.8270 (0.8270)	Acc@1 80.371 (80.371)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-01 23:05:51 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.694 Acc@5 95.712
[2023-02-01 23:05:51 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.7%
[2023-02-01 23:05:52 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.213 (1.213)	Loss 0.7325 (0.7325)	Acc@1 82.715 (82.715)	Acc@5 97.168 (97.168)	Mem 17417MB
[2023-02-01 23:06:00 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.298 Acc@5 96.318
[2023-02-01 23:06:00 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.3%
[2023-02-01 23:06:00 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.30% at 166 epoch
[2023-02-01 23:06:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][0/1251]	eta 0:36:47 lr 0.000412	time 1.7648 (1.7648)	loss 3.4762 (3.4762)	grad_norm 1.5073 (1.5073)	mem 17417MB
[2023-02-01 23:06:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][50/1251]	eta 0:11:56 lr 0.000412	time 0.5571 (0.5963)	loss 3.1108 (3.1171)	grad_norm 1.4688 (1.6299)	mem 17417MB
[2023-02-01 23:06:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][100/1251]	eta 0:11:09 lr 0.000412	time 0.5577 (0.5819)	loss 3.2961 (3.1575)	grad_norm 1.6567 (1.6373)	mem 17417MB
[2023-02-01 23:07:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][150/1251]	eta 0:10:36 lr 0.000412	time 0.5525 (0.5780)	loss 2.8203 (3.0884)	grad_norm 1.9263 (1.6405)	mem 17417MB
[2023-02-01 23:07:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][200/1251]	eta 0:10:04 lr 0.000411	time 0.6164 (0.5750)	loss 2.8705 (3.0733)	grad_norm 1.7178 (1.6334)	mem 17417MB
[2023-02-01 23:08:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][250/1251]	eta 0:09:34 lr 0.000411	time 0.5665 (0.5736)	loss 3.0729 (3.0707)	grad_norm 1.6583 (1.6260)	mem 17417MB
[2023-02-01 23:08:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][300/1251]	eta 0:09:05 lr 0.000411	time 0.5508 (0.5734)	loss 3.0963 (3.0673)	grad_norm 1.4532 (1.6273)	mem 17417MB
[2023-02-01 23:09:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][350/1251]	eta 0:08:36 lr 0.000411	time 0.5558 (0.5728)	loss 2.9902 (3.0827)	grad_norm 1.7822 (1.6240)	mem 17417MB
[2023-02-01 23:09:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][400/1251]	eta 0:08:07 lr 0.000411	time 0.5544 (0.5725)	loss 3.1310 (3.0817)	grad_norm 1.4435 (1.6276)	mem 17417MB
[2023-02-01 23:10:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][450/1251]	eta 0:07:38 lr 0.000410	time 0.5500 (0.5723)	loss 3.8089 (3.0759)	grad_norm 1.5912 (1.6292)	mem 17417MB
[2023-02-01 23:10:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][500/1251]	eta 0:07:09 lr 0.000410	time 0.5541 (0.5717)	loss 2.8662 (3.0794)	grad_norm 1.6369 (1.6316)	mem 17417MB
[2023-02-01 23:11:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][550/1251]	eta 0:06:40 lr 0.000410	time 0.5571 (0.5714)	loss 3.5437 (3.0692)	grad_norm 1.6416 (1.6363)	mem 17417MB
[2023-02-01 23:11:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][600/1251]	eta 0:06:11 lr 0.000410	time 0.5543 (0.5712)	loss 3.5054 (3.0804)	grad_norm 1.6986 (1.6407)	mem 17417MB
[2023-02-01 23:12:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][650/1251]	eta 0:05:43 lr 0.000410	time 0.5576 (0.5713)	loss 3.2609 (3.0759)	grad_norm 1.5877 (1.6418)	mem 17417MB
[2023-02-01 23:12:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][700/1251]	eta 0:05:14 lr 0.000409	time 0.5631 (0.5711)	loss 2.4939 (3.0775)	grad_norm 1.6772 (1.6434)	mem 17417MB
[2023-02-01 23:13:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][750/1251]	eta 0:04:45 lr 0.000409	time 0.5470 (0.5708)	loss 2.6856 (3.0804)	grad_norm 1.8138 (1.6431)	mem 17417MB
[2023-02-01 23:13:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][800/1251]	eta 0:04:17 lr 0.000409	time 0.5492 (0.5708)	loss 2.5207 (3.0810)	grad_norm 1.6090 (1.6391)	mem 17417MB
[2023-02-01 23:14:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][850/1251]	eta 0:03:48 lr 0.000409	time 0.5634 (0.5708)	loss 3.6954 (3.0965)	grad_norm 1.6385 (1.6386)	mem 17417MB
[2023-02-01 23:14:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][900/1251]	eta 0:03:20 lr 0.000409	time 0.5581 (0.5707)	loss 3.1179 (3.0976)	grad_norm 1.4707 (1.6390)	mem 17417MB
[2023-02-01 23:15:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][950/1251]	eta 0:02:51 lr 0.000408	time 0.5538 (0.5707)	loss 3.3244 (3.0966)	grad_norm 1.6701 (1.6438)	mem 17417MB
[2023-02-01 23:15:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][1000/1251]	eta 0:02:23 lr 0.000408	time 0.5531 (0.5707)	loss 2.1533 (3.0998)	grad_norm 1.7599 (1.6436)	mem 17417MB
[2023-02-01 23:16:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][1050/1251]	eta 0:01:54 lr 0.000408	time 0.5619 (0.5705)	loss 3.4470 (3.1026)	grad_norm 1.5633 (1.6426)	mem 17417MB
[2023-02-01 23:16:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][1100/1251]	eta 0:01:26 lr 0.000408	time 0.5571 (0.5707)	loss 3.1508 (3.1020)	grad_norm 2.0118 (1.6433)	mem 17417MB
[2023-02-01 23:16:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][1150/1251]	eta 0:00:57 lr 0.000408	time 0.5528 (0.5706)	loss 2.9026 (3.0936)	grad_norm 1.4209 (1.6417)	mem 17417MB
[2023-02-01 23:17:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][1200/1251]	eta 0:00:29 lr 0.000407	time 0.5578 (0.5706)	loss 3.0010 (3.0857)	grad_norm 1.5336 (1.6415)	mem 17417MB
[2023-02-01 23:17:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [168/300][1250/1251]	eta 0:00:00 lr 0.000407	time 0.5499 (0.5707)	loss 3.7718 (3.0897)	grad_norm 1.6422 (1.6437)	mem 17417MB
[2023-02-01 23:17:54 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 168 training takes 0:11:54
[2023-02-01 23:17:54 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_168.pth saving......
[2023-02-01 23:17:56 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_168.pth saved !!!
[2023-02-01 23:17:57 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.886 (0.886)	Loss 0.7894 (0.7894)	Acc@1 82.617 (82.617)	Acc@5 95.117 (95.117)	Mem 17417MB
[2023-02-01 23:18:05 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.898 Acc@5 95.710
[2023-02-01 23:18:05 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.9%
[2023-02-01 23:18:06 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.383 (1.383)	Loss 0.7350 (0.7350)	Acc@1 83.203 (83.203)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-01 23:18:14 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.316 Acc@5 96.344
[2023-02-01 23:18:14 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.3%
[2023-02-01 23:18:14 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.32% at 168 epoch
[2023-02-01 23:18:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][0/1251]	eta 0:34:42 lr 0.000407	time 1.6650 (1.6650)	loss 3.5459 (3.5459)	grad_norm 1.7668 (1.7668)	mem 17417MB
[2023-02-01 23:18:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][50/1251]	eta 0:11:50 lr 0.000407	time 0.5555 (0.5913)	loss 3.1277 (2.9354)	grad_norm 1.5085 (1.6394)	mem 17417MB
[2023-02-01 23:19:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][100/1251]	eta 0:11:11 lr 0.000407	time 0.5487 (0.5833)	loss 3.5196 (3.0311)	grad_norm 1.7729 (1.6590)	mem 17417MB
[2023-02-01 23:19:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][150/1251]	eta 0:10:37 lr 0.000407	time 0.5557 (0.5787)	loss 2.9955 (3.0538)	grad_norm 1.7350 (1.6634)	mem 17417MB
[2023-02-01 23:20:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][200/1251]	eta 0:10:05 lr 0.000406	time 0.5587 (0.5759)	loss 3.5128 (3.0416)	grad_norm 1.6753 (1.6574)	mem 17417MB
[2023-02-01 23:20:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][250/1251]	eta 0:09:35 lr 0.000406	time 0.5526 (0.5752)	loss 3.2513 (3.0716)	grad_norm 1.5043 (1.6563)	mem 17417MB
[2023-02-01 23:21:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][300/1251]	eta 0:09:06 lr 0.000406	time 0.5602 (0.5743)	loss 2.8838 (3.0752)	grad_norm 1.6253 (1.6533)	mem 17417MB
[2023-02-01 23:21:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][350/1251]	eta 0:08:36 lr 0.000406	time 0.5666 (0.5734)	loss 2.6865 (3.0717)	grad_norm 1.6191 (1.6467)	mem 17417MB
[2023-02-01 23:22:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][400/1251]	eta 0:08:07 lr 0.000406	time 0.5575 (0.5732)	loss 3.4184 (3.0778)	grad_norm 1.6129 (1.6465)	mem 17417MB
[2023-02-01 23:22:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][450/1251]	eta 0:07:38 lr 0.000405	time 0.6164 (0.5728)	loss 2.4805 (3.0860)	grad_norm 1.4282 (1.6454)	mem 17417MB
[2023-02-01 23:23:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][500/1251]	eta 0:07:10 lr 0.000405	time 0.5500 (0.5728)	loss 3.4773 (3.0935)	grad_norm 1.7363 (1.6408)	mem 17417MB
[2023-02-01 23:23:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][550/1251]	eta 0:06:41 lr 0.000405	time 0.6475 (0.5723)	loss 3.0463 (3.0993)	grad_norm 1.7661 (1.6444)	mem 17417MB
[2023-02-01 23:23:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][600/1251]	eta 0:06:12 lr 0.000405	time 0.5582 (0.5722)	loss 2.5639 (3.1099)	grad_norm 1.5409 (1.6458)	mem 17417MB
[2023-02-01 23:24:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][650/1251]	eta 0:05:43 lr 0.000405	time 0.5588 (0.5719)	loss 3.5707 (3.1090)	grad_norm 1.4323 (1.6471)	mem 17417MB
[2023-02-01 23:24:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][700/1251]	eta 0:05:15 lr 0.000404	time 0.5574 (0.5720)	loss 3.2760 (3.1108)	grad_norm 1.7105 (1.6470)	mem 17417MB
[2023-02-01 23:25:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][750/1251]	eta 0:04:46 lr 0.000404	time 0.5536 (0.5715)	loss 3.8486 (3.1139)	grad_norm 1.5492 (1.6459)	mem 17417MB
[2023-02-01 23:25:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][800/1251]	eta 0:04:17 lr 0.000404	time 0.6186 (0.5717)	loss 3.6329 (3.1110)	grad_norm 2.0464 (1.6463)	mem 17417MB
[2023-02-01 23:26:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][850/1251]	eta 0:03:49 lr 0.000404	time 0.5517 (0.5714)	loss 3.0705 (3.1070)	grad_norm 1.7111 (1.6467)	mem 17417MB
[2023-02-01 23:26:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][900/1251]	eta 0:03:20 lr 0.000404	time 0.5616 (0.5713)	loss 3.4158 (3.1043)	grad_norm 1.4204 (1.6456)	mem 17417MB
[2023-02-01 23:27:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][950/1251]	eta 0:02:51 lr 0.000403	time 0.5538 (0.5713)	loss 3.1581 (3.1035)	grad_norm 1.5636 (1.6453)	mem 17417MB
[2023-02-01 23:27:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][1000/1251]	eta 0:02:23 lr 0.000403	time 0.6280 (0.5712)	loss 3.7482 (3.1108)	grad_norm 1.7257 (1.6453)	mem 17417MB
[2023-02-01 23:28:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][1050/1251]	eta 0:01:54 lr 0.000403	time 0.5611 (0.5714)	loss 2.8757 (3.1131)	grad_norm 1.5219 (1.6458)	mem 17417MB
[2023-02-01 23:28:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][1100/1251]	eta 0:01:26 lr 0.000403	time 0.5560 (0.5711)	loss 3.3654 (3.1118)	grad_norm 1.8637 (1.6470)	mem 17417MB
[2023-02-01 23:29:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][1150/1251]	eta 0:00:57 lr 0.000402	time 0.5489 (0.5710)	loss 3.7472 (3.1137)	grad_norm 1.9531 (1.6483)	mem 17417MB
[2023-02-01 23:29:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][1200/1251]	eta 0:00:29 lr 0.000402	time 0.5598 (0.5710)	loss 1.8479 (3.1104)	grad_norm 1.6428 (1.6481)	mem 17417MB
[2023-02-01 23:30:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [169/300][1250/1251]	eta 0:00:00 lr 0.000402	time 0.6054 (0.5709)	loss 2.8030 (3.1108)	grad_norm 1.5873 (1.6492)	mem 17417MB
[2023-02-01 23:30:08 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 169 training takes 0:11:54
[2023-02-01 23:30:09 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_169.pth saving......
[2023-02-01 23:30:10 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_169.pth saved !!!
[2023-02-01 23:30:11 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.859 (0.859)	Loss 0.8376 (0.8376)	Acc@1 82.031 (82.031)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-01 23:30:19 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.704 Acc@5 95.648
[2023-02-01 23:30:19 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.7%
[2023-02-01 23:30:21 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.381 (1.381)	Loss 0.7565 (0.7565)	Acc@1 81.836 (81.836)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-01 23:30:29 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.356 Acc@5 96.372
[2023-02-01 23:30:29 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.4%
[2023-02-01 23:30:29 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.36% at 169 epoch
[2023-02-01 23:30:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][0/1251]	eta 0:36:11 lr 0.000402	time 1.7355 (1.7355)	loss 2.9483 (2.9483)	grad_norm 1.7606 (1.7606)	mem 17417MB
[2023-02-01 23:30:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][50/1251]	eta 0:11:55 lr 0.000402	time 0.6257 (0.5957)	loss 3.3242 (3.0700)	grad_norm 1.7925 (1.6798)	mem 17417MB
[2023-02-01 23:31:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][100/1251]	eta 0:11:11 lr 0.000402	time 0.5726 (0.5838)	loss 3.4794 (3.0759)	grad_norm 1.7451 (1.6905)	mem 17417MB
[2023-02-01 23:31:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][150/1251]	eta 0:10:37 lr 0.000401	time 0.5532 (0.5790)	loss 3.0583 (3.0992)	grad_norm 1.6370 (1.6626)	mem 17417MB
[2023-02-01 23:32:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][200/1251]	eta 0:10:06 lr 0.000401	time 0.5590 (0.5774)	loss 2.5399 (3.1032)	grad_norm 1.7264 (1.6699)	mem 17417MB
[2023-02-01 23:32:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][250/1251]	eta 0:09:36 lr 0.000401	time 0.5615 (0.5762)	loss 4.2176 (3.0954)	grad_norm 1.6642 (1.6633)	mem 17417MB
[2023-02-01 23:33:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][300/1251]	eta 0:09:07 lr 0.000401	time 0.5547 (0.5758)	loss 3.4649 (3.0997)	grad_norm 1.5583 (1.6616)	mem 17417MB
[2023-02-01 23:33:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][350/1251]	eta 0:08:38 lr 0.000401	time 0.5590 (0.5750)	loss 3.0435 (3.0975)	grad_norm 1.6815 (1.6635)	mem 17417MB
[2023-02-01 23:34:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][400/1251]	eta 0:08:08 lr 0.000400	time 0.6185 (0.5743)	loss 3.7089 (3.0902)	grad_norm 1.6470 (1.6691)	mem 17417MB
[2023-02-01 23:34:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][450/1251]	eta 0:07:39 lr 0.000400	time 0.5561 (0.5738)	loss 3.3447 (3.0841)	grad_norm 1.8108 (1.6643)	mem 17417MB
[2023-02-01 23:35:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][500/1251]	eta 0:07:10 lr 0.000400	time 0.5547 (0.5727)	loss 3.0954 (3.0876)	grad_norm 1.7070 (nan)	mem 17417MB
[2023-02-01 23:35:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][550/1251]	eta 0:06:41 lr 0.000400	time 0.5564 (0.5728)	loss 2.5351 (3.0877)	grad_norm 1.5431 (nan)	mem 17417MB
[2023-02-01 23:36:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][600/1251]	eta 0:06:12 lr 0.000400	time 0.5542 (0.5723)	loss 3.2016 (3.0847)	grad_norm 1.5274 (nan)	mem 17417MB
[2023-02-01 23:36:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][650/1251]	eta 0:05:44 lr 0.000399	time 0.5551 (0.5725)	loss 3.8621 (3.0809)	grad_norm 1.7099 (nan)	mem 17417MB
[2023-02-01 23:37:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][700/1251]	eta 0:05:15 lr 0.000399	time 0.5556 (0.5722)	loss 3.2529 (3.0858)	grad_norm 1.5666 (nan)	mem 17417MB
[2023-02-01 23:37:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][750/1251]	eta 0:04:46 lr 0.000399	time 0.5552 (0.5721)	loss 1.9876 (3.0871)	grad_norm 1.6910 (nan)	mem 17417MB
[2023-02-01 23:38:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][800/1251]	eta 0:04:17 lr 0.000399	time 0.5650 (0.5717)	loss 3.6707 (3.0860)	grad_norm 1.6153 (nan)	mem 17417MB
[2023-02-01 23:38:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][850/1251]	eta 0:03:49 lr 0.000399	time 0.5475 (0.5716)	loss 3.2196 (3.0933)	grad_norm 1.5882 (nan)	mem 17417MB
[2023-02-01 23:39:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][900/1251]	eta 0:03:20 lr 0.000398	time 0.5523 (0.5715)	loss 2.3032 (3.0921)	grad_norm 1.5377 (nan)	mem 17417MB
[2023-02-01 23:39:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][950/1251]	eta 0:02:52 lr 0.000398	time 0.5512 (0.5717)	loss 3.7391 (3.0938)	grad_norm 1.7262 (nan)	mem 17417MB
[2023-02-01 23:40:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][1000/1251]	eta 0:02:23 lr 0.000398	time 0.5515 (0.5714)	loss 3.6082 (3.0890)	grad_norm 1.8617 (nan)	mem 17417MB
[2023-02-01 23:40:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][1050/1251]	eta 0:01:54 lr 0.000398	time 0.5536 (0.5715)	loss 2.2412 (3.0863)	grad_norm 1.5925 (nan)	mem 17417MB
[2023-02-01 23:40:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][1100/1251]	eta 0:01:26 lr 0.000398	time 0.5540 (0.5714)	loss 3.5335 (3.0840)	grad_norm 1.6188 (nan)	mem 17417MB
[2023-02-01 23:41:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][1150/1251]	eta 0:00:57 lr 0.000397	time 0.5510 (0.5715)	loss 3.6034 (3.0824)	grad_norm 1.8651 (nan)	mem 17417MB
[2023-02-01 23:41:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][1200/1251]	eta 0:00:29 lr 0.000397	time 0.5574 (0.5713)	loss 3.2210 (3.0885)	grad_norm 1.9051 (nan)	mem 17417MB
[2023-02-01 23:42:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [170/300][1250/1251]	eta 0:00:00 lr 0.000397	time 0.5484 (0.5713)	loss 3.1678 (3.0870)	grad_norm 1.6093 (nan)	mem 17417MB
[2023-02-01 23:42:23 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 170 training takes 0:11:54
[2023-02-01 23:42:24 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_170.pth saving......
[2023-02-01 23:42:25 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_170.pth saved !!!
[2023-02-01 23:42:26 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.841 (0.841)	Loss 0.8613 (0.8613)	Acc@1 79.492 (79.492)	Acc@5 95.801 (95.801)	Mem 17417MB
[2023-02-01 23:42:34 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.726 Acc@5 95.606
[2023-02-01 23:42:34 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.7%
[2023-02-01 23:42:36 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.496 (1.496)	Loss 0.8328 (0.8328)	Acc@1 80.762 (80.762)	Acc@5 95.312 (95.312)	Mem 17417MB
[2023-02-01 23:42:43 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.378 Acc@5 96.354
[2023-02-01 23:42:43 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.4%
[2023-02-01 23:42:43 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.38% at 170 epoch
[2023-02-01 23:42:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][0/1251]	eta 0:36:11 lr 0.000397	time 1.7354 (1.7354)	loss 3.6900 (3.6900)	grad_norm 1.5869 (1.5869)	mem 17417MB
[2023-02-01 23:43:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][50/1251]	eta 0:11:58 lr 0.000397	time 0.5599 (0.5981)	loss 2.2588 (3.0187)	grad_norm 1.7564 (1.6482)	mem 17417MB
[2023-02-01 23:43:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][100/1251]	eta 0:11:12 lr 0.000397	time 0.5552 (0.5839)	loss 1.8272 (3.0109)	grad_norm 1.7692 (1.6723)	mem 17417MB
[2023-02-01 23:44:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][150/1251]	eta 0:10:37 lr 0.000396	time 0.5589 (0.5790)	loss 2.9232 (3.0663)	grad_norm 1.6388 (1.6942)	mem 17417MB
[2023-02-01 23:44:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][200/1251]	eta 0:10:05 lr 0.000396	time 0.5566 (0.5765)	loss 2.5758 (3.0549)	grad_norm 1.4514 (1.6823)	mem 17417MB
[2023-02-01 23:45:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][250/1251]	eta 0:09:35 lr 0.000396	time 0.5541 (0.5751)	loss 3.4302 (3.0578)	grad_norm 1.3983 (1.6750)	mem 17417MB
[2023-02-01 23:45:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][300/1251]	eta 0:09:06 lr 0.000396	time 0.5651 (0.5745)	loss 3.1956 (3.0396)	grad_norm 1.4734 (1.6695)	mem 17417MB
[2023-02-01 23:46:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][350/1251]	eta 0:08:36 lr 0.000396	time 0.5544 (0.5738)	loss 3.1433 (3.0464)	grad_norm 1.6324 (1.6612)	mem 17417MB
[2023-02-01 23:46:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][400/1251]	eta 0:08:07 lr 0.000395	time 0.5551 (0.5730)	loss 3.8729 (3.0583)	grad_norm 1.5996 (1.6598)	mem 17417MB
[2023-02-01 23:47:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][450/1251]	eta 0:07:38 lr 0.000395	time 0.5612 (0.5730)	loss 3.0123 (3.0550)	grad_norm 1.7731 (1.6600)	mem 17417MB
[2023-02-01 23:47:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][500/1251]	eta 0:07:09 lr 0.000395	time 0.5563 (0.5725)	loss 3.6612 (3.0615)	grad_norm 1.6617 (1.6587)	mem 17417MB
[2023-02-01 23:47:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][550/1251]	eta 0:06:41 lr 0.000395	time 0.5585 (0.5722)	loss 3.0348 (3.0737)	grad_norm 1.5801 (1.6596)	mem 17417MB
[2023-02-01 23:48:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][600/1251]	eta 0:06:12 lr 0.000395	time 0.5527 (0.5720)	loss 2.3720 (3.0738)	grad_norm 1.6916 (1.6633)	mem 17417MB
[2023-02-01 23:48:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][650/1251]	eta 0:05:43 lr 0.000394	time 0.5539 (0.5721)	loss 3.6221 (3.0710)	grad_norm 1.7304 (1.6628)	mem 17417MB
[2023-02-01 23:49:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][700/1251]	eta 0:05:15 lr 0.000394	time 0.5567 (0.5719)	loss 3.4048 (3.0806)	grad_norm 1.6752 (1.6623)	mem 17417MB
[2023-02-01 23:49:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][750/1251]	eta 0:04:46 lr 0.000394	time 0.5570 (0.5717)	loss 2.7058 (3.0825)	grad_norm 1.6021 (1.6598)	mem 17417MB
[2023-02-01 23:50:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][800/1251]	eta 0:04:17 lr 0.000394	time 0.5559 (0.5715)	loss 3.2524 (3.0782)	grad_norm 1.7638 (1.6582)	mem 17417MB
[2023-02-01 23:50:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][850/1251]	eta 0:03:49 lr 0.000394	time 0.5711 (0.5717)	loss 2.1389 (3.0834)	grad_norm 1.6670 (1.6575)	mem 17417MB
[2023-02-01 23:51:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][900/1251]	eta 0:03:20 lr 0.000393	time 0.5504 (0.5714)	loss 3.6291 (3.0820)	grad_norm 1.4810 (1.6597)	mem 17417MB
[2023-02-01 23:51:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][950/1251]	eta 0:02:51 lr 0.000393	time 0.5495 (0.5712)	loss 3.5901 (3.0798)	grad_norm 1.9326 (1.6589)	mem 17417MB
[2023-02-01 23:52:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][1000/1251]	eta 0:02:23 lr 0.000393	time 0.5573 (0.5714)	loss 2.4659 (3.0776)	grad_norm 1.4667 (1.6594)	mem 17417MB
[2023-02-01 23:52:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][1050/1251]	eta 0:01:54 lr 0.000393	time 0.5572 (0.5714)	loss 2.9602 (3.0797)	grad_norm 1.7196 (1.6598)	mem 17417MB
[2023-02-01 23:53:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][1100/1251]	eta 0:01:26 lr 0.000393	time 0.5550 (0.5714)	loss 2.4352 (3.0803)	grad_norm 1.5767 (1.6615)	mem 17417MB
[2023-02-01 23:53:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][1150/1251]	eta 0:00:57 lr 0.000392	time 0.5516 (0.5714)	loss 3.4124 (3.0859)	grad_norm 1.6815 (1.6610)	mem 17417MB
[2023-02-01 23:54:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][1200/1251]	eta 0:00:29 lr 0.000392	time 0.5595 (0.5712)	loss 3.8861 (3.0843)	grad_norm 1.6118 (1.6625)	mem 17417MB
[2023-02-01 23:54:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [171/300][1250/1251]	eta 0:00:00 lr 0.000392	time 0.5562 (0.5711)	loss 3.4977 (3.0862)	grad_norm 1.8530 (1.6636)	mem 17417MB
[2023-02-01 23:54:38 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 171 training takes 0:11:54
[2023-02-01 23:54:38 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_171.pth saving......
[2023-02-01 23:54:40 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_171.pth saved !!!
[2023-02-01 23:54:41 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.907 (0.907)	Loss 0.7628 (0.7628)	Acc@1 81.445 (81.445)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-01 23:54:49 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.938 Acc@5 95.736
[2023-02-01 23:54:49 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.9%
[2023-02-01 23:54:50 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.226 (1.226)	Loss 0.7979 (0.7979)	Acc@1 81.250 (81.250)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-01 23:54:58 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.398 Acc@5 96.362
[2023-02-01 23:54:58 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.4%
[2023-02-01 23:54:58 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.40% at 171 epoch
[2023-02-01 23:55:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][0/1251]	eta 0:38:10 lr 0.000392	time 1.8309 (1.8309)	loss 2.4264 (2.4264)	grad_norm 1.8667 (1.8667)	mem 17417MB
[2023-02-01 23:55:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][50/1251]	eta 0:11:53 lr 0.000392	time 0.5551 (0.5939)	loss 2.4151 (3.0371)	grad_norm 1.9872 (1.6827)	mem 17417MB
[2023-02-01 23:55:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][100/1251]	eta 0:11:12 lr 0.000392	time 0.5601 (0.5840)	loss 3.4721 (2.9900)	grad_norm 1.5263 (1.6787)	mem 17417MB
[2023-02-01 23:56:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][150/1251]	eta 0:10:36 lr 0.000391	time 0.5678 (0.5783)	loss 3.1020 (2.9951)	grad_norm 1.5198 (1.6675)	mem 17417MB
[2023-02-01 23:56:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][200/1251]	eta 0:10:06 lr 0.000391	time 0.5545 (0.5770)	loss 3.0158 (2.9960)	grad_norm 1.5343 (1.6630)	mem 17417MB
[2023-02-01 23:57:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][250/1251]	eta 0:09:35 lr 0.000391	time 0.5558 (0.5746)	loss 1.8509 (3.0061)	grad_norm 1.6338 (1.6628)	mem 17417MB
[2023-02-01 23:57:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][300/1251]	eta 0:09:06 lr 0.000391	time 0.6260 (0.5742)	loss 3.3996 (3.0257)	grad_norm 1.7965 (1.6576)	mem 17417MB
[2023-02-01 23:58:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][350/1251]	eta 0:08:36 lr 0.000391	time 0.5568 (0.5731)	loss 3.4053 (3.0162)	grad_norm 1.6122 (1.6569)	mem 17417MB
[2023-02-01 23:58:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][400/1251]	eta 0:08:07 lr 0.000390	time 0.5565 (0.5731)	loss 3.5819 (3.0135)	grad_norm 1.5788 (1.6596)	mem 17417MB
[2023-02-01 23:59:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][450/1251]	eta 0:07:38 lr 0.000390	time 0.5526 (0.5724)	loss 1.7902 (3.0219)	grad_norm 1.5731 (1.6584)	mem 17417MB
[2023-02-01 23:59:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][500/1251]	eta 0:07:09 lr 0.000390	time 0.5640 (0.5718)	loss 3.7360 (3.0272)	grad_norm 1.9098 (1.6577)	mem 17417MB
[2023-02-02 00:00:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][550/1251]	eta 0:06:40 lr 0.000390	time 0.5581 (0.5718)	loss 3.6650 (3.0336)	grad_norm 1.6429 (1.6551)	mem 17417MB
[2023-02-02 00:00:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][600/1251]	eta 0:06:12 lr 0.000390	time 0.5498 (0.5717)	loss 3.4998 (3.0396)	grad_norm 1.5871 (1.6543)	mem 17417MB
[2023-02-02 00:01:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][650/1251]	eta 0:05:43 lr 0.000389	time 0.5610 (0.5716)	loss 2.9983 (3.0485)	grad_norm 1.7175 (1.6574)	mem 17417MB
[2023-02-02 00:01:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][700/1251]	eta 0:05:14 lr 0.000389	time 0.5575 (0.5713)	loss 3.6515 (3.0444)	grad_norm 1.6715 (1.6571)	mem 17417MB
[2023-02-02 00:02:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][750/1251]	eta 0:04:46 lr 0.000389	time 0.5542 (0.5714)	loss 3.9548 (3.0501)	grad_norm 1.5886 (1.6557)	mem 17417MB
[2023-02-02 00:02:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][800/1251]	eta 0:04:17 lr 0.000389	time 0.5519 (0.5713)	loss 3.3162 (3.0519)	grad_norm 1.9267 (1.6571)	mem 17417MB
[2023-02-02 00:03:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][850/1251]	eta 0:03:48 lr 0.000389	time 0.5582 (0.5710)	loss 3.2950 (3.0476)	grad_norm 1.5781 (1.6573)	mem 17417MB
[2023-02-02 00:03:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][900/1251]	eta 0:03:20 lr 0.000388	time 0.5590 (0.5711)	loss 3.6710 (3.0545)	grad_norm 1.7479 (1.6611)	mem 17417MB
[2023-02-02 00:04:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][950/1251]	eta 0:02:51 lr 0.000388	time 0.5525 (0.5709)	loss 1.6775 (3.0553)	grad_norm 1.6125 (1.6619)	mem 17417MB
[2023-02-02 00:04:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][1000/1251]	eta 0:02:23 lr 0.000388	time 0.5625 (0.5710)	loss 3.3711 (3.0596)	grad_norm 1.6827 (1.6613)	mem 17417MB
[2023-02-02 00:04:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][1050/1251]	eta 0:01:54 lr 0.000388	time 0.5604 (0.5710)	loss 3.1071 (3.0623)	grad_norm 1.6639 (1.6607)	mem 17417MB
[2023-02-02 00:05:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][1100/1251]	eta 0:01:26 lr 0.000388	time 0.6360 (0.5711)	loss 3.4969 (3.0628)	grad_norm 1.6345 (1.6627)	mem 17417MB
[2023-02-02 00:05:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][1150/1251]	eta 0:00:57 lr 0.000387	time 0.5559 (0.5710)	loss 2.7993 (3.0620)	grad_norm 1.5391 (1.6642)	mem 17417MB
[2023-02-02 00:06:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][1200/1251]	eta 0:00:29 lr 0.000387	time 0.5609 (0.5709)	loss 3.9380 (3.0618)	grad_norm 1.6559 (1.6624)	mem 17417MB
[2023-02-02 00:06:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [172/300][1250/1251]	eta 0:00:00 lr 0.000387	time 0.5513 (0.5710)	loss 3.0291 (3.0611)	grad_norm 1.4980 (1.6629)	mem 17417MB
[2023-02-02 00:06:53 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 172 training takes 0:11:54
[2023-02-02 00:06:53 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_172.pth saving......
[2023-02-02 00:06:55 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_172.pth saved !!!
[2023-02-02 00:06:56 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.900 (0.900)	Loss 0.8991 (0.8991)	Acc@1 78.809 (78.809)	Acc@5 94.922 (94.922)	Mem 17417MB
[2023-02-02 00:07:03 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.784 Acc@5 95.684
[2023-02-02 00:07:03 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.8%
[2023-02-02 00:07:05 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.293 (1.293)	Loss 0.7086 (0.7086)	Acc@1 83.105 (83.105)	Acc@5 97.363 (97.363)	Mem 17417MB
[2023-02-02 00:07:13 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.450 Acc@5 96.366
[2023-02-02 00:07:13 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.4%
[2023-02-02 00:07:13 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.45% at 172 epoch
[2023-02-02 00:07:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][0/1251]	eta 0:37:19 lr 0.000387	time 1.7902 (1.7902)	loss 3.0325 (3.0325)	grad_norm 1.7255 (1.7255)	mem 17417MB
[2023-02-02 00:07:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][50/1251]	eta 0:11:59 lr 0.000387	time 0.5559 (0.5989)	loss 2.4697 (3.0291)	grad_norm 1.7207 (1.6853)	mem 17417MB
[2023-02-02 00:08:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][100/1251]	eta 0:11:12 lr 0.000387	time 0.6186 (0.5845)	loss 2.6002 (3.0348)	grad_norm 1.5426 (1.6746)	mem 17417MB
[2023-02-02 00:08:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][150/1251]	eta 0:10:37 lr 0.000386	time 0.5536 (0.5791)	loss 3.2425 (3.0472)	grad_norm 1.4981 (1.6676)	mem 17417MB
[2023-02-02 00:09:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][200/1251]	eta 0:10:05 lr 0.000386	time 0.5570 (0.5763)	loss 2.2522 (3.0619)	grad_norm 1.4752 (1.6623)	mem 17417MB
[2023-02-02 00:09:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][250/1251]	eta 0:09:35 lr 0.000386	time 0.5558 (0.5751)	loss 3.4463 (3.0877)	grad_norm 1.9391 (1.6695)	mem 17417MB
[2023-02-02 00:10:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][300/1251]	eta 0:09:06 lr 0.000386	time 0.5559 (0.5743)	loss 3.3866 (3.0838)	grad_norm 1.5052 (1.6714)	mem 17417MB
[2023-02-02 00:10:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][350/1251]	eta 0:08:36 lr 0.000386	time 0.5600 (0.5734)	loss 2.7055 (3.0909)	grad_norm 1.5290 (1.6741)	mem 17417MB
[2023-02-02 00:11:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][400/1251]	eta 0:08:07 lr 0.000385	time 0.5572 (0.5725)	loss 3.2848 (3.0737)	grad_norm 1.6706 (1.6800)	mem 17417MB
[2023-02-02 00:11:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][450/1251]	eta 0:07:38 lr 0.000385	time 0.5730 (0.5725)	loss 2.5784 (3.0762)	grad_norm 1.5469 (1.6801)	mem 17417MB
[2023-02-02 00:11:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][500/1251]	eta 0:07:09 lr 0.000385	time 0.6233 (0.5721)	loss 3.1128 (3.0731)	grad_norm 1.7982 (1.6795)	mem 17417MB
[2023-02-02 00:12:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][550/1251]	eta 0:06:40 lr 0.000385	time 0.5504 (0.5717)	loss 3.2985 (3.0745)	grad_norm 1.5528 (1.6770)	mem 17417MB
[2023-02-02 00:12:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][600/1251]	eta 0:06:12 lr 0.000385	time 0.5558 (0.5716)	loss 2.7319 (3.0772)	grad_norm 1.4722 (1.6764)	mem 17417MB
[2023-02-02 00:13:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][650/1251]	eta 0:05:43 lr 0.000384	time 0.5468 (0.5713)	loss 3.0866 (3.0831)	grad_norm 1.8920 (1.6785)	mem 17417MB
[2023-02-02 00:13:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][700/1251]	eta 0:05:14 lr 0.000384	time 0.5641 (0.5711)	loss 2.8491 (3.0870)	grad_norm 1.7416 (1.6785)	mem 17417MB
[2023-02-02 00:14:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][750/1251]	eta 0:04:46 lr 0.000384	time 0.5541 (0.5711)	loss 1.7887 (3.0786)	grad_norm 1.7862 (1.6791)	mem 17417MB
[2023-02-02 00:14:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][800/1251]	eta 0:04:17 lr 0.000384	time 0.5567 (0.5710)	loss 3.2966 (3.0779)	grad_norm 1.5373 (1.6824)	mem 17417MB
[2023-02-02 00:15:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][850/1251]	eta 0:03:48 lr 0.000384	time 0.5657 (0.5710)	loss 3.3168 (3.0842)	grad_norm 1.7801 (1.6845)	mem 17417MB
[2023-02-02 00:15:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][900/1251]	eta 0:03:20 lr 0.000383	time 0.6152 (0.5709)	loss 2.1857 (3.0838)	grad_norm 1.5430 (1.6833)	mem 17417MB
[2023-02-02 00:16:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][950/1251]	eta 0:02:51 lr 0.000383	time 0.5580 (0.5709)	loss 3.4711 (3.0927)	grad_norm 1.7047 (1.6834)	mem 17417MB
[2023-02-02 00:16:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][1000/1251]	eta 0:02:23 lr 0.000383	time 0.5593 (0.5708)	loss 3.1608 (3.0933)	grad_norm 1.4412 (1.6825)	mem 17417MB
[2023-02-02 00:17:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][1050/1251]	eta 0:01:54 lr 0.000383	time 0.5690 (0.5709)	loss 3.4962 (3.0918)	grad_norm 1.7036 (1.6832)	mem 17417MB
[2023-02-02 00:17:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][1100/1251]	eta 0:01:26 lr 0.000383	time 0.6377 (0.5708)	loss 2.4125 (3.0867)	grad_norm 1.6358 (1.6822)	mem 17417MB
[2023-02-02 00:18:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][1150/1251]	eta 0:00:57 lr 0.000382	time 0.5543 (0.5707)	loss 3.4358 (3.0854)	grad_norm 1.5407 (1.6856)	mem 17417MB
[2023-02-02 00:18:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][1200/1251]	eta 0:00:29 lr 0.000382	time 0.5594 (0.5706)	loss 3.0285 (3.0839)	grad_norm 1.4805 (1.6866)	mem 17417MB
[2023-02-02 00:19:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [173/300][1250/1251]	eta 0:00:00 lr 0.000382	time 0.6193 (0.5707)	loss 3.3940 (3.0874)	grad_norm 1.8676 (nan)	mem 17417MB
[2023-02-02 00:19:07 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 173 training takes 0:11:54
[2023-02-02 00:19:07 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_173.pth saving......
[2023-02-02 00:19:09 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_173.pth saved !!!
[2023-02-02 00:19:10 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.898 (0.898)	Loss 0.8175 (0.8175)	Acc@1 80.664 (80.664)	Acc@5 95.508 (95.508)	Mem 17417MB
[2023-02-02 00:19:18 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.030 Acc@5 95.720
[2023-02-02 00:19:18 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.0%
[2023-02-02 00:19:19 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.210 (1.210)	Loss 0.7555 (0.7555)	Acc@1 82.129 (82.129)	Acc@5 96.875 (96.875)	Mem 17417MB
[2023-02-02 00:19:27 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.476 Acc@5 96.404
[2023-02-02 00:19:27 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.5%
[2023-02-02 00:19:27 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.48% at 173 epoch
[2023-02-02 00:19:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][0/1251]	eta 0:36:15 lr 0.000382	time 1.7394 (1.7394)	loss 2.5724 (2.5724)	grad_norm 1.4964 (1.4964)	mem 17417MB
[2023-02-02 00:19:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][50/1251]	eta 0:11:51 lr 0.000382	time 0.5560 (0.5928)	loss 2.6231 (3.1085)	grad_norm 1.6549 (1.6597)	mem 17417MB
[2023-02-02 00:20:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][100/1251]	eta 0:11:09 lr 0.000381	time 0.5526 (0.5814)	loss 2.8018 (3.0513)	grad_norm 1.6596 (1.6663)	mem 17417MB
[2023-02-02 00:20:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][150/1251]	eta 0:10:35 lr 0.000381	time 0.5540 (0.5774)	loss 3.9605 (3.0486)	grad_norm 1.6315 (1.6882)	mem 17417MB
[2023-02-02 00:21:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][200/1251]	eta 0:10:05 lr 0.000381	time 0.5568 (0.5758)	loss 3.1569 (3.0844)	grad_norm 1.7087 (1.6996)	mem 17417MB
[2023-02-02 00:21:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][250/1251]	eta 0:09:35 lr 0.000381	time 0.5607 (0.5751)	loss 3.1148 (3.0864)	grad_norm 1.5932 (1.7060)	mem 17417MB
[2023-02-02 00:22:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][300/1251]	eta 0:09:05 lr 0.000381	time 0.5533 (0.5738)	loss 2.2728 (3.0827)	grad_norm 1.7450 (1.6955)	mem 17417MB
[2023-02-02 00:22:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][350/1251]	eta 0:08:36 lr 0.000380	time 0.5617 (0.5732)	loss 2.8872 (3.0886)	grad_norm 1.7941 (1.6947)	mem 17417MB
[2023-02-02 00:23:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][400/1251]	eta 0:08:07 lr 0.000380	time 0.5533 (0.5727)	loss 3.5758 (3.0969)	grad_norm 1.6146 (1.6953)	mem 17417MB
[2023-02-02 00:23:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][450/1251]	eta 0:07:38 lr 0.000380	time 0.6208 (0.5724)	loss 3.3870 (3.1025)	grad_norm 1.8372 (1.7005)	mem 17417MB
[2023-02-02 00:24:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][500/1251]	eta 0:07:09 lr 0.000380	time 0.5537 (0.5722)	loss 3.0160 (3.1116)	grad_norm 1.5603 (1.7016)	mem 17417MB
[2023-02-02 00:24:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][550/1251]	eta 0:06:40 lr 0.000380	time 0.5576 (0.5715)	loss 3.0312 (3.1002)	grad_norm 1.6491 (1.7000)	mem 17417MB
[2023-02-02 00:25:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][600/1251]	eta 0:06:12 lr 0.000379	time 0.5561 (0.5716)	loss 3.3167 (3.1001)	grad_norm 1.8105 (1.7011)	mem 17417MB
[2023-02-02 00:25:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][650/1251]	eta 0:05:43 lr 0.000379	time 0.5756 (0.5715)	loss 3.2100 (3.0936)	grad_norm 1.6982 (1.7010)	mem 17417MB
[2023-02-02 00:26:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][700/1251]	eta 0:05:14 lr 0.000379	time 0.5619 (0.5712)	loss 2.0565 (3.0903)	grad_norm 1.6598 (1.6980)	mem 17417MB
[2023-02-02 00:26:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][750/1251]	eta 0:04:46 lr 0.000379	time 0.5627 (0.5711)	loss 3.4865 (3.0834)	grad_norm 1.7073 (1.6973)	mem 17417MB
[2023-02-02 00:27:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][800/1251]	eta 0:04:17 lr 0.000379	time 0.5515 (0.5708)	loss 2.7616 (3.0800)	grad_norm 1.5983 (1.6975)	mem 17417MB
[2023-02-02 00:27:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][850/1251]	eta 0:03:48 lr 0.000378	time 0.5615 (0.5708)	loss 2.3174 (3.0836)	grad_norm 1.7119 (1.6969)	mem 17417MB
[2023-02-02 00:28:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][900/1251]	eta 0:03:20 lr 0.000378	time 0.5561 (0.5707)	loss 3.4570 (3.0880)	grad_norm 1.5826 (1.6961)	mem 17417MB
[2023-02-02 00:28:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][950/1251]	eta 0:02:51 lr 0.000378	time 0.5540 (0.5705)	loss 3.5788 (3.0882)	grad_norm 1.5813 (1.6947)	mem 17417MB
[2023-02-02 00:28:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][1000/1251]	eta 0:02:23 lr 0.000378	time 0.5693 (0.5707)	loss 2.8322 (3.0834)	grad_norm 1.7958 (1.6934)	mem 17417MB
[2023-02-02 00:29:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][1050/1251]	eta 0:01:54 lr 0.000378	time 0.5523 (0.5706)	loss 2.8044 (3.0820)	grad_norm 1.5909 (1.6944)	mem 17417MB
[2023-02-02 00:29:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][1100/1251]	eta 0:01:26 lr 0.000377	time 0.6308 (0.5707)	loss 2.4586 (3.0820)	grad_norm 1.6839 (1.6945)	mem 17417MB
[2023-02-02 00:30:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][1150/1251]	eta 0:00:57 lr 0.000377	time 0.6238 (0.5705)	loss 2.6361 (3.0850)	grad_norm 1.5933 (1.6939)	mem 17417MB
[2023-02-02 00:30:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][1200/1251]	eta 0:00:29 lr 0.000377	time 0.5511 (0.5704)	loss 3.0447 (3.0841)	grad_norm 1.4999 (1.6939)	mem 17417MB
[2023-02-02 00:31:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [174/300][1250/1251]	eta 0:00:00 lr 0.000377	time 0.5486 (0.5703)	loss 2.9419 (3.0834)	grad_norm 1.5896 (1.6917)	mem 17417MB
[2023-02-02 00:31:20 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 174 training takes 0:11:53
[2023-02-02 00:31:21 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_174.pth saving......
[2023-02-02 00:31:22 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_174.pth saved !!!
[2023-02-02 00:31:23 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.888 (0.888)	Loss 0.8056 (0.8056)	Acc@1 80.957 (80.957)	Acc@5 95.996 (95.996)	Mem 17417MB
[2023-02-02 00:31:31 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.906 Acc@5 95.762
[2023-02-02 00:31:31 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.9%
[2023-02-02 00:31:32 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.210 (1.210)	Loss 0.6984 (0.6984)	Acc@1 83.105 (83.105)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 00:31:40 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.496 Acc@5 96.402
[2023-02-02 00:31:40 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.5%
[2023-02-02 00:31:40 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.50% at 174 epoch
[2023-02-02 00:31:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][0/1251]	eta 0:34:52 lr 0.000377	time 1.6730 (1.6730)	loss 3.5022 (3.5022)	grad_norm 1.8562 (1.8562)	mem 17417MB
[2023-02-02 00:32:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][50/1251]	eta 0:11:58 lr 0.000377	time 0.6261 (0.5983)	loss 2.7323 (3.0569)	grad_norm 1.5703 (1.6775)	mem 17417MB
[2023-02-02 00:32:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][100/1251]	eta 0:11:15 lr 0.000376	time 0.5542 (0.5867)	loss 3.4749 (3.1145)	grad_norm 1.7144 (1.6808)	mem 17417MB
[2023-02-02 00:33:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][150/1251]	eta 0:10:40 lr 0.000376	time 0.5575 (0.5819)	loss 3.0824 (3.0843)	grad_norm 1.7137 (1.6880)	mem 17417MB
[2023-02-02 00:33:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][200/1251]	eta 0:10:08 lr 0.000376	time 0.5501 (0.5794)	loss 3.0704 (3.0751)	grad_norm 1.6481 (1.6971)	mem 17417MB
[2023-02-02 00:34:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][250/1251]	eta 0:09:38 lr 0.000376	time 0.6295 (0.5784)	loss 2.1822 (3.0514)	grad_norm 2.0453 (1.6930)	mem 17417MB
[2023-02-02 00:34:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][300/1251]	eta 0:09:08 lr 0.000376	time 0.6149 (0.5768)	loss 2.7963 (3.0631)	grad_norm 1.5980 (1.7034)	mem 17417MB
[2023-02-02 00:35:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][350/1251]	eta 0:08:39 lr 0.000375	time 0.5565 (0.5761)	loss 3.5597 (3.0676)	grad_norm 1.6550 (1.7015)	mem 17417MB
[2023-02-02 00:35:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][400/1251]	eta 0:08:09 lr 0.000375	time 0.5580 (0.5749)	loss 2.1708 (3.0548)	grad_norm 1.9443 (1.7025)	mem 17417MB
[2023-02-02 00:35:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][450/1251]	eta 0:07:40 lr 0.000375	time 0.5543 (0.5747)	loss 2.2407 (3.0591)	grad_norm 2.0152 (1.7000)	mem 17417MB
[2023-02-02 00:36:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][500/1251]	eta 0:07:11 lr 0.000375	time 0.5977 (0.5745)	loss 3.2686 (3.0660)	grad_norm 1.9025 (1.7011)	mem 17417MB
[2023-02-02 00:36:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][550/1251]	eta 0:06:42 lr 0.000375	time 0.5561 (0.5738)	loss 3.1645 (3.0685)	grad_norm 1.6688 (1.7060)	mem 17417MB
[2023-02-02 00:37:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][600/1251]	eta 0:06:13 lr 0.000374	time 0.5595 (0.5737)	loss 2.8452 (3.0784)	grad_norm 1.7147 (1.7087)	mem 17417MB
[2023-02-02 00:37:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][650/1251]	eta 0:05:44 lr 0.000374	time 0.5613 (0.5738)	loss 3.4637 (3.0747)	grad_norm 1.7835 (1.7049)	mem 17417MB
[2023-02-02 00:38:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][700/1251]	eta 0:05:16 lr 0.000374	time 0.5575 (0.5737)	loss 3.2682 (3.0709)	grad_norm 1.8009 (1.7046)	mem 17417MB
[2023-02-02 00:38:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][750/1251]	eta 0:04:47 lr 0.000374	time 0.5636 (0.5735)	loss 3.3168 (3.0685)	grad_norm 1.7409 (inf)	mem 17417MB
[2023-02-02 00:39:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][800/1251]	eta 0:04:18 lr 0.000374	time 0.6242 (0.5731)	loss 3.1500 (3.0679)	grad_norm 1.7570 (inf)	mem 17417MB
[2023-02-02 00:39:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][850/1251]	eta 0:03:49 lr 0.000373	time 0.6312 (0.5732)	loss 3.3561 (3.0658)	grad_norm 1.5083 (inf)	mem 17417MB
[2023-02-02 00:40:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][900/1251]	eta 0:03:21 lr 0.000373	time 0.5546 (0.5731)	loss 3.5882 (3.0663)	grad_norm 1.8468 (inf)	mem 17417MB
[2023-02-02 00:40:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][950/1251]	eta 0:02:52 lr 0.000373	time 0.5624 (0.5730)	loss 2.9760 (3.0636)	grad_norm 1.9028 (inf)	mem 17417MB
[2023-02-02 00:41:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][1000/1251]	eta 0:02:23 lr 0.000373	time 0.5573 (0.5731)	loss 3.4650 (3.0586)	grad_norm 1.6492 (inf)	mem 17417MB
[2023-02-02 00:41:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][1050/1251]	eta 0:01:55 lr 0.000373	time 0.5549 (0.5728)	loss 2.1001 (3.0585)	grad_norm 1.8673 (inf)	mem 17417MB
[2023-02-02 00:42:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][1100/1251]	eta 0:01:26 lr 0.000372	time 0.5518 (0.5727)	loss 3.1092 (3.0603)	grad_norm 1.6631 (inf)	mem 17417MB
[2023-02-02 00:42:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][1150/1251]	eta 0:00:57 lr 0.000372	time 0.5552 (0.5726)	loss 3.1629 (3.0625)	grad_norm 1.6196 (inf)	mem 17417MB
[2023-02-02 00:43:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][1200/1251]	eta 0:00:29 lr 0.000372	time 0.5648 (0.5725)	loss 3.3832 (3.0590)	grad_norm 1.8742 (inf)	mem 17417MB
[2023-02-02 00:43:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [175/300][1250/1251]	eta 0:00:00 lr 0.000372	time 0.5509 (0.5726)	loss 3.0188 (3.0574)	grad_norm 1.5872 (inf)	mem 17417MB
[2023-02-02 00:43:37 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 175 training takes 0:11:56
[2023-02-02 00:43:37 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_175.pth saving......
[2023-02-02 00:43:39 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_175.pth saved !!!
[2023-02-02 00:43:40 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.972 (0.972)	Loss 0.8351 (0.8351)	Acc@1 81.641 (81.641)	Acc@5 94.727 (94.727)	Mem 17417MB
[2023-02-02 00:43:48 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.062 Acc@5 95.684
[2023-02-02 00:43:48 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.1%
[2023-02-02 00:43:49 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.206 (1.206)	Loss 0.6670 (0.6670)	Acc@1 84.277 (84.277)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-02 00:43:57 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.496 Acc@5 96.418
[2023-02-02 00:43:57 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.5%
[2023-02-02 00:43:57 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.50% at 175 epoch
[2023-02-02 00:43:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][0/1251]	eta 0:36:45 lr 0.000372	time 1.7627 (1.7627)	loss 3.1823 (3.1823)	grad_norm 2.0208 (2.0208)	mem 17417MB
[2023-02-02 00:44:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][50/1251]	eta 0:11:52 lr 0.000372	time 0.5550 (0.5933)	loss 3.2218 (3.0113)	grad_norm 1.7247 (1.7003)	mem 17417MB
[2023-02-02 00:44:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][100/1251]	eta 0:11:08 lr 0.000371	time 0.6240 (0.5812)	loss 3.3920 (3.0699)	grad_norm 1.5725 (1.6913)	mem 17417MB
[2023-02-02 00:45:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][150/1251]	eta 0:10:35 lr 0.000371	time 0.5580 (0.5774)	loss 3.0281 (3.0649)	grad_norm 1.6913 (1.6954)	mem 17417MB
[2023-02-02 00:45:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][200/1251]	eta 0:10:05 lr 0.000371	time 0.5521 (0.5758)	loss 3.5405 (3.0473)	grad_norm 1.6272 (1.7010)	mem 17417MB
[2023-02-02 00:46:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][250/1251]	eta 0:09:34 lr 0.000371	time 0.5562 (0.5737)	loss 2.6899 (3.0333)	grad_norm 1.6339 (1.7078)	mem 17417MB
[2023-02-02 00:46:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][300/1251]	eta 0:09:05 lr 0.000371	time 0.6166 (0.5739)	loss 2.9310 (3.0495)	grad_norm 1.6562 (1.7124)	mem 17417MB
[2023-02-02 00:47:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][350/1251]	eta 0:08:36 lr 0.000370	time 0.5572 (0.5733)	loss 3.2407 (3.0652)	grad_norm 1.5647 (1.7094)	mem 17417MB
[2023-02-02 00:47:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][400/1251]	eta 0:08:07 lr 0.000370	time 0.5593 (0.5726)	loss 2.5160 (3.0721)	grad_norm 1.7388 (nan)	mem 17417MB
[2023-02-02 00:48:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][450/1251]	eta 0:07:38 lr 0.000370	time 0.5523 (0.5727)	loss 3.2734 (3.0816)	grad_norm 1.6261 (nan)	mem 17417MB
[2023-02-02 00:48:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][500/1251]	eta 0:07:09 lr 0.000370	time 0.6280 (0.5721)	loss 2.8258 (3.0853)	grad_norm 1.5421 (nan)	mem 17417MB
[2023-02-02 00:49:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][550/1251]	eta 0:06:40 lr 0.000370	time 0.5526 (0.5720)	loss 3.7069 (3.0798)	grad_norm 1.6885 (nan)	mem 17417MB
[2023-02-02 00:49:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][600/1251]	eta 0:06:12 lr 0.000369	time 0.5525 (0.5721)	loss 3.2009 (3.0721)	grad_norm 2.0755 (nan)	mem 17417MB
[2023-02-02 00:50:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][650/1251]	eta 0:05:43 lr 0.000369	time 0.5608 (0.5717)	loss 2.7879 (3.0698)	grad_norm 1.5658 (nan)	mem 17417MB
[2023-02-02 00:50:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][700/1251]	eta 0:05:15 lr 0.000369	time 0.5698 (0.5719)	loss 2.3858 (3.0660)	grad_norm 1.8197 (nan)	mem 17417MB
[2023-02-02 00:51:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][750/1251]	eta 0:04:46 lr 0.000369	time 0.5563 (0.5715)	loss 3.4219 (3.0657)	grad_norm 1.6139 (nan)	mem 17417MB
[2023-02-02 00:51:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][800/1251]	eta 0:04:17 lr 0.000369	time 0.5558 (0.5712)	loss 2.1528 (3.0650)	grad_norm 1.6783 (nan)	mem 17417MB
[2023-02-02 00:52:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][850/1251]	eta 0:03:49 lr 0.000368	time 0.5593 (0.5712)	loss 3.4083 (3.0585)	grad_norm 1.9981 (nan)	mem 17417MB
[2023-02-02 00:52:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][900/1251]	eta 0:03:20 lr 0.000368	time 0.6249 (0.5713)	loss 2.9014 (3.0609)	grad_norm 1.6879 (nan)	mem 17417MB
[2023-02-02 00:53:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][950/1251]	eta 0:02:51 lr 0.000368	time 0.5575 (0.5711)	loss 3.0156 (3.0633)	grad_norm 1.6489 (nan)	mem 17417MB
[2023-02-02 00:53:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][1000/1251]	eta 0:02:23 lr 0.000368	time 0.5582 (0.5712)	loss 3.2610 (3.0620)	grad_norm 1.6855 (nan)	mem 17417MB
[2023-02-02 00:53:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][1050/1251]	eta 0:01:54 lr 0.000368	time 0.5549 (0.5709)	loss 3.1639 (3.0629)	grad_norm 1.5390 (nan)	mem 17417MB
[2023-02-02 00:54:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][1100/1251]	eta 0:01:26 lr 0.000368	time 0.5559 (0.5710)	loss 3.0162 (3.0612)	grad_norm 1.6604 (nan)	mem 17417MB
[2023-02-02 00:54:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][1150/1251]	eta 0:00:57 lr 0.000367	time 0.5518 (0.5710)	loss 2.7016 (3.0608)	grad_norm 1.6565 (nan)	mem 17417MB
[2023-02-02 00:55:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][1200/1251]	eta 0:00:29 lr 0.000367	time 0.5552 (0.5710)	loss 2.5690 (3.0582)	grad_norm 1.5212 (nan)	mem 17417MB
[2023-02-02 00:55:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [176/300][1250/1251]	eta 0:00:00 lr 0.000367	time 0.5479 (0.5711)	loss 1.9723 (3.0600)	grad_norm 1.4669 (nan)	mem 17417MB
[2023-02-02 00:55:51 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 176 training takes 0:11:54
[2023-02-02 00:55:51 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_176.pth saving......
[2023-02-02 00:55:53 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_176.pth saved !!!
[2023-02-02 00:55:54 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.854 (0.854)	Loss 0.8471 (0.8471)	Acc@1 80.176 (80.176)	Acc@5 95.117 (95.117)	Mem 17417MB
[2023-02-02 00:56:02 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.922 Acc@5 95.740
[2023-02-02 00:56:02 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.9%
[2023-02-02 00:56:03 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.235 (1.235)	Loss 0.7439 (0.7439)	Acc@1 82.129 (82.129)	Acc@5 97.168 (97.168)	Mem 17417MB
[2023-02-02 00:56:11 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.542 Acc@5 96.426
[2023-02-02 00:56:11 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.5%
[2023-02-02 00:56:11 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.54% at 176 epoch
[2023-02-02 00:56:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][0/1251]	eta 0:34:51 lr 0.000367	time 1.6715 (1.6715)	loss 3.7578 (3.7578)	grad_norm 1.5967 (1.5967)	mem 17417MB
[2023-02-02 00:56:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][50/1251]	eta 0:11:51 lr 0.000367	time 0.5595 (0.5923)	loss 1.8910 (2.9823)	grad_norm 1.6908 (1.6857)	mem 17417MB
[2023-02-02 00:57:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][100/1251]	eta 0:11:10 lr 0.000367	time 0.5678 (0.5822)	loss 2.5379 (3.0108)	grad_norm 1.6597 (1.7044)	mem 17417MB
[2023-02-02 00:57:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][150/1251]	eta 0:10:36 lr 0.000366	time 0.5553 (0.5784)	loss 3.6886 (3.0101)	grad_norm 1.5162 (1.6903)	mem 17417MB
[2023-02-02 00:58:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][200/1251]	eta 0:10:05 lr 0.000366	time 0.5513 (0.5766)	loss 3.2079 (3.0274)	grad_norm 1.6969 (1.6960)	mem 17417MB
[2023-02-02 00:58:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][250/1251]	eta 0:09:35 lr 0.000366	time 0.6217 (0.5745)	loss 2.2582 (3.0599)	grad_norm 1.8729 (1.6968)	mem 17417MB
[2023-02-02 00:59:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][300/1251]	eta 0:09:06 lr 0.000366	time 0.6477 (0.5743)	loss 3.3996 (3.0608)	grad_norm 1.5314 (1.6980)	mem 17417MB
[2023-02-02 00:59:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][350/1251]	eta 0:08:36 lr 0.000366	time 0.5518 (0.5728)	loss 3.4410 (3.0392)	grad_norm 1.7793 (1.6973)	mem 17417MB
[2023-02-02 01:00:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][400/1251]	eta 0:08:07 lr 0.000365	time 0.5595 (0.5728)	loss 3.8984 (3.0278)	grad_norm 1.6825 (1.6991)	mem 17417MB
[2023-02-02 01:00:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][450/1251]	eta 0:07:38 lr 0.000365	time 0.6360 (0.5723)	loss 2.7969 (3.0355)	grad_norm 1.6535 (1.6988)	mem 17417MB
[2023-02-02 01:00:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][500/1251]	eta 0:07:09 lr 0.000365	time 0.5547 (0.5719)	loss 3.2858 (3.0287)	grad_norm 1.5621 (1.6986)	mem 17417MB
[2023-02-02 01:01:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][550/1251]	eta 0:06:40 lr 0.000365	time 0.5583 (0.5717)	loss 2.4055 (3.0487)	grad_norm 1.6068 (1.6991)	mem 17417MB
[2023-02-02 01:01:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][600/1251]	eta 0:06:12 lr 0.000365	time 0.5555 (0.5717)	loss 3.8102 (3.0608)	grad_norm 1.5501 (1.6983)	mem 17417MB
[2023-02-02 01:02:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][650/1251]	eta 0:05:43 lr 0.000364	time 0.5787 (0.5715)	loss 3.8933 (3.0684)	grad_norm 1.7546 (1.7032)	mem 17417MB
[2023-02-02 01:02:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][700/1251]	eta 0:05:14 lr 0.000364	time 0.6374 (0.5717)	loss 2.6614 (3.0664)	grad_norm 1.6989 (1.7111)	mem 17417MB
[2023-02-02 01:03:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][750/1251]	eta 0:04:46 lr 0.000364	time 0.5641 (0.5712)	loss 3.8693 (3.0670)	grad_norm 1.5967 (1.7080)	mem 17417MB
[2023-02-02 01:03:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][800/1251]	eta 0:04:17 lr 0.000364	time 0.6361 (0.5714)	loss 3.4235 (3.0635)	grad_norm 1.8643 (1.7070)	mem 17417MB
[2023-02-02 01:04:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][850/1251]	eta 0:03:49 lr 0.000364	time 0.5534 (0.5711)	loss 3.2212 (3.0592)	grad_norm 1.7412 (1.7060)	mem 17417MB
[2023-02-02 01:04:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][900/1251]	eta 0:03:20 lr 0.000363	time 0.6455 (0.5712)	loss 3.3002 (3.0596)	grad_norm 1.8649 (1.7074)	mem 17417MB
[2023-02-02 01:05:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][950/1251]	eta 0:02:51 lr 0.000363	time 0.5558 (0.5711)	loss 2.6377 (3.0629)	grad_norm 1.6302 (1.7073)	mem 17417MB
[2023-02-02 01:05:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][1000/1251]	eta 0:02:23 lr 0.000363	time 0.5575 (0.5711)	loss 3.4229 (3.0634)	grad_norm 1.6043 (1.7081)	mem 17417MB
[2023-02-02 01:06:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][1050/1251]	eta 0:01:54 lr 0.000363	time 0.5576 (0.5709)	loss 3.0194 (3.0616)	grad_norm 1.5281 (1.7073)	mem 17417MB
[2023-02-02 01:06:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][1100/1251]	eta 0:01:26 lr 0.000363	time 0.6285 (0.5711)	loss 2.5999 (3.0610)	grad_norm 1.6046 (1.7084)	mem 17417MB
[2023-02-02 01:07:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][1150/1251]	eta 0:00:57 lr 0.000362	time 0.5604 (0.5709)	loss 2.9936 (3.0590)	grad_norm 1.7034 (1.7092)	mem 17417MB
[2023-02-02 01:07:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][1200/1251]	eta 0:00:29 lr 0.000362	time 0.6343 (0.5709)	loss 2.7096 (3.0568)	grad_norm 1.8982 (1.7105)	mem 17417MB
[2023-02-02 01:08:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [177/300][1250/1251]	eta 0:00:00 lr 0.000362	time 0.5552 (0.5709)	loss 2.6110 (3.0579)	grad_norm 1.6176 (1.7107)	mem 17417MB
[2023-02-02 01:08:05 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 177 training takes 0:11:54
[2023-02-02 01:08:06 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_177.pth saving......
[2023-02-02 01:08:07 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_177.pth saved !!!
[2023-02-02 01:08:08 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.834 (0.834)	Loss 0.8562 (0.8562)	Acc@1 79.785 (79.785)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-02 01:08:16 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 80.924 Acc@5 95.720
[2023-02-02 01:08:16 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 80.9%
[2023-02-02 01:08:17 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.174 (1.174)	Loss 0.7330 (0.7330)	Acc@1 83.398 (83.398)	Acc@5 96.484 (96.484)	Mem 17417MB
[2023-02-02 01:08:25 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.550 Acc@5 96.474
[2023-02-02 01:08:25 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.6%
[2023-02-02 01:08:25 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.55% at 177 epoch
[2023-02-02 01:08:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][0/1251]	eta 0:38:14 lr 0.000362	time 1.8341 (1.8341)	loss 2.0509 (2.0509)	grad_norm 1.7321 (1.7321)	mem 17417MB
[2023-02-02 01:08:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][50/1251]	eta 0:11:58 lr 0.000362	time 0.5564 (0.5983)	loss 3.0074 (3.0438)	grad_norm 1.7672 (1.7283)	mem 17417MB
[2023-02-02 01:09:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][100/1251]	eta 0:11:14 lr 0.000362	time 0.5559 (0.5863)	loss 3.6279 (3.0565)	grad_norm 1.5649 (1.7157)	mem 17417MB
[2023-02-02 01:09:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][150/1251]	eta 0:10:39 lr 0.000361	time 0.5591 (0.5806)	loss 3.3992 (3.0852)	grad_norm 1.7778 (1.7295)	mem 17417MB
[2023-02-02 01:10:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][200/1251]	eta 0:10:07 lr 0.000361	time 0.6226 (0.5784)	loss 3.1042 (3.0802)	grad_norm 1.5916 (1.7145)	mem 17417MB
[2023-02-02 01:10:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][250/1251]	eta 0:09:36 lr 0.000361	time 0.6180 (0.5760)	loss 2.1848 (3.0603)	grad_norm 1.7536 (1.7112)	mem 17417MB
[2023-02-02 01:11:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][300/1251]	eta 0:09:07 lr 0.000361	time 0.5551 (0.5753)	loss 3.2792 (3.0660)	grad_norm 1.6673 (1.7091)	mem 17417MB
[2023-02-02 01:11:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][350/1251]	eta 0:08:37 lr 0.000361	time 0.5549 (0.5744)	loss 2.7053 (3.0710)	grad_norm 1.7243 (1.7051)	mem 17417MB
[2023-02-02 01:12:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][400/1251]	eta 0:08:08 lr 0.000360	time 0.5537 (0.5741)	loss 2.8304 (3.0597)	grad_norm 1.5211 (1.7074)	mem 17417MB
[2023-02-02 01:12:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][450/1251]	eta 0:07:39 lr 0.000360	time 0.5595 (0.5736)	loss 3.0261 (3.0640)	grad_norm 1.5394 (1.7057)	mem 17417MB
[2023-02-02 01:13:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][500/1251]	eta 0:07:10 lr 0.000360	time 0.5593 (0.5731)	loss 2.0803 (3.0621)	grad_norm 1.6621 (1.7018)	mem 17417MB
[2023-02-02 01:13:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][550/1251]	eta 0:06:41 lr 0.000360	time 0.5557 (0.5726)	loss 2.3775 (3.0559)	grad_norm 1.5522 (1.7036)	mem 17417MB
[2023-02-02 01:14:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][600/1251]	eta 0:06:12 lr 0.000360	time 0.5819 (0.5727)	loss 3.4327 (3.0534)	grad_norm 1.7018 (1.7073)	mem 17417MB
[2023-02-02 01:14:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][650/1251]	eta 0:05:44 lr 0.000359	time 0.5597 (0.5724)	loss 3.0113 (3.0516)	grad_norm 1.6014 (1.7089)	mem 17417MB
[2023-02-02 01:15:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][700/1251]	eta 0:05:15 lr 0.000359	time 0.5545 (0.5724)	loss 2.8927 (3.0535)	grad_norm 1.6589 (1.7082)	mem 17417MB
[2023-02-02 01:15:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][750/1251]	eta 0:04:46 lr 0.000359	time 0.5554 (0.5719)	loss 3.3050 (3.0543)	grad_norm 1.5638 (1.7058)	mem 17417MB
[2023-02-02 01:16:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][800/1251]	eta 0:04:17 lr 0.000359	time 0.6194 (0.5718)	loss 2.8842 (3.0646)	grad_norm 1.6499 (1.7048)	mem 17417MB
[2023-02-02 01:16:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][850/1251]	eta 0:03:49 lr 0.000359	time 0.5539 (0.5717)	loss 3.1312 (3.0667)	grad_norm 1.7371 (1.7056)	mem 17417MB
[2023-02-02 01:17:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][900/1251]	eta 0:03:20 lr 0.000358	time 0.5539 (0.5717)	loss 3.1181 (3.0720)	grad_norm 1.5862 (1.7048)	mem 17417MB
[2023-02-02 01:17:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][950/1251]	eta 0:02:52 lr 0.000358	time 0.5576 (0.5718)	loss 2.9370 (3.0615)	grad_norm 1.7439 (1.7063)	mem 17417MB
[2023-02-02 01:17:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][1000/1251]	eta 0:02:23 lr 0.000358	time 0.6328 (0.5718)	loss 2.3924 (3.0610)	grad_norm 1.4469 (1.7054)	mem 17417MB
[2023-02-02 01:18:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][1050/1251]	eta 0:01:54 lr 0.000358	time 0.5554 (0.5715)	loss 3.5965 (3.0673)	grad_norm 1.7853 (1.7080)	mem 17417MB
[2023-02-02 01:18:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][1100/1251]	eta 0:01:26 lr 0.000358	time 0.6266 (0.5716)	loss 3.2625 (3.0681)	grad_norm 1.7268 (1.7117)	mem 17417MB
[2023-02-02 01:19:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][1150/1251]	eta 0:00:57 lr 0.000357	time 0.5691 (0.5716)	loss 2.9705 (3.0641)	grad_norm 1.4690 (1.7102)	mem 17417MB
[2023-02-02 01:19:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][1200/1251]	eta 0:00:29 lr 0.000357	time 0.5567 (0.5715)	loss 3.7775 (3.0644)	grad_norm 1.7024 (1.7091)	mem 17417MB
[2023-02-02 01:20:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [178/300][1250/1251]	eta 0:00:00 lr 0.000357	time 0.6084 (0.5715)	loss 3.0766 (3.0613)	grad_norm 1.9634 (1.7123)	mem 17417MB
[2023-02-02 01:20:20 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 178 training takes 0:11:55
[2023-02-02 01:20:20 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_178.pth saving......
[2023-02-02 01:20:22 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_178.pth saved !!!
[2023-02-02 01:20:23 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.885 (0.885)	Loss 0.7195 (0.7195)	Acc@1 82.715 (82.715)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-02 01:20:31 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.142 Acc@5 95.888
[2023-02-02 01:20:31 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.1%
[2023-02-02 01:20:32 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.167 (1.167)	Loss 0.7613 (0.7613)	Acc@1 82.812 (82.812)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-02 01:20:40 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.622 Acc@5 96.466
[2023-02-02 01:20:40 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.6%
[2023-02-02 01:20:40 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.62% at 178 epoch
[2023-02-02 01:20:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][0/1251]	eta 0:34:01 lr 0.000357	time 1.6317 (1.6317)	loss 3.5283 (3.5283)	grad_norm 1.6398 (1.6398)	mem 17417MB
[2023-02-02 01:21:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][50/1251]	eta 0:11:46 lr 0.000357	time 0.5556 (0.5884)	loss 2.1962 (3.1321)	grad_norm 1.9029 (1.7278)	mem 17417MB
[2023-02-02 01:21:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][100/1251]	eta 0:11:10 lr 0.000357	time 0.5677 (0.5825)	loss 2.9658 (3.0666)	grad_norm 1.5690 (1.7208)	mem 17417MB
[2023-02-02 01:22:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][150/1251]	eta 0:10:36 lr 0.000356	time 0.5558 (0.5780)	loss 3.5680 (3.0852)	grad_norm 1.5825 (1.7218)	mem 17417MB
[2023-02-02 01:22:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][200/1251]	eta 0:10:04 lr 0.000356	time 0.5528 (0.5755)	loss 2.4219 (3.0850)	grad_norm 1.7791 (1.7357)	mem 17417MB
[2023-02-02 01:23:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][250/1251]	eta 0:09:35 lr 0.000356	time 0.6166 (0.5747)	loss 3.5053 (3.0802)	grad_norm 1.8629 (1.7436)	mem 17417MB
[2023-02-02 01:23:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][300/1251]	eta 0:09:05 lr 0.000356	time 0.5527 (0.5737)	loss 2.5474 (3.0705)	grad_norm 1.6858 (1.7398)	mem 17417MB
[2023-02-02 01:24:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][350/1251]	eta 0:08:36 lr 0.000356	time 0.5551 (0.5728)	loss 3.7183 (3.0603)	grad_norm 1.7582 (1.7372)	mem 17417MB
[2023-02-02 01:24:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][400/1251]	eta 0:08:07 lr 0.000355	time 0.5533 (0.5727)	loss 2.8030 (3.0588)	grad_norm 1.5372 (1.7354)	mem 17417MB
[2023-02-02 01:24:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][450/1251]	eta 0:07:38 lr 0.000355	time 0.5571 (0.5720)	loss 3.1926 (3.0556)	grad_norm 1.8109 (1.7333)	mem 17417MB
[2023-02-02 01:25:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][500/1251]	eta 0:07:09 lr 0.000355	time 0.5546 (0.5718)	loss 3.2913 (3.0538)	grad_norm 1.6393 (1.7298)	mem 17417MB
[2023-02-02 01:25:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][550/1251]	eta 0:06:40 lr 0.000355	time 0.5584 (0.5716)	loss 2.7558 (3.0549)	grad_norm 1.5777 (1.7285)	mem 17417MB
[2023-02-02 01:26:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][600/1251]	eta 0:06:12 lr 0.000355	time 0.5542 (0.5716)	loss 3.2449 (3.0578)	grad_norm 1.7196 (1.7270)	mem 17417MB
[2023-02-02 01:26:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][650/1251]	eta 0:05:43 lr 0.000354	time 0.5615 (0.5715)	loss 3.9143 (3.0605)	grad_norm 1.8272 (1.7253)	mem 17417MB
[2023-02-02 01:27:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][700/1251]	eta 0:05:14 lr 0.000354	time 0.5537 (0.5716)	loss 2.7470 (3.0595)	grad_norm 1.5436 (1.7240)	mem 17417MB
[2023-02-02 01:27:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][750/1251]	eta 0:04:46 lr 0.000354	time 0.5619 (0.5711)	loss 3.6097 (3.0546)	grad_norm 1.7414 (nan)	mem 17417MB
[2023-02-02 01:28:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][800/1251]	eta 0:04:17 lr 0.000354	time 0.5601 (0.5712)	loss 3.7428 (3.0535)	grad_norm 1.7781 (nan)	mem 17417MB
[2023-02-02 01:28:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][850/1251]	eta 0:03:49 lr 0.000354	time 0.5545 (0.5711)	loss 2.5950 (3.0503)	grad_norm 1.6235 (nan)	mem 17417MB
[2023-02-02 01:29:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][900/1251]	eta 0:03:20 lr 0.000353	time 0.5552 (0.5711)	loss 3.4312 (3.0485)	grad_norm 1.7210 (nan)	mem 17417MB
[2023-02-02 01:29:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][950/1251]	eta 0:02:51 lr 0.000353	time 0.5547 (0.5710)	loss 2.7412 (3.0444)	grad_norm 1.5439 (nan)	mem 17417MB
[2023-02-02 01:30:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][1000/1251]	eta 0:02:23 lr 0.000353	time 0.5573 (0.5708)	loss 3.6677 (3.0507)	grad_norm 1.5191 (nan)	mem 17417MB
[2023-02-02 01:30:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][1050/1251]	eta 0:01:54 lr 0.000353	time 0.5524 (0.5709)	loss 3.5851 (3.0459)	grad_norm 1.6593 (nan)	mem 17417MB
[2023-02-02 01:31:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][1100/1251]	eta 0:01:26 lr 0.000353	time 0.6534 (0.5708)	loss 3.3146 (3.0449)	grad_norm 1.9496 (nan)	mem 17417MB
[2023-02-02 01:31:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][1150/1251]	eta 0:00:57 lr 0.000352	time 0.5518 (0.5706)	loss 3.2684 (3.0478)	grad_norm 1.9935 (nan)	mem 17417MB
[2023-02-02 01:32:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][1200/1251]	eta 0:00:29 lr 0.000352	time 0.5541 (0.5706)	loss 3.8736 (3.0471)	grad_norm 1.6899 (nan)	mem 17417MB
[2023-02-02 01:32:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [179/300][1250/1251]	eta 0:00:00 lr 0.000352	time 0.5506 (0.5705)	loss 2.9986 (3.0450)	grad_norm 1.7088 (nan)	mem 17417MB
[2023-02-02 01:32:34 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 179 training takes 0:11:53
[2023-02-02 01:32:34 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_179.pth saving......
[2023-02-02 01:32:36 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_179.pth saved !!!
[2023-02-02 01:32:37 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.868 (0.868)	Loss 0.7744 (0.7744)	Acc@1 80.957 (80.957)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-02 01:32:45 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.172 Acc@5 95.862
[2023-02-02 01:32:45 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.2%
[2023-02-02 01:32:46 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.230 (1.230)	Loss 0.8237 (0.8237)	Acc@1 81.543 (81.543)	Acc@5 95.703 (95.703)	Mem 17417MB
[2023-02-02 01:32:54 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.658 Acc@5 96.494
[2023-02-02 01:32:54 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.7%
[2023-02-02 01:32:54 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.66% at 179 epoch
[2023-02-02 01:32:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][0/1251]	eta 0:35:06 lr 0.000352	time 1.6841 (1.6841)	loss 3.0691 (3.0691)	grad_norm 1.5049 (1.5049)	mem 17417MB
[2023-02-02 01:33:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][50/1251]	eta 0:11:50 lr 0.000352	time 0.5698 (0.5917)	loss 2.6427 (3.0887)	grad_norm 1.6146 (1.7390)	mem 17417MB
[2023-02-02 01:33:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][100/1251]	eta 0:11:09 lr 0.000352	time 0.5636 (0.5820)	loss 2.5737 (3.0618)	grad_norm 1.6667 (1.7283)	mem 17417MB
[2023-02-02 01:34:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][150/1251]	eta 0:10:35 lr 0.000351	time 0.5572 (0.5771)	loss 2.5783 (3.0337)	grad_norm 1.5747 (1.7414)	mem 17417MB
[2023-02-02 01:34:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][200/1251]	eta 0:10:04 lr 0.000351	time 0.5617 (0.5753)	loss 2.5632 (3.0404)	grad_norm 1.6790 (nan)	mem 17417MB
[2023-02-02 01:35:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][250/1251]	eta 0:09:34 lr 0.000351	time 0.6486 (0.5739)	loss 3.7235 (3.0319)	grad_norm 1.8477 (nan)	mem 17417MB
[2023-02-02 01:35:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][300/1251]	eta 0:09:04 lr 0.000351	time 0.5563 (0.5727)	loss 2.8459 (3.0241)	grad_norm 1.9152 (nan)	mem 17417MB
[2023-02-02 01:36:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][350/1251]	eta 0:08:35 lr 0.000351	time 0.5533 (0.5720)	loss 2.7928 (3.0286)	grad_norm 1.6680 (nan)	mem 17417MB
[2023-02-02 01:36:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][400/1251]	eta 0:08:06 lr 0.000350	time 0.6617 (0.5715)	loss 3.7689 (3.0394)	grad_norm 1.7158 (nan)	mem 17417MB
[2023-02-02 01:37:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][450/1251]	eta 0:07:37 lr 0.000350	time 0.5587 (0.5711)	loss 2.7817 (3.0383)	grad_norm 1.9618 (nan)	mem 17417MB
[2023-02-02 01:37:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][500/1251]	eta 0:07:08 lr 0.000350	time 0.5601 (0.5707)	loss 2.3617 (3.0326)	grad_norm 1.6102 (nan)	mem 17417MB
[2023-02-02 01:38:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][550/1251]	eta 0:06:39 lr 0.000350	time 0.5552 (0.5704)	loss 3.2659 (3.0349)	grad_norm 2.2665 (nan)	mem 17417MB
[2023-02-02 01:38:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][600/1251]	eta 0:06:11 lr 0.000350	time 0.5540 (0.5703)	loss 2.6068 (3.0418)	grad_norm 1.7675 (nan)	mem 17417MB
[2023-02-02 01:39:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][650/1251]	eta 0:05:42 lr 0.000349	time 0.5547 (0.5701)	loss 2.4753 (3.0435)	grad_norm 1.9036 (nan)	mem 17417MB
[2023-02-02 01:39:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][700/1251]	eta 0:05:13 lr 0.000349	time 0.5613 (0.5699)	loss 3.1947 (3.0483)	grad_norm 1.6887 (nan)	mem 17417MB
[2023-02-02 01:40:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][750/1251]	eta 0:04:45 lr 0.000349	time 0.5595 (0.5698)	loss 2.4515 (3.0451)	grad_norm 1.5173 (nan)	mem 17417MB
[2023-02-02 01:40:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][800/1251]	eta 0:04:16 lr 0.000349	time 0.5543 (0.5697)	loss 2.8688 (3.0494)	grad_norm 1.7169 (nan)	mem 17417MB
[2023-02-02 01:40:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][850/1251]	eta 0:03:48 lr 0.000349	time 0.5599 (0.5696)	loss 2.7705 (3.0533)	grad_norm 1.7231 (nan)	mem 17417MB
[2023-02-02 01:41:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][900/1251]	eta 0:03:19 lr 0.000348	time 0.5702 (0.5695)	loss 3.6581 (3.0539)	grad_norm 1.6193 (nan)	mem 17417MB
[2023-02-02 01:41:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][950/1251]	eta 0:02:51 lr 0.000348	time 0.5646 (0.5694)	loss 3.1221 (3.0517)	grad_norm 1.6609 (nan)	mem 17417MB
[2023-02-02 01:42:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][1000/1251]	eta 0:02:22 lr 0.000348	time 0.5550 (0.5696)	loss 3.2071 (3.0470)	grad_norm 1.6715 (nan)	mem 17417MB
[2023-02-02 01:42:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][1050/1251]	eta 0:01:54 lr 0.000348	time 0.5569 (0.5695)	loss 3.6041 (3.0457)	grad_norm 1.6342 (nan)	mem 17417MB
[2023-02-02 01:43:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][1100/1251]	eta 0:01:25 lr 0.000348	time 0.6121 (0.5693)	loss 3.7573 (3.0481)	grad_norm 1.6107 (nan)	mem 17417MB
[2023-02-02 01:43:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][1150/1251]	eta 0:00:57 lr 0.000348	time 0.5523 (0.5692)	loss 2.7386 (3.0470)	grad_norm 1.7505 (nan)	mem 17417MB
[2023-02-02 01:44:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][1200/1251]	eta 0:00:29 lr 0.000347	time 0.5551 (0.5690)	loss 3.7708 (3.0475)	grad_norm 1.7418 (nan)	mem 17417MB
[2023-02-02 01:44:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [180/300][1250/1251]	eta 0:00:00 lr 0.000347	time 0.5500 (0.5691)	loss 3.5217 (3.0529)	grad_norm 1.8699 (nan)	mem 17417MB
[2023-02-02 01:44:46 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 180 training takes 0:11:52
[2023-02-02 01:44:47 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_180.pth saving......
[2023-02-02 01:44:48 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_180.pth saved !!!
[2023-02-02 01:44:49 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.853 (0.853)	Loss 0.8429 (0.8429)	Acc@1 79.883 (79.883)	Acc@5 95.020 (95.020)	Mem 17417MB
[2023-02-02 01:44:57 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.174 Acc@5 95.902
[2023-02-02 01:44:57 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.2%
[2023-02-02 01:44:58 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.201 (1.201)	Loss 0.6982 (0.6982)	Acc@1 83.887 (83.887)	Acc@5 96.973 (96.973)	Mem 17417MB
[2023-02-02 01:45:06 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.686 Acc@5 96.472
[2023-02-02 01:45:06 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.7%
[2023-02-02 01:45:06 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.69% at 180 epoch
[2023-02-02 01:45:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][0/1251]	eta 0:36:08 lr 0.000347	time 1.7333 (1.7333)	loss 3.3707 (3.3707)	grad_norm 1.7711 (1.7711)	mem 17417MB
[2023-02-02 01:45:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][50/1251]	eta 0:11:52 lr 0.000347	time 0.5583 (0.5931)	loss 3.7446 (3.1348)	grad_norm 1.7186 (1.7034)	mem 17417MB
[2023-02-02 01:46:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][100/1251]	eta 0:11:09 lr 0.000347	time 0.5551 (0.5820)	loss 2.3912 (3.1109)	grad_norm 2.0159 (1.7328)	mem 17417MB
[2023-02-02 01:46:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][150/1251]	eta 0:10:35 lr 0.000347	time 0.5579 (0.5769)	loss 2.8552 (3.1049)	grad_norm 1.6820 (1.7222)	mem 17417MB
[2023-02-02 01:47:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][200/1251]	eta 0:10:04 lr 0.000346	time 0.5542 (0.5749)	loss 3.7006 (3.1200)	grad_norm 1.7233 (1.7361)	mem 17417MB
[2023-02-02 01:47:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][250/1251]	eta 0:09:34 lr 0.000346	time 0.5492 (0.5737)	loss 2.0776 (3.0949)	grad_norm 1.8334 (1.7378)	mem 17417MB
[2023-02-02 01:47:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][300/1251]	eta 0:09:04 lr 0.000346	time 0.6249 (0.5728)	loss 1.9150 (3.0837)	grad_norm 1.6741 (1.7385)	mem 17417MB
[2023-02-02 01:48:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][350/1251]	eta 0:08:35 lr 0.000346	time 0.5672 (0.5724)	loss 2.2740 (3.0720)	grad_norm 1.5347 (1.7361)	mem 17417MB
[2023-02-02 01:48:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][400/1251]	eta 0:08:06 lr 0.000346	time 0.5563 (0.5717)	loss 2.7170 (3.0604)	grad_norm 1.9096 (1.7359)	mem 17417MB
[2023-02-02 01:49:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][450/1251]	eta 0:07:37 lr 0.000345	time 0.5583 (0.5716)	loss 2.3787 (3.0592)	grad_norm 1.7595 (1.7385)	mem 17417MB
[2023-02-02 01:49:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][500/1251]	eta 0:07:08 lr 0.000345	time 0.5545 (0.5710)	loss 3.0802 (3.0665)	grad_norm 1.5004 (1.7442)	mem 17417MB
[2023-02-02 01:50:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][550/1251]	eta 0:06:40 lr 0.000345	time 0.5559 (0.5709)	loss 2.3386 (3.0658)	grad_norm 1.5813 (1.7416)	mem 17417MB
[2023-02-02 01:50:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][600/1251]	eta 0:06:11 lr 0.000345	time 0.5557 (0.5708)	loss 3.2852 (3.0640)	grad_norm 1.5268 (1.7370)	mem 17417MB
[2023-02-02 01:51:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][650/1251]	eta 0:05:42 lr 0.000345	time 0.5738 (0.5707)	loss 3.2022 (3.0633)	grad_norm 1.6267 (1.7381)	mem 17417MB
[2023-02-02 01:51:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][700/1251]	eta 0:05:14 lr 0.000344	time 0.5604 (0.5704)	loss 3.3729 (3.0650)	grad_norm 1.6277 (1.7334)	mem 17417MB
[2023-02-02 01:52:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][750/1251]	eta 0:04:45 lr 0.000344	time 0.5479 (0.5699)	loss 3.4231 (3.0576)	grad_norm 1.7108 (1.7340)	mem 17417MB
[2023-02-02 01:52:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][800/1251]	eta 0:04:17 lr 0.000344	time 0.5587 (0.5700)	loss 2.9419 (3.0583)	grad_norm 1.8641 (1.7342)	mem 17417MB
[2023-02-02 01:53:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][850/1251]	eta 0:03:48 lr 0.000344	time 0.5478 (0.5698)	loss 3.3160 (3.0562)	grad_norm 1.6391 (1.7315)	mem 17417MB
[2023-02-02 01:53:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][900/1251]	eta 0:03:20 lr 0.000344	time 0.5572 (0.5699)	loss 3.1359 (3.0517)	grad_norm 1.5912 (1.7335)	mem 17417MB
[2023-02-02 01:54:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][950/1251]	eta 0:02:51 lr 0.000343	time 0.5560 (0.5697)	loss 3.6578 (3.0508)	grad_norm 1.5248 (1.7344)	mem 17417MB
[2023-02-02 01:54:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][1000/1251]	eta 0:02:22 lr 0.000343	time 0.5560 (0.5696)	loss 2.8845 (3.0500)	grad_norm 1.5615 (1.7340)	mem 17417MB
[2023-02-02 01:55:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][1050/1251]	eta 0:01:54 lr 0.000343	time 0.5589 (0.5695)	loss 3.4522 (3.0517)	grad_norm 1.7050 (1.7326)	mem 17417MB
[2023-02-02 01:55:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][1100/1251]	eta 0:01:25 lr 0.000343	time 0.6218 (0.5694)	loss 2.5779 (3.0525)	grad_norm 1.7898 (1.7317)	mem 17417MB
[2023-02-02 01:56:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][1150/1251]	eta 0:00:57 lr 0.000343	time 0.5619 (0.5694)	loss 3.2093 (3.0501)	grad_norm 1.8162 (1.7316)	mem 17417MB
[2023-02-02 01:56:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][1200/1251]	eta 0:00:29 lr 0.000342	time 0.5531 (0.5693)	loss 2.6895 (3.0531)	grad_norm 1.5491 (1.7325)	mem 17417MB
[2023-02-02 01:56:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [181/300][1250/1251]	eta 0:00:00 lr 0.000342	time 0.5554 (0.5694)	loss 3.3173 (3.0515)	grad_norm 1.7507 (1.7324)	mem 17417MB
[2023-02-02 01:56:59 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 181 training takes 0:11:52
[2023-02-02 01:56:59 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_181.pth saving......
[2023-02-02 01:57:01 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_181.pth saved !!!
[2023-02-02 01:57:01 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.849 (0.849)	Loss 0.8949 (0.8949)	Acc@1 81.055 (81.055)	Acc@5 93.457 (93.457)	Mem 17417MB
[2023-02-02 01:57:09 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.184 Acc@5 95.820
[2023-02-02 01:57:09 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.2%
[2023-02-02 01:57:10 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.174 (1.174)	Loss 0.7079 (0.7079)	Acc@1 83.594 (83.594)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-02 01:57:18 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.724 Acc@5 96.502
[2023-02-02 01:57:18 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.7%
[2023-02-02 01:57:18 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.72% at 181 epoch
[2023-02-02 01:57:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][0/1251]	eta 0:36:13 lr 0.000342	time 1.7373 (1.7373)	loss 1.9585 (1.9585)	grad_norm 1.4625 (1.4625)	mem 17417MB
[2023-02-02 01:57:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][50/1251]	eta 0:11:49 lr 0.000342	time 0.5552 (0.5904)	loss 3.5629 (3.0730)	grad_norm 1.8425 (1.7298)	mem 17417MB
[2023-02-02 01:58:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][100/1251]	eta 0:11:09 lr 0.000342	time 0.6120 (0.5820)	loss 3.4024 (3.0483)	grad_norm 1.7466 (1.7420)	mem 17417MB
[2023-02-02 01:58:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][150/1251]	eta 0:10:35 lr 0.000342	time 0.5622 (0.5773)	loss 2.0844 (3.0433)	grad_norm 1.6833 (1.7411)	mem 17417MB
[2023-02-02 01:59:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][200/1251]	eta 0:10:04 lr 0.000341	time 0.5559 (0.5751)	loss 3.3688 (3.0283)	grad_norm 1.8182 (1.7446)	mem 17417MB
[2023-02-02 01:59:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][250/1251]	eta 0:09:34 lr 0.000341	time 0.5639 (0.5740)	loss 3.0792 (3.0253)	grad_norm 1.5765 (1.7462)	mem 17417MB
[2023-02-02 02:00:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][300/1251]	eta 0:09:05 lr 0.000341	time 0.5513 (0.5733)	loss 3.2430 (3.0261)	grad_norm 1.7252 (1.7417)	mem 17417MB
[2023-02-02 02:00:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][350/1251]	eta 0:08:35 lr 0.000341	time 0.5566 (0.5726)	loss 3.7158 (3.0539)	grad_norm 1.9176 (1.7452)	mem 17417MB
[2023-02-02 02:01:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][400/1251]	eta 0:08:06 lr 0.000341	time 0.5637 (0.5721)	loss 3.4134 (3.0608)	grad_norm 1.7571 (1.7421)	mem 17417MB
[2023-02-02 02:01:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][450/1251]	eta 0:07:37 lr 0.000340	time 0.5586 (0.5716)	loss 3.4088 (3.0556)	grad_norm 1.6971 (1.7409)	mem 17417MB
[2023-02-02 02:02:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][500/1251]	eta 0:07:09 lr 0.000340	time 0.6156 (0.5716)	loss 3.3050 (3.0548)	grad_norm 1.7074 (1.7382)	mem 17417MB
[2023-02-02 02:02:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][550/1251]	eta 0:06:40 lr 0.000340	time 0.5620 (0.5711)	loss 2.7961 (3.0604)	grad_norm 1.6227 (1.7348)	mem 17417MB
[2023-02-02 02:03:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][600/1251]	eta 0:06:11 lr 0.000340	time 0.5559 (0.5710)	loss 3.5448 (3.0602)	grad_norm 1.8313 (1.7336)	mem 17417MB
[2023-02-02 02:03:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][650/1251]	eta 0:05:43 lr 0.000340	time 0.5583 (0.5708)	loss 2.5545 (3.0551)	grad_norm 1.8146 (1.7336)	mem 17417MB
[2023-02-02 02:03:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][700/1251]	eta 0:05:14 lr 0.000339	time 0.5548 (0.5708)	loss 3.1531 (3.0564)	grad_norm 1.7441 (1.7337)	mem 17417MB
[2023-02-02 02:04:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][750/1251]	eta 0:04:45 lr 0.000339	time 0.5602 (0.5704)	loss 2.5597 (3.0508)	grad_norm 1.9410 (1.7349)	mem 17417MB
[2023-02-02 02:04:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][800/1251]	eta 0:04:17 lr 0.000339	time 0.5578 (0.5704)	loss 2.1924 (3.0405)	grad_norm 1.6234 (1.7374)	mem 17417MB
[2023-02-02 02:05:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][850/1251]	eta 0:03:48 lr 0.000339	time 0.5516 (0.5703)	loss 3.3587 (3.0384)	grad_norm 1.6740 (1.7399)	mem 17417MB
[2023-02-02 02:05:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][900/1251]	eta 0:03:20 lr 0.000339	time 0.6135 (0.5705)	loss 2.9819 (3.0383)	grad_norm 1.9154 (1.7400)	mem 17417MB
[2023-02-02 02:06:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][950/1251]	eta 0:02:51 lr 0.000338	time 0.5587 (0.5703)	loss 2.5129 (3.0425)	grad_norm 1.6242 (1.7423)	mem 17417MB
[2023-02-02 02:06:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][1000/1251]	eta 0:02:23 lr 0.000338	time 0.5530 (0.5702)	loss 3.5645 (3.0407)	grad_norm 2.1545 (1.7430)	mem 17417MB
[2023-02-02 02:07:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][1050/1251]	eta 0:01:54 lr 0.000338	time 0.5733 (0.5701)	loss 3.0819 (3.0423)	grad_norm 1.6949 (1.7441)	mem 17417MB
[2023-02-02 02:07:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][1100/1251]	eta 0:01:26 lr 0.000338	time 0.5525 (0.5701)	loss 3.2669 (3.0482)	grad_norm 1.8634 (1.7442)	mem 17417MB
[2023-02-02 02:08:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][1150/1251]	eta 0:00:57 lr 0.000338	time 0.5606 (0.5701)	loss 3.4060 (3.0474)	grad_norm 1.9561 (1.7461)	mem 17417MB
[2023-02-02 02:08:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][1200/1251]	eta 0:00:29 lr 0.000338	time 0.6497 (0.5701)	loss 2.9996 (3.0463)	grad_norm 1.9441 (1.7466)	mem 17417MB
[2023-02-02 02:09:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [182/300][1250/1251]	eta 0:00:00 lr 0.000337	time 0.5513 (0.5700)	loss 1.8477 (3.0440)	grad_norm 1.5088 (1.7484)	mem 17417MB
[2023-02-02 02:09:12 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 182 training takes 0:11:53
[2023-02-02 02:09:12 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_182.pth saving......
[2023-02-02 02:09:14 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_182.pth saved !!!
[2023-02-02 02:09:14 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.872 (0.872)	Loss 0.7990 (0.7990)	Acc@1 80.859 (80.859)	Acc@5 95.605 (95.605)	Mem 17417MB
[2023-02-02 02:09:22 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.302 Acc@5 95.968
[2023-02-02 02:09:22 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.3%
[2023-02-02 02:09:24 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.230 (1.230)	Loss 0.7744 (0.7744)	Acc@1 81.543 (81.543)	Acc@5 95.410 (95.410)	Mem 17417MB
[2023-02-02 02:09:32 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.752 Acc@5 96.534
[2023-02-02 02:09:32 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.8%
[2023-02-02 02:09:32 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.75% at 182 epoch
[2023-02-02 02:09:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][0/1251]	eta 0:37:11 lr 0.000337	time 1.7839 (1.7839)	loss 2.7588 (2.7588)	grad_norm 1.7943 (1.7943)	mem 17417MB
[2023-02-02 02:10:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][50/1251]	eta 0:11:53 lr 0.000337	time 0.5569 (0.5941)	loss 3.0049 (2.9953)	grad_norm 1.6466 (1.7391)	mem 17417MB
[2023-02-02 02:10:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][100/1251]	eta 0:11:09 lr 0.000337	time 0.5535 (0.5815)	loss 2.5231 (2.9728)	grad_norm 1.8119 (1.7250)	mem 17417MB
[2023-02-02 02:10:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][150/1251]	eta 0:10:35 lr 0.000337	time 0.5549 (0.5772)	loss 3.4557 (3.0519)	grad_norm 1.6593 (1.7252)	mem 17417MB
[2023-02-02 02:11:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][200/1251]	eta 0:10:03 lr 0.000337	time 0.5492 (0.5746)	loss 3.3773 (3.0710)	grad_norm 1.8471 (1.7295)	mem 17417MB
[2023-02-02 02:11:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][250/1251]	eta 0:09:33 lr 0.000336	time 0.5563 (0.5730)	loss 3.0712 (3.0717)	grad_norm 1.4703 (1.7354)	mem 17417MB
[2023-02-02 02:12:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][300/1251]	eta 0:09:04 lr 0.000336	time 0.5556 (0.5723)	loss 2.5809 (3.0588)	grad_norm 1.7839 (1.7384)	mem 17417MB
[2023-02-02 02:12:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][350/1251]	eta 0:08:34 lr 0.000336	time 0.5686 (0.5714)	loss 2.1886 (3.0478)	grad_norm 1.8410 (1.7424)	mem 17417MB
[2023-02-02 02:13:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][400/1251]	eta 0:08:05 lr 0.000336	time 0.5632 (0.5707)	loss 3.9338 (3.0516)	grad_norm 1.8492 (1.7456)	mem 17417MB
[2023-02-02 02:13:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][450/1251]	eta 0:07:37 lr 0.000336	time 0.6185 (0.5707)	loss 3.0007 (3.0243)	grad_norm 1.7182 (1.7476)	mem 17417MB
[2023-02-02 02:14:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][500/1251]	eta 0:07:08 lr 0.000335	time 0.5620 (0.5700)	loss 3.0281 (3.0179)	grad_norm 1.6338 (1.7464)	mem 17417MB
[2023-02-02 02:14:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][550/1251]	eta 0:06:39 lr 0.000335	time 0.5578 (0.5700)	loss 3.3809 (3.0250)	grad_norm 1.8000 (1.7463)	mem 17417MB
[2023-02-02 02:15:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][600/1251]	eta 0:06:11 lr 0.000335	time 0.5562 (0.5699)	loss 3.3916 (3.0238)	grad_norm 1.7050 (1.7461)	mem 17417MB
[2023-02-02 02:15:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][650/1251]	eta 0:05:42 lr 0.000335	time 0.5563 (0.5699)	loss 2.5202 (3.0227)	grad_norm 1.5688 (1.7484)	mem 17417MB
[2023-02-02 02:16:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][700/1251]	eta 0:05:13 lr 0.000335	time 0.5625 (0.5697)	loss 3.4240 (3.0338)	grad_norm 1.7617 (1.7491)	mem 17417MB
[2023-02-02 02:16:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][750/1251]	eta 0:04:45 lr 0.000334	time 0.5630 (0.5697)	loss 3.1929 (3.0349)	grad_norm 1.4762 (1.7472)	mem 17417MB
[2023-02-02 02:17:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][800/1251]	eta 0:04:16 lr 0.000334	time 0.5533 (0.5695)	loss 3.5948 (3.0327)	grad_norm 1.7609 (nan)	mem 17417MB
[2023-02-02 02:17:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][850/1251]	eta 0:03:48 lr 0.000334	time 0.5542 (0.5695)	loss 2.8518 (3.0358)	grad_norm 1.6785 (nan)	mem 17417MB
[2023-02-02 02:18:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][900/1251]	eta 0:03:19 lr 0.000334	time 0.5589 (0.5695)	loss 3.2750 (3.0326)	grad_norm 1.6735 (nan)	mem 17417MB
[2023-02-02 02:18:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][950/1251]	eta 0:02:51 lr 0.000334	time 0.5577 (0.5694)	loss 3.3755 (3.0290)	grad_norm 1.5187 (nan)	mem 17417MB
[2023-02-02 02:19:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][1000/1251]	eta 0:02:22 lr 0.000333	time 0.5587 (0.5693)	loss 1.8966 (3.0330)	grad_norm 1.7336 (nan)	mem 17417MB
[2023-02-02 02:19:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][1050/1251]	eta 0:01:54 lr 0.000333	time 0.5577 (0.5692)	loss 3.3458 (3.0362)	grad_norm 1.6307 (nan)	mem 17417MB
[2023-02-02 02:19:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][1100/1251]	eta 0:01:25 lr 0.000333	time 0.5686 (0.5690)	loss 2.9618 (3.0318)	grad_norm 1.7417 (nan)	mem 17417MB
[2023-02-02 02:20:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][1150/1251]	eta 0:00:57 lr 0.000333	time 0.5486 (0.5690)	loss 3.1051 (3.0240)	grad_norm 1.6008 (nan)	mem 17417MB
[2023-02-02 02:20:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][1200/1251]	eta 0:00:29 lr 0.000333	time 0.5622 (0.5690)	loss 3.4452 (3.0228)	grad_norm 1.7353 (nan)	mem 17417MB
[2023-02-02 02:21:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [183/300][1250/1251]	eta 0:00:00 lr 0.000332	time 0.5491 (0.5689)	loss 1.6794 (3.0266)	grad_norm 1.7858 (nan)	mem 17417MB
[2023-02-02 02:21:23 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 183 training takes 0:11:51
[2023-02-02 02:21:24 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_183.pth saving......
[2023-02-02 02:21:25 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_183.pth saved !!!
[2023-02-02 02:21:26 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.868 (0.868)	Loss 0.7259 (0.7259)	Acc@1 82.031 (82.031)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 02:21:34 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.300 Acc@5 95.904
[2023-02-02 02:21:34 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.3%
[2023-02-02 02:21:36 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.363 (1.363)	Loss 0.7281 (0.7281)	Acc@1 81.348 (81.348)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-02 02:21:44 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.776 Acc@5 96.578
[2023-02-02 02:21:44 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.8%
[2023-02-02 02:21:44 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.78% at 183 epoch
[2023-02-02 02:21:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][0/1251]	eta 0:33:18 lr 0.000332	time 1.5973 (1.5973)	loss 2.1009 (2.1009)	grad_norm 1.5501 (1.5501)	mem 17417MB
[2023-02-02 02:22:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][50/1251]	eta 0:11:46 lr 0.000332	time 0.5580 (0.5880)	loss 2.7048 (3.0399)	grad_norm 1.7184 (1.7457)	mem 17417MB
[2023-02-02 02:22:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][100/1251]	eta 0:11:07 lr 0.000332	time 0.6566 (0.5802)	loss 1.8321 (3.0118)	grad_norm 1.8186 (1.7454)	mem 17417MB
[2023-02-02 02:23:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][150/1251]	eta 0:10:33 lr 0.000332	time 0.5605 (0.5755)	loss 3.0046 (3.0008)	grad_norm 1.7386 (1.7548)	mem 17417MB
[2023-02-02 02:23:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][200/1251]	eta 0:10:03 lr 0.000332	time 0.5606 (0.5746)	loss 2.9226 (3.0244)	grad_norm 1.6466 (1.7509)	mem 17417MB
[2023-02-02 02:24:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][250/1251]	eta 0:09:33 lr 0.000331	time 0.6151 (0.5730)	loss 3.0246 (3.0604)	grad_norm 1.7330 (1.7505)	mem 17417MB
[2023-02-02 02:24:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][300/1251]	eta 0:09:04 lr 0.000331	time 0.5538 (0.5725)	loss 3.1767 (3.0573)	grad_norm 1.7699 (1.7647)	mem 17417MB
[2023-02-02 02:25:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][350/1251]	eta 0:08:34 lr 0.000331	time 0.5519 (0.5715)	loss 2.8848 (3.0490)	grad_norm 1.4494 (1.7733)	mem 17417MB
[2023-02-02 02:25:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][400/1251]	eta 0:08:06 lr 0.000331	time 0.5540 (0.5711)	loss 3.1078 (3.0583)	grad_norm 2.0146 (1.7683)	mem 17417MB
[2023-02-02 02:26:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][450/1251]	eta 0:07:37 lr 0.000331	time 0.5502 (0.5710)	loss 3.3513 (3.0533)	grad_norm 1.7538 (1.7658)	mem 17417MB
[2023-02-02 02:26:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][500/1251]	eta 0:07:08 lr 0.000331	time 0.5587 (0.5705)	loss 2.4114 (3.0553)	grad_norm 1.7081 (1.7615)	mem 17417MB
[2023-02-02 02:26:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][550/1251]	eta 0:06:39 lr 0.000330	time 0.5529 (0.5704)	loss 2.9455 (3.0626)	grad_norm 1.9492 (1.7626)	mem 17417MB
[2023-02-02 02:27:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][600/1251]	eta 0:06:11 lr 0.000330	time 0.5597 (0.5702)	loss 3.2553 (3.0664)	grad_norm 1.4780 (1.7610)	mem 17417MB
[2023-02-02 02:27:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][650/1251]	eta 0:05:42 lr 0.000330	time 0.5583 (0.5702)	loss 3.4331 (3.0665)	grad_norm 1.8265 (1.7612)	mem 17417MB
[2023-02-02 02:28:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][700/1251]	eta 0:05:14 lr 0.000330	time 0.5543 (0.5700)	loss 3.6579 (3.0694)	grad_norm 1.8097 (1.7625)	mem 17417MB
[2023-02-02 02:28:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][750/1251]	eta 0:04:45 lr 0.000330	time 0.5504 (0.5700)	loss 3.1811 (3.0638)	grad_norm 1.7182 (1.7628)	mem 17417MB
[2023-02-02 02:29:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][800/1251]	eta 0:04:16 lr 0.000329	time 0.6239 (0.5698)	loss 3.3210 (3.0621)	grad_norm 1.7449 (1.7622)	mem 17417MB
[2023-02-02 02:29:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][850/1251]	eta 0:03:48 lr 0.000329	time 0.5619 (0.5697)	loss 2.3132 (3.0556)	grad_norm 2.2088 (1.7619)	mem 17417MB
[2023-02-02 02:30:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][900/1251]	eta 0:03:19 lr 0.000329	time 0.5529 (0.5697)	loss 3.2033 (3.0584)	grad_norm 1.7899 (1.7597)	mem 17417MB
[2023-02-02 02:30:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][950/1251]	eta 0:02:51 lr 0.000329	time 0.5574 (0.5697)	loss 2.8652 (3.0525)	grad_norm 1.8919 (1.7594)	mem 17417MB
[2023-02-02 02:31:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][1000/1251]	eta 0:02:22 lr 0.000329	time 0.5534 (0.5697)	loss 2.4187 (3.0476)	grad_norm 1.6677 (1.7588)	mem 17417MB
[2023-02-02 02:31:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][1050/1251]	eta 0:01:54 lr 0.000328	time 0.6415 (0.5697)	loss 3.5861 (3.0477)	grad_norm 1.6843 (1.7582)	mem 17417MB
[2023-02-02 02:32:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][1100/1251]	eta 0:01:26 lr 0.000328	time 0.6274 (0.5696)	loss 2.8953 (3.0483)	grad_norm 1.7797 (1.7556)	mem 17417MB
[2023-02-02 02:32:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][1150/1251]	eta 0:00:57 lr 0.000328	time 0.5575 (0.5695)	loss 3.6349 (3.0458)	grad_norm 1.8333 (1.7548)	mem 17417MB
[2023-02-02 02:33:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][1200/1251]	eta 0:00:29 lr 0.000328	time 0.5811 (0.5694)	loss 2.7703 (3.0518)	grad_norm 1.5939 (1.7553)	mem 17417MB
[2023-02-02 02:33:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [184/300][1250/1251]	eta 0:00:00 lr 0.000328	time 0.5508 (0.5695)	loss 2.8891 (3.0535)	grad_norm 1.6544 (1.7563)	mem 17417MB
[2023-02-02 02:33:36 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 184 training takes 0:11:52
[2023-02-02 02:33:36 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_184.pth saving......
[2023-02-02 02:33:38 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_184.pth saved !!!
[2023-02-02 02:33:39 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.022 (1.022)	Loss 0.8804 (0.8804)	Acc@1 79.102 (79.102)	Acc@5 95.117 (95.117)	Mem 17417MB
[2023-02-02 02:33:47 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.350 Acc@5 95.854
[2023-02-02 02:33:47 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.4%
[2023-02-02 02:33:48 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.215 (1.215)	Loss 0.7683 (0.7683)	Acc@1 82.910 (82.910)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-02 02:33:56 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.822 Acc@5 96.574
[2023-02-02 02:33:56 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.8%
[2023-02-02 02:33:56 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.82% at 184 epoch
[2023-02-02 02:33:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][0/1251]	eta 0:38:53 lr 0.000328	time 1.8654 (1.8654)	loss 2.8875 (2.8875)	grad_norm 1.7445 (1.7445)	mem 17417MB
[2023-02-02 02:34:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][50/1251]	eta 0:11:54 lr 0.000327	time 0.5551 (0.5953)	loss 2.1274 (2.9174)	grad_norm 1.6061 (1.7656)	mem 17417MB
[2023-02-02 02:34:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][100/1251]	eta 0:11:11 lr 0.000327	time 0.5563 (0.5830)	loss 2.0775 (2.9806)	grad_norm 1.7792 (1.7439)	mem 17417MB
[2023-02-02 02:35:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][150/1251]	eta 0:10:36 lr 0.000327	time 0.6285 (0.5781)	loss 3.0694 (3.0078)	grad_norm 1.6338 (1.7435)	mem 17417MB
[2023-02-02 02:35:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][200/1251]	eta 0:10:04 lr 0.000327	time 0.5537 (0.5752)	loss 2.9191 (2.9886)	grad_norm 1.6302 (1.7480)	mem 17417MB
[2023-02-02 02:36:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][250/1251]	eta 0:09:33 lr 0.000327	time 0.5484 (0.5732)	loss 3.3397 (3.0122)	grad_norm 1.7359 (1.7529)	mem 17417MB
[2023-02-02 02:36:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][300/1251]	eta 0:09:04 lr 0.000326	time 0.5578 (0.5728)	loss 2.8501 (3.0030)	grad_norm 1.8338 (nan)	mem 17417MB
[2023-02-02 02:37:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][350/1251]	eta 0:08:35 lr 0.000326	time 0.5561 (0.5716)	loss 3.3241 (2.9959)	grad_norm 1.9383 (nan)	mem 17417MB
[2023-02-02 02:37:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][400/1251]	eta 0:08:06 lr 0.000326	time 0.5581 (0.5715)	loss 3.5810 (3.0038)	grad_norm 1.9167 (nan)	mem 17417MB
[2023-02-02 02:38:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][450/1251]	eta 0:07:37 lr 0.000326	time 0.5550 (0.5714)	loss 2.7277 (3.0040)	grad_norm 1.7076 (nan)	mem 17417MB
[2023-02-02 02:38:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][500/1251]	eta 0:07:08 lr 0.000326	time 0.5808 (0.5709)	loss 2.8259 (3.0092)	grad_norm 1.8055 (nan)	mem 17417MB
[2023-02-02 02:39:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][550/1251]	eta 0:06:40 lr 0.000325	time 0.5543 (0.5709)	loss 2.3824 (3.0088)	grad_norm 1.5286 (nan)	mem 17417MB
[2023-02-02 02:39:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][600/1251]	eta 0:06:11 lr 0.000325	time 0.5533 (0.5710)	loss 2.8832 (3.0114)	grad_norm 1.6438 (nan)	mem 17417MB
[2023-02-02 02:40:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][650/1251]	eta 0:05:42 lr 0.000325	time 0.5484 (0.5705)	loss 3.1220 (3.0128)	grad_norm 1.6158 (nan)	mem 17417MB
[2023-02-02 02:40:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][700/1251]	eta 0:05:14 lr 0.000325	time 0.5662 (0.5704)	loss 3.1346 (3.0244)	grad_norm 1.6872 (nan)	mem 17417MB
[2023-02-02 02:41:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][750/1251]	eta 0:04:45 lr 0.000325	time 0.5565 (0.5701)	loss 3.9763 (3.0262)	grad_norm 1.8401 (nan)	mem 17417MB
[2023-02-02 02:41:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][800/1251]	eta 0:04:17 lr 0.000325	time 0.5531 (0.5703)	loss 3.1977 (3.0324)	grad_norm 1.7805 (nan)	mem 17417MB
[2023-02-02 02:42:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][850/1251]	eta 0:03:48 lr 0.000324	time 0.5574 (0.5701)	loss 3.5317 (3.0376)	grad_norm 1.6223 (nan)	mem 17417MB
[2023-02-02 02:42:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][900/1251]	eta 0:03:20 lr 0.000324	time 0.6439 (0.5700)	loss 2.8208 (3.0294)	grad_norm 1.7588 (nan)	mem 17417MB
[2023-02-02 02:42:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][950/1251]	eta 0:02:51 lr 0.000324	time 0.5592 (0.5697)	loss 2.8034 (3.0266)	grad_norm 1.7238 (nan)	mem 17417MB
[2023-02-02 02:43:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][1000/1251]	eta 0:02:22 lr 0.000324	time 0.5571 (0.5697)	loss 2.9309 (3.0297)	grad_norm 1.8244 (nan)	mem 17417MB
[2023-02-02 02:43:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][1050/1251]	eta 0:01:54 lr 0.000324	time 0.5546 (0.5695)	loss 3.1902 (3.0283)	grad_norm 1.8499 (nan)	mem 17417MB
[2023-02-02 02:44:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][1100/1251]	eta 0:01:26 lr 0.000323	time 0.6343 (0.5696)	loss 1.9774 (3.0273)	grad_norm 2.0460 (nan)	mem 17417MB
[2023-02-02 02:44:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][1150/1251]	eta 0:00:57 lr 0.000323	time 0.5621 (0.5694)	loss 2.4752 (3.0268)	grad_norm 1.6207 (nan)	mem 17417MB
[2023-02-02 02:45:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][1200/1251]	eta 0:00:29 lr 0.000323	time 0.5536 (0.5694)	loss 3.7714 (3.0276)	grad_norm 1.7207 (nan)	mem 17417MB
[2023-02-02 02:45:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [185/300][1250/1251]	eta 0:00:00 lr 0.000323	time 0.5501 (0.5694)	loss 3.2941 (3.0308)	grad_norm 1.7649 (nan)	mem 17417MB
[2023-02-02 02:45:49 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 185 training takes 0:11:52
[2023-02-02 02:45:49 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_185.pth saving......
[2023-02-02 02:45:51 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_185.pth saved !!!
[2023-02-02 02:45:52 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.857 (0.857)	Loss 0.7875 (0.7875)	Acc@1 81.055 (81.055)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-02 02:46:00 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.576 Acc@5 95.910
[2023-02-02 02:46:00 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.6%
[2023-02-02 02:46:01 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.258 (1.258)	Loss 0.7202 (0.7202)	Acc@1 83.984 (83.984)	Acc@5 96.582 (96.582)	Mem 17417MB
[2023-02-02 02:46:09 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.810 Acc@5 96.572
[2023-02-02 02:46:09 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.8%
[2023-02-02 02:46:09 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.82% at 184 epoch
[2023-02-02 02:46:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][0/1251]	eta 0:36:25 lr 0.000323	time 1.7473 (1.7473)	loss 2.5468 (2.5468)	grad_norm 1.5109 (1.5109)	mem 17417MB
[2023-02-02 02:46:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][50/1251]	eta 0:11:53 lr 0.000323	time 0.5640 (0.5944)	loss 2.1463 (2.9631)	grad_norm 1.8111 (1.8010)	mem 17417MB
[2023-02-02 02:47:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][100/1251]	eta 0:11:10 lr 0.000322	time 0.5543 (0.5823)	loss 1.8772 (3.0318)	grad_norm 1.7800 (1.7716)	mem 17417MB
[2023-02-02 02:47:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][150/1251]	eta 0:10:34 lr 0.000322	time 0.5549 (0.5767)	loss 3.5255 (3.0531)	grad_norm 1.6856 (1.7640)	mem 17417MB
[2023-02-02 02:48:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][200/1251]	eta 0:10:02 lr 0.000322	time 0.5579 (0.5735)	loss 2.7261 (3.0264)	grad_norm 1.7022 (1.7617)	mem 17417MB
[2023-02-02 02:48:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][250/1251]	eta 0:09:33 lr 0.000322	time 0.5516 (0.5726)	loss 2.8690 (3.0328)	grad_norm 1.9845 (1.7710)	mem 17417MB
[2023-02-02 02:49:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][300/1251]	eta 0:09:03 lr 0.000322	time 0.5477 (0.5714)	loss 3.2773 (3.0239)	grad_norm 1.7575 (1.7665)	mem 17417MB
[2023-02-02 02:49:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][350/1251]	eta 0:08:34 lr 0.000321	time 0.5548 (0.5708)	loss 3.2832 (3.0351)	grad_norm 1.5724 (1.7697)	mem 17417MB
[2023-02-02 02:49:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][400/1251]	eta 0:08:05 lr 0.000321	time 0.5555 (0.5704)	loss 3.2202 (3.0366)	grad_norm 1.5325 (1.7674)	mem 17417MB
[2023-02-02 02:50:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][450/1251]	eta 0:07:36 lr 0.000321	time 0.5574 (0.5699)	loss 3.6767 (3.0343)	grad_norm 1.8939 (1.7671)	mem 17417MB
[2023-02-02 02:50:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][500/1251]	eta 0:07:07 lr 0.000321	time 0.5553 (0.5699)	loss 2.3692 (3.0236)	grad_norm 1.7222 (1.7631)	mem 17417MB
[2023-02-02 02:51:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][550/1251]	eta 0:06:39 lr 0.000321	time 0.5646 (0.5695)	loss 2.1868 (3.0208)	grad_norm 1.7566 (1.7613)	mem 17417MB
[2023-02-02 02:51:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][600/1251]	eta 0:06:10 lr 0.000320	time 0.5554 (0.5695)	loss 3.3280 (3.0228)	grad_norm 1.7741 (1.7612)	mem 17417MB
[2023-02-02 02:52:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][650/1251]	eta 0:05:42 lr 0.000320	time 0.5602 (0.5693)	loss 2.3676 (3.0136)	grad_norm 1.8871 (1.7637)	mem 17417MB
[2023-02-02 02:52:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][700/1251]	eta 0:05:13 lr 0.000320	time 0.5578 (0.5690)	loss 3.4087 (3.0218)	grad_norm 1.6366 (1.7658)	mem 17417MB
[2023-02-02 02:53:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][750/1251]	eta 0:04:45 lr 0.000320	time 0.5597 (0.5689)	loss 3.4092 (3.0267)	grad_norm 2.0669 (1.7645)	mem 17417MB
[2023-02-02 02:53:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][800/1251]	eta 0:04:16 lr 0.000320	time 0.5602 (0.5689)	loss 3.1560 (3.0263)	grad_norm 1.7052 (1.7651)	mem 17417MB
[2023-02-02 02:54:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][850/1251]	eta 0:03:48 lr 0.000320	time 0.5588 (0.5687)	loss 2.4384 (3.0272)	grad_norm 1.7307 (1.7647)	mem 17417MB
[2023-02-02 02:54:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][900/1251]	eta 0:03:19 lr 0.000319	time 0.5556 (0.5688)	loss 3.2447 (3.0295)	grad_norm 2.2334 (1.7652)	mem 17417MB
[2023-02-02 02:55:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][950/1251]	eta 0:02:51 lr 0.000319	time 0.5525 (0.5685)	loss 2.5298 (3.0209)	grad_norm 1.5815 (1.7659)	mem 17417MB
[2023-02-02 02:55:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][1000/1251]	eta 0:02:22 lr 0.000319	time 0.5617 (0.5685)	loss 2.0524 (3.0212)	grad_norm 1.8802 (1.7673)	mem 17417MB
[2023-02-02 02:56:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][1050/1251]	eta 0:01:54 lr 0.000319	time 0.5574 (0.5685)	loss 3.0756 (3.0185)	grad_norm 2.0140 (1.7664)	mem 17417MB
[2023-02-02 02:56:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][1100/1251]	eta 0:01:25 lr 0.000319	time 0.6459 (0.5685)	loss 3.5888 (3.0146)	grad_norm 1.7089 (1.7647)	mem 17417MB
[2023-02-02 02:57:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][1150/1251]	eta 0:00:57 lr 0.000318	time 0.6212 (0.5685)	loss 3.2733 (3.0096)	grad_norm 1.8171 (1.7675)	mem 17417MB
[2023-02-02 02:57:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][1200/1251]	eta 0:00:28 lr 0.000318	time 0.5494 (0.5684)	loss 3.7251 (3.0075)	grad_norm 1.7874 (1.7652)	mem 17417MB
[2023-02-02 02:58:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [186/300][1250/1251]	eta 0:00:00 lr 0.000318	time 0.5567 (0.5684)	loss 3.2901 (3.0134)	grad_norm 1.6770 (1.7657)	mem 17417MB
[2023-02-02 02:58:00 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 186 training takes 0:11:51
[2023-02-02 02:58:00 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_186.pth saving......
[2023-02-02 02:58:02 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_186.pth saved !!!
[2023-02-02 02:58:03 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.827 (0.827)	Loss 0.7531 (0.7531)	Acc@1 81.348 (81.348)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-02 02:58:11 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.392 Acc@5 96.022
[2023-02-02 02:58:11 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.4%
[2023-02-02 02:58:12 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.162 (1.162)	Loss 0.7937 (0.7937)	Acc@1 82.227 (82.227)	Acc@5 95.312 (95.312)	Mem 17417MB
[2023-02-02 02:58:20 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.878 Acc@5 96.542
[2023-02-02 02:58:20 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.9%
[2023-02-02 02:58:20 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.88% at 186 epoch
[2023-02-02 02:58:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][0/1251]	eta 0:35:29 lr 0.000318	time 1.7024 (1.7024)	loss 3.0033 (3.0033)	grad_norm 1.6898 (1.6898)	mem 17417MB
[2023-02-02 02:58:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][50/1251]	eta 0:11:54 lr 0.000318	time 0.5593 (0.5947)	loss 3.5573 (3.0643)	grad_norm 1.6256 (1.7743)	mem 17417MB
[2023-02-02 02:59:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][100/1251]	eta 0:11:11 lr 0.000318	time 0.5620 (0.5837)	loss 2.8063 (2.9872)	grad_norm 1.6233 (1.7844)	mem 17417MB
[2023-02-02 02:59:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][150/1251]	eta 0:10:37 lr 0.000317	time 0.5584 (0.5790)	loss 3.3052 (2.9796)	grad_norm 1.6142 (1.7848)	mem 17417MB
[2023-02-02 03:00:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][200/1251]	eta 0:10:05 lr 0.000317	time 0.5645 (0.5757)	loss 3.5074 (3.0068)	grad_norm 1.7053 (nan)	mem 17417MB
[2023-02-02 03:00:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][250/1251]	eta 0:09:35 lr 0.000317	time 0.6292 (0.5747)	loss 3.0690 (3.0254)	grad_norm 1.6966 (nan)	mem 17417MB
[2023-02-02 03:01:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][300/1251]	eta 0:09:05 lr 0.000317	time 0.5558 (0.5735)	loss 3.4685 (3.0328)	grad_norm 1.7780 (nan)	mem 17417MB
[2023-02-02 03:01:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][350/1251]	eta 0:08:36 lr 0.000317	time 0.5583 (0.5728)	loss 2.2023 (3.0145)	grad_norm 1.6948 (nan)	mem 17417MB
[2023-02-02 03:02:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][400/1251]	eta 0:08:06 lr 0.000316	time 0.5610 (0.5722)	loss 3.5620 (3.0132)	grad_norm 1.8777 (nan)	mem 17417MB
[2023-02-02 03:02:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][450/1251]	eta 0:07:38 lr 0.000316	time 0.5530 (0.5722)	loss 3.4865 (3.0306)	grad_norm 1.8727 (nan)	mem 17417MB
[2023-02-02 03:03:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][500/1251]	eta 0:07:09 lr 0.000316	time 0.5508 (0.5717)	loss 2.1779 (3.0236)	grad_norm 1.7511 (nan)	mem 17417MB
[2023-02-02 03:03:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][550/1251]	eta 0:06:40 lr 0.000316	time 0.5608 (0.5716)	loss 1.6903 (3.0219)	grad_norm 1.7654 (nan)	mem 17417MB
[2023-02-02 03:04:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][600/1251]	eta 0:06:11 lr 0.000316	time 0.5589 (0.5712)	loss 3.5284 (3.0329)	grad_norm 1.8529 (nan)	mem 17417MB
[2023-02-02 03:04:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][650/1251]	eta 0:05:43 lr 0.000315	time 0.5611 (0.5712)	loss 3.5381 (3.0252)	grad_norm 1.8082 (nan)	mem 17417MB
[2023-02-02 03:05:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][700/1251]	eta 0:05:14 lr 0.000315	time 0.5576 (0.5710)	loss 2.4914 (3.0220)	grad_norm 1.5888 (nan)	mem 17417MB
[2023-02-02 03:05:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][750/1251]	eta 0:04:46 lr 0.000315	time 0.5609 (0.5709)	loss 3.2822 (3.0161)	grad_norm 1.6135 (nan)	mem 17417MB
[2023-02-02 03:05:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][800/1251]	eta 0:04:17 lr 0.000315	time 0.5571 (0.5707)	loss 2.5057 (3.0128)	grad_norm 1.8271 (nan)	mem 17417MB
[2023-02-02 03:06:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][850/1251]	eta 0:03:48 lr 0.000315	time 0.6261 (0.5707)	loss 2.5924 (3.0101)	grad_norm 1.5155 (nan)	mem 17417MB
[2023-02-02 03:06:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][900/1251]	eta 0:03:20 lr 0.000315	time 0.5576 (0.5708)	loss 1.9804 (3.0006)	grad_norm 1.9113 (nan)	mem 17417MB
[2023-02-02 03:07:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][950/1251]	eta 0:02:51 lr 0.000314	time 0.5587 (0.5705)	loss 3.1694 (3.0000)	grad_norm 2.0558 (nan)	mem 17417MB
[2023-02-02 03:07:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][1000/1251]	eta 0:02:23 lr 0.000314	time 0.5554 (0.5705)	loss 3.0566 (3.0069)	grad_norm 1.9973 (nan)	mem 17417MB
[2023-02-02 03:08:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][1050/1251]	eta 0:01:54 lr 0.000314	time 0.5630 (0.5704)	loss 3.3357 (3.0055)	grad_norm 1.7572 (nan)	mem 17417MB
[2023-02-02 03:08:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][1100/1251]	eta 0:01:26 lr 0.000314	time 0.5548 (0.5703)	loss 3.4048 (3.0046)	grad_norm 1.9514 (nan)	mem 17417MB
[2023-02-02 03:09:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][1150/1251]	eta 0:00:57 lr 0.000314	time 0.5531 (0.5703)	loss 2.9448 (3.0046)	grad_norm 1.7412 (nan)	mem 17417MB
[2023-02-02 03:09:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][1200/1251]	eta 0:00:29 lr 0.000313	time 0.5562 (0.5704)	loss 3.0344 (3.0082)	grad_norm 1.6539 (nan)	mem 17417MB
[2023-02-02 03:10:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [187/300][1250/1251]	eta 0:00:00 lr 0.000313	time 0.5499 (0.5705)	loss 3.1988 (3.0047)	grad_norm 1.7157 (nan)	mem 17417MB
[2023-02-02 03:10:14 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 187 training takes 0:11:53
[2023-02-02 03:10:14 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_187.pth saving......
[2023-02-02 03:10:16 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_187.pth saved !!!
[2023-02-02 03:10:17 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.868 (0.868)	Loss 0.7395 (0.7395)	Acc@1 82.422 (82.422)	Acc@5 96.875 (96.875)	Mem 17417MB
[2023-02-02 03:10:24 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.536 Acc@5 95.940
[2023-02-02 03:10:24 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.5%
[2023-02-02 03:10:26 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.212 (1.212)	Loss 0.7771 (0.7771)	Acc@1 81.934 (81.934)	Acc@5 95.508 (95.508)	Mem 17417MB
[2023-02-02 03:10:34 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.928 Acc@5 96.558
[2023-02-02 03:10:34 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 82.9%
[2023-02-02 03:10:34 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.93% at 187 epoch
[2023-02-02 03:10:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][0/1251]	eta 0:34:59 lr 0.000313	time 1.6783 (1.6783)	loss 2.6510 (2.6510)	grad_norm 1.7194 (1.7194)	mem 17417MB
[2023-02-02 03:11:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][50/1251]	eta 0:11:50 lr 0.000313	time 0.5667 (0.5913)	loss 3.4689 (3.0506)	grad_norm 1.9588 (1.7768)	mem 17417MB
[2023-02-02 03:11:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][100/1251]	eta 0:11:08 lr 0.000313	time 0.6214 (0.5805)	loss 3.1993 (2.9909)	grad_norm 1.6666 (1.7710)	mem 17417MB
[2023-02-02 03:12:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][150/1251]	eta 0:10:34 lr 0.000313	time 0.5601 (0.5766)	loss 2.9754 (3.0196)	grad_norm 1.6584 (1.7672)	mem 17417MB
[2023-02-02 03:12:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][200/1251]	eta 0:10:03 lr 0.000312	time 0.5549 (0.5747)	loss 2.8480 (3.0229)	grad_norm 1.8203 (1.7719)	mem 17417MB
[2023-02-02 03:12:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][250/1251]	eta 0:09:33 lr 0.000312	time 0.5545 (0.5733)	loss 2.8239 (3.0291)	grad_norm 1.7179 (1.7767)	mem 17417MB
[2023-02-02 03:13:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][300/1251]	eta 0:09:04 lr 0.000312	time 0.5493 (0.5728)	loss 2.8743 (3.0202)	grad_norm 1.6990 (1.7754)	mem 17417MB
[2023-02-02 03:13:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][350/1251]	eta 0:08:35 lr 0.000312	time 0.5583 (0.5720)	loss 2.0076 (3.0151)	grad_norm 1.9694 (1.7766)	mem 17417MB
[2023-02-02 03:14:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][400/1251]	eta 0:08:06 lr 0.000312	time 0.5522 (0.5718)	loss 3.3394 (3.0372)	grad_norm 2.0644 (1.7818)	mem 17417MB
[2023-02-02 03:14:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][450/1251]	eta 0:07:37 lr 0.000311	time 0.5547 (0.5711)	loss 3.1922 (3.0405)	grad_norm 1.8466 (1.7804)	mem 17417MB
[2023-02-02 03:15:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][500/1251]	eta 0:07:08 lr 0.000311	time 0.6312 (0.5709)	loss 2.5548 (3.0289)	grad_norm 1.6417 (1.7819)	mem 17417MB
[2023-02-02 03:15:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][550/1251]	eta 0:06:40 lr 0.000311	time 0.5585 (0.5708)	loss 2.7743 (3.0211)	grad_norm 1.8455 (1.7830)	mem 17417MB
[2023-02-02 03:16:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][600/1251]	eta 0:06:11 lr 0.000311	time 0.5566 (0.5708)	loss 3.0120 (3.0134)	grad_norm 1.6150 (1.7857)	mem 17417MB
[2023-02-02 03:16:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][650/1251]	eta 0:05:42 lr 0.000311	time 0.5516 (0.5705)	loss 3.2429 (3.0129)	grad_norm 1.7897 (1.7849)	mem 17417MB
[2023-02-02 03:17:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][700/1251]	eta 0:05:14 lr 0.000311	time 0.5546 (0.5704)	loss 2.5866 (3.0193)	grad_norm 1.7700 (1.7849)	mem 17417MB
[2023-02-02 03:17:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][750/1251]	eta 0:04:45 lr 0.000310	time 0.5576 (0.5703)	loss 2.8022 (3.0192)	grad_norm 1.8634 (1.7889)	mem 17417MB
[2023-02-02 03:18:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][800/1251]	eta 0:04:17 lr 0.000310	time 0.5541 (0.5703)	loss 3.4485 (3.0218)	grad_norm 2.0370 (1.7876)	mem 17417MB
[2023-02-02 03:18:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][850/1251]	eta 0:03:48 lr 0.000310	time 0.5561 (0.5702)	loss 3.1211 (3.0220)	grad_norm 1.6446 (1.7880)	mem 17417MB
[2023-02-02 03:19:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][900/1251]	eta 0:03:20 lr 0.000310	time 0.6275 (0.5701)	loss 3.3763 (3.0206)	grad_norm 1.7511 (1.7870)	mem 17417MB
[2023-02-02 03:19:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][950/1251]	eta 0:02:51 lr 0.000310	time 0.5591 (0.5700)	loss 3.2857 (3.0178)	grad_norm 1.5621 (1.7876)	mem 17417MB
[2023-02-02 03:20:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][1000/1251]	eta 0:02:23 lr 0.000309	time 0.5556 (0.5700)	loss 2.4570 (3.0139)	grad_norm 1.7605 (nan)	mem 17417MB
[2023-02-02 03:20:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][1050/1251]	eta 0:01:54 lr 0.000309	time 0.5711 (0.5699)	loss 3.4805 (3.0094)	grad_norm 1.7405 (nan)	mem 17417MB
[2023-02-02 03:21:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][1100/1251]	eta 0:01:26 lr 0.000309	time 0.5554 (0.5698)	loss 2.0245 (3.0089)	grad_norm 1.6899 (nan)	mem 17417MB
[2023-02-02 03:21:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][1150/1251]	eta 0:00:57 lr 0.000309	time 0.5561 (0.5698)	loss 3.0752 (3.0095)	grad_norm 1.6861 (nan)	mem 17417MB
[2023-02-02 03:21:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][1200/1251]	eta 0:00:29 lr 0.000309	time 0.5647 (0.5698)	loss 3.4328 (3.0100)	grad_norm 1.6496 (nan)	mem 17417MB
[2023-02-02 03:22:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [188/300][1250/1251]	eta 0:00:00 lr 0.000308	time 0.5519 (0.5698)	loss 3.0638 (3.0118)	grad_norm 1.9900 (nan)	mem 17417MB
[2023-02-02 03:22:26 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 188 training takes 0:11:52
[2023-02-02 03:22:27 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_188.pth saving......
[2023-02-02 03:22:28 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_188.pth saved !!!
[2023-02-02 03:22:29 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.862 (0.862)	Loss 0.8368 (0.8368)	Acc@1 81.348 (81.348)	Acc@5 94.238 (94.238)	Mem 17417MB
[2023-02-02 03:22:37 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.368 Acc@5 96.012
[2023-02-02 03:22:37 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.4%
[2023-02-02 03:22:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.227 (1.227)	Loss 0.7980 (0.7980)	Acc@1 82.031 (82.031)	Acc@5 96.484 (96.484)	Mem 17417MB
[2023-02-02 03:22:46 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.950 Acc@5 96.570
[2023-02-02 03:22:46 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.0%
[2023-02-02 03:22:46 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.95% at 188 epoch
[2023-02-02 03:22:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][0/1251]	eta 0:34:48 lr 0.000308	time 1.6695 (1.6695)	loss 2.7916 (2.7916)	grad_norm 1.6561 (1.6561)	mem 17417MB
[2023-02-02 03:23:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][50/1251]	eta 0:11:49 lr 0.000308	time 0.5509 (0.5909)	loss 2.7032 (2.9193)	grad_norm 1.9070 (1.7596)	mem 17417MB
[2023-02-02 03:23:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][100/1251]	eta 0:11:08 lr 0.000308	time 0.5592 (0.5812)	loss 3.2336 (2.9470)	grad_norm 1.9159 (1.7661)	mem 17417MB
[2023-02-02 03:24:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][150/1251]	eta 0:10:35 lr 0.000308	time 0.5521 (0.5772)	loss 3.1412 (2.9917)	grad_norm 1.7206 (1.7766)	mem 17417MB
[2023-02-02 03:24:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][200/1251]	eta 0:10:04 lr 0.000308	time 0.5519 (0.5751)	loss 2.8661 (3.0083)	grad_norm 1.5932 (1.7842)	mem 17417MB
[2023-02-02 03:25:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][250/1251]	eta 0:09:34 lr 0.000307	time 0.5596 (0.5736)	loss 3.1822 (3.0070)	grad_norm 1.9196 (1.7896)	mem 17417MB
[2023-02-02 03:25:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][300/1251]	eta 0:09:04 lr 0.000307	time 0.5602 (0.5726)	loss 3.7067 (2.9945)	grad_norm 1.6530 (1.7934)	mem 17417MB
[2023-02-02 03:26:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][350/1251]	eta 0:08:34 lr 0.000307	time 0.5551 (0.5716)	loss 2.9624 (2.9850)	grad_norm 1.6873 (1.7951)	mem 17417MB
[2023-02-02 03:26:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][400/1251]	eta 0:08:05 lr 0.000307	time 0.5583 (0.5709)	loss 3.5727 (2.9807)	grad_norm 1.8088 (1.7959)	mem 17417MB
[2023-02-02 03:27:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][450/1251]	eta 0:07:37 lr 0.000307	time 0.6236 (0.5708)	loss 2.1077 (2.9708)	grad_norm 1.7505 (1.7959)	mem 17417MB
[2023-02-02 03:27:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][500/1251]	eta 0:07:08 lr 0.000307	time 0.5605 (0.5702)	loss 3.3764 (2.9698)	grad_norm 1.6634 (1.7982)	mem 17417MB
[2023-02-02 03:28:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][550/1251]	eta 0:06:39 lr 0.000306	time 0.5576 (0.5703)	loss 3.2581 (2.9712)	grad_norm 1.7177 (1.7996)	mem 17417MB
[2023-02-02 03:28:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][600/1251]	eta 0:06:11 lr 0.000306	time 0.5539 (0.5701)	loss 3.0687 (2.9644)	grad_norm 1.7132 (1.7998)	mem 17417MB
[2023-02-02 03:28:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][650/1251]	eta 0:05:42 lr 0.000306	time 0.5534 (0.5702)	loss 2.8232 (2.9627)	grad_norm 1.5799 (1.8026)	mem 17417MB
[2023-02-02 03:29:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][700/1251]	eta 0:05:14 lr 0.000306	time 0.5577 (0.5701)	loss 3.1715 (2.9654)	grad_norm 1.9732 (1.8042)	mem 17417MB
[2023-02-02 03:29:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][750/1251]	eta 0:04:45 lr 0.000306	time 0.6364 (0.5700)	loss 3.1160 (2.9591)	grad_norm 1.6970 (1.8035)	mem 17417MB
[2023-02-02 03:30:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][800/1251]	eta 0:04:16 lr 0.000305	time 0.5631 (0.5698)	loss 3.3463 (2.9689)	grad_norm 1.6965 (1.8020)	mem 17417MB
[2023-02-02 03:30:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][850/1251]	eta 0:03:48 lr 0.000305	time 0.5549 (0.5698)	loss 2.1128 (2.9656)	grad_norm 1.7900 (nan)	mem 17417MB
[2023-02-02 03:31:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][900/1251]	eta 0:03:19 lr 0.000305	time 0.5565 (0.5697)	loss 3.1915 (2.9672)	grad_norm 1.7870 (nan)	mem 17417MB
[2023-02-02 03:31:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][950/1251]	eta 0:02:51 lr 0.000305	time 0.5633 (0.5696)	loss 2.3635 (2.9715)	grad_norm 1.8177 (nan)	mem 17417MB
[2023-02-02 03:32:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][1000/1251]	eta 0:02:22 lr 0.000305	time 0.5606 (0.5696)	loss 2.6220 (2.9727)	grad_norm 1.6531 (nan)	mem 17417MB
[2023-02-02 03:32:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][1050/1251]	eta 0:01:54 lr 0.000304	time 0.5589 (0.5696)	loss 2.7386 (2.9699)	grad_norm 1.8987 (nan)	mem 17417MB
[2023-02-02 03:33:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][1100/1251]	eta 0:01:26 lr 0.000304	time 0.6498 (0.5697)	loss 3.1564 (2.9681)	grad_norm 2.4921 (nan)	mem 17417MB
[2023-02-02 03:33:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][1150/1251]	eta 0:00:57 lr 0.000304	time 0.5552 (0.5696)	loss 2.5125 (2.9704)	grad_norm 1.7400 (nan)	mem 17417MB
[2023-02-02 03:34:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][1200/1251]	eta 0:00:29 lr 0.000304	time 0.6461 (0.5696)	loss 3.2508 (2.9715)	grad_norm 1.8707 (nan)	mem 17417MB
[2023-02-02 03:34:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [189/300][1250/1251]	eta 0:00:00 lr 0.000304	time 0.6405 (0.5696)	loss 2.4171 (2.9740)	grad_norm 1.9208 (nan)	mem 17417MB
[2023-02-02 03:34:39 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 189 training takes 0:11:52
[2023-02-02 03:34:39 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_189.pth saving......
[2023-02-02 03:34:41 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_189.pth saved !!!
[2023-02-02 03:34:42 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.961 (0.961)	Loss 0.8030 (0.8030)	Acc@1 81.250 (81.250)	Acc@5 95.312 (95.312)	Mem 17417MB
[2023-02-02 03:34:50 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.558 Acc@5 96.066
[2023-02-02 03:34:50 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.6%
[2023-02-02 03:34:51 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.218 (1.218)	Loss 0.7779 (0.7779)	Acc@1 82.227 (82.227)	Acc@5 95.117 (95.117)	Mem 17417MB
[2023-02-02 03:34:59 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.960 Acc@5 96.576
[2023-02-02 03:34:59 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.0%
[2023-02-02 03:34:59 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 82.96% at 189 epoch
[2023-02-02 03:35:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][0/1251]	eta 0:33:21 lr 0.000304	time 1.5996 (1.5996)	loss 3.0541 (3.0541)	grad_norm 1.5629 (1.5629)	mem 17417MB
[2023-02-02 03:35:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][50/1251]	eta 0:11:51 lr 0.000303	time 0.5597 (0.5921)	loss 2.9662 (2.9454)	grad_norm 1.6946 (1.7749)	mem 17417MB
[2023-02-02 03:35:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][100/1251]	eta 0:11:10 lr 0.000303	time 0.5568 (0.5822)	loss 3.3756 (2.9538)	grad_norm 2.1960 (1.7981)	mem 17417MB
[2023-02-02 03:36:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][150/1251]	eta 0:10:37 lr 0.000303	time 0.5606 (0.5789)	loss 2.0180 (2.9769)	grad_norm 1.8033 (1.7888)	mem 17417MB
[2023-02-02 03:36:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][200/1251]	eta 0:10:07 lr 0.000303	time 0.6224 (0.5780)	loss 2.4536 (2.9838)	grad_norm 1.7901 (1.7931)	mem 17417MB
[2023-02-02 03:37:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][250/1251]	eta 0:09:36 lr 0.000303	time 0.5563 (0.5758)	loss 3.0619 (2.9662)	grad_norm 1.7344 (1.8002)	mem 17417MB
[2023-02-02 03:37:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][300/1251]	eta 0:09:07 lr 0.000303	time 0.5567 (0.5752)	loss 3.3225 (2.9639)	grad_norm 1.6858 (1.8013)	mem 17417MB
[2023-02-02 03:38:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][350/1251]	eta 0:08:37 lr 0.000302	time 0.5543 (0.5740)	loss 2.3840 (2.9697)	grad_norm 1.6927 (1.8059)	mem 17417MB
[2023-02-02 03:38:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][400/1251]	eta 0:08:08 lr 0.000302	time 0.5635 (0.5736)	loss 2.9222 (2.9739)	grad_norm 1.9429 (1.8077)	mem 17417MB
[2023-02-02 03:39:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][450/1251]	eta 0:07:39 lr 0.000302	time 0.5647 (0.5732)	loss 2.6836 (2.9739)	grad_norm 1.8134 (1.8066)	mem 17417MB
[2023-02-02 03:39:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][500/1251]	eta 0:07:10 lr 0.000302	time 0.5631 (0.5729)	loss 3.2911 (2.9833)	grad_norm 1.7030 (1.8083)	mem 17417MB
[2023-02-02 03:40:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][550/1251]	eta 0:06:41 lr 0.000302	time 0.5530 (0.5728)	loss 2.7633 (2.9785)	grad_norm 2.3274 (1.8051)	mem 17417MB
[2023-02-02 03:40:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][600/1251]	eta 0:06:12 lr 0.000301	time 0.5584 (0.5729)	loss 3.3545 (2.9765)	grad_norm 2.0151 (1.8028)	mem 17417MB
[2023-02-02 03:41:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][650/1251]	eta 0:05:44 lr 0.000301	time 0.5525 (0.5728)	loss 3.2597 (2.9800)	grad_norm 1.8240 (1.8032)	mem 17417MB
[2023-02-02 03:41:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][700/1251]	eta 0:05:15 lr 0.000301	time 0.5578 (0.5724)	loss 2.9310 (2.9872)	grad_norm 1.6148 (1.8014)	mem 17417MB
[2023-02-02 03:42:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][750/1251]	eta 0:04:46 lr 0.000301	time 0.5579 (0.5722)	loss 3.3704 (2.9824)	grad_norm 1.8932 (1.8008)	mem 17417MB
[2023-02-02 03:42:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][800/1251]	eta 0:04:18 lr 0.000301	time 0.6230 (0.5721)	loss 3.3492 (2.9836)	grad_norm 1.6133 (1.8002)	mem 17417MB
[2023-02-02 03:43:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][850/1251]	eta 0:03:49 lr 0.000300	time 0.5610 (0.5720)	loss 3.3320 (2.9818)	grad_norm 1.9229 (1.7985)	mem 17417MB
[2023-02-02 03:43:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][900/1251]	eta 0:03:20 lr 0.000300	time 0.5563 (0.5718)	loss 2.3254 (2.9805)	grad_norm 2.1170 (1.7989)	mem 17417MB
[2023-02-02 03:44:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][950/1251]	eta 0:02:52 lr 0.000300	time 0.5621 (0.5717)	loss 2.8762 (2.9789)	grad_norm 1.8430 (1.8034)	mem 17417MB
[2023-02-02 03:44:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][1000/1251]	eta 0:02:23 lr 0.000300	time 0.5688 (0.5717)	loss 3.5041 (2.9822)	grad_norm 2.0054 (1.8051)	mem 17417MB
[2023-02-02 03:45:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][1050/1251]	eta 0:01:54 lr 0.000300	time 0.5641 (0.5715)	loss 3.1893 (2.9823)	grad_norm 1.7469 (1.8032)	mem 17417MB
[2023-02-02 03:45:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][1100/1251]	eta 0:01:26 lr 0.000300	time 0.6279 (0.5716)	loss 3.5256 (2.9872)	grad_norm 1.5777 (1.8029)	mem 17417MB
[2023-02-02 03:45:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][1150/1251]	eta 0:00:57 lr 0.000299	time 0.5525 (0.5715)	loss 3.2966 (2.9846)	grad_norm 1.6967 (1.8054)	mem 17417MB
[2023-02-02 03:46:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][1200/1251]	eta 0:00:29 lr 0.000299	time 0.6226 (0.5714)	loss 2.1466 (2.9843)	grad_norm 1.8112 (1.8069)	mem 17417MB
[2023-02-02 03:46:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [190/300][1250/1251]	eta 0:00:00 lr 0.000299	time 0.5551 (0.5713)	loss 2.0290 (2.9830)	grad_norm 1.5280 (1.8062)	mem 17417MB
[2023-02-02 03:46:54 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 190 training takes 0:11:54
[2023-02-02 03:46:54 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_190.pth saving......
[2023-02-02 03:46:56 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_190.pth saved !!!
[2023-02-02 03:46:57 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.843 (0.843)	Loss 0.8731 (0.8731)	Acc@1 79.102 (79.102)	Acc@5 94.531 (94.531)	Mem 17417MB
[2023-02-02 03:47:05 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.784 Acc@5 96.042
[2023-02-02 03:47:05 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.8%
[2023-02-02 03:47:06 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.182 (1.182)	Loss 0.7520 (0.7520)	Acc@1 82.520 (82.520)	Acc@5 96.875 (96.875)	Mem 17417MB
[2023-02-02 03:47:14 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.998 Acc@5 96.562
[2023-02-02 03:47:14 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.0%
[2023-02-02 03:47:14 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.00% at 190 epoch
[2023-02-02 03:47:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][0/1251]	eta 0:36:04 lr 0.000299	time 1.7301 (1.7301)	loss 3.3447 (3.3447)	grad_norm 2.0376 (2.0376)	mem 17417MB
[2023-02-02 03:47:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][50/1251]	eta 0:11:51 lr 0.000299	time 0.6546 (0.5925)	loss 3.2179 (2.8893)	grad_norm 1.8156 (1.8397)	mem 17417MB
[2023-02-02 03:48:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][100/1251]	eta 0:11:08 lr 0.000299	time 0.5514 (0.5805)	loss 3.0275 (2.9491)	grad_norm 1.7030 (1.8427)	mem 17417MB
[2023-02-02 03:48:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][150/1251]	eta 0:10:33 lr 0.000298	time 0.5562 (0.5756)	loss 3.7300 (2.9492)	grad_norm 1.8782 (1.8123)	mem 17417MB
[2023-02-02 03:49:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][200/1251]	eta 0:10:03 lr 0.000298	time 0.5543 (0.5739)	loss 3.5003 (2.9638)	grad_norm 1.7575 (1.8099)	mem 17417MB
[2023-02-02 03:49:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][250/1251]	eta 0:09:32 lr 0.000298	time 0.5566 (0.5720)	loss 3.0396 (2.9689)	grad_norm 1.6026 (1.8072)	mem 17417MB
[2023-02-02 03:50:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][300/1251]	eta 0:09:04 lr 0.000298	time 0.5692 (0.5721)	loss 2.9571 (2.9901)	grad_norm 1.6045 (1.8080)	mem 17417MB
[2023-02-02 03:50:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][350/1251]	eta 0:08:34 lr 0.000298	time 0.5552 (0.5708)	loss 3.5833 (3.0073)	grad_norm 1.6860 (1.8124)	mem 17417MB
[2023-02-02 03:51:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][400/1251]	eta 0:08:05 lr 0.000297	time 0.5572 (0.5707)	loss 3.3503 (3.0150)	grad_norm 1.6398 (1.8123)	mem 17417MB
[2023-02-02 03:51:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][450/1251]	eta 0:07:36 lr 0.000297	time 0.5580 (0.5705)	loss 3.4514 (3.0101)	grad_norm 1.8335 (1.8064)	mem 17417MB
[2023-02-02 03:52:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][500/1251]	eta 0:07:08 lr 0.000297	time 0.5571 (0.5701)	loss 3.3380 (3.0064)	grad_norm 1.8647 (1.8082)	mem 17417MB
[2023-02-02 03:52:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][550/1251]	eta 0:06:39 lr 0.000297	time 0.5524 (0.5700)	loss 3.2936 (3.0126)	grad_norm 1.7029 (1.8093)	mem 17417MB
[2023-02-02 03:52:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][600/1251]	eta 0:06:11 lr 0.000297	time 0.5497 (0.5700)	loss 3.4565 (3.0114)	grad_norm 1.7466 (1.8126)	mem 17417MB
[2023-02-02 03:53:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][650/1251]	eta 0:05:42 lr 0.000296	time 0.5518 (0.5698)	loss 3.1255 (3.0099)	grad_norm 1.6131 (1.8147)	mem 17417MB
[2023-02-02 03:53:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][700/1251]	eta 0:05:13 lr 0.000296	time 0.5693 (0.5697)	loss 2.4030 (3.0085)	grad_norm 1.8388 (1.8120)	mem 17417MB
[2023-02-02 03:54:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][750/1251]	eta 0:04:45 lr 0.000296	time 0.5583 (0.5695)	loss 3.3013 (3.0090)	grad_norm 2.1361 (1.8145)	mem 17417MB
[2023-02-02 03:54:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][800/1251]	eta 0:04:16 lr 0.000296	time 0.5551 (0.5695)	loss 2.8831 (3.0131)	grad_norm 1.9349 (1.8168)	mem 17417MB
[2023-02-02 03:55:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][850/1251]	eta 0:03:48 lr 0.000296	time 0.5563 (0.5695)	loss 2.9251 (3.0133)	grad_norm 1.7379 (1.8169)	mem 17417MB
[2023-02-02 03:55:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][900/1251]	eta 0:03:19 lr 0.000296	time 0.5596 (0.5694)	loss 3.0855 (3.0082)	grad_norm 1.7482 (1.8176)	mem 17417MB
[2023-02-02 03:56:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][950/1251]	eta 0:02:51 lr 0.000295	time 0.5546 (0.5693)	loss 2.6636 (2.9985)	grad_norm 2.0450 (1.8166)	mem 17417MB
[2023-02-02 03:56:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][1000/1251]	eta 0:02:22 lr 0.000295	time 0.5532 (0.5693)	loss 3.1367 (2.9947)	grad_norm 2.0625 (1.8193)	mem 17417MB
[2023-02-02 03:57:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][1050/1251]	eta 0:01:54 lr 0.000295	time 0.5534 (0.5692)	loss 3.3150 (2.9957)	grad_norm 1.6499 (1.8169)	mem 17417MB
[2023-02-02 03:57:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][1100/1251]	eta 0:01:25 lr 0.000295	time 0.6226 (0.5692)	loss 2.7569 (2.9974)	grad_norm 1.6848 (1.8150)	mem 17417MB
[2023-02-02 03:58:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][1150/1251]	eta 0:00:57 lr 0.000295	time 0.5560 (0.5692)	loss 2.9470 (2.9981)	grad_norm 1.9103 (1.8172)	mem 17417MB
[2023-02-02 03:58:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][1200/1251]	eta 0:00:29 lr 0.000294	time 0.5528 (0.5692)	loss 1.9174 (2.9978)	grad_norm 1.7559 (1.8163)	mem 17417MB
[2023-02-02 03:59:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [191/300][1250/1251]	eta 0:00:00 lr 0.000294	time 0.5551 (0.5691)	loss 3.0801 (2.9986)	grad_norm 1.8591 (1.8157)	mem 17417MB
[2023-02-02 03:59:06 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 191 training takes 0:11:52
[2023-02-02 03:59:06 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_191.pth saving......
[2023-02-02 03:59:08 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_191.pth saved !!!
[2023-02-02 03:59:09 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.866 (0.866)	Loss 0.7688 (0.7688)	Acc@1 81.641 (81.641)	Acc@5 95.898 (95.898)	Mem 17417MB
[2023-02-02 03:59:17 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.716 Acc@5 96.044
[2023-02-02 03:59:17 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.7%
[2023-02-02 03:59:18 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.213 (1.213)	Loss 0.7435 (0.7435)	Acc@1 82.324 (82.324)	Acc@5 96.582 (96.582)	Mem 17417MB
[2023-02-02 03:59:26 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.066 Acc@5 96.570
[2023-02-02 03:59:26 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.1%
[2023-02-02 03:59:26 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.07% at 191 epoch
[2023-02-02 03:59:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][0/1251]	eta 0:34:55 lr 0.000294	time 1.6748 (1.6748)	loss 2.0273 (2.0273)	grad_norm 1.9272 (1.9272)	mem 17417MB
[2023-02-02 03:59:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][50/1251]	eta 0:11:49 lr 0.000294	time 0.5552 (0.5907)	loss 3.1105 (2.9543)	grad_norm 2.3014 (1.8033)	mem 17417MB
[2023-02-02 04:00:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][100/1251]	eta 0:11:10 lr 0.000294	time 0.5579 (0.5823)	loss 3.5143 (3.0439)	grad_norm 1.8043 (1.7919)	mem 17417MB
[2023-02-02 04:00:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][150/1251]	eta 0:10:35 lr 0.000294	time 0.5492 (0.5775)	loss 2.2386 (3.0002)	grad_norm 1.7825 (1.7984)	mem 17417MB
[2023-02-02 04:01:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][200/1251]	eta 0:10:05 lr 0.000293	time 0.5535 (0.5762)	loss 3.4600 (2.9985)	grad_norm 1.6145 (1.7999)	mem 17417MB
[2023-02-02 04:01:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][250/1251]	eta 0:09:34 lr 0.000293	time 0.5626 (0.5742)	loss 2.9249 (2.9993)	grad_norm 1.8913 (1.8001)	mem 17417MB
[2023-02-02 04:02:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][300/1251]	eta 0:09:05 lr 0.000293	time 0.5585 (0.5739)	loss 2.1123 (2.9829)	grad_norm 1.8441 (1.8019)	mem 17417MB
[2023-02-02 04:02:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][350/1251]	eta 0:08:36 lr 0.000293	time 0.5528 (0.5731)	loss 3.1589 (2.9813)	grad_norm 1.6116 (1.8019)	mem 17417MB
[2023-02-02 04:03:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][400/1251]	eta 0:08:07 lr 0.000293	time 0.6431 (0.5729)	loss 3.5802 (2.9953)	grad_norm 1.9972 (1.8023)	mem 17417MB
[2023-02-02 04:03:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][450/1251]	eta 0:07:38 lr 0.000293	time 0.5564 (0.5725)	loss 3.5036 (2.9906)	grad_norm 1.9195 (1.8102)	mem 17417MB
[2023-02-02 04:04:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][500/1251]	eta 0:07:09 lr 0.000292	time 0.5650 (0.5720)	loss 3.3224 (2.9936)	grad_norm 1.9921 (1.8185)	mem 17417MB
[2023-02-02 04:04:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][550/1251]	eta 0:06:40 lr 0.000292	time 0.6248 (0.5719)	loss 3.3139 (2.9916)	grad_norm 1.7784 (1.8186)	mem 17417MB
[2023-02-02 04:05:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][600/1251]	eta 0:06:12 lr 0.000292	time 0.5541 (0.5719)	loss 3.6319 (2.9912)	grad_norm 1.8035 (1.8183)	mem 17417MB
[2023-02-02 04:05:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][650/1251]	eta 0:05:43 lr 0.000292	time 0.5544 (0.5718)	loss 1.8615 (2.9843)	grad_norm 1.6103 (1.8213)	mem 17417MB
[2023-02-02 04:06:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][700/1251]	eta 0:05:15 lr 0.000292	time 0.5595 (0.5719)	loss 2.7699 (2.9827)	grad_norm 2.1424 (1.8247)	mem 17417MB
[2023-02-02 04:06:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][750/1251]	eta 0:04:46 lr 0.000291	time 0.5545 (0.5716)	loss 2.9654 (2.9805)	grad_norm 1.7758 (1.8218)	mem 17417MB
[2023-02-02 04:07:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][800/1251]	eta 0:04:17 lr 0.000291	time 0.5658 (0.5716)	loss 2.8256 (2.9862)	grad_norm 1.8032 (1.8202)	mem 17417MB
[2023-02-02 04:07:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][850/1251]	eta 0:03:49 lr 0.000291	time 0.5592 (0.5713)	loss 3.3840 (2.9970)	grad_norm 1.7124 (1.8200)	mem 17417MB
[2023-02-02 04:08:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][900/1251]	eta 0:03:20 lr 0.000291	time 0.5536 (0.5713)	loss 3.1667 (3.0005)	grad_norm 1.8381 (1.8201)	mem 17417MB
[2023-02-02 04:08:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][950/1251]	eta 0:02:51 lr 0.000291	time 0.5593 (0.5711)	loss 2.6154 (3.0021)	grad_norm 1.8210 (1.8174)	mem 17417MB
[2023-02-02 04:08:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][1000/1251]	eta 0:02:23 lr 0.000290	time 0.5546 (0.5711)	loss 2.6974 (2.9970)	grad_norm 1.6614 (1.8177)	mem 17417MB
[2023-02-02 04:09:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][1050/1251]	eta 0:01:54 lr 0.000290	time 0.5527 (0.5710)	loss 3.3248 (2.9984)	grad_norm 1.7101 (1.8170)	mem 17417MB
[2023-02-02 04:09:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][1100/1251]	eta 0:01:26 lr 0.000290	time 0.6233 (0.5709)	loss 3.2322 (2.9935)	grad_norm 1.7553 (1.8157)	mem 17417MB
[2023-02-02 04:10:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][1150/1251]	eta 0:00:57 lr 0.000290	time 0.5503 (0.5709)	loss 3.5078 (2.9945)	grad_norm 1.9084 (1.8154)	mem 17417MB
[2023-02-02 04:10:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][1200/1251]	eta 0:00:29 lr 0.000290	time 0.5513 (0.5707)	loss 2.4968 (2.9964)	grad_norm 2.1726 (1.8179)	mem 17417MB
[2023-02-02 04:11:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [192/300][1250/1251]	eta 0:00:00 lr 0.000290	time 0.5508 (0.5708)	loss 3.2295 (2.9975)	grad_norm 1.7493 (inf)	mem 17417MB
[2023-02-02 04:11:20 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 192 training takes 0:11:54
[2023-02-02 04:11:20 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_192.pth saving......
[2023-02-02 04:11:22 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_192.pth saved !!!
[2023-02-02 04:11:23 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.888 (0.888)	Loss 0.7487 (0.7487)	Acc@1 83.105 (83.105)	Acc@5 95.996 (95.996)	Mem 17417MB
[2023-02-02 04:11:31 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.726 Acc@5 96.002
[2023-02-02 04:11:31 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.7%
[2023-02-02 04:11:32 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.265 (1.265)	Loss 0.7654 (0.7654)	Acc@1 81.445 (81.445)	Acc@5 95.312 (95.312)	Mem 17417MB
[2023-02-02 04:11:40 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.078 Acc@5 96.566
[2023-02-02 04:11:40 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.1%
[2023-02-02 04:11:40 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.08% at 192 epoch
[2023-02-02 04:11:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][0/1251]	eta 0:36:03 lr 0.000290	time 1.7296 (1.7296)	loss 3.0565 (3.0565)	grad_norm 1.6581 (1.6581)	mem 17417MB
[2023-02-02 04:12:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][50/1251]	eta 0:11:53 lr 0.000289	time 0.5612 (0.5939)	loss 3.1558 (3.0117)	grad_norm 1.7907 (1.8278)	mem 17417MB
[2023-02-02 04:12:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][100/1251]	eta 0:11:09 lr 0.000289	time 0.5591 (0.5820)	loss 2.9172 (2.9891)	grad_norm 1.7760 (1.8211)	mem 17417MB
[2023-02-02 04:13:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][150/1251]	eta 0:10:37 lr 0.000289	time 0.5614 (0.5786)	loss 3.4225 (2.9933)	grad_norm 1.7030 (1.8124)	mem 17417MB
[2023-02-02 04:13:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][200/1251]	eta 0:10:05 lr 0.000289	time 0.5611 (0.5759)	loss 1.8793 (2.9832)	grad_norm 1.7087 (1.8133)	mem 17417MB
[2023-02-02 04:14:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][250/1251]	eta 0:09:34 lr 0.000289	time 0.5564 (0.5742)	loss 2.6544 (2.9723)	grad_norm 1.9026 (1.8213)	mem 17417MB
[2023-02-02 04:14:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][300/1251]	eta 0:09:05 lr 0.000288	time 0.5712 (0.5735)	loss 1.7506 (2.9670)	grad_norm 2.2414 (1.8268)	mem 17417MB
[2023-02-02 04:15:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][350/1251]	eta 0:08:36 lr 0.000288	time 0.5564 (0.5728)	loss 3.3274 (2.9535)	grad_norm 1.7618 (1.8298)	mem 17417MB
[2023-02-02 04:15:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][400/1251]	eta 0:08:07 lr 0.000288	time 0.5528 (0.5725)	loss 3.2292 (2.9507)	grad_norm 1.8928 (1.8264)	mem 17417MB
[2023-02-02 04:15:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][450/1251]	eta 0:07:38 lr 0.000288	time 0.5651 (0.5723)	loss 2.7503 (2.9473)	grad_norm 1.7869 (1.8309)	mem 17417MB
[2023-02-02 04:16:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][500/1251]	eta 0:07:09 lr 0.000288	time 0.5603 (0.5717)	loss 2.7373 (2.9433)	grad_norm 1.7434 (1.8299)	mem 17417MB
[2023-02-02 04:16:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][550/1251]	eta 0:06:40 lr 0.000288	time 0.5550 (0.5716)	loss 2.8267 (2.9493)	grad_norm 1.8812 (1.8341)	mem 17417MB
[2023-02-02 04:17:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][600/1251]	eta 0:06:11 lr 0.000287	time 0.5549 (0.5713)	loss 3.7327 (2.9526)	grad_norm 1.7111 (1.8333)	mem 17417MB
[2023-02-02 04:17:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][650/1251]	eta 0:05:43 lr 0.000287	time 0.5592 (0.5713)	loss 2.1793 (2.9489)	grad_norm 1.7551 (1.8331)	mem 17417MB
[2023-02-02 04:18:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][700/1251]	eta 0:05:14 lr 0.000287	time 0.5524 (0.5711)	loss 3.2486 (2.9587)	grad_norm 1.5370 (1.8309)	mem 17417MB
[2023-02-02 04:18:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][750/1251]	eta 0:04:45 lr 0.000287	time 0.5581 (0.5708)	loss 3.5415 (2.9586)	grad_norm 2.0584 (1.8303)	mem 17417MB
[2023-02-02 04:19:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][800/1251]	eta 0:04:17 lr 0.000287	time 0.5614 (0.5708)	loss 3.3243 (2.9654)	grad_norm 1.6853 (1.8320)	mem 17417MB
[2023-02-02 04:19:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][850/1251]	eta 0:03:48 lr 0.000286	time 0.5531 (0.5709)	loss 3.2275 (2.9648)	grad_norm 1.8149 (1.8324)	mem 17417MB
[2023-02-02 04:20:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][900/1251]	eta 0:03:20 lr 0.000286	time 0.5631 (0.5709)	loss 3.3492 (2.9613)	grad_norm 1.9392 (1.8321)	mem 17417MB
[2023-02-02 04:20:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][950/1251]	eta 0:02:51 lr 0.000286	time 0.5611 (0.5707)	loss 3.5982 (2.9640)	grad_norm 1.9476 (1.8309)	mem 17417MB
[2023-02-02 04:21:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][1000/1251]	eta 0:02:23 lr 0.000286	time 0.5574 (0.5705)	loss 2.9941 (2.9641)	grad_norm 1.7677 (1.8298)	mem 17417MB
[2023-02-02 04:21:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][1050/1251]	eta 0:01:54 lr 0.000286	time 0.5701 (0.5705)	loss 2.4808 (2.9682)	grad_norm 2.1721 (1.8332)	mem 17417MB
[2023-02-02 04:22:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][1100/1251]	eta 0:01:26 lr 0.000285	time 0.6286 (0.5705)	loss 2.4563 (2.9623)	grad_norm 1.9022 (1.8319)	mem 17417MB
[2023-02-02 04:22:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][1150/1251]	eta 0:00:57 lr 0.000285	time 0.5529 (0.5704)	loss 2.9198 (2.9635)	grad_norm 1.7337 (1.8308)	mem 17417MB
[2023-02-02 04:23:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][1200/1251]	eta 0:00:29 lr 0.000285	time 0.5551 (0.5704)	loss 2.5284 (2.9562)	grad_norm 1.7445 (1.8313)	mem 17417MB
[2023-02-02 04:23:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [193/300][1250/1251]	eta 0:00:00 lr 0.000285	time 0.5497 (0.5704)	loss 3.0879 (2.9634)	grad_norm 1.7933 (1.8300)	mem 17417MB
[2023-02-02 04:23:34 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 193 training takes 0:11:53
[2023-02-02 04:23:34 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_193.pth saving......
[2023-02-02 04:23:36 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_193.pth saved !!!
[2023-02-02 04:23:37 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.920 (0.920)	Loss 0.7595 (0.7595)	Acc@1 82.129 (82.129)	Acc@5 95.996 (95.996)	Mem 17417MB
[2023-02-02 04:23:45 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.802 Acc@5 96.162
[2023-02-02 04:23:45 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.8%
[2023-02-02 04:23:46 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.195 (1.195)	Loss 0.6905 (0.6905)	Acc@1 83.301 (83.301)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-02 04:23:54 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.084 Acc@5 96.574
[2023-02-02 04:23:54 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.1%
[2023-02-02 04:23:54 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.08% at 193 epoch
[2023-02-02 04:23:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][0/1251]	eta 0:34:54 lr 0.000285	time 1.6740 (1.6740)	loss 2.9094 (2.9094)	grad_norm 1.8207 (1.8207)	mem 17417MB
[2023-02-02 04:24:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][50/1251]	eta 0:11:49 lr 0.000285	time 0.5571 (0.5906)	loss 2.9024 (2.9673)	grad_norm 1.9132 (1.8309)	mem 17417MB
[2023-02-02 04:24:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][100/1251]	eta 0:11:08 lr 0.000285	time 0.5523 (0.5812)	loss 2.8175 (3.0029)	grad_norm 1.6828 (1.8097)	mem 17417MB
[2023-02-02 04:25:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][150/1251]	eta 0:10:35 lr 0.000284	time 0.5697 (0.5772)	loss 3.5786 (2.9678)	grad_norm 1.8271 (1.8153)	mem 17417MB
[2023-02-02 04:25:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][200/1251]	eta 0:10:04 lr 0.000284	time 0.5565 (0.5751)	loss 3.1759 (2.9360)	grad_norm 1.9591 (nan)	mem 17417MB
[2023-02-02 04:26:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][250/1251]	eta 0:09:34 lr 0.000284	time 0.5611 (0.5736)	loss 3.3538 (2.9398)	grad_norm 1.7554 (nan)	mem 17417MB
[2023-02-02 04:26:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][300/1251]	eta 0:09:05 lr 0.000284	time 0.5578 (0.5734)	loss 2.8415 (2.9534)	grad_norm 1.7699 (nan)	mem 17417MB
[2023-02-02 04:27:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][350/1251]	eta 0:08:35 lr 0.000284	time 0.5536 (0.5724)	loss 3.0459 (2.9668)	grad_norm 1.7950 (nan)	mem 17417MB
[2023-02-02 04:27:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][400/1251]	eta 0:08:06 lr 0.000283	time 0.5532 (0.5723)	loss 2.9964 (2.9581)	grad_norm 1.8221 (nan)	mem 17417MB
[2023-02-02 04:28:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][450/1251]	eta 0:07:37 lr 0.000283	time 0.5593 (0.5714)	loss 2.6216 (2.9634)	grad_norm 1.9144 (nan)	mem 17417MB
[2023-02-02 04:28:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][500/1251]	eta 0:07:08 lr 0.000283	time 0.5586 (0.5712)	loss 2.9085 (2.9592)	grad_norm 2.1224 (nan)	mem 17417MB
[2023-02-02 04:29:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][550/1251]	eta 0:06:40 lr 0.000283	time 0.5546 (0.5709)	loss 2.8830 (2.9622)	grad_norm 2.1711 (nan)	mem 17417MB
[2023-02-02 04:29:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][600/1251]	eta 0:06:11 lr 0.000283	time 0.5559 (0.5708)	loss 3.1196 (2.9727)	grad_norm 1.7428 (nan)	mem 17417MB
[2023-02-02 04:30:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][650/1251]	eta 0:05:43 lr 0.000282	time 0.5638 (0.5707)	loss 3.5176 (2.9696)	grad_norm 1.9271 (nan)	mem 17417MB
[2023-02-02 04:30:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][700/1251]	eta 0:05:14 lr 0.000282	time 0.6385 (0.5705)	loss 3.0694 (2.9604)	grad_norm 1.9488 (nan)	mem 17417MB
[2023-02-02 04:31:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][750/1251]	eta 0:04:45 lr 0.000282	time 0.5631 (0.5702)	loss 3.5336 (2.9676)	grad_norm 1.6261 (nan)	mem 17417MB
[2023-02-02 04:31:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][800/1251]	eta 0:04:17 lr 0.000282	time 0.5607 (0.5702)	loss 3.0807 (2.9677)	grad_norm 1.7546 (nan)	mem 17417MB
[2023-02-02 04:31:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][850/1251]	eta 0:03:48 lr 0.000282	time 0.5513 (0.5700)	loss 2.3496 (2.9625)	grad_norm 1.5646 (nan)	mem 17417MB
[2023-02-02 04:32:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][900/1251]	eta 0:03:20 lr 0.000282	time 0.5548 (0.5700)	loss 3.4360 (2.9558)	grad_norm 1.6308 (nan)	mem 17417MB
[2023-02-02 04:32:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][950/1251]	eta 0:02:51 lr 0.000281	time 0.5519 (0.5699)	loss 1.9412 (2.9583)	grad_norm 1.8847 (nan)	mem 17417MB
[2023-02-02 04:33:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][1000/1251]	eta 0:02:23 lr 0.000281	time 0.5541 (0.5698)	loss 2.0099 (2.9629)	grad_norm 1.7005 (nan)	mem 17417MB
[2023-02-02 04:33:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][1050/1251]	eta 0:01:54 lr 0.000281	time 0.5580 (0.5698)	loss 2.7390 (2.9650)	grad_norm 1.9493 (nan)	mem 17417MB
[2023-02-02 04:34:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][1100/1251]	eta 0:01:26 lr 0.000281	time 0.6155 (0.5698)	loss 3.0963 (2.9591)	grad_norm 1.6783 (nan)	mem 17417MB
[2023-02-02 04:34:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][1150/1251]	eta 0:00:57 lr 0.000281	time 0.5531 (0.5698)	loss 2.2158 (2.9574)	grad_norm 2.0604 (nan)	mem 17417MB
[2023-02-02 04:35:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][1200/1251]	eta 0:00:29 lr 0.000280	time 0.5508 (0.5697)	loss 1.9179 (2.9580)	grad_norm 2.1049 (nan)	mem 17417MB
[2023-02-02 04:35:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [194/300][1250/1251]	eta 0:00:00 lr 0.000280	time 0.5488 (0.5697)	loss 3.7132 (2.9547)	grad_norm 1.7892 (nan)	mem 17417MB
[2023-02-02 04:35:47 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 194 training takes 0:11:52
[2023-02-02 04:35:47 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_194.pth saving......
[2023-02-02 04:35:49 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_194.pth saved !!!
[2023-02-02 04:35:50 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.921 (0.921)	Loss 0.8713 (0.8713)	Acc@1 79.785 (79.785)	Acc@5 95.703 (95.703)	Mem 17417MB
[2023-02-02 04:35:57 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.816 Acc@5 96.012
[2023-02-02 04:35:57 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.8%
[2023-02-02 04:35:59 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.250 (1.250)	Loss 0.6994 (0.6994)	Acc@1 83.984 (83.984)	Acc@5 96.973 (96.973)	Mem 17417MB
[2023-02-02 04:36:07 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.140 Acc@5 96.624
[2023-02-02 04:36:07 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.1%
[2023-02-02 04:36:07 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.14% at 194 epoch
[2023-02-02 04:36:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][0/1251]	eta 0:36:01 lr 0.000280	time 1.7279 (1.7279)	loss 3.1863 (3.1863)	grad_norm 2.0137 (2.0137)	mem 17417MB
[2023-02-02 04:36:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][50/1251]	eta 0:11:55 lr 0.000280	time 0.5519 (0.5960)	loss 2.1692 (2.9138)	grad_norm 1.7969 (1.8089)	mem 17417MB
[2023-02-02 04:37:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][100/1251]	eta 0:11:11 lr 0.000280	time 0.5489 (0.5836)	loss 3.7569 (2.9385)	grad_norm 1.6763 (1.8086)	mem 17417MB
[2023-02-02 04:37:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][150/1251]	eta 0:10:36 lr 0.000280	time 0.5547 (0.5784)	loss 3.5008 (2.9822)	grad_norm 1.9247 (1.8189)	mem 17417MB
[2023-02-02 04:38:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][200/1251]	eta 0:10:06 lr 0.000280	time 0.5545 (0.5767)	loss 3.5188 (2.9694)	grad_norm 1.8557 (1.8168)	mem 17417MB
[2023-02-02 04:38:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][250/1251]	eta 0:09:35 lr 0.000279	time 0.5538 (0.5748)	loss 3.1165 (2.9802)	grad_norm 1.9953 (1.8300)	mem 17417MB
[2023-02-02 04:39:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][300/1251]	eta 0:09:06 lr 0.000279	time 0.5552 (0.5742)	loss 2.0746 (2.9781)	grad_norm 1.7964 (1.8324)	mem 17417MB
[2023-02-02 04:39:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][350/1251]	eta 0:08:36 lr 0.000279	time 0.5537 (0.5734)	loss 1.8684 (2.9770)	grad_norm 1.8693 (1.8312)	mem 17417MB
[2023-02-02 04:39:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][400/1251]	eta 0:08:07 lr 0.000279	time 0.5699 (0.5730)	loss 3.4529 (2.9758)	grad_norm 1.9519 (1.8278)	mem 17417MB
[2023-02-02 04:40:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][450/1251]	eta 0:07:38 lr 0.000279	time 0.5547 (0.5725)	loss 2.9285 (2.9683)	grad_norm 1.7772 (1.8282)	mem 17417MB
[2023-02-02 04:40:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][500/1251]	eta 0:07:09 lr 0.000278	time 0.5579 (0.5718)	loss 2.9066 (2.9748)	grad_norm 1.8472 (1.8401)	mem 17417MB
[2023-02-02 04:41:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][550/1251]	eta 0:06:40 lr 0.000278	time 0.5534 (0.5715)	loss 2.0991 (2.9731)	grad_norm 1.8304 (1.8360)	mem 17417MB
[2023-02-02 04:41:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][600/1251]	eta 0:06:12 lr 0.000278	time 0.5554 (0.5716)	loss 2.8973 (2.9692)	grad_norm 1.8964 (1.8314)	mem 17417MB
[2023-02-02 04:42:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][650/1251]	eta 0:05:43 lr 0.000278	time 0.5545 (0.5715)	loss 3.1618 (2.9779)	grad_norm 1.7735 (1.8332)	mem 17417MB
[2023-02-02 04:42:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][700/1251]	eta 0:05:14 lr 0.000278	time 0.5569 (0.5712)	loss 2.5550 (2.9800)	grad_norm 1.6319 (1.8352)	mem 17417MB
[2023-02-02 04:43:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][750/1251]	eta 0:04:46 lr 0.000278	time 0.5639 (0.5712)	loss 3.0492 (2.9844)	grad_norm 1.7091 (1.8308)	mem 17417MB
[2023-02-02 04:43:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][800/1251]	eta 0:04:17 lr 0.000277	time 0.5562 (0.5709)	loss 2.3338 (2.9808)	grad_norm 2.2300 (1.8315)	mem 17417MB
[2023-02-02 04:44:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][850/1251]	eta 0:03:48 lr 0.000277	time 0.5603 (0.5710)	loss 2.1292 (2.9787)	grad_norm 1.8837 (1.8314)	mem 17417MB
[2023-02-02 04:44:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][900/1251]	eta 0:03:20 lr 0.000277	time 0.5575 (0.5709)	loss 2.5292 (2.9730)	grad_norm 1.6330 (1.8323)	mem 17417MB
[2023-02-02 04:45:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][950/1251]	eta 0:02:51 lr 0.000277	time 0.5554 (0.5708)	loss 3.0144 (2.9793)	grad_norm 1.7286 (1.8347)	mem 17417MB
[2023-02-02 04:45:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][1000/1251]	eta 0:02:23 lr 0.000277	time 0.5525 (0.5706)	loss 3.3260 (2.9827)	grad_norm 1.9142 (inf)	mem 17417MB
[2023-02-02 04:46:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][1050/1251]	eta 0:01:54 lr 0.000276	time 0.5534 (0.5705)	loss 2.5714 (2.9861)	grad_norm 1.9208 (inf)	mem 17417MB
[2023-02-02 04:46:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][1100/1251]	eta 0:01:26 lr 0.000276	time 0.5576 (0.5704)	loss 2.4116 (2.9832)	grad_norm 1.7047 (inf)	mem 17417MB
[2023-02-02 04:47:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][1150/1251]	eta 0:00:57 lr 0.000276	time 0.5794 (0.5705)	loss 3.7031 (2.9807)	grad_norm 2.0110 (inf)	mem 17417MB
[2023-02-02 04:47:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][1200/1251]	eta 0:00:29 lr 0.000276	time 0.5612 (0.5703)	loss 2.6898 (2.9800)	grad_norm 1.7709 (inf)	mem 17417MB
[2023-02-02 04:48:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [195/300][1250/1251]	eta 0:00:00 lr 0.000276	time 0.5500 (0.5702)	loss 3.7589 (2.9794)	grad_norm 1.9291 (inf)	mem 17417MB
[2023-02-02 04:48:00 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 195 training takes 0:11:53
[2023-02-02 04:48:00 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_195.pth saving......
[2023-02-02 04:48:02 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_195.pth saved !!!
[2023-02-02 04:48:03 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.841 (0.841)	Loss 0.8640 (0.8640)	Acc@1 79.688 (79.688)	Acc@5 94.531 (94.531)	Mem 17417MB
[2023-02-02 04:48:11 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.774 Acc@5 96.012
[2023-02-02 04:48:11 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.8%
[2023-02-02 04:48:12 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.313 (1.313)	Loss 0.7490 (0.7490)	Acc@1 83.887 (83.887)	Acc@5 95.898 (95.898)	Mem 17417MB
[2023-02-02 04:48:20 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.136 Acc@5 96.616
[2023-02-02 04:48:20 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.1%
[2023-02-02 04:48:20 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.14% at 194 epoch
[2023-02-02 04:48:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][0/1251]	eta 0:35:04 lr 0.000276	time 1.6819 (1.6819)	loss 3.1589 (3.1589)	grad_norm 1.9062 (1.9062)	mem 17417MB
[2023-02-02 04:48:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][50/1251]	eta 0:11:46 lr 0.000275	time 0.5530 (0.5886)	loss 2.5314 (2.8939)	grad_norm 1.7989 (1.8297)	mem 17417MB
[2023-02-02 04:49:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][100/1251]	eta 0:11:05 lr 0.000275	time 0.5561 (0.5784)	loss 2.5306 (2.9320)	grad_norm 1.8187 (1.8587)	mem 17417MB
[2023-02-02 04:49:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][150/1251]	eta 0:10:32 lr 0.000275	time 0.5533 (0.5749)	loss 3.3372 (2.9547)	grad_norm 1.6994 (1.8721)	mem 17417MB
[2023-02-02 04:50:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][200/1251]	eta 0:10:02 lr 0.000275	time 0.5558 (0.5736)	loss 2.0667 (2.9245)	grad_norm 1.6990 (1.8621)	mem 17417MB
[2023-02-02 04:50:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][250/1251]	eta 0:09:32 lr 0.000275	time 0.5535 (0.5721)	loss 3.1084 (2.9140)	grad_norm 1.7611 (1.8632)	mem 17417MB
[2023-02-02 04:51:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][300/1251]	eta 0:09:04 lr 0.000275	time 0.5536 (0.5722)	loss 2.7594 (2.9024)	grad_norm 1.8495 (1.8538)	mem 17417MB
[2023-02-02 04:51:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][350/1251]	eta 0:08:34 lr 0.000274	time 0.5582 (0.5714)	loss 3.2337 (2.9162)	grad_norm 1.8263 (1.8531)	mem 17417MB
[2023-02-02 04:52:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][400/1251]	eta 0:08:06 lr 0.000274	time 0.5562 (0.5713)	loss 2.8885 (2.9183)	grad_norm 1.7717 (1.8560)	mem 17417MB
[2023-02-02 04:52:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][450/1251]	eta 0:07:37 lr 0.000274	time 0.5577 (0.5711)	loss 3.2167 (2.9239)	grad_norm 2.0342 (1.8504)	mem 17417MB
[2023-02-02 04:53:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][500/1251]	eta 0:07:08 lr 0.000274	time 0.5772 (0.5705)	loss 3.3938 (2.9362)	grad_norm 1.8967 (1.8523)	mem 17417MB
[2023-02-02 04:53:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][550/1251]	eta 0:06:40 lr 0.000274	time 0.5700 (0.5707)	loss 2.5030 (2.9427)	grad_norm 2.0900 (1.8540)	mem 17417MB
[2023-02-02 04:54:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][600/1251]	eta 0:06:11 lr 0.000273	time 0.5558 (0.5704)	loss 2.7638 (2.9478)	grad_norm 1.8023 (1.8565)	mem 17417MB
[2023-02-02 04:54:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][650/1251]	eta 0:05:42 lr 0.000273	time 0.5579 (0.5704)	loss 2.1791 (2.9560)	grad_norm 1.6937 (1.8551)	mem 17417MB
[2023-02-02 04:55:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][700/1251]	eta 0:05:14 lr 0.000273	time 0.5633 (0.5703)	loss 3.0977 (2.9604)	grad_norm 1.8821 (1.8636)	mem 17417MB
[2023-02-02 04:55:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][750/1251]	eta 0:04:45 lr 0.000273	time 0.5586 (0.5702)	loss 3.0455 (2.9568)	grad_norm 1.7747 (1.8658)	mem 17417MB
[2023-02-02 04:55:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][800/1251]	eta 0:04:17 lr 0.000273	time 0.5575 (0.5701)	loss 3.1681 (2.9571)	grad_norm 1.9492 (1.8632)	mem 17417MB
[2023-02-02 04:56:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][850/1251]	eta 0:03:48 lr 0.000273	time 0.5518 (0.5701)	loss 2.9585 (2.9526)	grad_norm 1.8845 (1.8619)	mem 17417MB
[2023-02-02 04:56:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][900/1251]	eta 0:03:20 lr 0.000272	time 0.5592 (0.5700)	loss 2.1907 (2.9487)	grad_norm 1.7372 (1.8623)	mem 17417MB
[2023-02-02 04:57:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][950/1251]	eta 0:02:51 lr 0.000272	time 0.5602 (0.5698)	loss 3.5832 (2.9494)	grad_norm 1.9022 (1.8640)	mem 17417MB
[2023-02-02 04:57:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][1000/1251]	eta 0:02:23 lr 0.000272	time 0.5584 (0.5698)	loss 2.5551 (2.9512)	grad_norm 1.6927 (1.8626)	mem 17417MB
[2023-02-02 04:58:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][1050/1251]	eta 0:01:54 lr 0.000272	time 0.6369 (0.5698)	loss 3.3419 (2.9556)	grad_norm 1.7628 (1.8631)	mem 17417MB
[2023-02-02 04:58:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][1100/1251]	eta 0:01:26 lr 0.000272	time 0.6223 (0.5699)	loss 2.2172 (2.9550)	grad_norm 2.2496 (1.8634)	mem 17417MB
[2023-02-02 04:59:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][1150/1251]	eta 0:00:57 lr 0.000271	time 0.5544 (0.5698)	loss 2.0829 (2.9594)	grad_norm 2.1336 (1.8643)	mem 17417MB
[2023-02-02 04:59:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][1200/1251]	eta 0:00:29 lr 0.000271	time 0.6297 (0.5698)	loss 3.7268 (2.9605)	grad_norm 1.9000 (1.8642)	mem 17417MB
[2023-02-02 05:00:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [196/300][1250/1251]	eta 0:00:00 lr 0.000271	time 0.5552 (0.5698)	loss 2.0288 (2.9603)	grad_norm 1.8518 (1.8637)	mem 17417MB
[2023-02-02 05:00:13 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 196 training takes 0:11:52
[2023-02-02 05:00:13 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_196.pth saving......
[2023-02-02 05:00:15 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_196.pth saved !!!
[2023-02-02 05:00:16 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.904 (0.904)	Loss 0.7246 (0.7246)	Acc@1 83.008 (83.008)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-02 05:00:24 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.768 Acc@5 96.032
[2023-02-02 05:00:24 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.8%
[2023-02-02 05:00:25 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.353 (1.353)	Loss 0.6965 (0.6965)	Acc@1 85.059 (85.059)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-02 05:00:33 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.126 Acc@5 96.636
[2023-02-02 05:00:33 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.1%
[2023-02-02 05:00:33 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.14% at 194 epoch
[2023-02-02 05:00:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][0/1251]	eta 0:33:47 lr 0.000271	time 1.6211 (1.6211)	loss 3.0218 (3.0218)	grad_norm 1.8965 (1.8965)	mem 17417MB
[2023-02-02 05:01:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][50/1251]	eta 0:11:49 lr 0.000271	time 0.5509 (0.5904)	loss 3.1152 (2.9242)	grad_norm 1.7245 (1.8298)	mem 17417MB
[2023-02-02 05:01:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][100/1251]	eta 0:11:07 lr 0.000271	time 0.5530 (0.5799)	loss 3.2439 (2.9632)	grad_norm 2.0713 (1.8475)	mem 17417MB
[2023-02-02 05:02:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][150/1251]	eta 0:10:33 lr 0.000271	time 0.5519 (0.5756)	loss 2.7588 (2.9738)	grad_norm 1.7363 (1.8624)	mem 17417MB
[2023-02-02 05:02:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][200/1251]	eta 0:10:03 lr 0.000270	time 0.5533 (0.5738)	loss 3.0055 (2.9860)	grad_norm 1.7104 (1.8703)	mem 17417MB
[2023-02-02 05:02:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][250/1251]	eta 0:09:32 lr 0.000270	time 0.5547 (0.5720)	loss 3.3342 (2.9925)	grad_norm 1.7911 (1.8756)	mem 17417MB
[2023-02-02 05:03:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][300/1251]	eta 0:09:03 lr 0.000270	time 0.6374 (0.5717)	loss 3.1818 (2.9930)	grad_norm 1.8165 (1.8710)	mem 17417MB
[2023-02-02 05:03:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][350/1251]	eta 0:08:34 lr 0.000270	time 0.5523 (0.5707)	loss 2.8854 (2.9852)	grad_norm 1.9321 (1.8636)	mem 17417MB
[2023-02-02 05:04:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][400/1251]	eta 0:08:05 lr 0.000270	time 0.5488 (0.5707)	loss 2.7732 (2.9779)	grad_norm 1.7226 (1.8657)	mem 17417MB
[2023-02-02 05:04:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][450/1251]	eta 0:07:36 lr 0.000269	time 0.5550 (0.5701)	loss 2.7534 (2.9743)	grad_norm 1.9690 (1.8653)	mem 17417MB
[2023-02-02 05:05:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][500/1251]	eta 0:07:07 lr 0.000269	time 0.5525 (0.5698)	loss 2.9535 (2.9762)	grad_norm 1.9332 (1.8645)	mem 17417MB
[2023-02-02 05:05:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][550/1251]	eta 0:06:39 lr 0.000269	time 0.5573 (0.5698)	loss 2.5091 (2.9661)	grad_norm 2.2877 (1.8681)	mem 17417MB
[2023-02-02 05:06:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][600/1251]	eta 0:06:10 lr 0.000269	time 0.5604 (0.5697)	loss 3.3422 (2.9624)	grad_norm 1.7551 (1.8689)	mem 17417MB
[2023-02-02 05:06:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][650/1251]	eta 0:05:42 lr 0.000269	time 0.5626 (0.5698)	loss 3.2382 (2.9634)	grad_norm 1.9171 (1.8668)	mem 17417MB
[2023-02-02 05:07:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][700/1251]	eta 0:05:13 lr 0.000269	time 0.5635 (0.5697)	loss 3.1784 (2.9702)	grad_norm 1.6678 (1.8656)	mem 17417MB
[2023-02-02 05:07:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][750/1251]	eta 0:04:45 lr 0.000268	time 0.5526 (0.5695)	loss 3.6118 (2.9757)	grad_norm 2.1986 (1.8631)	mem 17417MB
[2023-02-02 05:08:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][800/1251]	eta 0:04:16 lr 0.000268	time 0.5495 (0.5695)	loss 2.8531 (2.9748)	grad_norm 1.8362 (1.8702)	mem 17417MB
[2023-02-02 05:08:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][850/1251]	eta 0:03:48 lr 0.000268	time 0.5559 (0.5694)	loss 2.1539 (2.9734)	grad_norm 1.7296 (1.8672)	mem 17417MB
[2023-02-02 05:09:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][900/1251]	eta 0:03:19 lr 0.000268	time 0.5593 (0.5695)	loss 3.1020 (2.9694)	grad_norm 1.8768 (1.8660)	mem 17417MB
[2023-02-02 05:09:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][950/1251]	eta 0:02:51 lr 0.000268	time 0.5580 (0.5694)	loss 2.1702 (2.9657)	grad_norm 1.7905 (1.8654)	mem 17417MB
[2023-02-02 05:10:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][1000/1251]	eta 0:02:22 lr 0.000267	time 0.5556 (0.5692)	loss 3.4801 (2.9717)	grad_norm 2.1237 (nan)	mem 17417MB
[2023-02-02 05:10:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][1050/1251]	eta 0:01:54 lr 0.000267	time 0.5553 (0.5693)	loss 3.2227 (2.9706)	grad_norm 1.7371 (nan)	mem 17417MB
[2023-02-02 05:11:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][1100/1251]	eta 0:01:25 lr 0.000267	time 0.6295 (0.5693)	loss 3.5817 (2.9698)	grad_norm 1.8096 (nan)	mem 17417MB
[2023-02-02 05:11:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][1150/1251]	eta 0:00:57 lr 0.000267	time 0.6465 (0.5692)	loss 3.0522 (2.9705)	grad_norm 2.0669 (nan)	mem 17417MB
[2023-02-02 05:11:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][1200/1251]	eta 0:00:29 lr 0.000267	time 0.5569 (0.5692)	loss 3.1588 (2.9719)	grad_norm 1.8499 (nan)	mem 17417MB
[2023-02-02 05:12:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [197/300][1250/1251]	eta 0:00:00 lr 0.000267	time 0.5534 (0.5693)	loss 2.8760 (2.9720)	grad_norm 2.4595 (nan)	mem 17417MB
[2023-02-02 05:12:26 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 197 training takes 0:11:52
[2023-02-02 05:12:26 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_197.pth saving......
[2023-02-02 05:12:28 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_197.pth saved !!!
[2023-02-02 05:12:29 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.853 (0.853)	Loss 0.7585 (0.7585)	Acc@1 82.520 (82.520)	Acc@5 95.508 (95.508)	Mem 17417MB
[2023-02-02 05:12:36 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.866 Acc@5 96.040
[2023-02-02 05:12:36 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.9%
[2023-02-02 05:12:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.160 (1.160)	Loss 0.7148 (0.7148)	Acc@1 83.398 (83.398)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 05:12:46 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.204 Acc@5 96.650
[2023-02-02 05:12:46 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.2%
[2023-02-02 05:12:46 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.20% at 197 epoch
[2023-02-02 05:12:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][0/1251]	eta 0:35:48 lr 0.000267	time 1.7172 (1.7172)	loss 3.1619 (3.1619)	grad_norm 1.6325 (1.6325)	mem 17417MB
[2023-02-02 05:13:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][50/1251]	eta 0:11:50 lr 0.000266	time 0.5541 (0.5918)	loss 3.3467 (3.0710)	grad_norm 2.2198 (1.8734)	mem 17417MB
[2023-02-02 05:13:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][100/1251]	eta 0:11:11 lr 0.000266	time 0.5505 (0.5838)	loss 2.8053 (2.9959)	grad_norm 1.9335 (1.8967)	mem 17417MB
[2023-02-02 05:14:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][150/1251]	eta 0:10:36 lr 0.000266	time 0.5600 (0.5782)	loss 3.2543 (2.9822)	grad_norm 1.7428 (1.8921)	mem 17417MB
[2023-02-02 05:14:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][200/1251]	eta 0:10:04 lr 0.000266	time 0.5538 (0.5755)	loss 3.3593 (2.9656)	grad_norm 2.1066 (1.8788)	mem 17417MB
[2023-02-02 05:15:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][250/1251]	eta 0:09:34 lr 0.000266	time 0.5486 (0.5742)	loss 2.7478 (2.9526)	grad_norm 1.7417 (1.8779)	mem 17417MB
[2023-02-02 05:15:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][300/1251]	eta 0:09:04 lr 0.000265	time 0.5559 (0.5729)	loss 3.1248 (2.9435)	grad_norm 1.6979 (1.8748)	mem 17417MB
[2023-02-02 05:16:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][350/1251]	eta 0:08:35 lr 0.000265	time 0.5623 (0.5724)	loss 2.9842 (2.9304)	grad_norm 1.7852 (1.8809)	mem 17417MB
[2023-02-02 05:16:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][400/1251]	eta 0:08:06 lr 0.000265	time 0.5596 (0.5716)	loss 3.0678 (2.9465)	grad_norm 2.0104 (1.8821)	mem 17417MB
[2023-02-02 05:17:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][450/1251]	eta 0:07:37 lr 0.000265	time 0.5460 (0.5711)	loss 3.4922 (2.9419)	grad_norm 1.8653 (1.8812)	mem 17417MB
[2023-02-02 05:17:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][500/1251]	eta 0:07:08 lr 0.000265	time 0.5549 (0.5711)	loss 3.0435 (2.9381)	grad_norm 1.7927 (1.8808)	mem 17417MB
[2023-02-02 05:18:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][550/1251]	eta 0:06:40 lr 0.000265	time 0.5629 (0.5707)	loss 2.3064 (2.9504)	grad_norm 1.6618 (1.8818)	mem 17417MB
[2023-02-02 05:18:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][600/1251]	eta 0:06:11 lr 0.000264	time 0.5548 (0.5708)	loss 2.6137 (2.9506)	grad_norm 1.8181 (1.8842)	mem 17417MB
[2023-02-02 05:18:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][650/1251]	eta 0:05:43 lr 0.000264	time 0.5758 (0.5707)	loss 3.0926 (2.9465)	grad_norm 1.7511 (1.8855)	mem 17417MB
[2023-02-02 05:19:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][700/1251]	eta 0:05:14 lr 0.000264	time 0.5628 (0.5704)	loss 2.4183 (2.9474)	grad_norm 1.8161 (1.8856)	mem 17417MB
[2023-02-02 05:19:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][750/1251]	eta 0:04:45 lr 0.000264	time 0.5564 (0.5703)	loss 2.7378 (2.9493)	grad_norm 1.8483 (1.8863)	mem 17417MB
[2023-02-02 05:20:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][800/1251]	eta 0:04:17 lr 0.000264	time 0.5573 (0.5702)	loss 2.1539 (2.9456)	grad_norm 1.8924 (1.8853)	mem 17417MB
[2023-02-02 05:20:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][850/1251]	eta 0:03:48 lr 0.000263	time 0.5622 (0.5703)	loss 2.6692 (2.9467)	grad_norm 2.1843 (1.8884)	mem 17417MB
[2023-02-02 05:21:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][900/1251]	eta 0:03:20 lr 0.000263	time 0.5590 (0.5703)	loss 2.8620 (2.9429)	grad_norm 1.6755 (1.8879)	mem 17417MB
[2023-02-02 05:21:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][950/1251]	eta 0:02:51 lr 0.000263	time 0.5609 (0.5701)	loss 2.6205 (2.9413)	grad_norm 1.7962 (1.8895)	mem 17417MB
[2023-02-02 05:22:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][1000/1251]	eta 0:02:23 lr 0.000263	time 0.5535 (0.5700)	loss 3.0883 (2.9405)	grad_norm 1.6778 (1.8859)	mem 17417MB
[2023-02-02 05:22:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][1050/1251]	eta 0:01:54 lr 0.000263	time 0.5593 (0.5700)	loss 3.0341 (2.9346)	grad_norm 2.0897 (inf)	mem 17417MB
[2023-02-02 05:23:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][1100/1251]	eta 0:01:26 lr 0.000263	time 0.7258 (0.5699)	loss 3.0609 (2.9382)	grad_norm 1.7006 (inf)	mem 17417MB
[2023-02-02 05:23:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][1150/1251]	eta 0:00:57 lr 0.000262	time 0.6279 (0.5699)	loss 2.4854 (2.9391)	grad_norm 1.8603 (inf)	mem 17417MB
[2023-02-02 05:24:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][1200/1251]	eta 0:00:29 lr 0.000262	time 0.5589 (0.5697)	loss 2.9243 (2.9426)	grad_norm 1.9463 (inf)	mem 17417MB
[2023-02-02 05:24:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [198/300][1250/1251]	eta 0:00:00 lr 0.000262	time 0.5506 (0.5697)	loss 2.6745 (2.9430)	grad_norm 1.6849 (inf)	mem 17417MB
[2023-02-02 05:24:38 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 198 training takes 0:11:52
[2023-02-02 05:24:39 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_198.pth saving......
[2023-02-02 05:24:40 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_198.pth saved !!!
[2023-02-02 05:24:41 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.850 (0.850)	Loss 0.7758 (0.7758)	Acc@1 81.055 (81.055)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-02 05:24:49 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.010 Acc@5 96.232
[2023-02-02 05:24:49 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.0%
[2023-02-02 05:24:50 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.178 (1.178)	Loss 0.6610 (0.6610)	Acc@1 84.375 (84.375)	Acc@5 97.363 (97.363)	Mem 17417MB
[2023-02-02 05:24:58 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.220 Acc@5 96.628
[2023-02-02 05:24:58 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.2%
[2023-02-02 05:24:58 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.22% at 198 epoch
[2023-02-02 05:25:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][0/1251]	eta 0:34:36 lr 0.000262	time 1.6600 (1.6600)	loss 2.2216 (2.2216)	grad_norm 2.2295 (2.2295)	mem 17417MB
[2023-02-02 05:25:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][50/1251]	eta 0:11:52 lr 0.000262	time 0.5540 (0.5937)	loss 2.1173 (2.9423)	grad_norm 1.7613 (1.8659)	mem 17417MB
[2023-02-02 05:25:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][100/1251]	eta 0:11:10 lr 0.000262	time 0.5556 (0.5823)	loss 2.9442 (2.9164)	grad_norm 1.5968 (1.8729)	mem 17417MB
[2023-02-02 05:26:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][150/1251]	eta 0:10:36 lr 0.000261	time 0.5528 (0.5778)	loss 2.7687 (2.9570)	grad_norm 1.9107 (1.8789)	mem 17417MB
[2023-02-02 05:26:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][200/1251]	eta 0:10:04 lr 0.000261	time 0.5538 (0.5750)	loss 1.9990 (2.9290)	grad_norm 1.9108 (1.8911)	mem 17417MB
[2023-02-02 05:27:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][250/1251]	eta 0:09:35 lr 0.000261	time 0.6222 (0.5748)	loss 3.3829 (2.9321)	grad_norm 2.0115 (1.8841)	mem 17417MB
[2023-02-02 05:27:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][300/1251]	eta 0:09:05 lr 0.000261	time 0.5505 (0.5734)	loss 2.0896 (2.9301)	grad_norm 1.8052 (1.8749)	mem 17417MB
[2023-02-02 05:28:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][350/1251]	eta 0:08:36 lr 0.000261	time 0.5734 (0.5733)	loss 2.1548 (2.9317)	grad_norm 1.9456 (1.8800)	mem 17417MB
[2023-02-02 05:28:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][400/1251]	eta 0:08:07 lr 0.000261	time 0.5501 (0.5724)	loss 2.5949 (2.9427)	grad_norm 1.8116 (1.8861)	mem 17417MB
[2023-02-02 05:29:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][450/1251]	eta 0:07:38 lr 0.000260	time 0.5559 (0.5721)	loss 3.0757 (2.9506)	grad_norm 2.3781 (1.8857)	mem 17417MB
[2023-02-02 05:29:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][500/1251]	eta 0:07:09 lr 0.000260	time 0.5555 (0.5715)	loss 2.4604 (2.9377)	grad_norm 1.9718 (1.8858)	mem 17417MB
[2023-02-02 05:30:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][550/1251]	eta 0:06:40 lr 0.000260	time 0.5548 (0.5711)	loss 1.9350 (2.9321)	grad_norm 2.2648 (1.8875)	mem 17417MB
[2023-02-02 05:30:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][600/1251]	eta 0:06:11 lr 0.000260	time 0.5487 (0.5710)	loss 3.1160 (2.9365)	grad_norm 1.9446 (1.8898)	mem 17417MB
[2023-02-02 05:31:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][650/1251]	eta 0:05:43 lr 0.000260	time 0.5528 (0.5711)	loss 2.9939 (2.9379)	grad_norm 1.7430 (1.8911)	mem 17417MB
[2023-02-02 05:31:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][700/1251]	eta 0:05:14 lr 0.000259	time 0.5639 (0.5708)	loss 2.6807 (2.9343)	grad_norm 1.8627 (1.8881)	mem 17417MB
[2023-02-02 05:32:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][750/1251]	eta 0:04:45 lr 0.000259	time 0.5531 (0.5708)	loss 2.7722 (2.9441)	grad_norm 1.7657 (1.8893)	mem 17417MB
[2023-02-02 05:32:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][800/1251]	eta 0:04:17 lr 0.000259	time 0.5613 (0.5708)	loss 3.4917 (2.9407)	grad_norm 1.8162 (1.8873)	mem 17417MB
[2023-02-02 05:33:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][850/1251]	eta 0:03:48 lr 0.000259	time 0.6126 (0.5707)	loss 3.3401 (2.9473)	grad_norm 2.0005 (1.8859)	mem 17417MB
[2023-02-02 05:33:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][900/1251]	eta 0:03:20 lr 0.000259	time 0.5553 (0.5706)	loss 2.4154 (2.9508)	grad_norm 2.1349 (1.8854)	mem 17417MB
[2023-02-02 05:34:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][950/1251]	eta 0:02:51 lr 0.000259	time 0.5574 (0.5704)	loss 3.0030 (2.9532)	grad_norm 1.9055 (1.8849)	mem 17417MB
[2023-02-02 05:34:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][1000/1251]	eta 0:02:23 lr 0.000258	time 0.5578 (0.5704)	loss 3.2968 (2.9534)	grad_norm 1.7425 (1.8864)	mem 17417MB
[2023-02-02 05:34:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][1050/1251]	eta 0:01:54 lr 0.000258	time 0.5551 (0.5703)	loss 3.4478 (2.9487)	grad_norm 2.0787 (1.8854)	mem 17417MB
[2023-02-02 05:35:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][1100/1251]	eta 0:01:26 lr 0.000258	time 0.5519 (0.5702)	loss 2.8456 (2.9458)	grad_norm 2.0716 (1.8852)	mem 17417MB
[2023-02-02 05:35:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][1150/1251]	eta 0:00:57 lr 0.000258	time 0.5593 (0.5701)	loss 2.0917 (2.9409)	grad_norm 1.9035 (1.8903)	mem 17417MB
[2023-02-02 05:36:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][1200/1251]	eta 0:00:29 lr 0.000258	time 0.5517 (0.5701)	loss 3.0498 (2.9381)	grad_norm 1.8261 (1.8920)	mem 17417MB
[2023-02-02 05:36:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [199/300][1250/1251]	eta 0:00:00 lr 0.000258	time 0.5523 (0.5701)	loss 2.7653 (2.9388)	grad_norm 1.8011 (1.8900)	mem 17417MB
[2023-02-02 05:36:52 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 199 training takes 0:11:53
[2023-02-02 05:36:52 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_199.pth saving......
[2023-02-02 05:36:54 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_199.pth saved !!!
[2023-02-02 05:36:55 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.905 (0.905)	Loss 0.7752 (0.7752)	Acc@1 82.227 (82.227)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-02 05:37:03 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.078 Acc@5 96.204
[2023-02-02 05:37:03 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.1%
[2023-02-02 05:37:04 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.186 (1.186)	Loss 0.6973 (0.6973)	Acc@1 83.594 (83.594)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 05:37:12 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.236 Acc@5 96.656
[2023-02-02 05:37:12 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.2%
[2023-02-02 05:37:12 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.24% at 199 epoch
[2023-02-02 05:37:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][0/1251]	eta 0:34:14 lr 0.000258	time 1.6421 (1.6421)	loss 2.7878 (2.7878)	grad_norm 1.7094 (1.7094)	mem 17417MB
[2023-02-02 05:37:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][50/1251]	eta 0:11:52 lr 0.000257	time 0.5686 (0.5930)	loss 1.9025 (2.9197)	grad_norm 2.3302 (1.9503)	mem 17417MB
[2023-02-02 05:38:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][100/1251]	eta 0:11:09 lr 0.000257	time 0.6280 (0.5814)	loss 3.2934 (2.9010)	grad_norm 2.2355 (1.9205)	mem 17417MB
[2023-02-02 05:38:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][150/1251]	eta 0:10:34 lr 0.000257	time 0.5514 (0.5765)	loss 1.9694 (2.9012)	grad_norm 1.9251 (1.8878)	mem 17417MB
[2023-02-02 05:39:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][200/1251]	eta 0:10:03 lr 0.000257	time 0.5476 (0.5746)	loss 2.8300 (2.9048)	grad_norm 1.8524 (1.8788)	mem 17417MB
[2023-02-02 05:39:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][250/1251]	eta 0:09:33 lr 0.000257	time 0.6486 (0.5734)	loss 3.1447 (2.8942)	grad_norm 2.1401 (1.8951)	mem 17417MB
[2023-02-02 05:40:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][300/1251]	eta 0:09:04 lr 0.000256	time 0.6214 (0.5726)	loss 2.7574 (2.9172)	grad_norm 1.7680 (1.8912)	mem 17417MB
[2023-02-02 05:40:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][350/1251]	eta 0:08:35 lr 0.000256	time 0.5513 (0.5721)	loss 2.9490 (2.9142)	grad_norm 1.8926 (1.8938)	mem 17417MB
[2023-02-02 05:41:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][400/1251]	eta 0:08:06 lr 0.000256	time 0.5589 (0.5715)	loss 2.7769 (2.9179)	grad_norm 2.0264 (1.8900)	mem 17417MB
[2023-02-02 05:41:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][450/1251]	eta 0:07:37 lr 0.000256	time 0.5570 (0.5714)	loss 3.5178 (2.9224)	grad_norm 1.7302 (1.8895)	mem 17417MB
[2023-02-02 05:41:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][500/1251]	eta 0:07:08 lr 0.000256	time 0.6167 (0.5709)	loss 3.4179 (2.9196)	grad_norm 1.7559 (1.8831)	mem 17417MB
[2023-02-02 05:42:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][550/1251]	eta 0:06:40 lr 0.000256	time 0.5539 (0.5707)	loss 2.2041 (2.9200)	grad_norm 1.7506 (1.8906)	mem 17417MB
[2023-02-02 05:42:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][600/1251]	eta 0:06:11 lr 0.000255	time 0.5675 (0.5706)	loss 3.0425 (2.9220)	grad_norm 2.0503 (1.8883)	mem 17417MB
[2023-02-02 05:43:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][650/1251]	eta 0:05:42 lr 0.000255	time 0.5593 (0.5704)	loss 2.3218 (2.9255)	grad_norm 1.9966 (1.8871)	mem 17417MB
[2023-02-02 05:43:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][700/1251]	eta 0:05:14 lr 0.000255	time 0.5490 (0.5705)	loss 2.5583 (2.9318)	grad_norm 1.6521 (1.8886)	mem 17417MB
[2023-02-02 05:44:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][750/1251]	eta 0:04:45 lr 0.000255	time 0.5577 (0.5703)	loss 3.2911 (2.9388)	grad_norm 1.9157 (1.8879)	mem 17417MB
[2023-02-02 05:44:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][800/1251]	eta 0:04:17 lr 0.000255	time 0.5629 (0.5702)	loss 3.1388 (2.9390)	grad_norm 1.6220 (1.8878)	mem 17417MB
[2023-02-02 05:45:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][850/1251]	eta 0:03:48 lr 0.000254	time 0.5530 (0.5702)	loss 2.2614 (2.9429)	grad_norm 2.2072 (1.8879)	mem 17417MB
[2023-02-02 05:45:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][900/1251]	eta 0:03:20 lr 0.000254	time 0.6098 (0.5702)	loss 2.9553 (2.9398)	grad_norm 1.5898 (1.8889)	mem 17417MB
[2023-02-02 05:46:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][950/1251]	eta 0:02:51 lr 0.000254	time 0.5553 (0.5702)	loss 2.6394 (2.9392)	grad_norm 2.0524 (1.8932)	mem 17417MB
[2023-02-02 05:46:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][1000/1251]	eta 0:02:23 lr 0.000254	time 0.5553 (0.5701)	loss 2.5749 (2.9407)	grad_norm 1.7196 (1.8948)	mem 17417MB
[2023-02-02 05:47:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][1050/1251]	eta 0:01:54 lr 0.000254	time 0.5616 (0.5701)	loss 3.3113 (2.9375)	grad_norm 1.7907 (1.8923)	mem 17417MB
[2023-02-02 05:47:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][1100/1251]	eta 0:01:26 lr 0.000254	time 0.5557 (0.5700)	loss 3.2330 (2.9371)	grad_norm 1.8146 (1.8917)	mem 17417MB
[2023-02-02 05:48:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][1150/1251]	eta 0:00:57 lr 0.000253	time 0.5590 (0.5700)	loss 2.6900 (2.9388)	grad_norm 2.1238 (1.8927)	mem 17417MB
[2023-02-02 05:48:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][1200/1251]	eta 0:00:29 lr 0.000253	time 0.5546 (0.5699)	loss 3.2057 (2.9423)	grad_norm 1.8514 (1.8931)	mem 17417MB
[2023-02-02 05:49:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [200/300][1250/1251]	eta 0:00:00 lr 0.000253	time 0.5502 (0.5701)	loss 3.4520 (2.9471)	grad_norm 2.2090 (1.8928)	mem 17417MB
[2023-02-02 05:49:05 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 200 training takes 0:11:53
[2023-02-02 05:49:05 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_200.pth saving......
[2023-02-02 05:49:07 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_200.pth saved !!!
[2023-02-02 05:49:08 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.865 (0.865)	Loss 0.7129 (0.7129)	Acc@1 82.422 (82.422)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-02 05:49:16 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.988 Acc@5 96.142
[2023-02-02 05:49:16 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.0%
[2023-02-02 05:49:17 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.231 (1.231)	Loss 0.7148 (0.7148)	Acc@1 83.008 (83.008)	Acc@5 96.484 (96.484)	Mem 17417MB
[2023-02-02 05:49:25 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.256 Acc@5 96.652
[2023-02-02 05:49:25 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.3%
[2023-02-02 05:49:25 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.26% at 200 epoch
[2023-02-02 05:49:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][0/1251]	eta 0:35:38 lr 0.000253	time 1.7098 (1.7098)	loss 2.2800 (2.2800)	grad_norm 1.8027 (1.8027)	mem 17417MB
[2023-02-02 05:49:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][50/1251]	eta 0:11:51 lr 0.000253	time 0.5614 (0.5926)	loss 2.9793 (2.9089)	grad_norm 1.7526 (1.9071)	mem 17417MB
[2023-02-02 05:50:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][100/1251]	eta 0:11:08 lr 0.000253	time 0.5560 (0.5810)	loss 2.8197 (2.9310)	grad_norm 1.8224 (1.8892)	mem 17417MB
[2023-02-02 05:50:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][150/1251]	eta 0:10:35 lr 0.000252	time 0.5579 (0.5768)	loss 3.3681 (2.9760)	grad_norm 1.8147 (1.8808)	mem 17417MB
[2023-02-02 05:51:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][200/1251]	eta 0:10:04 lr 0.000252	time 0.5616 (0.5750)	loss 3.8773 (2.9938)	grad_norm 1.9364 (1.8883)	mem 17417MB
[2023-02-02 05:51:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][250/1251]	eta 0:09:33 lr 0.000252	time 0.5612 (0.5730)	loss 3.0255 (2.9812)	grad_norm 1.8155 (1.8889)	mem 17417MB
[2023-02-02 05:52:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][300/1251]	eta 0:09:04 lr 0.000252	time 0.5529 (0.5727)	loss 3.3302 (2.9478)	grad_norm 1.7592 (1.8863)	mem 17417MB
[2023-02-02 05:52:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][350/1251]	eta 0:08:35 lr 0.000252	time 0.5539 (0.5719)	loss 3.0940 (2.9410)	grad_norm 1.7552 (1.8900)	mem 17417MB
[2023-02-02 05:53:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][400/1251]	eta 0:08:06 lr 0.000252	time 0.5576 (0.5718)	loss 3.5631 (2.9471)	grad_norm 1.9070 (1.8984)	mem 17417MB
[2023-02-02 05:53:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][450/1251]	eta 0:07:37 lr 0.000251	time 0.6227 (0.5713)	loss 3.3791 (2.9563)	grad_norm 1.9108 (1.8975)	mem 17417MB
[2023-02-02 05:54:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][500/1251]	eta 0:07:08 lr 0.000251	time 0.5573 (0.5708)	loss 3.2517 (2.9589)	grad_norm 2.0371 (1.8997)	mem 17417MB
[2023-02-02 05:54:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][550/1251]	eta 0:06:39 lr 0.000251	time 0.5513 (0.5706)	loss 2.6259 (2.9515)	grad_norm 1.9763 (1.9004)	mem 17417MB
[2023-02-02 05:55:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][600/1251]	eta 0:06:11 lr 0.000251	time 0.5595 (0.5706)	loss 3.1700 (2.9456)	grad_norm 1.9067 (1.8994)	mem 17417MB
[2023-02-02 05:55:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][650/1251]	eta 0:05:42 lr 0.000251	time 0.5489 (0.5703)	loss 3.5665 (2.9446)	grad_norm 1.9684 (1.9000)	mem 17417MB
[2023-02-02 05:56:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][700/1251]	eta 0:05:14 lr 0.000251	time 0.5549 (0.5703)	loss 3.2606 (2.9431)	grad_norm 1.7362 (1.8973)	mem 17417MB
[2023-02-02 05:56:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][750/1251]	eta 0:04:45 lr 0.000250	time 0.5566 (0.5701)	loss 3.3273 (2.9406)	grad_norm 1.7238 (1.8931)	mem 17417MB
[2023-02-02 05:57:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][800/1251]	eta 0:04:17 lr 0.000250	time 0.6406 (0.5701)	loss 3.4758 (2.9500)	grad_norm 2.0123 (1.8933)	mem 17417MB
[2023-02-02 05:57:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][850/1251]	eta 0:03:48 lr 0.000250	time 0.5651 (0.5700)	loss 3.0272 (2.9501)	grad_norm 2.0839 (1.8961)	mem 17417MB
[2023-02-02 05:57:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][900/1251]	eta 0:03:20 lr 0.000250	time 0.5582 (0.5698)	loss 2.9399 (2.9524)	grad_norm 2.0648 (1.8971)	mem 17417MB
[2023-02-02 05:58:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][950/1251]	eta 0:02:51 lr 0.000250	time 0.5584 (0.5697)	loss 2.8960 (2.9589)	grad_norm 1.7488 (1.8975)	mem 17417MB
[2023-02-02 05:58:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][1000/1251]	eta 0:02:23 lr 0.000249	time 0.5524 (0.5698)	loss 2.5770 (2.9558)	grad_norm 1.9498 (1.8975)	mem 17417MB
[2023-02-02 05:59:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][1050/1251]	eta 0:01:54 lr 0.000249	time 0.5499 (0.5696)	loss 2.8859 (2.9515)	grad_norm 1.9781 (1.8987)	mem 17417MB
[2023-02-02 05:59:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][1100/1251]	eta 0:01:26 lr 0.000249	time 0.6327 (0.5697)	loss 3.2186 (2.9494)	grad_norm 1.9968 (1.8980)	mem 17417MB
[2023-02-02 06:00:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][1150/1251]	eta 0:00:57 lr 0.000249	time 0.5534 (0.5695)	loss 2.2970 (2.9476)	grad_norm 1.7635 (1.8996)	mem 17417MB
[2023-02-02 06:00:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][1200/1251]	eta 0:00:29 lr 0.000249	time 0.6349 (0.5695)	loss 2.8065 (2.9457)	grad_norm 2.0917 (1.9002)	mem 17417MB
[2023-02-02 06:01:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [201/300][1250/1251]	eta 0:00:00 lr 0.000249	time 0.5486 (0.5694)	loss 3.5640 (2.9467)	grad_norm 1.8185 (1.9021)	mem 17417MB
[2023-02-02 06:01:18 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 201 training takes 0:11:52
[2023-02-02 06:01:18 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_201.pth saving......
[2023-02-02 06:01:20 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_201.pth saved !!!
[2023-02-02 06:01:21 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.998 (0.998)	Loss 0.8126 (0.8126)	Acc@1 80.176 (80.176)	Acc@5 95.898 (95.898)	Mem 17417MB
[2023-02-02 06:01:28 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.032 Acc@5 96.184
[2023-02-02 06:01:28 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.0%
[2023-02-02 06:01:30 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.194 (1.194)	Loss 0.7757 (0.7757)	Acc@1 81.250 (81.250)	Acc@5 96.582 (96.582)	Mem 17417MB
[2023-02-02 06:01:38 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.286 Acc@5 96.660
[2023-02-02 06:01:38 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.3%
[2023-02-02 06:01:38 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.29% at 201 epoch
[2023-02-02 06:01:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][0/1251]	eta 0:36:03 lr 0.000249	time 1.7296 (1.7296)	loss 3.1868 (3.1868)	grad_norm 1.7459 (1.7459)	mem 17417MB
[2023-02-02 06:02:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][50/1251]	eta 0:11:53 lr 0.000248	time 0.5552 (0.5941)	loss 3.1461 (2.9677)	grad_norm 1.7949 (1.8601)	mem 17417MB
[2023-02-02 06:02:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][100/1251]	eta 0:11:10 lr 0.000248	time 0.5613 (0.5826)	loss 3.5957 (3.0229)	grad_norm 1.8835 (1.8710)	mem 17417MB
[2023-02-02 06:03:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][150/1251]	eta 0:10:36 lr 0.000248	time 0.5544 (0.5783)	loss 3.1818 (2.9471)	grad_norm 1.8237 (1.8674)	mem 17417MB
[2023-02-02 06:03:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][200/1251]	eta 0:10:05 lr 0.000248	time 0.5460 (0.5760)	loss 3.1565 (2.9575)	grad_norm 1.6824 (1.8668)	mem 17417MB
[2023-02-02 06:04:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][250/1251]	eta 0:09:34 lr 0.000248	time 0.5544 (0.5744)	loss 2.7498 (2.9520)	grad_norm 1.8571 (1.8748)	mem 17417MB
[2023-02-02 06:04:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][300/1251]	eta 0:09:05 lr 0.000248	time 0.5606 (0.5737)	loss 3.0050 (2.9426)	grad_norm 1.7228 (1.8792)	mem 17417MB
[2023-02-02 06:04:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][350/1251]	eta 0:08:35 lr 0.000247	time 0.5606 (0.5727)	loss 2.7494 (2.9302)	grad_norm 1.7637 (1.8856)	mem 17417MB
[2023-02-02 06:05:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][400/1251]	eta 0:08:06 lr 0.000247	time 0.5555 (0.5723)	loss 3.2901 (2.9248)	grad_norm 2.2486 (1.8810)	mem 17417MB
[2023-02-02 06:05:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][450/1251]	eta 0:07:38 lr 0.000247	time 0.5558 (0.5718)	loss 2.9040 (2.9359)	grad_norm 1.8133 (1.8826)	mem 17417MB
[2023-02-02 06:06:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][500/1251]	eta 0:07:09 lr 0.000247	time 0.5548 (0.5716)	loss 3.5296 (2.9435)	grad_norm 2.0055 (1.8819)	mem 17417MB
[2023-02-02 06:06:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][550/1251]	eta 0:06:40 lr 0.000247	time 0.5482 (0.5715)	loss 3.3583 (2.9477)	grad_norm 1.9323 (1.8811)	mem 17417MB
[2023-02-02 06:07:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][600/1251]	eta 0:06:11 lr 0.000246	time 0.5607 (0.5714)	loss 3.1298 (2.9497)	grad_norm 2.0632 (1.8831)	mem 17417MB
[2023-02-02 06:07:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][650/1251]	eta 0:05:43 lr 0.000246	time 0.5523 (0.5712)	loss 1.7689 (2.9468)	grad_norm 1.7310 (1.8867)	mem 17417MB
[2023-02-02 06:08:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][700/1251]	eta 0:05:14 lr 0.000246	time 0.5540 (0.5710)	loss 2.9105 (2.9487)	grad_norm 1.8561 (1.8878)	mem 17417MB
[2023-02-02 06:08:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][750/1251]	eta 0:04:46 lr 0.000246	time 0.5563 (0.5710)	loss 3.2404 (2.9430)	grad_norm 1.8797 (1.8913)	mem 17417MB
[2023-02-02 06:09:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][800/1251]	eta 0:04:17 lr 0.000246	time 0.6266 (0.5710)	loss 3.0598 (2.9392)	grad_norm 1.8254 (1.8924)	mem 17417MB
[2023-02-02 06:09:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][850/1251]	eta 0:03:48 lr 0.000246	time 0.5576 (0.5709)	loss 3.2039 (2.9374)	grad_norm 2.4054 (1.8919)	mem 17417MB
[2023-02-02 06:10:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][900/1251]	eta 0:03:20 lr 0.000245	time 0.5873 (0.5708)	loss 2.7196 (2.9321)	grad_norm 1.8298 (1.8929)	mem 17417MB
[2023-02-02 06:10:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][950/1251]	eta 0:02:51 lr 0.000245	time 0.5554 (0.5707)	loss 3.2605 (2.9264)	grad_norm 1.7683 (1.8941)	mem 17417MB
[2023-02-02 06:11:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][1000/1251]	eta 0:02:23 lr 0.000245	time 0.5595 (0.5708)	loss 3.1822 (2.9256)	grad_norm 1.5770 (1.8953)	mem 17417MB
[2023-02-02 06:11:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][1050/1251]	eta 0:01:54 lr 0.000245	time 0.5606 (0.5707)	loss 3.2527 (2.9263)	grad_norm 2.2367 (1.8951)	mem 17417MB
[2023-02-02 06:12:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][1100/1251]	eta 0:01:26 lr 0.000245	time 0.6252 (0.5707)	loss 3.1825 (2.9286)	grad_norm 1.7190 (1.8950)	mem 17417MB
[2023-02-02 06:12:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][1150/1251]	eta 0:00:57 lr 0.000245	time 0.5616 (0.5706)	loss 2.2728 (2.9320)	grad_norm 2.0833 (1.8973)	mem 17417MB
[2023-02-02 06:13:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][1200/1251]	eta 0:00:29 lr 0.000244	time 0.6450 (0.5706)	loss 3.1024 (2.9351)	grad_norm 1.8949 (1.8983)	mem 17417MB
[2023-02-02 06:13:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [202/300][1250/1251]	eta 0:00:00 lr 0.000244	time 0.5480 (0.5705)	loss 3.1554 (2.9334)	grad_norm 1.6433 (1.9019)	mem 17417MB
[2023-02-02 06:13:31 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 202 training takes 0:11:53
[2023-02-02 06:13:32 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_202.pth saving......
[2023-02-02 06:13:33 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_202.pth saved !!!
[2023-02-02 06:13:34 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.864 (0.864)	Loss 0.8311 (0.8311)	Acc@1 80.859 (80.859)	Acc@5 95.801 (95.801)	Mem 17417MB
[2023-02-02 06:13:42 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.936 Acc@5 96.120
[2023-02-02 06:13:42 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 81.9%
[2023-02-02 06:13:43 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.196 (1.196)	Loss 0.7881 (0.7881)	Acc@1 81.738 (81.738)	Acc@5 95.605 (95.605)	Mem 17417MB
[2023-02-02 06:13:51 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.296 Acc@5 96.656
[2023-02-02 06:13:51 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.3%
[2023-02-02 06:13:51 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.30% at 202 epoch
[2023-02-02 06:13:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][0/1251]	eta 0:36:10 lr 0.000244	time 1.7349 (1.7349)	loss 2.4414 (2.4414)	grad_norm 1.7865 (1.7865)	mem 17417MB
[2023-02-02 06:14:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][50/1251]	eta 0:11:53 lr 0.000244	time 0.5627 (0.5942)	loss 3.6834 (3.0147)	grad_norm 2.1029 (1.9640)	mem 17417MB
[2023-02-02 06:14:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][100/1251]	eta 0:11:10 lr 0.000244	time 0.6431 (0.5826)	loss 3.5037 (2.9674)	grad_norm 1.9045 (1.9218)	mem 17417MB
[2023-02-02 06:15:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][150/1251]	eta 0:10:35 lr 0.000244	time 0.5549 (0.5774)	loss 3.1131 (2.9741)	grad_norm 2.0219 (1.9105)	mem 17417MB
[2023-02-02 06:15:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][200/1251]	eta 0:10:04 lr 0.000243	time 0.5499 (0.5751)	loss 3.7806 (2.9949)	grad_norm 1.6658 (1.9021)	mem 17417MB
[2023-02-02 06:16:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][250/1251]	eta 0:09:34 lr 0.000243	time 0.6185 (0.5738)	loss 2.0629 (2.9819)	grad_norm 1.9014 (1.9099)	mem 17417MB
[2023-02-02 06:16:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][300/1251]	eta 0:09:05 lr 0.000243	time 0.5595 (0.5732)	loss 3.1235 (2.9520)	grad_norm 1.8798 (1.9120)	mem 17417MB
[2023-02-02 06:17:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][350/1251]	eta 0:08:35 lr 0.000243	time 0.5488 (0.5722)	loss 2.7904 (2.9429)	grad_norm 1.8969 (1.9166)	mem 17417MB
[2023-02-02 06:17:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][400/1251]	eta 0:08:06 lr 0.000243	time 0.5579 (0.5721)	loss 2.9528 (2.9352)	grad_norm 1.8455 (1.9112)	mem 17417MB
[2023-02-02 06:18:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][450/1251]	eta 0:07:38 lr 0.000243	time 0.5565 (0.5718)	loss 3.2709 (2.9343)	grad_norm 1.7459 (1.9066)	mem 17417MB
[2023-02-02 06:18:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][500/1251]	eta 0:07:09 lr 0.000242	time 0.5551 (0.5713)	loss 1.4865 (2.9242)	grad_norm 1.9968 (1.9044)	mem 17417MB
[2023-02-02 06:19:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][550/1251]	eta 0:06:40 lr 0.000242	time 0.5567 (0.5711)	loss 3.0132 (2.9256)	grad_norm 1.8190 (1.9036)	mem 17417MB
[2023-02-02 06:19:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][600/1251]	eta 0:06:11 lr 0.000242	time 0.5604 (0.5710)	loss 3.5618 (2.9318)	grad_norm 1.8914 (1.9058)	mem 17417MB
[2023-02-02 06:20:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][650/1251]	eta 0:05:43 lr 0.000242	time 0.6398 (0.5710)	loss 3.0345 (2.9357)	grad_norm 1.8748 (1.9086)	mem 17417MB
[2023-02-02 06:20:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][700/1251]	eta 0:05:14 lr 0.000242	time 0.5580 (0.5707)	loss 2.6513 (2.9396)	grad_norm 1.8381 (1.9064)	mem 17417MB
[2023-02-02 06:21:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][750/1251]	eta 0:04:45 lr 0.000242	time 0.6426 (0.5706)	loss 2.4994 (2.9440)	grad_norm 2.2116 (1.9078)	mem 17417MB
[2023-02-02 06:21:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][800/1251]	eta 0:04:17 lr 0.000241	time 0.5562 (0.5706)	loss 2.8377 (2.9477)	grad_norm 1.6768 (1.9113)	mem 17417MB
[2023-02-02 06:21:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][850/1251]	eta 0:03:48 lr 0.000241	time 0.5641 (0.5706)	loss 3.3228 (2.9404)	grad_norm 1.7659 (inf)	mem 17417MB
[2023-02-02 06:22:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][900/1251]	eta 0:03:20 lr 0.000241	time 0.5521 (0.5704)	loss 2.7859 (2.9472)	grad_norm 1.7412 (inf)	mem 17417MB
[2023-02-02 06:22:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][950/1251]	eta 0:02:51 lr 0.000241	time 0.5538 (0.5704)	loss 2.5089 (2.9507)	grad_norm 1.9688 (inf)	mem 17417MB
[2023-02-02 06:23:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][1000/1251]	eta 0:02:23 lr 0.000241	time 0.5562 (0.5702)	loss 2.1334 (2.9504)	grad_norm 2.1852 (inf)	mem 17417MB
[2023-02-02 06:23:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][1050/1251]	eta 0:01:54 lr 0.000240	time 0.5625 (0.5702)	loss 3.4035 (2.9474)	grad_norm 1.9923 (inf)	mem 17417MB
[2023-02-02 06:24:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][1100/1251]	eta 0:01:26 lr 0.000240	time 0.6386 (0.5701)	loss 2.2815 (2.9493)	grad_norm 1.7722 (inf)	mem 17417MB
[2023-02-02 06:24:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][1150/1251]	eta 0:00:57 lr 0.000240	time 0.5609 (0.5701)	loss 2.4518 (2.9467)	grad_norm 1.9032 (inf)	mem 17417MB
[2023-02-02 06:25:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][1200/1251]	eta 0:00:29 lr 0.000240	time 0.5496 (0.5700)	loss 3.0888 (2.9528)	grad_norm 2.1327 (inf)	mem 17417MB
[2023-02-02 06:25:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [203/300][1250/1251]	eta 0:00:00 lr 0.000240	time 0.5532 (0.5701)	loss 2.7123 (2.9533)	grad_norm 2.1476 (inf)	mem 17417MB
[2023-02-02 06:25:45 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 203 training takes 0:11:53
[2023-02-02 06:25:45 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_203.pth saving......
[2023-02-02 06:25:47 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_203.pth saved !!!
[2023-02-02 06:25:47 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.901 (0.901)	Loss 0.7180 (0.7180)	Acc@1 83.594 (83.594)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-02 06:25:55 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 81.956 Acc@5 96.176
[2023-02-02 06:25:55 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.0%
[2023-02-02 06:25:57 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.185 (1.185)	Loss 0.6574 (0.6574)	Acc@1 84.863 (84.863)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-02 06:26:05 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.340 Acc@5 96.646
[2023-02-02 06:26:05 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.3%
[2023-02-02 06:26:05 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.34% at 203 epoch
[2023-02-02 06:26:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][0/1251]	eta 0:37:08 lr 0.000240	time 1.7817 (1.7817)	loss 2.1600 (2.1600)	grad_norm 1.7624 (1.7624)	mem 17417MB
[2023-02-02 06:26:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][50/1251]	eta 0:11:53 lr 0.000240	time 0.5617 (0.5942)	loss 2.9140 (2.9055)	grad_norm 1.8378 (1.8705)	mem 17417MB
[2023-02-02 06:27:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][100/1251]	eta 0:11:10 lr 0.000239	time 0.6496 (0.5826)	loss 2.9891 (2.9478)	grad_norm 1.7774 (1.8940)	mem 17417MB
[2023-02-02 06:27:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][150/1251]	eta 0:10:35 lr 0.000239	time 0.5511 (0.5774)	loss 3.1589 (2.9361)	grad_norm 2.1859 (1.9217)	mem 17417MB
[2023-02-02 06:28:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][200/1251]	eta 0:10:04 lr 0.000239	time 0.5554 (0.5749)	loss 3.4848 (2.9364)	grad_norm 1.8654 (1.9218)	mem 17417MB
[2023-02-02 06:28:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][250/1251]	eta 0:09:34 lr 0.000239	time 0.5534 (0.5738)	loss 3.2875 (2.9532)	grad_norm 1.8611 (1.9148)	mem 17417MB
[2023-02-02 06:28:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][300/1251]	eta 0:09:05 lr 0.000239	time 0.5532 (0.5732)	loss 1.8166 (2.9447)	grad_norm 2.0127 (1.9226)	mem 17417MB
[2023-02-02 06:29:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][350/1251]	eta 0:08:36 lr 0.000239	time 0.5598 (0.5730)	loss 2.1476 (2.9482)	grad_norm 1.6927 (1.9250)	mem 17417MB
[2023-02-02 06:29:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][400/1251]	eta 0:08:07 lr 0.000238	time 0.5600 (0.5723)	loss 2.4152 (2.9540)	grad_norm 1.9733 (1.9199)	mem 17417MB
[2023-02-02 06:30:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][450/1251]	eta 0:07:37 lr 0.000238	time 0.5518 (0.5718)	loss 3.4283 (2.9402)	grad_norm 1.6904 (1.9178)	mem 17417MB
[2023-02-02 06:30:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][500/1251]	eta 0:07:09 lr 0.000238	time 0.5608 (0.5713)	loss 2.9796 (2.9452)	grad_norm 1.8679 (1.9179)	mem 17417MB
[2023-02-02 06:31:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][550/1251]	eta 0:06:40 lr 0.000238	time 0.5511 (0.5712)	loss 3.0727 (2.9453)	grad_norm 1.7248 (1.9114)	mem 17417MB
[2023-02-02 06:31:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][600/1251]	eta 0:06:11 lr 0.000238	time 0.5542 (0.5714)	loss 2.1768 (2.9516)	grad_norm 2.2394 (1.9167)	mem 17417MB
[2023-02-02 06:32:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][650/1251]	eta 0:05:43 lr 0.000237	time 0.5553 (0.5712)	loss 3.1007 (2.9437)	grad_norm 2.0039 (1.9201)	mem 17417MB
[2023-02-02 06:32:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][700/1251]	eta 0:05:14 lr 0.000237	time 0.5628 (0.5711)	loss 3.2281 (2.9522)	grad_norm 1.7181 (1.9158)	mem 17417MB
[2023-02-02 06:33:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][750/1251]	eta 0:04:46 lr 0.000237	time 0.6198 (0.5709)	loss 2.6977 (2.9529)	grad_norm 2.0960 (1.9195)	mem 17417MB
[2023-02-02 06:33:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][800/1251]	eta 0:04:17 lr 0.000237	time 0.5594 (0.5710)	loss 2.8113 (2.9499)	grad_norm 2.1899 (1.9204)	mem 17417MB
[2023-02-02 06:34:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][850/1251]	eta 0:03:48 lr 0.000237	time 0.5549 (0.5708)	loss 2.2266 (2.9489)	grad_norm 1.7970 (1.9176)	mem 17417MB
[2023-02-02 06:34:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][900/1251]	eta 0:03:20 lr 0.000237	time 0.6209 (0.5707)	loss 2.2747 (2.9413)	grad_norm 1.6424 (1.9207)	mem 17417MB
[2023-02-02 06:35:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][950/1251]	eta 0:02:51 lr 0.000236	time 0.5595 (0.5706)	loss 2.5458 (2.9419)	grad_norm 1.9290 (1.9204)	mem 17417MB
[2023-02-02 06:35:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][1000/1251]	eta 0:02:23 lr 0.000236	time 0.5585 (0.5706)	loss 2.2514 (2.9379)	grad_norm 1.7134 (1.9185)	mem 17417MB
[2023-02-02 06:36:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][1050/1251]	eta 0:01:54 lr 0.000236	time 0.5690 (0.5705)	loss 3.0514 (2.9424)	grad_norm 2.4343 (1.9206)	mem 17417MB
[2023-02-02 06:36:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][1100/1251]	eta 0:01:26 lr 0.000236	time 0.6195 (0.5706)	loss 3.0266 (2.9433)	grad_norm 2.0864 (1.9203)	mem 17417MB
[2023-02-02 06:37:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][1150/1251]	eta 0:00:57 lr 0.000236	time 0.5591 (0.5704)	loss 3.3275 (2.9425)	grad_norm 2.2553 (1.9205)	mem 17417MB
[2023-02-02 06:37:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][1200/1251]	eta 0:00:29 lr 0.000236	time 0.5613 (0.5703)	loss 2.7133 (2.9427)	grad_norm 1.7531 (1.9219)	mem 17417MB
[2023-02-02 06:37:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [204/300][1250/1251]	eta 0:00:00 lr 0.000235	time 0.5507 (0.5703)	loss 2.7924 (2.9437)	grad_norm 1.8835 (1.9215)	mem 17417MB
[2023-02-02 06:37:58 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 204 training takes 0:11:53
[2023-02-02 06:37:58 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_204.pth saving......
[2023-02-02 06:38:00 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_204.pth saved !!!
[2023-02-02 06:38:01 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.928 (0.928)	Loss 0.8293 (0.8293)	Acc@1 81.445 (81.445)	Acc@5 95.703 (95.703)	Mem 17417MB
[2023-02-02 06:38:09 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.232 Acc@5 96.308
[2023-02-02 06:38:09 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.2%
[2023-02-02 06:38:10 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.216 (1.216)	Loss 0.7431 (0.7431)	Acc@1 83.594 (83.594)	Acc@5 96.582 (96.582)	Mem 17417MB
[2023-02-02 06:38:18 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.336 Acc@5 96.674
[2023-02-02 06:38:18 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.3%
[2023-02-02 06:38:18 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.34% at 203 epoch
[2023-02-02 06:38:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][0/1251]	eta 0:34:56 lr 0.000235	time 1.6756 (1.6756)	loss 3.1606 (3.1606)	grad_norm 1.6517 (1.6517)	mem 17417MB
[2023-02-02 06:38:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][50/1251]	eta 0:11:48 lr 0.000235	time 0.5638 (0.5899)	loss 3.3756 (2.9871)	grad_norm 1.9498 (1.9987)	mem 17417MB
[2023-02-02 06:39:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][100/1251]	eta 0:11:09 lr 0.000235	time 0.5560 (0.5817)	loss 3.3039 (3.0251)	grad_norm 1.9145 (1.9236)	mem 17417MB
[2023-02-02 06:39:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][150/1251]	eta 0:10:35 lr 0.000235	time 0.5616 (0.5775)	loss 2.8603 (2.9698)	grad_norm 1.8628 (1.9493)	mem 17417MB
[2023-02-02 06:40:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][200/1251]	eta 0:10:04 lr 0.000235	time 0.5589 (0.5748)	loss 3.5609 (2.9749)	grad_norm 1.8786 (1.9373)	mem 17417MB
[2023-02-02 06:40:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][250/1251]	eta 0:09:34 lr 0.000235	time 0.5579 (0.5740)	loss 3.3935 (2.9406)	grad_norm 1.9499 (1.9413)	mem 17417MB
[2023-02-02 06:41:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][300/1251]	eta 0:09:04 lr 0.000234	time 0.5543 (0.5730)	loss 2.9134 (2.9432)	grad_norm 1.8117 (1.9412)	mem 17417MB
[2023-02-02 06:41:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][350/1251]	eta 0:08:36 lr 0.000234	time 0.5545 (0.5729)	loss 2.9395 (2.9386)	grad_norm 2.1502 (1.9383)	mem 17417MB
[2023-02-02 06:42:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][400/1251]	eta 0:08:06 lr 0.000234	time 0.5608 (0.5722)	loss 3.1693 (2.9362)	grad_norm 2.1564 (1.9417)	mem 17417MB
[2023-02-02 06:42:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][450/1251]	eta 0:07:38 lr 0.000234	time 0.5600 (0.5718)	loss 2.7814 (2.9475)	grad_norm 2.0631 (1.9394)	mem 17417MB
[2023-02-02 06:43:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][500/1251]	eta 0:07:09 lr 0.000234	time 0.5559 (0.5716)	loss 3.4246 (2.9475)	grad_norm 1.7687 (1.9373)	mem 17417MB
[2023-02-02 06:43:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][550/1251]	eta 0:06:40 lr 0.000233	time 0.5595 (0.5712)	loss 2.6673 (2.9488)	grad_norm 1.7889 (1.9368)	mem 17417MB
[2023-02-02 06:44:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][600/1251]	eta 0:06:11 lr 0.000233	time 0.5560 (0.5712)	loss 2.8947 (2.9449)	grad_norm 1.9983 (nan)	mem 17417MB
[2023-02-02 06:44:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][650/1251]	eta 0:05:43 lr 0.000233	time 0.5598 (0.5710)	loss 3.4416 (2.9340)	grad_norm 2.0270 (nan)	mem 17417MB
[2023-02-02 06:44:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][700/1251]	eta 0:05:14 lr 0.000233	time 0.5560 (0.5707)	loss 2.8026 (2.9332)	grad_norm 1.7949 (nan)	mem 17417MB
[2023-02-02 06:45:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][750/1251]	eta 0:04:45 lr 0.000233	time 0.5582 (0.5707)	loss 3.0842 (2.9289)	grad_norm 2.0405 (nan)	mem 17417MB
[2023-02-02 06:45:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][800/1251]	eta 0:04:17 lr 0.000233	time 0.5547 (0.5705)	loss 3.0178 (2.9313)	grad_norm 1.8378 (nan)	mem 17417MB
[2023-02-02 06:46:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][850/1251]	eta 0:03:48 lr 0.000232	time 0.5559 (0.5703)	loss 2.3185 (2.9327)	grad_norm 2.1248 (nan)	mem 17417MB
[2023-02-02 06:46:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][900/1251]	eta 0:03:20 lr 0.000232	time 0.6473 (0.5705)	loss 3.6301 (2.9273)	grad_norm 2.0491 (nan)	mem 17417MB
[2023-02-02 06:47:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][950/1251]	eta 0:02:51 lr 0.000232	time 0.5635 (0.5701)	loss 3.2269 (2.9257)	grad_norm 1.7724 (nan)	mem 17417MB
[2023-02-02 06:47:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][1000/1251]	eta 0:02:23 lr 0.000232	time 0.5637 (0.5702)	loss 2.1938 (2.9259)	grad_norm 1.8693 (nan)	mem 17417MB
[2023-02-02 06:48:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][1050/1251]	eta 0:01:54 lr 0.000232	time 0.5547 (0.5701)	loss 3.4293 (2.9262)	grad_norm 2.1006 (nan)	mem 17417MB
[2023-02-02 06:48:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][1100/1251]	eta 0:01:26 lr 0.000232	time 0.6231 (0.5700)	loss 2.1030 (2.9282)	grad_norm 2.1316 (nan)	mem 17417MB
[2023-02-02 06:49:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][1150/1251]	eta 0:00:57 lr 0.000231	time 0.5549 (0.5701)	loss 3.1633 (2.9265)	grad_norm 2.0172 (nan)	mem 17417MB
[2023-02-02 06:49:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][1200/1251]	eta 0:00:29 lr 0.000231	time 0.5644 (0.5700)	loss 2.9489 (2.9253)	grad_norm 1.9923 (nan)	mem 17417MB
[2023-02-02 06:50:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [205/300][1250/1251]	eta 0:00:00 lr 0.000231	time 0.5531 (0.5700)	loss 1.6558 (2.9258)	grad_norm 1.7363 (nan)	mem 17417MB
[2023-02-02 06:50:12 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 205 training takes 0:11:53
[2023-02-02 06:50:12 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_205.pth saving......
[2023-02-02 06:50:13 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_205.pth saved !!!
[2023-02-02 06:50:14 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.848 (0.848)	Loss 0.8105 (0.8105)	Acc@1 81.348 (81.348)	Acc@5 95.996 (95.996)	Mem 17417MB
[2023-02-02 06:50:22 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.224 Acc@5 96.278
[2023-02-02 06:50:22 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.2%
[2023-02-02 06:50:23 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.212 (1.212)	Loss 0.7364 (0.7364)	Acc@1 82.812 (82.812)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 06:50:31 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.320 Acc@5 96.688
[2023-02-02 06:50:31 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.3%
[2023-02-02 06:50:31 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.34% at 203 epoch
[2023-02-02 06:50:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][0/1251]	eta 0:36:36 lr 0.000231	time 1.7558 (1.7558)	loss 3.0195 (3.0195)	grad_norm 1.8156 (1.8156)	mem 17417MB
[2023-02-02 06:51:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][50/1251]	eta 0:11:56 lr 0.000231	time 0.5566 (0.5968)	loss 3.3469 (2.8457)	grad_norm 1.8932 (1.9636)	mem 17417MB
[2023-02-02 06:51:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][100/1251]	eta 0:11:12 lr 0.000231	time 0.5633 (0.5839)	loss 2.0344 (2.8735)	grad_norm 1.9756 (1.9197)	mem 17417MB
[2023-02-02 06:51:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][150/1251]	eta 0:10:37 lr 0.000231	time 0.5594 (0.5788)	loss 3.4518 (2.8893)	grad_norm 1.7647 (1.9432)	mem 17417MB
[2023-02-02 06:52:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][200/1251]	eta 0:10:05 lr 0.000230	time 0.5562 (0.5758)	loss 3.5525 (2.9148)	grad_norm 1.9936 (1.9260)	mem 17417MB
[2023-02-02 06:52:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][250/1251]	eta 0:09:35 lr 0.000230	time 0.5548 (0.5749)	loss 3.3132 (2.9301)	grad_norm 1.7079 (1.9298)	mem 17417MB
[2023-02-02 06:53:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][300/1251]	eta 0:09:05 lr 0.000230	time 0.5578 (0.5740)	loss 2.0244 (2.9310)	grad_norm 1.6672 (1.9380)	mem 17417MB
[2023-02-02 06:53:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][350/1251]	eta 0:08:36 lr 0.000230	time 0.5552 (0.5729)	loss 3.0799 (2.9170)	grad_norm 1.7369 (1.9363)	mem 17417MB
[2023-02-02 06:54:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][400/1251]	eta 0:08:06 lr 0.000230	time 0.5521 (0.5721)	loss 3.1698 (2.9154)	grad_norm 2.4869 (1.9377)	mem 17417MB
[2023-02-02 06:54:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][450/1251]	eta 0:07:37 lr 0.000230	time 0.5805 (0.5717)	loss 2.6647 (2.8988)	grad_norm 1.9041 (1.9383)	mem 17417MB
[2023-02-02 06:55:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][500/1251]	eta 0:07:08 lr 0.000229	time 0.5529 (0.5709)	loss 2.0035 (2.8929)	grad_norm 1.6846 (1.9386)	mem 17417MB
[2023-02-02 06:55:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][550/1251]	eta 0:06:40 lr 0.000229	time 0.5533 (0.5708)	loss 3.2956 (2.8920)	grad_norm 1.9269 (1.9374)	mem 17417MB
[2023-02-02 06:56:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][600/1251]	eta 0:06:11 lr 0.000229	time 0.5613 (0.5705)	loss 2.9993 (2.8927)	grad_norm 1.9810 (1.9376)	mem 17417MB
[2023-02-02 06:56:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][650/1251]	eta 0:05:43 lr 0.000229	time 0.5513 (0.5708)	loss 2.3445 (2.8955)	grad_norm 1.9339 (1.9366)	mem 17417MB
[2023-02-02 06:57:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][700/1251]	eta 0:05:14 lr 0.000229	time 0.5547 (0.5704)	loss 3.2108 (2.9006)	grad_norm 2.2535 (1.9338)	mem 17417MB
[2023-02-02 06:57:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][750/1251]	eta 0:04:45 lr 0.000228	time 0.5663 (0.5703)	loss 2.1646 (2.8896)	grad_norm 1.8350 (1.9367)	mem 17417MB
[2023-02-02 06:58:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][800/1251]	eta 0:04:17 lr 0.000228	time 0.5721 (0.5700)	loss 3.0979 (2.8907)	grad_norm 1.7278 (1.9358)	mem 17417MB
[2023-02-02 06:58:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][850/1251]	eta 0:03:48 lr 0.000228	time 0.5586 (0.5702)	loss 3.4628 (2.8974)	grad_norm 1.8878 (1.9359)	mem 17417MB
[2023-02-02 06:59:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][900/1251]	eta 0:03:20 lr 0.000228	time 0.5546 (0.5701)	loss 2.5838 (2.9009)	grad_norm 1.7938 (1.9377)	mem 17417MB
[2023-02-02 06:59:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][950/1251]	eta 0:02:51 lr 0.000228	time 0.5605 (0.5701)	loss 3.0088 (2.9030)	grad_norm 2.0258 (1.9404)	mem 17417MB
[2023-02-02 07:00:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][1000/1251]	eta 0:02:23 lr 0.000228	time 0.5600 (0.5699)	loss 3.0460 (2.9000)	grad_norm 2.2376 (1.9408)	mem 17417MB
[2023-02-02 07:00:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][1050/1251]	eta 0:01:54 lr 0.000227	time 0.5506 (0.5701)	loss 3.2876 (2.9057)	grad_norm 2.1297 (1.9414)	mem 17417MB
[2023-02-02 07:00:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][1100/1251]	eta 0:01:26 lr 0.000227	time 0.5470 (0.5699)	loss 2.9823 (2.9087)	grad_norm 1.9353 (1.9412)	mem 17417MB
[2023-02-02 07:01:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][1150/1251]	eta 0:00:57 lr 0.000227	time 0.5540 (0.5699)	loss 3.4764 (2.9053)	grad_norm 1.8199 (1.9412)	mem 17417MB
[2023-02-02 07:01:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][1200/1251]	eta 0:00:29 lr 0.000227	time 0.5630 (0.5698)	loss 3.1193 (2.9110)	grad_norm 1.8305 (1.9413)	mem 17417MB
[2023-02-02 07:02:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [206/300][1250/1251]	eta 0:00:00 lr 0.000227	time 0.6191 (0.5698)	loss 2.5002 (2.9126)	grad_norm 1.8503 (1.9427)	mem 17417MB
[2023-02-02 07:02:24 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 206 training takes 0:11:52
[2023-02-02 07:02:24 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_206.pth saving......
[2023-02-02 07:02:26 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_206.pth saved !!!
[2023-02-02 07:02:27 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.868 (0.868)	Loss 0.7901 (0.7901)	Acc@1 81.543 (81.543)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-02 07:02:35 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.292 Acc@5 96.342
[2023-02-02 07:02:35 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.3%
[2023-02-02 07:02:36 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.253 (1.253)	Loss 0.7155 (0.7155)	Acc@1 83.008 (83.008)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 07:02:44 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.290 Acc@5 96.696
[2023-02-02 07:02:44 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.3%
[2023-02-02 07:02:44 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.34% at 203 epoch
[2023-02-02 07:02:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][0/1251]	eta 0:39:26 lr 0.000227	time 1.8916 (1.8916)	loss 2.9219 (2.9219)	grad_norm 2.1048 (2.1048)	mem 17417MB
[2023-02-02 07:03:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][50/1251]	eta 0:11:55 lr 0.000227	time 0.5650 (0.5955)	loss 2.2304 (2.9388)	grad_norm 2.0784 (1.9362)	mem 17417MB
[2023-02-02 07:03:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][100/1251]	eta 0:11:12 lr 0.000226	time 0.5579 (0.5841)	loss 3.2725 (2.8547)	grad_norm 1.7988 (1.9304)	mem 17417MB
[2023-02-02 07:04:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][150/1251]	eta 0:10:36 lr 0.000226	time 0.5762 (0.5778)	loss 2.3971 (2.8624)	grad_norm 1.7326 (1.9355)	mem 17417MB
[2023-02-02 07:04:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][200/1251]	eta 0:10:05 lr 0.000226	time 0.5632 (0.5758)	loss 3.3224 (2.8924)	grad_norm 1.7267 (nan)	mem 17417MB
[2023-02-02 07:05:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][250/1251]	eta 0:09:35 lr 0.000226	time 0.5572 (0.5746)	loss 2.4670 (2.8992)	grad_norm 1.8464 (nan)	mem 17417MB
[2023-02-02 07:05:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][300/1251]	eta 0:09:05 lr 0.000226	time 0.5649 (0.5732)	loss 2.9459 (2.9057)	grad_norm 1.9605 (nan)	mem 17417MB
[2023-02-02 07:06:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][350/1251]	eta 0:08:35 lr 0.000226	time 0.5548 (0.5725)	loss 2.4272 (2.8962)	grad_norm 2.1294 (nan)	mem 17417MB
[2023-02-02 07:06:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][400/1251]	eta 0:08:06 lr 0.000225	time 0.5548 (0.5721)	loss 2.3618 (2.9075)	grad_norm 1.8491 (nan)	mem 17417MB
[2023-02-02 07:07:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][450/1251]	eta 0:07:37 lr 0.000225	time 0.5572 (0.5714)	loss 2.8421 (2.9138)	grad_norm 1.9598 (nan)	mem 17417MB
[2023-02-02 07:07:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][500/1251]	eta 0:07:08 lr 0.000225	time 0.5573 (0.5708)	loss 3.2674 (2.9197)	grad_norm 1.9542 (nan)	mem 17417MB
[2023-02-02 07:07:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][550/1251]	eta 0:06:39 lr 0.000225	time 0.5542 (0.5705)	loss 2.9738 (2.9140)	grad_norm 2.1852 (nan)	mem 17417MB
[2023-02-02 07:08:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][600/1251]	eta 0:06:11 lr 0.000225	time 0.5618 (0.5705)	loss 3.3836 (2.9076)	grad_norm 2.2028 (nan)	mem 17417MB
[2023-02-02 07:08:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][650/1251]	eta 0:05:42 lr 0.000225	time 0.5559 (0.5703)	loss 3.0965 (2.9057)	grad_norm 1.8916 (nan)	mem 17417MB
[2023-02-02 07:09:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][700/1251]	eta 0:05:14 lr 0.000224	time 0.5569 (0.5699)	loss 3.4260 (2.8996)	grad_norm 2.1930 (nan)	mem 17417MB
[2023-02-02 07:09:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][750/1251]	eta 0:04:45 lr 0.000224	time 0.5566 (0.5698)	loss 3.3393 (2.8964)	grad_norm 1.9941 (nan)	mem 17417MB
[2023-02-02 07:10:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][800/1251]	eta 0:04:16 lr 0.000224	time 0.5548 (0.5697)	loss 3.2800 (2.9020)	grad_norm 2.4252 (nan)	mem 17417MB
[2023-02-02 07:10:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][850/1251]	eta 0:03:48 lr 0.000224	time 0.5620 (0.5697)	loss 2.9610 (2.9011)	grad_norm 2.0034 (nan)	mem 17417MB
[2023-02-02 07:11:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][900/1251]	eta 0:03:19 lr 0.000224	time 0.5662 (0.5696)	loss 3.0622 (2.8993)	grad_norm 2.1039 (nan)	mem 17417MB
[2023-02-02 07:11:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][950/1251]	eta 0:02:51 lr 0.000224	time 0.5637 (0.5693)	loss 3.3849 (2.9026)	grad_norm 2.3481 (nan)	mem 17417MB
[2023-02-02 07:12:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][1000/1251]	eta 0:02:22 lr 0.000223	time 0.6348 (0.5692)	loss 3.1377 (2.9064)	grad_norm 1.8499 (nan)	mem 17417MB
[2023-02-02 07:12:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][1050/1251]	eta 0:01:54 lr 0.000223	time 0.5549 (0.5693)	loss 3.2136 (2.9069)	grad_norm 1.9218 (nan)	mem 17417MB
[2023-02-02 07:13:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][1100/1251]	eta 0:01:25 lr 0.000223	time 0.5623 (0.5692)	loss 3.5280 (2.9130)	grad_norm 1.9360 (nan)	mem 17417MB
[2023-02-02 07:13:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][1150/1251]	eta 0:00:57 lr 0.000223	time 0.5606 (0.5693)	loss 3.0741 (2.9085)	grad_norm 1.8397 (nan)	mem 17417MB
[2023-02-02 07:14:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][1200/1251]	eta 0:00:29 lr 0.000223	time 0.5546 (0.5692)	loss 2.2814 (2.9103)	grad_norm 2.0128 (nan)	mem 17417MB
[2023-02-02 07:14:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [207/300][1250/1251]	eta 0:00:00 lr 0.000223	time 0.5487 (0.5691)	loss 2.9178 (2.9098)	grad_norm 1.7982 (nan)	mem 17417MB
[2023-02-02 07:14:36 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 207 training takes 0:11:52
[2023-02-02 07:14:36 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_207.pth saving......
[2023-02-02 07:14:38 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_207.pth saved !!!
[2023-02-02 07:14:39 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.937 (0.937)	Loss 0.7770 (0.7770)	Acc@1 81.934 (81.934)	Acc@5 95.898 (95.898)	Mem 17417MB
[2023-02-02 07:14:47 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.296 Acc@5 96.254
[2023-02-02 07:14:47 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.3%
[2023-02-02 07:14:48 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.175 (1.175)	Loss 0.7248 (0.7248)	Acc@1 82.422 (82.422)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-02 07:14:56 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.302 Acc@5 96.700
[2023-02-02 07:14:56 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.3%
[2023-02-02 07:14:56 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.34% at 203 epoch
[2023-02-02 07:14:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][0/1251]	eta 0:36:27 lr 0.000222	time 1.7488 (1.7488)	loss 3.2850 (3.2850)	grad_norm 2.0909 (2.0909)	mem 17417MB
[2023-02-02 07:15:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][50/1251]	eta 0:11:48 lr 0.000222	time 0.5569 (0.5903)	loss 3.3866 (2.8576)	grad_norm 1.7585 (1.9283)	mem 17417MB
[2023-02-02 07:15:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][100/1251]	eta 0:11:08 lr 0.000222	time 0.5596 (0.5806)	loss 3.1040 (2.8746)	grad_norm 2.0565 (1.9552)	mem 17417MB
[2023-02-02 07:16:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][150/1251]	eta 0:10:33 lr 0.000222	time 0.5611 (0.5755)	loss 3.0190 (2.8718)	grad_norm 1.9084 (1.9520)	mem 17417MB
[2023-02-02 07:16:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][200/1251]	eta 0:10:03 lr 0.000222	time 0.5590 (0.5738)	loss 2.1328 (2.8881)	grad_norm 1.7876 (1.9746)	mem 17417MB
[2023-02-02 07:17:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][250/1251]	eta 0:09:33 lr 0.000222	time 0.5568 (0.5728)	loss 3.3226 (2.8751)	grad_norm 1.8490 (1.9622)	mem 17417MB
[2023-02-02 07:17:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][300/1251]	eta 0:09:03 lr 0.000221	time 0.5604 (0.5719)	loss 2.2856 (2.8835)	grad_norm 2.1173 (1.9578)	mem 17417MB
[2023-02-02 07:18:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][350/1251]	eta 0:08:34 lr 0.000221	time 0.5776 (0.5713)	loss 3.1205 (2.8913)	grad_norm 1.9287 (1.9602)	mem 17417MB
[2023-02-02 07:18:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][400/1251]	eta 0:08:05 lr 0.000221	time 0.5560 (0.5708)	loss 2.6710 (2.8815)	grad_norm 1.8588 (1.9546)	mem 17417MB
[2023-02-02 07:19:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][450/1251]	eta 0:07:37 lr 0.000221	time 0.5607 (0.5706)	loss 3.1052 (2.8851)	grad_norm 1.9563 (1.9568)	mem 17417MB
[2023-02-02 07:19:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][500/1251]	eta 0:07:08 lr 0.000221	time 0.5583 (0.5700)	loss 2.9838 (2.8916)	grad_norm 1.8404 (1.9532)	mem 17417MB
[2023-02-02 07:20:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][550/1251]	eta 0:06:39 lr 0.000221	time 0.5583 (0.5702)	loss 3.1556 (2.8872)	grad_norm 1.7330 (1.9589)	mem 17417MB
[2023-02-02 07:20:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][600/1251]	eta 0:06:11 lr 0.000220	time 0.5592 (0.5701)	loss 3.5893 (2.8916)	grad_norm 1.8206 (1.9633)	mem 17417MB
[2023-02-02 07:21:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][650/1251]	eta 0:05:42 lr 0.000220	time 0.5588 (0.5700)	loss 3.4801 (2.8903)	grad_norm 1.7015 (1.9627)	mem 17417MB
[2023-02-02 07:21:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][700/1251]	eta 0:05:13 lr 0.000220	time 0.5549 (0.5697)	loss 3.4329 (2.8918)	grad_norm 1.9754 (1.9617)	mem 17417MB
[2023-02-02 07:22:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][750/1251]	eta 0:04:45 lr 0.000220	time 0.5527 (0.5697)	loss 3.7565 (2.8836)	grad_norm 1.8643 (1.9615)	mem 17417MB
[2023-02-02 07:22:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][800/1251]	eta 0:04:16 lr 0.000220	time 0.5620 (0.5696)	loss 2.4692 (2.8845)	grad_norm 2.0255 (1.9625)	mem 17417MB
[2023-02-02 07:23:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][850/1251]	eta 0:03:48 lr 0.000220	time 0.5596 (0.5695)	loss 2.9370 (2.8804)	grad_norm 2.0355 (1.9615)	mem 17417MB
[2023-02-02 07:23:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][900/1251]	eta 0:03:19 lr 0.000219	time 0.5612 (0.5694)	loss 3.0630 (2.8771)	grad_norm 1.8620 (1.9595)	mem 17417MB
[2023-02-02 07:23:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][950/1251]	eta 0:02:51 lr 0.000219	time 0.5590 (0.5693)	loss 3.0154 (2.8791)	grad_norm 1.8541 (1.9622)	mem 17417MB
[2023-02-02 07:24:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][1000/1251]	eta 0:02:22 lr 0.000219	time 0.5539 (0.5693)	loss 3.1862 (2.8789)	grad_norm 1.9734 (1.9647)	mem 17417MB
[2023-02-02 07:24:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][1050/1251]	eta 0:01:54 lr 0.000219	time 0.5578 (0.5693)	loss 3.0137 (2.8795)	grad_norm 1.8135 (1.9661)	mem 17417MB
[2023-02-02 07:25:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][1100/1251]	eta 0:01:25 lr 0.000219	time 0.6284 (0.5692)	loss 2.1980 (2.8800)	grad_norm 2.3312 (1.9652)	mem 17417MB
[2023-02-02 07:25:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][1150/1251]	eta 0:00:57 lr 0.000219	time 0.5543 (0.5694)	loss 2.4664 (2.8802)	grad_norm 1.8383 (1.9655)	mem 17417MB
[2023-02-02 07:26:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][1200/1251]	eta 0:00:29 lr 0.000218	time 0.6190 (0.5693)	loss 2.8176 (2.8819)	grad_norm 2.0005 (1.9663)	mem 17417MB
[2023-02-02 07:26:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [208/300][1250/1251]	eta 0:00:00 lr 0.000218	time 0.6120 (0.5692)	loss 2.5613 (2.8853)	grad_norm 1.8425 (1.9682)	mem 17417MB
[2023-02-02 07:26:49 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 208 training takes 0:11:52
[2023-02-02 07:26:49 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_208.pth saving......
[2023-02-02 07:26:50 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_208.pth saved !!!
[2023-02-02 07:26:51 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.880 (0.880)	Loss 0.7568 (0.7568)	Acc@1 82.227 (82.227)	Acc@5 97.363 (97.363)	Mem 17417MB
[2023-02-02 07:26:59 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.228 Acc@5 96.258
[2023-02-02 07:26:59 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.2%
[2023-02-02 07:27:01 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.413 (1.413)	Loss 0.6422 (0.6422)	Acc@1 84.766 (84.766)	Acc@5 97.656 (97.656)	Mem 17417MB
[2023-02-02 07:27:09 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.310 Acc@5 96.708
[2023-02-02 07:27:09 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.3%
[2023-02-02 07:27:09 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.34% at 203 epoch
[2023-02-02 07:27:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][0/1251]	eta 0:36:43 lr 0.000218	time 1.7611 (1.7611)	loss 3.0070 (3.0070)	grad_norm 1.8966 (1.8966)	mem 17417MB
[2023-02-02 07:27:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][50/1251]	eta 0:11:51 lr 0.000218	time 0.5566 (0.5921)	loss 3.2358 (2.9170)	grad_norm 1.6644 (1.9697)	mem 17417MB
[2023-02-02 07:28:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][100/1251]	eta 0:11:07 lr 0.000218	time 0.5521 (0.5799)	loss 2.3190 (2.9341)	grad_norm 1.7594 (1.9444)	mem 17417MB
[2023-02-02 07:28:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][150/1251]	eta 0:10:33 lr 0.000218	time 0.5571 (0.5757)	loss 3.2460 (2.9296)	grad_norm 1.8069 (1.9454)	mem 17417MB
[2023-02-02 07:29:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][200/1251]	eta 0:10:02 lr 0.000218	time 0.5537 (0.5735)	loss 2.3542 (2.9182)	grad_norm 2.1796 (1.9394)	mem 17417MB
[2023-02-02 07:29:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][250/1251]	eta 0:09:32 lr 0.000217	time 0.5617 (0.5723)	loss 2.9124 (2.8949)	grad_norm 1.9543 (1.9437)	mem 17417MB
[2023-02-02 07:30:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][300/1251]	eta 0:09:03 lr 0.000217	time 0.5508 (0.5716)	loss 3.0466 (2.9012)	grad_norm 2.0981 (1.9417)	mem 17417MB
[2023-02-02 07:30:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][350/1251]	eta 0:08:34 lr 0.000217	time 0.5542 (0.5708)	loss 3.3345 (2.8974)	grad_norm 1.8555 (1.9482)	mem 17417MB
[2023-02-02 07:30:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][400/1251]	eta 0:08:05 lr 0.000217	time 0.5562 (0.5703)	loss 3.0936 (2.8875)	grad_norm 1.9601 (1.9499)	mem 17417MB
[2023-02-02 07:31:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][450/1251]	eta 0:07:36 lr 0.000217	time 0.5595 (0.5701)	loss 3.1945 (2.8950)	grad_norm 2.0147 (1.9644)	mem 17417MB
[2023-02-02 07:31:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][500/1251]	eta 0:07:07 lr 0.000217	time 0.5543 (0.5695)	loss 3.4055 (2.8944)	grad_norm 1.8782 (1.9628)	mem 17417MB
[2023-02-02 07:32:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][550/1251]	eta 0:06:39 lr 0.000216	time 0.5563 (0.5695)	loss 2.8825 (2.8897)	grad_norm 2.1686 (1.9655)	mem 17417MB
[2023-02-02 07:32:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][600/1251]	eta 0:06:10 lr 0.000216	time 0.5618 (0.5695)	loss 1.9396 (2.8824)	grad_norm 2.1587 (1.9677)	mem 17417MB
[2023-02-02 07:33:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][650/1251]	eta 0:05:42 lr 0.000216	time 0.5529 (0.5694)	loss 3.2762 (2.8886)	grad_norm 2.1213 (1.9675)	mem 17417MB
[2023-02-02 07:33:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][700/1251]	eta 0:05:13 lr 0.000216	time 0.5554 (0.5691)	loss 2.6174 (2.8872)	grad_norm 2.0504 (1.9684)	mem 17417MB
[2023-02-02 07:34:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][750/1251]	eta 0:04:45 lr 0.000216	time 0.5624 (0.5691)	loss 2.5839 (2.8915)	grad_norm 1.8414 (1.9685)	mem 17417MB
[2023-02-02 07:34:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][800/1251]	eta 0:04:16 lr 0.000216	time 0.5556 (0.5691)	loss 2.7624 (2.8936)	grad_norm 1.7937 (1.9688)	mem 17417MB
[2023-02-02 07:35:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][850/1251]	eta 0:03:48 lr 0.000215	time 0.5569 (0.5689)	loss 2.0732 (2.8954)	grad_norm 1.8588 (1.9703)	mem 17417MB
[2023-02-02 07:35:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][900/1251]	eta 0:03:19 lr 0.000215	time 0.5608 (0.5687)	loss 3.9082 (2.8936)	grad_norm 2.2546 (1.9750)	mem 17417MB
[2023-02-02 07:36:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][950/1251]	eta 0:02:51 lr 0.000215	time 0.5777 (0.5685)	loss 2.9504 (2.8987)	grad_norm 2.1203 (1.9748)	mem 17417MB
[2023-02-02 07:36:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][1000/1251]	eta 0:02:22 lr 0.000215	time 0.5564 (0.5685)	loss 3.5039 (2.9046)	grad_norm 2.0938 (1.9746)	mem 17417MB
[2023-02-02 07:37:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][1050/1251]	eta 0:01:54 lr 0.000215	time 0.5594 (0.5686)	loss 3.1298 (2.9070)	grad_norm 1.9545 (1.9748)	mem 17417MB
[2023-02-02 07:37:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][1100/1251]	eta 0:01:25 lr 0.000215	time 0.6302 (0.5686)	loss 2.4932 (2.9083)	grad_norm 2.0945 (1.9735)	mem 17417MB
[2023-02-02 07:38:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][1150/1251]	eta 0:00:57 lr 0.000214	time 0.5937 (0.5685)	loss 2.6153 (2.9056)	grad_norm 2.1162 (1.9743)	mem 17417MB
[2023-02-02 07:38:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][1200/1251]	eta 0:00:28 lr 0.000214	time 0.5512 (0.5684)	loss 2.9010 (2.9067)	grad_norm 2.0963 (1.9751)	mem 17417MB
[2023-02-02 07:39:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [209/300][1250/1251]	eta 0:00:00 lr 0.000214	time 0.6376 (0.5684)	loss 2.5034 (2.9033)	grad_norm 1.7086 (1.9746)	mem 17417MB
[2023-02-02 07:39:00 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 209 training takes 0:11:51
[2023-02-02 07:39:00 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_209.pth saving......
[2023-02-02 07:39:02 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_209.pth saved !!!
[2023-02-02 07:39:03 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.849 (0.849)	Loss 0.6598 (0.6598)	Acc@1 84.082 (84.082)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-02 07:39:11 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.242 Acc@5 96.214
[2023-02-02 07:39:11 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.2%
[2023-02-02 07:39:12 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.270 (1.270)	Loss 0.7093 (0.7093)	Acc@1 84.180 (84.180)	Acc@5 95.996 (95.996)	Mem 17417MB
[2023-02-02 07:39:20 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.296 Acc@5 96.700
[2023-02-02 07:39:20 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.3%
[2023-02-02 07:39:20 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.34% at 203 epoch
[2023-02-02 07:39:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][0/1251]	eta 0:34:41 lr 0.000214	time 1.6637 (1.6637)	loss 3.2663 (3.2663)	grad_norm 1.8099 (1.8099)	mem 17417MB
[2023-02-02 07:39:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][50/1251]	eta 0:11:51 lr 0.000214	time 0.6333 (0.5924)	loss 2.8146 (2.8436)	grad_norm 1.9752 (1.9434)	mem 17417MB
[2023-02-02 07:40:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][100/1251]	eta 0:11:07 lr 0.000214	time 0.5576 (0.5798)	loss 1.9948 (2.8145)	grad_norm 2.0136 (inf)	mem 17417MB
[2023-02-02 07:40:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][150/1251]	eta 0:10:32 lr 0.000214	time 0.5575 (0.5747)	loss 2.9253 (2.8133)	grad_norm 2.5078 (inf)	mem 17417MB
[2023-02-02 07:41:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][200/1251]	eta 0:10:02 lr 0.000213	time 0.5550 (0.5733)	loss 3.1585 (2.8478)	grad_norm 2.2370 (inf)	mem 17417MB
[2023-02-02 07:41:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][250/1251]	eta 0:09:32 lr 0.000213	time 0.6480 (0.5724)	loss 3.0588 (2.8804)	grad_norm 1.9170 (inf)	mem 17417MB
[2023-02-02 07:42:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][300/1251]	eta 0:09:03 lr 0.000213	time 0.5588 (0.5714)	loss 3.2631 (2.8780)	grad_norm 2.0130 (inf)	mem 17417MB
[2023-02-02 07:42:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][350/1251]	eta 0:08:34 lr 0.000213	time 0.5519 (0.5708)	loss 3.0879 (2.8951)	grad_norm 1.9357 (inf)	mem 17417MB
[2023-02-02 07:43:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][400/1251]	eta 0:08:05 lr 0.000213	time 0.5536 (0.5703)	loss 3.3863 (2.9010)	grad_norm 1.7225 (inf)	mem 17417MB
[2023-02-02 07:43:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][450/1251]	eta 0:07:36 lr 0.000213	time 0.5547 (0.5701)	loss 2.6891 (2.8872)	grad_norm 1.8177 (inf)	mem 17417MB
[2023-02-02 07:44:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][500/1251]	eta 0:07:08 lr 0.000212	time 0.5509 (0.5699)	loss 3.3227 (2.8797)	grad_norm 1.8606 (inf)	mem 17417MB
[2023-02-02 07:44:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][550/1251]	eta 0:06:39 lr 0.000212	time 0.5554 (0.5696)	loss 2.6501 (2.8863)	grad_norm 2.1430 (inf)	mem 17417MB
[2023-02-02 07:45:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][600/1251]	eta 0:06:10 lr 0.000212	time 0.5533 (0.5696)	loss 2.9626 (2.8869)	grad_norm 1.9493 (inf)	mem 17417MB
[2023-02-02 07:45:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][650/1251]	eta 0:05:42 lr 0.000212	time 0.6173 (0.5695)	loss 2.2674 (2.8941)	grad_norm 2.2038 (inf)	mem 17417MB
[2023-02-02 07:45:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][700/1251]	eta 0:05:13 lr 0.000212	time 0.5632 (0.5693)	loss 3.4700 (2.8969)	grad_norm 1.8870 (inf)	mem 17417MB
[2023-02-02 07:46:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][750/1251]	eta 0:04:45 lr 0.000212	time 0.5485 (0.5692)	loss 3.3769 (2.8956)	grad_norm 2.1743 (inf)	mem 17417MB
[2023-02-02 07:46:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][800/1251]	eta 0:04:16 lr 0.000211	time 0.5584 (0.5693)	loss 2.6271 (2.8914)	grad_norm 1.9733 (inf)	mem 17417MB
[2023-02-02 07:47:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][850/1251]	eta 0:03:48 lr 0.000211	time 0.5558 (0.5694)	loss 2.8648 (2.8946)	grad_norm 1.9167 (inf)	mem 17417MB
[2023-02-02 07:47:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][900/1251]	eta 0:03:19 lr 0.000211	time 0.5652 (0.5692)	loss 3.3381 (2.8976)	grad_norm 1.9706 (inf)	mem 17417MB
[2023-02-02 07:48:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][950/1251]	eta 0:02:51 lr 0.000211	time 0.5640 (0.5691)	loss 2.7384 (2.8928)	grad_norm 2.1230 (inf)	mem 17417MB
[2023-02-02 07:48:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][1000/1251]	eta 0:02:22 lr 0.000211	time 0.5550 (0.5690)	loss 2.9141 (2.8932)	grad_norm 2.4389 (inf)	mem 17417MB
[2023-02-02 07:49:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][1050/1251]	eta 0:01:54 lr 0.000211	time 0.6276 (0.5691)	loss 3.1225 (2.8948)	grad_norm 1.9658 (inf)	mem 17417MB
[2023-02-02 07:49:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][1100/1251]	eta 0:01:25 lr 0.000210	time 0.6423 (0.5690)	loss 3.2197 (2.8915)	grad_norm 2.0132 (inf)	mem 17417MB
[2023-02-02 07:50:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][1150/1251]	eta 0:00:57 lr 0.000210	time 0.6273 (0.5690)	loss 3.0139 (2.8940)	grad_norm 2.3565 (inf)	mem 17417MB
[2023-02-02 07:50:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][1200/1251]	eta 0:00:29 lr 0.000210	time 0.5560 (0.5688)	loss 2.7273 (2.8915)	grad_norm 1.7520 (inf)	mem 17417MB
[2023-02-02 07:51:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [210/300][1250/1251]	eta 0:00:00 lr 0.000210	time 0.5508 (0.5687)	loss 3.1289 (2.8869)	grad_norm 1.9464 (inf)	mem 17417MB
[2023-02-02 07:51:12 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 210 training takes 0:11:51
[2023-02-02 07:51:12 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_210.pth saving......
[2023-02-02 07:51:14 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_210.pth saved !!!
[2023-02-02 07:51:14 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.844 (0.844)	Loss 0.7010 (0.7010)	Acc@1 83.984 (83.984)	Acc@5 95.996 (95.996)	Mem 17417MB
[2023-02-02 07:51:22 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.296 Acc@5 96.208
[2023-02-02 07:51:22 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.3%
[2023-02-02 07:51:24 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.267 (1.267)	Loss 0.6917 (0.6917)	Acc@1 83.887 (83.887)	Acc@5 96.875 (96.875)	Mem 17417MB
[2023-02-02 07:51:32 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.328 Acc@5 96.700
[2023-02-02 07:51:32 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.3%
[2023-02-02 07:51:32 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.34% at 203 epoch
[2023-02-02 07:51:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][0/1251]	eta 0:35:36 lr 0.000210	time 1.7075 (1.7075)	loss 2.8056 (2.8056)	grad_norm 2.0653 (2.0653)	mem 17417MB
[2023-02-02 07:52:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][50/1251]	eta 0:11:56 lr 0.000210	time 0.6627 (0.5965)	loss 2.8725 (2.8100)	grad_norm 2.0234 (1.9639)	mem 17417MB
[2023-02-02 07:52:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][100/1251]	eta 0:11:11 lr 0.000210	time 0.5541 (0.5836)	loss 1.9654 (2.8009)	grad_norm 1.9139 (1.9911)	mem 17417MB
[2023-02-02 07:52:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][150/1251]	eta 0:10:36 lr 0.000209	time 0.5551 (0.5782)	loss 3.2538 (2.8192)	grad_norm 2.0928 (1.9719)	mem 17417MB
[2023-02-02 07:53:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][200/1251]	eta 0:10:05 lr 0.000209	time 0.5702 (0.5758)	loss 2.4982 (2.7974)	grad_norm 1.6994 (1.9673)	mem 17417MB
[2023-02-02 07:53:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][250/1251]	eta 0:09:35 lr 0.000209	time 0.5552 (0.5746)	loss 3.1354 (2.8272)	grad_norm 1.8034 (1.9719)	mem 17417MB
[2023-02-02 07:54:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][300/1251]	eta 0:09:05 lr 0.000209	time 0.5569 (0.5736)	loss 3.2498 (2.8381)	grad_norm 1.8236 (1.9717)	mem 17417MB
[2023-02-02 07:54:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][350/1251]	eta 0:08:36 lr 0.000209	time 0.5581 (0.5732)	loss 3.0792 (2.8455)	grad_norm 1.9100 (1.9724)	mem 17417MB
[2023-02-02 07:55:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][400/1251]	eta 0:08:07 lr 0.000209	time 0.5543 (0.5724)	loss 3.2251 (2.8380)	grad_norm 1.8953 (1.9781)	mem 17417MB
[2023-02-02 07:55:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][450/1251]	eta 0:07:38 lr 0.000208	time 0.5578 (0.5723)	loss 2.2066 (2.8522)	grad_norm 2.0132 (1.9860)	mem 17417MB
[2023-02-02 07:56:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][500/1251]	eta 0:07:09 lr 0.000208	time 0.5587 (0.5717)	loss 2.8719 (2.8412)	grad_norm 2.0537 (1.9836)	mem 17417MB
[2023-02-02 07:56:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][550/1251]	eta 0:06:40 lr 0.000208	time 0.5663 (0.5713)	loss 2.3574 (2.8531)	grad_norm 2.0334 (1.9857)	mem 17417MB
[2023-02-02 07:57:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][600/1251]	eta 0:06:11 lr 0.000208	time 0.5525 (0.5712)	loss 2.5826 (2.8516)	grad_norm 2.3393 (1.9916)	mem 17417MB
[2023-02-02 07:57:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][650/1251]	eta 0:05:43 lr 0.000208	time 0.5557 (0.5712)	loss 3.1534 (2.8577)	grad_norm 2.0411 (1.9927)	mem 17417MB
[2023-02-02 07:58:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][700/1251]	eta 0:05:14 lr 0.000208	time 0.5589 (0.5710)	loss 2.7293 (2.8564)	grad_norm 1.9817 (1.9924)	mem 17417MB
[2023-02-02 07:58:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][750/1251]	eta 0:04:45 lr 0.000207	time 0.5598 (0.5708)	loss 2.9608 (2.8636)	grad_norm 1.8806 (1.9912)	mem 17417MB
[2023-02-02 07:59:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][800/1251]	eta 0:04:17 lr 0.000207	time 0.5636 (0.5707)	loss 2.2848 (2.8623)	grad_norm 1.7836 (1.9956)	mem 17417MB
[2023-02-02 07:59:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][850/1251]	eta 0:03:48 lr 0.000207	time 0.6172 (0.5707)	loss 3.2126 (2.8683)	grad_norm 1.8943 (1.9964)	mem 17417MB
[2023-02-02 08:00:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][900/1251]	eta 0:03:20 lr 0.000207	time 0.5530 (0.5707)	loss 2.0674 (2.8656)	grad_norm 2.0442 (1.9978)	mem 17417MB
[2023-02-02 08:00:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][950/1251]	eta 0:02:51 lr 0.000207	time 0.5509 (0.5706)	loss 2.7894 (2.8619)	grad_norm 1.8043 (1.9964)	mem 17417MB
[2023-02-02 08:01:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][1000/1251]	eta 0:02:23 lr 0.000207	time 0.5640 (0.5706)	loss 2.9622 (2.8665)	grad_norm 1.9202 (1.9985)	mem 17417MB
[2023-02-02 08:01:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][1050/1251]	eta 0:01:54 lr 0.000206	time 0.5678 (0.5705)	loss 2.9750 (2.8674)	grad_norm 1.9880 (1.9964)	mem 17417MB
[2023-02-02 08:02:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][1100/1251]	eta 0:01:26 lr 0.000206	time 0.5593 (0.5705)	loss 2.9952 (2.8652)	grad_norm 1.9880 (1.9969)	mem 17417MB
[2023-02-02 08:02:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][1150/1251]	eta 0:00:57 lr 0.000206	time 0.5561 (0.5704)	loss 2.3269 (2.8649)	grad_norm 1.8951 (1.9946)	mem 17417MB
[2023-02-02 08:02:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][1200/1251]	eta 0:00:29 lr 0.000206	time 0.5520 (0.5705)	loss 1.7753 (2.8629)	grad_norm 1.8897 (1.9947)	mem 17417MB
[2023-02-02 08:03:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [211/300][1250/1251]	eta 0:00:00 lr 0.000206	time 0.5498 (0.5704)	loss 3.3735 (2.8659)	grad_norm 1.8637 (nan)	mem 17417MB
[2023-02-02 08:03:25 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 211 training takes 0:11:53
[2023-02-02 08:03:25 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_211.pth saving......
[2023-02-02 08:03:27 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_211.pth saved !!!
[2023-02-02 08:03:28 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.935 (0.935)	Loss 0.7372 (0.7372)	Acc@1 83.594 (83.594)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-02 08:03:36 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.268 Acc@5 96.324
[2023-02-02 08:03:36 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.3%
[2023-02-02 08:03:37 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.207 (1.207)	Loss 0.8046 (0.8046)	Acc@1 81.641 (81.641)	Acc@5 95.703 (95.703)	Mem 17417MB
[2023-02-02 08:03:45 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.336 Acc@5 96.714
[2023-02-02 08:03:45 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.3%
[2023-02-02 08:03:45 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.34% at 203 epoch
[2023-02-02 08:03:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][0/1251]	eta 0:36:51 lr 0.000206	time 1.7679 (1.7679)	loss 1.8765 (1.8765)	grad_norm 1.7887 (1.7887)	mem 17417MB
[2023-02-02 08:04:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][50/1251]	eta 0:11:54 lr 0.000206	time 0.5589 (0.5948)	loss 2.8682 (2.7777)	grad_norm 1.8743 (2.0108)	mem 17417MB
[2023-02-02 08:04:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][100/1251]	eta 0:11:09 lr 0.000205	time 0.6281 (0.5819)	loss 1.7963 (2.8297)	grad_norm 2.2370 (2.0143)	mem 17417MB
[2023-02-02 08:05:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][150/1251]	eta 0:10:35 lr 0.000205	time 0.5739 (0.5774)	loss 2.9036 (2.8582)	grad_norm 1.8265 (2.0258)	mem 17417MB
[2023-02-02 08:05:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][200/1251]	eta 0:10:04 lr 0.000205	time 0.5547 (0.5747)	loss 3.0916 (2.8816)	grad_norm 2.2078 (2.0089)	mem 17417MB
[2023-02-02 08:06:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][250/1251]	eta 0:09:34 lr 0.000205	time 0.5555 (0.5735)	loss 3.1923 (2.8721)	grad_norm 1.8543 (2.0231)	mem 17417MB
[2023-02-02 08:06:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][300/1251]	eta 0:09:04 lr 0.000205	time 0.5503 (0.5730)	loss 2.2287 (2.8580)	grad_norm 2.1392 (2.0231)	mem 17417MB
[2023-02-02 08:07:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][350/1251]	eta 0:08:35 lr 0.000205	time 0.5555 (0.5723)	loss 3.0722 (2.8443)	grad_norm 1.8461 (2.0134)	mem 17417MB
[2023-02-02 08:07:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][400/1251]	eta 0:08:06 lr 0.000204	time 0.5512 (0.5720)	loss 3.1500 (2.8423)	grad_norm 2.0063 (2.0126)	mem 17417MB
[2023-02-02 08:08:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][450/1251]	eta 0:07:37 lr 0.000204	time 0.5532 (0.5718)	loss 3.4945 (2.8432)	grad_norm 1.7972 (2.0103)	mem 17417MB
[2023-02-02 08:08:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][500/1251]	eta 0:07:09 lr 0.000204	time 0.6310 (0.5713)	loss 3.2579 (2.8398)	grad_norm 2.1521 (2.0110)	mem 17417MB
[2023-02-02 08:09:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][550/1251]	eta 0:06:40 lr 0.000204	time 0.5566 (0.5711)	loss 2.7866 (2.8445)	grad_norm 2.2357 (2.0125)	mem 17417MB
[2023-02-02 08:09:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][600/1251]	eta 0:06:11 lr 0.000204	time 0.5651 (0.5711)	loss 2.8597 (2.8479)	grad_norm 2.1539 (2.0077)	mem 17417MB
[2023-02-02 08:09:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][650/1251]	eta 0:05:43 lr 0.000204	time 0.5567 (0.5710)	loss 3.0335 (2.8513)	grad_norm 1.7930 (2.0115)	mem 17417MB
[2023-02-02 08:10:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][700/1251]	eta 0:05:14 lr 0.000203	time 0.5637 (0.5710)	loss 2.5339 (2.8522)	grad_norm 2.3211 (2.0139)	mem 17417MB
[2023-02-02 08:10:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][750/1251]	eta 0:04:46 lr 0.000203	time 0.5519 (0.5709)	loss 3.2305 (2.8532)	grad_norm 2.1754 (2.0141)	mem 17417MB
[2023-02-02 08:11:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][800/1251]	eta 0:04:17 lr 0.000203	time 0.5542 (0.5707)	loss 2.6532 (2.8553)	grad_norm 2.1385 (2.0163)	mem 17417MB
[2023-02-02 08:11:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][850/1251]	eta 0:03:48 lr 0.000203	time 0.5587 (0.5706)	loss 2.9161 (2.8539)	grad_norm 2.0014 (2.0156)	mem 17417MB
[2023-02-02 08:12:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][900/1251]	eta 0:03:20 lr 0.000203	time 0.6197 (0.5706)	loss 3.2198 (2.8556)	grad_norm 2.0669 (2.0181)	mem 17417MB
[2023-02-02 08:12:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][950/1251]	eta 0:02:51 lr 0.000203	time 0.5546 (0.5706)	loss 2.1504 (2.8567)	grad_norm 1.7462 (2.0152)	mem 17417MB
[2023-02-02 08:13:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][1000/1251]	eta 0:02:23 lr 0.000202	time 0.5533 (0.5703)	loss 3.3500 (2.8566)	grad_norm 2.0858 (2.0164)	mem 17417MB
[2023-02-02 08:13:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][1050/1251]	eta 0:01:54 lr 0.000202	time 0.5543 (0.5703)	loss 2.7040 (2.8550)	grad_norm 1.9577 (2.0158)	mem 17417MB
[2023-02-02 08:14:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][1100/1251]	eta 0:01:26 lr 0.000202	time 0.5519 (0.5703)	loss 2.6774 (2.8553)	grad_norm 1.8682 (2.0140)	mem 17417MB
[2023-02-02 08:14:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][1150/1251]	eta 0:00:57 lr 0.000202	time 0.5552 (0.5701)	loss 3.3640 (2.8552)	grad_norm 2.1632 (2.0155)	mem 17417MB
[2023-02-02 08:15:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][1200/1251]	eta 0:00:29 lr 0.000202	time 0.5596 (0.5702)	loss 2.4181 (2.8571)	grad_norm 1.9643 (2.0150)	mem 17417MB
[2023-02-02 08:15:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [212/300][1250/1251]	eta 0:00:00 lr 0.000202	time 0.5512 (0.5702)	loss 2.7615 (2.8562)	grad_norm 1.9523 (2.0130)	mem 17417MB
[2023-02-02 08:15:39 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 212 training takes 0:11:53
[2023-02-02 08:15:39 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_212.pth saving......
[2023-02-02 08:15:41 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_212.pth saved !!!
[2023-02-02 08:15:42 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.001 (1.001)	Loss 0.7338 (0.7338)	Acc@1 81.738 (81.738)	Acc@5 95.996 (95.996)	Mem 17417MB
[2023-02-02 08:15:50 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.242 Acc@5 96.278
[2023-02-02 08:15:50 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.2%
[2023-02-02 08:15:51 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.282 (1.282)	Loss 0.7096 (0.7096)	Acc@1 83.301 (83.301)	Acc@5 97.168 (97.168)	Mem 17417MB
[2023-02-02 08:15:59 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.370 Acc@5 96.732
[2023-02-02 08:15:59 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.4%
[2023-02-02 08:15:59 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.37% at 212 epoch
[2023-02-02 08:16:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][0/1251]	eta 0:34:41 lr 0.000202	time 1.6643 (1.6643)	loss 3.4941 (3.4941)	grad_norm 2.0427 (2.0427)	mem 17417MB
[2023-02-02 08:16:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][50/1251]	eta 0:11:52 lr 0.000201	time 0.5504 (0.5934)	loss 2.5943 (2.8196)	grad_norm 1.8234 (1.9655)	mem 17417MB
[2023-02-02 08:16:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][100/1251]	eta 0:11:10 lr 0.000201	time 0.5505 (0.5828)	loss 3.4718 (2.8083)	grad_norm 1.8571 (1.9703)	mem 17417MB
[2023-02-02 08:17:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][150/1251]	eta 0:10:36 lr 0.000201	time 0.5556 (0.5779)	loss 2.7020 (2.8382)	grad_norm 2.0709 (1.9655)	mem 17417MB
[2023-02-02 08:17:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][200/1251]	eta 0:10:05 lr 0.000201	time 0.5592 (0.5758)	loss 3.1448 (2.8508)	grad_norm 2.3940 (1.9774)	mem 17417MB
[2023-02-02 08:18:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][250/1251]	eta 0:09:34 lr 0.000201	time 0.5506 (0.5736)	loss 2.8374 (2.8488)	grad_norm 2.5393 (2.0036)	mem 17417MB
[2023-02-02 08:18:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][300/1251]	eta 0:09:05 lr 0.000201	time 0.5576 (0.5733)	loss 2.9629 (2.8678)	grad_norm 2.0437 (2.0086)	mem 17417MB
[2023-02-02 08:19:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][350/1251]	eta 0:08:35 lr 0.000200	time 0.5545 (0.5724)	loss 2.7612 (2.8580)	grad_norm 2.1208 (2.0077)	mem 17417MB
[2023-02-02 08:19:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][400/1251]	eta 0:08:06 lr 0.000200	time 0.5560 (0.5722)	loss 2.4249 (2.8603)	grad_norm 2.0165 (2.0178)	mem 17417MB
[2023-02-02 08:20:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][450/1251]	eta 0:07:38 lr 0.000200	time 0.6241 (0.5721)	loss 2.2884 (2.8560)	grad_norm 2.0460 (2.0146)	mem 17417MB
[2023-02-02 08:20:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][500/1251]	eta 0:07:08 lr 0.000200	time 0.5531 (0.5710)	loss 2.4251 (2.8415)	grad_norm 2.0085 (2.0113)	mem 17417MB
[2023-02-02 08:21:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][550/1251]	eta 0:06:40 lr 0.000200	time 0.5501 (0.5709)	loss 3.5357 (2.8423)	grad_norm 2.2281 (2.0127)	mem 17417MB
[2023-02-02 08:21:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][600/1251]	eta 0:06:11 lr 0.000200	time 0.5520 (0.5708)	loss 2.8449 (2.8528)	grad_norm 1.9281 (2.0106)	mem 17417MB
[2023-02-02 08:22:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][650/1251]	eta 0:05:42 lr 0.000199	time 0.5475 (0.5705)	loss 2.8893 (2.8583)	grad_norm 2.0086 (2.0084)	mem 17417MB
[2023-02-02 08:22:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][700/1251]	eta 0:05:14 lr 0.000199	time 0.5588 (0.5705)	loss 2.1976 (2.8597)	grad_norm 1.9239 (2.0110)	mem 17417MB
[2023-02-02 08:23:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][750/1251]	eta 0:04:45 lr 0.000199	time 0.5541 (0.5700)	loss 3.3601 (2.8530)	grad_norm 1.9959 (2.0097)	mem 17417MB
[2023-02-02 08:23:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][800/1251]	eta 0:04:17 lr 0.000199	time 0.5557 (0.5699)	loss 3.5045 (2.8550)	grad_norm 2.2270 (2.0128)	mem 17417MB
[2023-02-02 08:24:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][850/1251]	eta 0:03:48 lr 0.000199	time 0.5583 (0.5698)	loss 2.5392 (2.8580)	grad_norm 2.1468 (2.0148)	mem 17417MB
[2023-02-02 08:24:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][900/1251]	eta 0:03:19 lr 0.000199	time 0.5576 (0.5696)	loss 3.2866 (2.8558)	grad_norm 1.8762 (2.0132)	mem 17417MB
[2023-02-02 08:25:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][950/1251]	eta 0:02:51 lr 0.000199	time 0.5607 (0.5697)	loss 3.0622 (2.8589)	grad_norm 2.3872 (2.0162)	mem 17417MB
[2023-02-02 08:25:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][1000/1251]	eta 0:02:22 lr 0.000198	time 0.5625 (0.5694)	loss 2.7322 (2.8563)	grad_norm 2.2005 (2.0151)	mem 17417MB
[2023-02-02 08:25:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][1050/1251]	eta 0:01:54 lr 0.000198	time 0.5810 (0.5696)	loss 2.9651 (2.8601)	grad_norm 1.8613 (2.0151)	mem 17417MB
[2023-02-02 08:26:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][1100/1251]	eta 0:01:26 lr 0.000198	time 0.6229 (0.5696)	loss 3.3276 (2.8658)	grad_norm 2.0459 (2.0133)	mem 17417MB
[2023-02-02 08:26:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][1150/1251]	eta 0:00:57 lr 0.000198	time 0.5579 (0.5695)	loss 2.4183 (2.8633)	grad_norm 1.8384 (2.0156)	mem 17417MB
[2023-02-02 08:27:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][1200/1251]	eta 0:00:29 lr 0.000198	time 0.5666 (0.5696)	loss 3.7233 (2.8632)	grad_norm 2.0014 (2.0130)	mem 17417MB
[2023-02-02 08:27:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [213/300][1250/1251]	eta 0:00:00 lr 0.000198	time 0.5511 (0.5696)	loss 2.3507 (2.8700)	grad_norm 2.1027 (2.0142)	mem 17417MB
[2023-02-02 08:27:51 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 213 training takes 0:11:52
[2023-02-02 08:27:52 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_213.pth saving......
[2023-02-02 08:27:53 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_213.pth saved !!!
[2023-02-02 08:27:54 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.958 (0.958)	Loss 0.7112 (0.7112)	Acc@1 83.789 (83.789)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-02 08:28:02 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.412 Acc@5 96.304
[2023-02-02 08:28:02 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.4%
[2023-02-02 08:28:04 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.482 (1.482)	Loss 0.7093 (0.7093)	Acc@1 83.887 (83.887)	Acc@5 96.875 (96.875)	Mem 17417MB
[2023-02-02 08:28:12 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.346 Acc@5 96.732
[2023-02-02 08:28:12 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.3%
[2023-02-02 08:28:12 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.37% at 212 epoch
[2023-02-02 08:28:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][0/1251]	eta 0:34:50 lr 0.000198	time 1.6713 (1.6713)	loss 3.6376 (3.6376)	grad_norm 2.1275 (2.1275)	mem 17417MB
[2023-02-02 08:28:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][50/1251]	eta 0:11:51 lr 0.000197	time 0.5573 (0.5923)	loss 2.9347 (2.9120)	grad_norm 1.9623 (1.9842)	mem 17417MB
[2023-02-02 08:29:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][100/1251]	eta 0:11:11 lr 0.000197	time 0.5556 (0.5833)	loss 3.6894 (2.8987)	grad_norm 2.1310 (2.0052)	mem 17417MB
[2023-02-02 08:29:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][150/1251]	eta 0:10:35 lr 0.000197	time 0.5572 (0.5770)	loss 3.3261 (2.8907)	grad_norm 1.8931 (2.0053)	mem 17417MB
[2023-02-02 08:30:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][200/1251]	eta 0:10:05 lr 0.000197	time 0.5512 (0.5762)	loss 2.8672 (2.8884)	grad_norm 1.8224 (2.0125)	mem 17417MB
[2023-02-02 08:30:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][250/1251]	eta 0:09:34 lr 0.000197	time 0.5550 (0.5743)	loss 2.1978 (2.9028)	grad_norm 1.9257 (2.0056)	mem 17417MB
[2023-02-02 08:31:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][300/1251]	eta 0:09:05 lr 0.000197	time 0.5622 (0.5736)	loss 3.3670 (2.9122)	grad_norm 1.7796 (2.0115)	mem 17417MB
[2023-02-02 08:31:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][350/1251]	eta 0:08:35 lr 0.000196	time 0.5536 (0.5725)	loss 3.1972 (2.8883)	grad_norm 2.0040 (2.0165)	mem 17417MB
[2023-02-02 08:32:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][400/1251]	eta 0:08:06 lr 0.000196	time 0.5588 (0.5721)	loss 3.2734 (2.8921)	grad_norm 2.0159 (2.0183)	mem 17417MB
[2023-02-02 08:32:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][450/1251]	eta 0:07:37 lr 0.000196	time 0.5580 (0.5717)	loss 3.0211 (2.8839)	grad_norm 1.7778 (2.0177)	mem 17417MB
[2023-02-02 08:32:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][500/1251]	eta 0:07:09 lr 0.000196	time 0.5517 (0.5713)	loss 2.4200 (2.8822)	grad_norm 2.0035 (2.0152)	mem 17417MB
[2023-02-02 08:33:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][550/1251]	eta 0:06:40 lr 0.000196	time 0.5598 (0.5712)	loss 3.3557 (2.8882)	grad_norm 1.9358 (2.0135)	mem 17417MB
[2023-02-02 08:33:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][600/1251]	eta 0:06:11 lr 0.000196	time 0.5554 (0.5714)	loss 3.0309 (2.8986)	grad_norm 2.0616 (2.0145)	mem 17417MB
[2023-02-02 08:34:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][650/1251]	eta 0:05:43 lr 0.000195	time 0.5633 (0.5713)	loss 3.1486 (2.8950)	grad_norm 1.9672 (2.0175)	mem 17417MB
[2023-02-02 08:34:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][700/1251]	eta 0:05:14 lr 0.000195	time 0.5479 (0.5711)	loss 3.5153 (2.8844)	grad_norm 1.7945 (2.0173)	mem 17417MB
[2023-02-02 08:35:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][750/1251]	eta 0:04:46 lr 0.000195	time 0.5606 (0.5709)	loss 2.3869 (2.8839)	grad_norm 1.9194 (2.0175)	mem 17417MB
[2023-02-02 08:35:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][800/1251]	eta 0:04:17 lr 0.000195	time 0.6189 (0.5708)	loss 2.8749 (2.8841)	grad_norm 2.0786 (2.0183)	mem 17417MB
[2023-02-02 08:36:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][850/1251]	eta 0:03:48 lr 0.000195	time 0.5548 (0.5707)	loss 2.9496 (2.8865)	grad_norm 2.0317 (2.0186)	mem 17417MB
[2023-02-02 08:36:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][900/1251]	eta 0:03:20 lr 0.000195	time 0.5692 (0.5708)	loss 4.1372 (2.8920)	grad_norm 1.9705 (2.0237)	mem 17417MB
[2023-02-02 08:37:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][950/1251]	eta 0:02:51 lr 0.000194	time 0.5665 (0.5706)	loss 3.0693 (2.8911)	grad_norm 2.2996 (2.0244)	mem 17417MB
[2023-02-02 08:37:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][1000/1251]	eta 0:02:23 lr 0.000194	time 0.5640 (0.5707)	loss 2.6351 (2.8894)	grad_norm 1.9508 (2.0248)	mem 17417MB
[2023-02-02 08:38:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][1050/1251]	eta 0:01:54 lr 0.000194	time 0.5563 (0.5708)	loss 2.9784 (2.8921)	grad_norm 1.9508 (2.0281)	mem 17417MB
[2023-02-02 08:38:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][1100/1251]	eta 0:01:26 lr 0.000194	time 0.6255 (0.5708)	loss 2.5239 (2.8885)	grad_norm 1.9143 (2.0270)	mem 17417MB
[2023-02-02 08:39:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][1150/1251]	eta 0:00:57 lr 0.000194	time 0.5548 (0.5707)	loss 3.3434 (2.8893)	grad_norm 1.8064 (2.0262)	mem 17417MB
[2023-02-02 08:39:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][1200/1251]	eta 0:00:29 lr 0.000194	time 0.6147 (0.5706)	loss 3.0976 (2.8848)	grad_norm 1.9561 (2.0257)	mem 17417MB
[2023-02-02 08:40:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [214/300][1250/1251]	eta 0:00:00 lr 0.000193	time 0.5494 (0.5707)	loss 2.0519 (2.8816)	grad_norm 2.3741 (2.0264)	mem 17417MB
[2023-02-02 08:40:06 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 214 training takes 0:11:54
[2023-02-02 08:40:06 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_214.pth saving......
[2023-02-02 08:40:08 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_214.pth saved !!!
[2023-02-02 08:40:09 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.886 (0.886)	Loss 0.7611 (0.7611)	Acc@1 82.422 (82.422)	Acc@5 95.703 (95.703)	Mem 17417MB
[2023-02-02 08:40:17 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.262 Acc@5 96.398
[2023-02-02 08:40:17 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.3%
[2023-02-02 08:40:18 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.224 (1.224)	Loss 0.6656 (0.6656)	Acc@1 84.863 (84.863)	Acc@5 97.363 (97.363)	Mem 17417MB
[2023-02-02 08:40:26 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.376 Acc@5 96.752
[2023-02-02 08:40:26 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.4%
[2023-02-02 08:40:26 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.38% at 214 epoch
[2023-02-02 08:40:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][0/1251]	eta 0:35:53 lr 0.000193	time 1.7217 (1.7217)	loss 2.3374 (2.3374)	grad_norm 2.0561 (2.0561)	mem 17417MB
[2023-02-02 08:40:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][50/1251]	eta 0:11:52 lr 0.000193	time 0.5665 (0.5937)	loss 3.0584 (3.0426)	grad_norm 1.7760 (2.0182)	mem 17417MB
[2023-02-02 08:41:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][100/1251]	eta 0:11:07 lr 0.000193	time 0.5716 (0.5801)	loss 3.5589 (2.9351)	grad_norm 2.2871 (2.0207)	mem 17417MB
[2023-02-02 08:41:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][150/1251]	eta 0:10:33 lr 0.000193	time 0.5623 (0.5751)	loss 2.4083 (2.8992)	grad_norm 1.8395 (2.0270)	mem 17417MB
[2023-02-02 08:42:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][200/1251]	eta 0:10:02 lr 0.000193	time 0.5563 (0.5736)	loss 3.3556 (2.8812)	grad_norm 1.9844 (2.0391)	mem 17417MB
[2023-02-02 08:42:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][250/1251]	eta 0:09:32 lr 0.000193	time 0.5684 (0.5722)	loss 2.9323 (2.8711)	grad_norm 2.2602 (2.0335)	mem 17417MB
[2023-02-02 08:43:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][300/1251]	eta 0:09:04 lr 0.000193	time 0.5617 (0.5721)	loss 3.0774 (2.8826)	grad_norm 2.1927 (inf)	mem 17417MB
[2023-02-02 08:43:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][350/1251]	eta 0:08:34 lr 0.000192	time 0.5566 (0.5713)	loss 1.6617 (2.8782)	grad_norm 1.9687 (inf)	mem 17417MB
[2023-02-02 08:44:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][400/1251]	eta 0:08:06 lr 0.000192	time 0.5588 (0.5712)	loss 3.0578 (2.8837)	grad_norm 1.9852 (inf)	mem 17417MB
[2023-02-02 08:44:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][450/1251]	eta 0:07:37 lr 0.000192	time 0.5509 (0.5708)	loss 3.0845 (2.8946)	grad_norm 2.0596 (inf)	mem 17417MB
[2023-02-02 08:45:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][500/1251]	eta 0:07:08 lr 0.000192	time 0.5541 (0.5704)	loss 2.9971 (2.8948)	grad_norm 2.1138 (inf)	mem 17417MB
[2023-02-02 08:45:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][550/1251]	eta 0:06:39 lr 0.000192	time 0.5645 (0.5703)	loss 2.3890 (2.8946)	grad_norm 1.8568 (inf)	mem 17417MB
[2023-02-02 08:46:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][600/1251]	eta 0:06:11 lr 0.000192	time 0.5547 (0.5704)	loss 1.9911 (2.8884)	grad_norm 2.0790 (inf)	mem 17417MB
[2023-02-02 08:46:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][650/1251]	eta 0:05:42 lr 0.000191	time 0.5647 (0.5702)	loss 3.1890 (2.8851)	grad_norm 1.7001 (inf)	mem 17417MB
[2023-02-02 08:47:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][700/1251]	eta 0:05:14 lr 0.000191	time 0.5574 (0.5699)	loss 1.9405 (2.8848)	grad_norm 2.3273 (inf)	mem 17417MB
[2023-02-02 08:47:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][750/1251]	eta 0:04:45 lr 0.000191	time 0.5623 (0.5698)	loss 3.2320 (2.8869)	grad_norm 1.8184 (inf)	mem 17417MB
[2023-02-02 08:48:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][800/1251]	eta 0:04:16 lr 0.000191	time 0.5660 (0.5698)	loss 2.9764 (2.8813)	grad_norm 1.8490 (inf)	mem 17417MB
[2023-02-02 08:48:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][850/1251]	eta 0:03:48 lr 0.000191	time 0.5563 (0.5700)	loss 2.7912 (2.8800)	grad_norm 2.6133 (inf)	mem 17417MB
[2023-02-02 08:48:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][900/1251]	eta 0:03:20 lr 0.000191	time 0.5558 (0.5698)	loss 2.9431 (2.8806)	grad_norm 1.9838 (inf)	mem 17417MB
[2023-02-02 08:49:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][950/1251]	eta 0:02:51 lr 0.000190	time 0.5569 (0.5696)	loss 3.3252 (2.8768)	grad_norm 2.1953 (inf)	mem 17417MB
[2023-02-02 08:49:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][1000/1251]	eta 0:02:22 lr 0.000190	time 0.5733 (0.5696)	loss 2.9310 (2.8746)	grad_norm 1.9197 (inf)	mem 17417MB
[2023-02-02 08:50:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][1050/1251]	eta 0:01:54 lr 0.000190	time 0.5575 (0.5694)	loss 3.0491 (2.8782)	grad_norm 1.9054 (inf)	mem 17417MB
[2023-02-02 08:50:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][1100/1251]	eta 0:01:25 lr 0.000190	time 0.6312 (0.5694)	loss 1.6698 (2.8763)	grad_norm 1.8884 (inf)	mem 17417MB
[2023-02-02 08:51:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][1150/1251]	eta 0:00:57 lr 0.000190	time 0.5677 (0.5693)	loss 3.0339 (2.8762)	grad_norm 2.0430 (inf)	mem 17417MB
[2023-02-02 08:51:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][1200/1251]	eta 0:00:29 lr 0.000190	time 0.5525 (0.5692)	loss 3.0115 (2.8713)	grad_norm 1.9933 (inf)	mem 17417MB
[2023-02-02 08:52:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [215/300][1250/1251]	eta 0:00:00 lr 0.000189	time 0.5501 (0.5692)	loss 2.9540 (2.8720)	grad_norm 1.9846 (inf)	mem 17417MB
[2023-02-02 08:52:18 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 215 training takes 0:11:52
[2023-02-02 08:52:18 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_215.pth saving......
[2023-02-02 08:52:20 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_215.pth saved !!!
[2023-02-02 08:52:21 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.869 (0.869)	Loss 0.6826 (0.6826)	Acc@1 83.398 (83.398)	Acc@5 97.266 (97.266)	Mem 17417MB
[2023-02-02 08:52:29 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.366 Acc@5 96.330
[2023-02-02 08:52:29 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.4%
[2023-02-02 08:52:30 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.190 (1.190)	Loss 0.7398 (0.7398)	Acc@1 82.910 (82.910)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-02 08:52:38 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.386 Acc@5 96.778
[2023-02-02 08:52:38 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.4%
[2023-02-02 08:52:38 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.39% at 215 epoch
[2023-02-02 08:52:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][0/1251]	eta 0:37:43 lr 0.000189	time 1.8090 (1.8090)	loss 2.7511 (2.7511)	grad_norm 2.1355 (2.1355)	mem 17417MB
[2023-02-02 08:53:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][50/1251]	eta 0:11:52 lr 0.000189	time 0.5458 (0.5930)	loss 2.9289 (2.9301)	grad_norm 2.3816 (2.0897)	mem 17417MB
[2023-02-02 08:53:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][100/1251]	eta 0:11:09 lr 0.000189	time 0.5561 (0.5816)	loss 3.7335 (2.9085)	grad_norm 2.2175 (2.0916)	mem 17417MB
[2023-02-02 08:54:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][150/1251]	eta 0:10:35 lr 0.000189	time 0.5470 (0.5770)	loss 2.5630 (2.8586)	grad_norm 2.0929 (2.1097)	mem 17417MB
[2023-02-02 08:54:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][200/1251]	eta 0:10:03 lr 0.000189	time 0.5629 (0.5744)	loss 2.9321 (2.8738)	grad_norm 2.2186 (2.0929)	mem 17417MB
[2023-02-02 08:55:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][250/1251]	eta 0:09:34 lr 0.000189	time 0.5566 (0.5735)	loss 2.7812 (2.8458)	grad_norm 1.9854 (2.0757)	mem 17417MB
[2023-02-02 08:55:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][300/1251]	eta 0:09:04 lr 0.000189	time 0.6153 (0.5725)	loss 2.9387 (2.8491)	grad_norm 1.8515 (2.0618)	mem 17417MB
[2023-02-02 08:55:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][350/1251]	eta 0:08:35 lr 0.000188	time 0.5854 (0.5719)	loss 2.1746 (2.8436)	grad_norm 1.8144 (2.0598)	mem 17417MB
[2023-02-02 08:56:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][400/1251]	eta 0:08:06 lr 0.000188	time 0.5473 (0.5717)	loss 3.1437 (2.8497)	grad_norm 1.9637 (2.0645)	mem 17417MB
[2023-02-02 08:56:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][450/1251]	eta 0:07:37 lr 0.000188	time 0.5541 (0.5714)	loss 3.1194 (2.8447)	grad_norm 1.8694 (2.0607)	mem 17417MB
[2023-02-02 08:57:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][500/1251]	eta 0:07:09 lr 0.000188	time 0.5579 (0.5713)	loss 3.0167 (2.8565)	grad_norm 1.9868 (2.0578)	mem 17417MB
[2023-02-02 08:57:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][550/1251]	eta 0:06:40 lr 0.000188	time 0.5579 (0.5710)	loss 3.3184 (2.8499)	grad_norm 2.1030 (2.0612)	mem 17417MB
[2023-02-02 08:58:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][600/1251]	eta 0:06:11 lr 0.000188	time 0.5604 (0.5710)	loss 2.8669 (2.8390)	grad_norm 2.5951 (2.0650)	mem 17417MB
[2023-02-02 08:58:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][650/1251]	eta 0:05:43 lr 0.000187	time 0.5602 (0.5708)	loss 2.5375 (2.8373)	grad_norm 1.8798 (2.0703)	mem 17417MB
[2023-02-02 08:59:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][700/1251]	eta 0:05:14 lr 0.000187	time 0.5591 (0.5707)	loss 2.9863 (2.8339)	grad_norm 2.0955 (2.0693)	mem 17417MB
[2023-02-02 08:59:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][750/1251]	eta 0:04:45 lr 0.000187	time 0.5558 (0.5704)	loss 2.8455 (2.8310)	grad_norm 1.9993 (2.0697)	mem 17417MB
[2023-02-02 09:00:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][800/1251]	eta 0:04:17 lr 0.000187	time 0.6205 (0.5707)	loss 2.4921 (2.8259)	grad_norm 2.0110 (2.0664)	mem 17417MB
[2023-02-02 09:00:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][850/1251]	eta 0:03:48 lr 0.000187	time 0.5508 (0.5704)	loss 2.1403 (2.8238)	grad_norm 1.9990 (2.0691)	mem 17417MB
[2023-02-02 09:01:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][900/1251]	eta 0:03:20 lr 0.000187	time 0.5548 (0.5703)	loss 2.9652 (2.8261)	grad_norm 1.9018 (2.0648)	mem 17417MB
[2023-02-02 09:01:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][950/1251]	eta 0:02:51 lr 0.000186	time 0.5579 (0.5702)	loss 3.2572 (2.8319)	grad_norm 1.7090 (2.0635)	mem 17417MB
[2023-02-02 09:02:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][1000/1251]	eta 0:02:23 lr 0.000186	time 0.5566 (0.5701)	loss 2.5820 (2.8288)	grad_norm 1.7184 (2.0645)	mem 17417MB
[2023-02-02 09:02:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][1050/1251]	eta 0:01:54 lr 0.000186	time 0.5576 (0.5700)	loss 3.3097 (2.8340)	grad_norm 1.9338 (2.0639)	mem 17417MB
[2023-02-02 09:03:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][1100/1251]	eta 0:01:26 lr 0.000186	time 0.6238 (0.5700)	loss 3.3533 (2.8450)	grad_norm 2.0185 (nan)	mem 17417MB
[2023-02-02 09:03:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][1150/1251]	eta 0:00:57 lr 0.000186	time 0.6123 (0.5698)	loss 2.4139 (2.8465)	grad_norm 2.0586 (nan)	mem 17417MB
[2023-02-02 09:04:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][1200/1251]	eta 0:00:29 lr 0.000186	time 0.5564 (0.5698)	loss 3.2439 (2.8467)	grad_norm 2.0861 (nan)	mem 17417MB
[2023-02-02 09:04:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [216/300][1250/1251]	eta 0:00:00 lr 0.000186	time 0.5479 (0.5697)	loss 3.3982 (2.8477)	grad_norm 2.5379 (nan)	mem 17417MB
[2023-02-02 09:04:31 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 216 training takes 0:11:52
[2023-02-02 09:04:31 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_216.pth saving......
[2023-02-02 09:04:33 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_216.pth saved !!!
[2023-02-02 09:04:34 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.868 (0.868)	Loss 0.8323 (0.8323)	Acc@1 80.469 (80.469)	Acc@5 95.410 (95.410)	Mem 17417MB
[2023-02-02 09:04:42 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.460 Acc@5 96.362
[2023-02-02 09:04:42 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.5%
[2023-02-02 09:04:43 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.200 (1.200)	Loss 0.6200 (0.6200)	Acc@1 84.668 (84.668)	Acc@5 98.047 (98.047)	Mem 17417MB
[2023-02-02 09:04:51 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.432 Acc@5 96.808
[2023-02-02 09:04:51 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.4%
[2023-02-02 09:04:51 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.43% at 216 epoch
[2023-02-02 09:04:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][0/1251]	eta 0:35:18 lr 0.000185	time 1.6935 (1.6935)	loss 2.6422 (2.6422)	grad_norm 2.3888 (2.3888)	mem 17417MB
[2023-02-02 09:05:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][50/1251]	eta 0:11:48 lr 0.000185	time 0.5562 (0.5898)	loss 2.8810 (2.7608)	grad_norm 1.8658 (2.0765)	mem 17417MB
[2023-02-02 09:05:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][100/1251]	eta 0:11:11 lr 0.000185	time 0.5596 (0.5834)	loss 3.0879 (2.8070)	grad_norm 2.0387 (2.0367)	mem 17417MB
[2023-02-02 09:06:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][150/1251]	eta 0:10:36 lr 0.000185	time 0.5541 (0.5780)	loss 2.3042 (2.7990)	grad_norm 2.0582 (2.0424)	mem 17417MB
[2023-02-02 09:06:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][200/1251]	eta 0:10:04 lr 0.000185	time 0.5562 (0.5754)	loss 3.2516 (2.8124)	grad_norm 2.3810 (2.0495)	mem 17417MB
[2023-02-02 09:07:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][250/1251]	eta 0:09:34 lr 0.000185	time 0.5521 (0.5743)	loss 2.9489 (2.8156)	grad_norm 2.3445 (2.0497)	mem 17417MB
[2023-02-02 09:07:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][300/1251]	eta 0:09:05 lr 0.000185	time 0.5572 (0.5738)	loss 2.8336 (2.8096)	grad_norm 1.8915 (2.0506)	mem 17417MB
[2023-02-02 09:08:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][350/1251]	eta 0:08:36 lr 0.000184	time 0.5513 (0.5734)	loss 3.0735 (2.8251)	grad_norm 1.8317 (2.0456)	mem 17417MB
[2023-02-02 09:08:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][400/1251]	eta 0:08:07 lr 0.000184	time 0.5502 (0.5730)	loss 3.4274 (2.8250)	grad_norm 1.5699 (2.0409)	mem 17417MB
[2023-02-02 09:09:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][450/1251]	eta 0:07:38 lr 0.000184	time 0.5652 (0.5728)	loss 2.2801 (2.8172)	grad_norm 1.9112 (2.0443)	mem 17417MB
[2023-02-02 09:09:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][500/1251]	eta 0:07:09 lr 0.000184	time 0.5505 (0.5723)	loss 2.5968 (2.8237)	grad_norm 1.8907 (2.0464)	mem 17417MB
[2023-02-02 09:10:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][550/1251]	eta 0:06:40 lr 0.000184	time 0.6324 (0.5720)	loss 3.3510 (2.8286)	grad_norm 1.9658 (2.0444)	mem 17417MB
[2023-02-02 09:10:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][600/1251]	eta 0:06:12 lr 0.000184	time 0.5564 (0.5716)	loss 2.7053 (2.8324)	grad_norm 2.0765 (2.0454)	mem 17417MB
[2023-02-02 09:11:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][650/1251]	eta 0:05:43 lr 0.000183	time 0.5530 (0.5714)	loss 3.1431 (2.8366)	grad_norm 2.1171 (2.0526)	mem 17417MB
[2023-02-02 09:11:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][700/1251]	eta 0:05:14 lr 0.000183	time 0.5508 (0.5713)	loss 3.2056 (2.8360)	grad_norm 1.9961 (2.0515)	mem 17417MB
[2023-02-02 09:12:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][750/1251]	eta 0:04:46 lr 0.000183	time 0.5615 (0.5710)	loss 2.7636 (2.8319)	grad_norm 2.5240 (2.0520)	mem 17417MB
[2023-02-02 09:12:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][800/1251]	eta 0:04:17 lr 0.000183	time 0.5532 (0.5708)	loss 2.1765 (2.8370)	grad_norm 2.0353 (2.0550)	mem 17417MB
[2023-02-02 09:12:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][850/1251]	eta 0:03:48 lr 0.000183	time 0.6154 (0.5706)	loss 3.3412 (2.8330)	grad_norm 2.2117 (2.0575)	mem 17417MB
[2023-02-02 09:13:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][900/1251]	eta 0:03:20 lr 0.000183	time 0.5542 (0.5707)	loss 2.9425 (2.8330)	grad_norm 1.8319 (2.0597)	mem 17417MB
[2023-02-02 09:13:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][950/1251]	eta 0:02:51 lr 0.000183	time 0.5567 (0.5704)	loss 2.5169 (2.8331)	grad_norm 1.9732 (2.0586)	mem 17417MB
[2023-02-02 09:14:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][1000/1251]	eta 0:02:23 lr 0.000182	time 0.5635 (0.5703)	loss 2.9191 (2.8314)	grad_norm 1.9427 (2.0596)	mem 17417MB
[2023-02-02 09:14:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][1050/1251]	eta 0:01:54 lr 0.000182	time 0.5536 (0.5703)	loss 2.7248 (2.8279)	grad_norm 1.8975 (2.0597)	mem 17417MB
[2023-02-02 09:15:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][1100/1251]	eta 0:01:26 lr 0.000182	time 0.6180 (0.5701)	loss 2.9551 (2.8192)	grad_norm 2.2457 (2.0597)	mem 17417MB
[2023-02-02 09:15:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][1150/1251]	eta 0:00:57 lr 0.000182	time 0.5609 (0.5700)	loss 2.9476 (2.8192)	grad_norm 1.9235 (2.0578)	mem 17417MB
[2023-02-02 09:16:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][1200/1251]	eta 0:00:29 lr 0.000182	time 0.5538 (0.5701)	loss 2.7387 (2.8187)	grad_norm 2.0455 (2.0573)	mem 17417MB
[2023-02-02 09:16:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [217/300][1250/1251]	eta 0:00:00 lr 0.000182	time 0.5496 (0.5702)	loss 3.1809 (2.8213)	grad_norm 2.1660 (2.0568)	mem 17417MB
[2023-02-02 09:16:44 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 217 training takes 0:11:53
[2023-02-02 09:16:45 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_217.pth saving......
[2023-02-02 09:16:46 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_217.pth saved !!!
[2023-02-02 09:16:47 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.885 (0.885)	Loss 0.7918 (0.7918)	Acc@1 82.520 (82.520)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-02 09:16:55 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.382 Acc@5 96.362
[2023-02-02 09:16:55 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.4%
[2023-02-02 09:16:57 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.305 (1.305)	Loss 0.7161 (0.7161)	Acc@1 82.715 (82.715)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-02 09:17:04 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.446 Acc@5 96.792
[2023-02-02 09:17:04 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.4%
[2023-02-02 09:17:04 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.45% at 217 epoch
[2023-02-02 09:17:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][0/1251]	eta 0:38:35 lr 0.000182	time 1.8508 (1.8508)	loss 2.6575 (2.6575)	grad_norm 1.8143 (1.8143)	mem 17417MB
[2023-02-02 09:17:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][50/1251]	eta 0:11:57 lr 0.000181	time 0.5536 (0.5971)	loss 2.4586 (2.8988)	grad_norm 2.0669 (2.0340)	mem 17417MB
[2023-02-02 09:18:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][100/1251]	eta 0:11:10 lr 0.000181	time 0.6187 (0.5828)	loss 1.9638 (2.8512)	grad_norm 2.1414 (2.0348)	mem 17417MB
[2023-02-02 09:18:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][150/1251]	eta 0:10:37 lr 0.000181	time 0.5556 (0.5789)	loss 3.2720 (2.8392)	grad_norm 2.4376 (2.0530)	mem 17417MB
[2023-02-02 09:19:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][200/1251]	eta 0:10:05 lr 0.000181	time 0.5547 (0.5757)	loss 2.8470 (2.8607)	grad_norm 2.1676 (2.0683)	mem 17417MB
[2023-02-02 09:19:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][250/1251]	eta 0:09:35 lr 0.000181	time 0.5593 (0.5746)	loss 3.6636 (2.8607)	grad_norm 2.0839 (2.0658)	mem 17417MB
[2023-02-02 09:19:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][300/1251]	eta 0:09:05 lr 0.000181	time 0.5511 (0.5736)	loss 2.8609 (2.8406)	grad_norm 2.2035 (2.0717)	mem 17417MB
[2023-02-02 09:20:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][350/1251]	eta 0:08:36 lr 0.000180	time 0.5525 (0.5730)	loss 2.4101 (2.8358)	grad_norm 1.8171 (2.0728)	mem 17417MB
[2023-02-02 09:20:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][400/1251]	eta 0:08:06 lr 0.000180	time 0.5603 (0.5722)	loss 3.0732 (2.8306)	grad_norm 2.0553 (2.0744)	mem 17417MB
[2023-02-02 09:21:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][450/1251]	eta 0:07:37 lr 0.000180	time 0.5538 (0.5716)	loss 3.0826 (2.8346)	grad_norm 2.0325 (2.0686)	mem 17417MB
[2023-02-02 09:21:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][500/1251]	eta 0:07:08 lr 0.000180	time 0.6139 (0.5709)	loss 2.6476 (2.8389)	grad_norm 1.7971 (2.0652)	mem 17417MB
[2023-02-02 09:22:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][550/1251]	eta 0:06:40 lr 0.000180	time 0.5474 (0.5709)	loss 2.5277 (2.8397)	grad_norm 1.9570 (2.0632)	mem 17417MB
[2023-02-02 09:22:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][600/1251]	eta 0:06:11 lr 0.000180	time 0.5521 (0.5709)	loss 3.6845 (2.8443)	grad_norm 1.8640 (2.0703)	mem 17417MB
[2023-02-02 09:23:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][650/1251]	eta 0:05:43 lr 0.000180	time 0.5560 (0.5708)	loss 3.6618 (2.8449)	grad_norm 2.2397 (2.0719)	mem 17417MB
[2023-02-02 09:23:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][700/1251]	eta 0:05:14 lr 0.000179	time 0.5562 (0.5706)	loss 3.2419 (2.8539)	grad_norm 1.9172 (2.0740)	mem 17417MB
[2023-02-02 09:24:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][750/1251]	eta 0:04:45 lr 0.000179	time 0.6249 (0.5704)	loss 1.9730 (2.8515)	grad_norm 2.1266 (2.0732)	mem 17417MB
[2023-02-02 09:24:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][800/1251]	eta 0:04:17 lr 0.000179	time 0.5550 (0.5704)	loss 3.3545 (2.8521)	grad_norm 2.0235 (2.0739)	mem 17417MB
[2023-02-02 09:25:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][850/1251]	eta 0:03:48 lr 0.000179	time 0.5511 (0.5704)	loss 3.0938 (2.8588)	grad_norm 1.9699 (2.0738)	mem 17417MB
[2023-02-02 09:25:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][900/1251]	eta 0:03:20 lr 0.000179	time 0.6232 (0.5704)	loss 3.0274 (2.8550)	grad_norm 2.1958 (2.0797)	mem 17417MB
[2023-02-02 09:26:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][950/1251]	eta 0:02:51 lr 0.000179	time 0.5588 (0.5704)	loss 2.0404 (2.8573)	grad_norm 1.9451 (inf)	mem 17417MB
[2023-02-02 09:26:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][1000/1251]	eta 0:02:23 lr 0.000178	time 0.6126 (0.5704)	loss 2.7967 (2.8534)	grad_norm 2.1081 (inf)	mem 17417MB
[2023-02-02 09:27:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][1050/1251]	eta 0:01:54 lr 0.000178	time 0.5576 (0.5702)	loss 3.2281 (2.8483)	grad_norm 1.7903 (inf)	mem 17417MB
[2023-02-02 09:27:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][1100/1251]	eta 0:01:26 lr 0.000178	time 0.5567 (0.5703)	loss 2.3441 (2.8517)	grad_norm 2.2089 (inf)	mem 17417MB
[2023-02-02 09:28:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][1150/1251]	eta 0:00:57 lr 0.000178	time 0.5472 (0.5701)	loss 3.1225 (2.8532)	grad_norm 1.9238 (inf)	mem 17417MB
[2023-02-02 09:28:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][1200/1251]	eta 0:00:29 lr 0.000178	time 0.5527 (0.5701)	loss 3.3585 (2.8549)	grad_norm 2.2811 (inf)	mem 17417MB
[2023-02-02 09:28:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [218/300][1250/1251]	eta 0:00:00 lr 0.000178	time 0.5496 (0.5701)	loss 3.1023 (2.8538)	grad_norm 1.8552 (inf)	mem 17417MB
[2023-02-02 09:28:58 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 218 training takes 0:11:53
[2023-02-02 09:28:58 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_218.pth saving......
[2023-02-02 09:29:00 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_218.pth saved !!!
[2023-02-02 09:29:01 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.859 (0.859)	Loss 0.7636 (0.7636)	Acc@1 82.715 (82.715)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-02 09:29:09 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.472 Acc@5 96.420
[2023-02-02 09:29:09 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.5%
[2023-02-02 09:29:11 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.407 (1.407)	Loss 0.6911 (0.6911)	Acc@1 84.082 (84.082)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-02 09:29:18 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.460 Acc@5 96.798
[2023-02-02 09:29:18 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.5%
[2023-02-02 09:29:18 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.46% at 218 epoch
[2023-02-02 09:29:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][0/1251]	eta 0:36:45 lr 0.000178	time 1.7626 (1.7626)	loss 2.6669 (2.6669)	grad_norm 2.0744 (2.0744)	mem 17417MB
[2023-02-02 09:29:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][50/1251]	eta 0:11:53 lr 0.000177	time 0.5642 (0.5941)	loss 3.4296 (2.8512)	grad_norm 2.0197 (2.0824)	mem 17417MB
[2023-02-02 09:30:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][100/1251]	eta 0:11:12 lr 0.000177	time 0.5621 (0.5844)	loss 2.1417 (2.8130)	grad_norm 1.8296 (2.0810)	mem 17417MB
[2023-02-02 09:30:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][150/1251]	eta 0:10:37 lr 0.000177	time 0.5614 (0.5793)	loss 2.2143 (2.8365)	grad_norm 2.2543 (2.1016)	mem 17417MB
[2023-02-02 09:31:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][200/1251]	eta 0:10:07 lr 0.000177	time 0.5531 (0.5777)	loss 3.4071 (2.8393)	grad_norm 2.5816 (2.1034)	mem 17417MB
[2023-02-02 09:31:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][250/1251]	eta 0:09:36 lr 0.000177	time 0.6205 (0.5758)	loss 3.0432 (2.8554)	grad_norm 2.2793 (2.0932)	mem 17417MB
[2023-02-02 09:32:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][300/1251]	eta 0:09:06 lr 0.000177	time 0.5499 (0.5750)	loss 2.6020 (2.8513)	grad_norm 1.9266 (2.0975)	mem 17417MB
[2023-02-02 09:32:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][350/1251]	eta 0:08:37 lr 0.000177	time 0.5516 (0.5739)	loss 2.9362 (2.8464)	grad_norm 1.8800 (2.0920)	mem 17417MB
[2023-02-02 09:33:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][400/1251]	eta 0:08:07 lr 0.000176	time 0.5581 (0.5733)	loss 3.2200 (2.8486)	grad_norm 2.0428 (2.0909)	mem 17417MB
[2023-02-02 09:33:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][450/1251]	eta 0:07:38 lr 0.000176	time 0.6196 (0.5729)	loss 2.2217 (2.8433)	grad_norm 2.1356 (2.0864)	mem 17417MB
[2023-02-02 09:34:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][500/1251]	eta 0:07:09 lr 0.000176	time 0.5540 (0.5725)	loss 1.4689 (2.8327)	grad_norm 2.0669 (2.0906)	mem 17417MB
[2023-02-02 09:34:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][550/1251]	eta 0:06:41 lr 0.000176	time 0.5562 (0.5721)	loss 2.8397 (2.8338)	grad_norm 1.8337 (2.0931)	mem 17417MB
[2023-02-02 09:35:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][600/1251]	eta 0:06:12 lr 0.000176	time 0.5515 (0.5720)	loss 2.9190 (2.8358)	grad_norm 1.9458 (2.0923)	mem 17417MB
[2023-02-02 09:35:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][650/1251]	eta 0:05:43 lr 0.000176	time 0.5571 (0.5720)	loss 2.9714 (2.8301)	grad_norm 1.8035 (2.0936)	mem 17417MB
[2023-02-02 09:35:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][700/1251]	eta 0:05:15 lr 0.000175	time 0.5561 (0.5719)	loss 2.7627 (2.8377)	grad_norm 1.9075 (2.0981)	mem 17417MB
[2023-02-02 09:36:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][750/1251]	eta 0:04:46 lr 0.000175	time 0.5534 (0.5716)	loss 3.2130 (2.8369)	grad_norm 2.0502 (2.0960)	mem 17417MB
[2023-02-02 09:36:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][800/1251]	eta 0:04:17 lr 0.000175	time 0.5549 (0.5714)	loss 2.7121 (2.8364)	grad_norm 1.8133 (2.0911)	mem 17417MB
[2023-02-02 09:37:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][850/1251]	eta 0:03:49 lr 0.000175	time 0.5533 (0.5713)	loss 3.0102 (2.8391)	grad_norm 2.9963 (2.0917)	mem 17417MB
[2023-02-02 09:37:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][900/1251]	eta 0:03:20 lr 0.000175	time 0.5593 (0.5714)	loss 3.3286 (2.8424)	grad_norm 2.1147 (2.0906)	mem 17417MB
[2023-02-02 09:38:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][950/1251]	eta 0:02:51 lr 0.000175	time 0.5568 (0.5711)	loss 3.4448 (2.8448)	grad_norm 2.3269 (2.0941)	mem 17417MB
[2023-02-02 09:38:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][1000/1251]	eta 0:02:23 lr 0.000175	time 0.5539 (0.5711)	loss 2.8045 (2.8431)	grad_norm 2.1868 (2.0927)	mem 17417MB
[2023-02-02 09:39:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][1050/1251]	eta 0:01:54 lr 0.000174	time 0.5572 (0.5711)	loss 3.3509 (2.8404)	grad_norm 1.9817 (2.0906)	mem 17417MB
[2023-02-02 09:39:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][1100/1251]	eta 0:01:26 lr 0.000174	time 0.5525 (0.5710)	loss 2.4166 (2.8422)	grad_norm 2.1767 (2.0913)	mem 17417MB
[2023-02-02 09:40:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][1150/1251]	eta 0:00:57 lr 0.000174	time 0.6343 (0.5711)	loss 2.7926 (2.8415)	grad_norm 2.0657 (2.0926)	mem 17417MB
[2023-02-02 09:40:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][1200/1251]	eta 0:00:29 lr 0.000174	time 0.5578 (0.5709)	loss 2.7307 (2.8362)	grad_norm 2.2011 (2.0961)	mem 17417MB
[2023-02-02 09:41:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [219/300][1250/1251]	eta 0:00:00 lr 0.000174	time 0.5503 (0.5709)	loss 2.8424 (2.8369)	grad_norm 2.0708 (2.0961)	mem 17417MB
[2023-02-02 09:41:13 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 219 training takes 0:11:54
[2023-02-02 09:41:13 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_219.pth saving......
[2023-02-02 09:41:15 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_219.pth saved !!!
[2023-02-02 09:41:16 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.922 (0.922)	Loss 0.7596 (0.7596)	Acc@1 82.715 (82.715)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-02 09:41:24 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.588 Acc@5 96.308
[2023-02-02 09:41:24 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.6%
[2023-02-02 09:41:25 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.229 (1.229)	Loss 0.7002 (0.7002)	Acc@1 83.496 (83.496)	Acc@5 96.973 (96.973)	Mem 17417MB
[2023-02-02 09:41:33 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.490 Acc@5 96.798
[2023-02-02 09:41:33 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.5%
[2023-02-02 09:41:33 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.49% at 219 epoch
[2023-02-02 09:41:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][0/1251]	eta 0:34:59 lr 0.000174	time 1.6783 (1.6783)	loss 3.1687 (3.1687)	grad_norm 1.9686 (1.9686)	mem 17417MB
[2023-02-02 09:42:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][50/1251]	eta 0:11:50 lr 0.000174	time 0.5527 (0.5918)	loss 2.8820 (2.8226)	grad_norm 2.1100 (2.0958)	mem 17417MB
[2023-02-02 09:42:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][100/1251]	eta 0:11:10 lr 0.000173	time 0.5527 (0.5823)	loss 2.7043 (2.8235)	grad_norm 1.9213 (2.0817)	mem 17417MB
[2023-02-02 09:43:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][150/1251]	eta 0:10:36 lr 0.000173	time 0.5604 (0.5777)	loss 3.1612 (2.8524)	grad_norm 2.1743 (2.0774)	mem 17417MB
[2023-02-02 09:43:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][200/1251]	eta 0:10:05 lr 0.000173	time 0.5726 (0.5759)	loss 3.2920 (2.8490)	grad_norm 2.0950 (2.0755)	mem 17417MB
[2023-02-02 09:43:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][250/1251]	eta 0:09:34 lr 0.000173	time 0.5561 (0.5739)	loss 2.9637 (2.8506)	grad_norm 2.1360 (2.0782)	mem 17417MB
[2023-02-02 09:44:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][300/1251]	eta 0:09:05 lr 0.000173	time 0.5593 (0.5733)	loss 2.7306 (2.8451)	grad_norm 1.9390 (2.0833)	mem 17417MB
[2023-02-02 09:44:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][350/1251]	eta 0:08:35 lr 0.000173	time 0.5545 (0.5723)	loss 3.3680 (2.8359)	grad_norm 2.0413 (2.0806)	mem 17417MB
[2023-02-02 09:45:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][400/1251]	eta 0:08:06 lr 0.000173	time 0.5569 (0.5721)	loss 2.0144 (2.8357)	grad_norm 2.6656 (2.0866)	mem 17417MB
[2023-02-02 09:45:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][450/1251]	eta 0:07:38 lr 0.000172	time 0.5497 (0.5718)	loss 2.4189 (2.8211)	grad_norm 2.1837 (2.0861)	mem 17417MB
[2023-02-02 09:46:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][500/1251]	eta 0:07:08 lr 0.000172	time 0.5568 (0.5712)	loss 3.2832 (2.8220)	grad_norm 2.0640 (2.0852)	mem 17417MB
[2023-02-02 09:46:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][550/1251]	eta 0:06:40 lr 0.000172	time 0.5653 (0.5714)	loss 2.6870 (2.8170)	grad_norm 1.9561 (2.0891)	mem 17417MB
[2023-02-02 09:47:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][600/1251]	eta 0:06:11 lr 0.000172	time 0.5739 (0.5712)	loss 2.4586 (2.8096)	grad_norm 1.8347 (2.0885)	mem 17417MB
[2023-02-02 09:47:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][650/1251]	eta 0:05:43 lr 0.000172	time 0.5525 (0.5710)	loss 2.8128 (2.8164)	grad_norm 2.2179 (2.0891)	mem 17417MB
[2023-02-02 09:48:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][700/1251]	eta 0:05:14 lr 0.000172	time 0.5534 (0.5710)	loss 3.0177 (2.8224)	grad_norm 1.9974 (2.0875)	mem 17417MB
[2023-02-02 09:48:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][750/1251]	eta 0:04:45 lr 0.000171	time 0.6368 (0.5708)	loss 2.8872 (2.8251)	grad_norm 1.9917 (2.0898)	mem 17417MB
[2023-02-02 09:49:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][800/1251]	eta 0:04:17 lr 0.000171	time 0.6131 (0.5708)	loss 2.5712 (2.8253)	grad_norm 2.1390 (2.0896)	mem 17417MB
[2023-02-02 09:49:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][850/1251]	eta 0:03:48 lr 0.000171	time 0.5579 (0.5707)	loss 3.0614 (2.8257)	grad_norm 1.9327 (2.0891)	mem 17417MB
[2023-02-02 09:50:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][900/1251]	eta 0:03:20 lr 0.000171	time 0.5553 (0.5707)	loss 2.2922 (2.8268)	grad_norm 2.1631 (2.0892)	mem 17417MB
[2023-02-02 09:50:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][950/1251]	eta 0:02:51 lr 0.000171	time 0.6454 (0.5706)	loss 2.9708 (2.8291)	grad_norm 2.0774 (2.0877)	mem 17417MB
[2023-02-02 09:51:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][1000/1251]	eta 0:02:23 lr 0.000171	time 0.5529 (0.5705)	loss 1.9896 (2.8347)	grad_norm 1.7984 (2.0853)	mem 17417MB
[2023-02-02 09:51:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][1050/1251]	eta 0:01:54 lr 0.000171	time 0.5518 (0.5704)	loss 2.1547 (2.8333)	grad_norm 2.2171 (2.0874)	mem 17417MB
[2023-02-02 09:52:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][1100/1251]	eta 0:01:26 lr 0.000170	time 0.6263 (0.5705)	loss 2.4032 (2.8261)	grad_norm 2.1022 (2.0881)	mem 17417MB
[2023-02-02 09:52:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][1150/1251]	eta 0:00:57 lr 0.000170	time 0.5595 (0.5705)	loss 1.8614 (2.8283)	grad_norm 1.8779 (2.0894)	mem 17417MB
[2023-02-02 09:52:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][1200/1251]	eta 0:00:29 lr 0.000170	time 0.5521 (0.5704)	loss 2.9758 (2.8293)	grad_norm 2.2901 (2.0904)	mem 17417MB
[2023-02-02 09:53:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [220/300][1250/1251]	eta 0:00:00 lr 0.000170	time 0.5495 (0.5704)	loss 3.1698 (2.8314)	grad_norm 2.1827 (2.0881)	mem 17417MB
[2023-02-02 09:53:27 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 220 training takes 0:11:53
[2023-02-02 09:53:27 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_220.pth saving......
[2023-02-02 09:53:29 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_220.pth saved !!!
[2023-02-02 09:53:30 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.002 (1.002)	Loss 0.7099 (0.7099)	Acc@1 83.984 (83.984)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 09:53:38 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.654 Acc@5 96.416
[2023-02-02 09:53:38 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.7%
[2023-02-02 09:53:39 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.228 (1.228)	Loss 0.6564 (0.6564)	Acc@1 83.887 (83.887)	Acc@5 97.656 (97.656)	Mem 17417MB
[2023-02-02 09:53:47 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.510 Acc@5 96.786
[2023-02-02 09:53:47 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.5%
[2023-02-02 09:53:47 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.51% at 220 epoch
[2023-02-02 09:53:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][0/1251]	eta 0:34:57 lr 0.000170	time 1.6764 (1.6764)	loss 2.4494 (2.4494)	grad_norm 2.0202 (2.0202)	mem 17417MB
[2023-02-02 09:54:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][50/1251]	eta 0:11:50 lr 0.000170	time 0.6445 (0.5919)	loss 2.5286 (2.8675)	grad_norm 1.9047 (2.1573)	mem 17417MB
[2023-02-02 09:54:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][100/1251]	eta 0:11:08 lr 0.000170	time 0.5618 (0.5809)	loss 1.7763 (2.8061)	grad_norm 2.0232 (2.1562)	mem 17417MB
[2023-02-02 09:55:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][150/1251]	eta 0:10:35 lr 0.000169	time 0.5575 (0.5772)	loss 3.2390 (2.8058)	grad_norm 2.4121 (2.1255)	mem 17417MB
[2023-02-02 09:55:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][200/1251]	eta 0:10:04 lr 0.000169	time 0.5553 (0.5754)	loss 2.3229 (2.8298)	grad_norm 1.9318 (2.1251)	mem 17417MB
[2023-02-02 09:56:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][250/1251]	eta 0:09:34 lr 0.000169	time 0.5524 (0.5739)	loss 3.1137 (2.8483)	grad_norm 2.2279 (inf)	mem 17417MB
[2023-02-02 09:56:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][300/1251]	eta 0:09:05 lr 0.000169	time 0.5744 (0.5733)	loss 3.1006 (2.8507)	grad_norm 1.9186 (inf)	mem 17417MB
[2023-02-02 09:57:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][350/1251]	eta 0:08:35 lr 0.000169	time 0.5501 (0.5720)	loss 2.8853 (2.8416)	grad_norm 1.9606 (inf)	mem 17417MB
[2023-02-02 09:57:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][400/1251]	eta 0:08:06 lr 0.000169	time 0.5514 (0.5720)	loss 3.3287 (2.8375)	grad_norm 2.0213 (inf)	mem 17417MB
[2023-02-02 09:58:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][450/1251]	eta 0:07:37 lr 0.000169	time 0.5599 (0.5713)	loss 2.2268 (2.8219)	grad_norm 1.8063 (inf)	mem 17417MB
[2023-02-02 09:58:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][500/1251]	eta 0:07:08 lr 0.000168	time 0.5558 (0.5711)	loss 3.0591 (2.8212)	grad_norm 1.9846 (inf)	mem 17417MB
[2023-02-02 09:59:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][550/1251]	eta 0:06:40 lr 0.000168	time 0.6148 (0.5713)	loss 2.8680 (2.8221)	grad_norm 1.9040 (inf)	mem 17417MB
[2023-02-02 09:59:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][600/1251]	eta 0:06:11 lr 0.000168	time 0.5545 (0.5710)	loss 3.0173 (2.8257)	grad_norm 2.2325 (inf)	mem 17417MB
[2023-02-02 09:59:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][650/1251]	eta 0:05:43 lr 0.000168	time 0.5565 (0.5708)	loss 3.0784 (2.8325)	grad_norm 2.2792 (inf)	mem 17417MB
[2023-02-02 10:00:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][700/1251]	eta 0:05:14 lr 0.000168	time 0.5574 (0.5706)	loss 2.8909 (2.8355)	grad_norm 2.1648 (inf)	mem 17417MB
[2023-02-02 10:00:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][750/1251]	eta 0:04:45 lr 0.000168	time 0.5522 (0.5703)	loss 3.1673 (2.8321)	grad_norm 2.4217 (inf)	mem 17417MB
[2023-02-02 10:01:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][800/1251]	eta 0:04:17 lr 0.000168	time 0.5518 (0.5703)	loss 3.2463 (2.8319)	grad_norm 2.0907 (inf)	mem 17417MB
[2023-02-02 10:01:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][850/1251]	eta 0:03:48 lr 0.000167	time 0.5569 (0.5700)	loss 2.4185 (2.8247)	grad_norm 2.2452 (inf)	mem 17417MB
[2023-02-02 10:02:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][900/1251]	eta 0:03:20 lr 0.000167	time 0.5480 (0.5701)	loss 3.0444 (2.8245)	grad_norm 2.1590 (inf)	mem 17417MB
[2023-02-02 10:02:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][950/1251]	eta 0:02:51 lr 0.000167	time 0.5564 (0.5699)	loss 2.8812 (2.8241)	grad_norm 2.4931 (inf)	mem 17417MB
[2023-02-02 10:03:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][1000/1251]	eta 0:02:23 lr 0.000167	time 0.5590 (0.5697)	loss 3.4674 (2.8302)	grad_norm 2.0304 (inf)	mem 17417MB
[2023-02-02 10:03:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][1050/1251]	eta 0:01:54 lr 0.000167	time 0.5740 (0.5697)	loss 2.7316 (2.8267)	grad_norm 2.0817 (inf)	mem 17417MB
[2023-02-02 10:04:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][1100/1251]	eta 0:01:26 lr 0.000167	time 0.5628 (0.5697)	loss 2.1384 (2.8257)	grad_norm 2.3614 (inf)	mem 17417MB
[2023-02-02 10:04:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][1150/1251]	eta 0:00:57 lr 0.000166	time 0.5585 (0.5694)	loss 2.4471 (2.8262)	grad_norm 1.9305 (inf)	mem 17417MB
[2023-02-02 10:05:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][1200/1251]	eta 0:00:29 lr 0.000166	time 0.6294 (0.5696)	loss 2.5346 (2.8256)	grad_norm 2.0260 (inf)	mem 17417MB
[2023-02-02 10:05:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [221/300][1250/1251]	eta 0:00:00 lr 0.000166	time 0.5500 (0.5695)	loss 2.6631 (2.8259)	grad_norm 2.0715 (inf)	mem 17417MB
[2023-02-02 10:05:39 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 221 training takes 0:11:52
[2023-02-02 10:05:40 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_221.pth saving......
[2023-02-02 10:05:41 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_221.pth saved !!!
[2023-02-02 10:05:42 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.999 (0.999)	Loss 0.7812 (0.7812)	Acc@1 82.129 (82.129)	Acc@5 95.605 (95.605)	Mem 17417MB
[2023-02-02 10:05:50 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.642 Acc@5 96.438
[2023-02-02 10:05:50 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.6%
[2023-02-02 10:05:52 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.222 (1.222)	Loss 0.7146 (0.7146)	Acc@1 83.203 (83.203)	Acc@5 96.875 (96.875)	Mem 17417MB
[2023-02-02 10:06:00 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.530 Acc@5 96.818
[2023-02-02 10:06:00 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.5%
[2023-02-02 10:06:00 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.53% at 221 epoch
[2023-02-02 10:06:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][0/1251]	eta 0:34:41 lr 0.000166	time 1.6642 (1.6642)	loss 3.2455 (3.2455)	grad_norm 1.9843 (1.9843)	mem 17417MB
[2023-02-02 10:06:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][50/1251]	eta 0:11:49 lr 0.000166	time 0.5575 (0.5908)	loss 3.0371 (2.8385)	grad_norm 2.3736 (2.1384)	mem 17417MB
[2023-02-02 10:06:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][100/1251]	eta 0:11:08 lr 0.000166	time 0.5690 (0.5810)	loss 3.1101 (2.7200)	grad_norm 2.2423 (2.1270)	mem 17417MB
[2023-02-02 10:07:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][150/1251]	eta 0:10:34 lr 0.000166	time 0.5614 (0.5762)	loss 2.9350 (2.7462)	grad_norm 2.0024 (2.1172)	mem 17417MB
[2023-02-02 10:07:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][200/1251]	eta 0:10:04 lr 0.000166	time 0.5609 (0.5748)	loss 3.1440 (2.7561)	grad_norm 1.9846 (2.1183)	mem 17417MB
[2023-02-02 10:08:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][250/1251]	eta 0:09:33 lr 0.000165	time 0.5609 (0.5734)	loss 3.1709 (2.7728)	grad_norm 2.3177 (2.1290)	mem 17417MB
[2023-02-02 10:08:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][300/1251]	eta 0:09:05 lr 0.000165	time 0.5592 (0.5734)	loss 2.1642 (2.7803)	grad_norm 2.0313 (2.1305)	mem 17417MB
[2023-02-02 10:09:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][350/1251]	eta 0:08:35 lr 0.000165	time 0.5669 (0.5723)	loss 2.4983 (2.7687)	grad_norm 1.9909 (2.1206)	mem 17417MB
[2023-02-02 10:09:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][400/1251]	eta 0:08:06 lr 0.000165	time 0.6414 (0.5721)	loss 3.0647 (2.7735)	grad_norm 2.0337 (2.1248)	mem 17417MB
[2023-02-02 10:10:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][450/1251]	eta 0:07:37 lr 0.000165	time 0.5556 (0.5713)	loss 2.5780 (2.7755)	grad_norm 2.0068 (2.1185)	mem 17417MB
[2023-02-02 10:10:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][500/1251]	eta 0:07:08 lr 0.000165	time 0.5563 (0.5708)	loss 1.8806 (2.7713)	grad_norm 2.0476 (2.1178)	mem 17417MB
[2023-02-02 10:11:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][550/1251]	eta 0:06:39 lr 0.000164	time 0.5590 (0.5706)	loss 2.3038 (2.7686)	grad_norm 2.6162 (2.1212)	mem 17417MB
[2023-02-02 10:11:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][600/1251]	eta 0:06:11 lr 0.000164	time 0.5577 (0.5704)	loss 3.5915 (2.7764)	grad_norm 2.2521 (2.1278)	mem 17417MB
[2023-02-02 10:12:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][650/1251]	eta 0:05:42 lr 0.000164	time 0.5597 (0.5704)	loss 2.8719 (2.7780)	grad_norm 2.2952 (2.1276)	mem 17417MB
[2023-02-02 10:12:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][700/1251]	eta 0:05:14 lr 0.000164	time 0.5538 (0.5701)	loss 3.1467 (2.7761)	grad_norm 2.2121 (2.1299)	mem 17417MB
[2023-02-02 10:13:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][750/1251]	eta 0:04:45 lr 0.000164	time 0.5564 (0.5701)	loss 3.2039 (2.7731)	grad_norm 3.0102 (2.1317)	mem 17417MB
[2023-02-02 10:13:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][800/1251]	eta 0:04:16 lr 0.000164	time 0.5720 (0.5698)	loss 3.5777 (2.7724)	grad_norm 2.1892 (2.1323)	mem 17417MB
[2023-02-02 10:14:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][850/1251]	eta 0:03:48 lr 0.000164	time 0.5491 (0.5697)	loss 2.8989 (2.7762)	grad_norm 1.9503 (2.1295)	mem 17417MB
[2023-02-02 10:14:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][900/1251]	eta 0:03:19 lr 0.000163	time 0.5539 (0.5696)	loss 2.0984 (2.7768)	grad_norm 1.8939 (2.1303)	mem 17417MB
[2023-02-02 10:15:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][950/1251]	eta 0:02:51 lr 0.000163	time 0.5549 (0.5695)	loss 2.9188 (2.7779)	grad_norm 2.3985 (2.1282)	mem 17417MB
[2023-02-02 10:15:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][1000/1251]	eta 0:02:22 lr 0.000163	time 0.5540 (0.5695)	loss 3.1405 (2.7821)	grad_norm 2.2115 (inf)	mem 17417MB
[2023-02-02 10:15:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][1050/1251]	eta 0:01:54 lr 0.000163	time 0.5597 (0.5694)	loss 2.8557 (2.7793)	grad_norm 2.4641 (inf)	mem 17417MB
[2023-02-02 10:16:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][1100/1251]	eta 0:01:25 lr 0.000163	time 0.6471 (0.5692)	loss 2.5147 (2.7783)	grad_norm 2.3836 (inf)	mem 17417MB
[2023-02-02 10:16:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][1150/1251]	eta 0:00:57 lr 0.000163	time 0.6269 (0.5693)	loss 2.8023 (2.7843)	grad_norm 1.9510 (inf)	mem 17417MB
[2023-02-02 10:17:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][1200/1251]	eta 0:00:29 lr 0.000163	time 0.5739 (0.5691)	loss 2.9284 (2.7829)	grad_norm 1.9192 (inf)	mem 17417MB
[2023-02-02 10:17:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [222/300][1250/1251]	eta 0:00:00 lr 0.000162	time 0.5492 (0.5692)	loss 2.8544 (2.7839)	grad_norm 2.1795 (inf)	mem 17417MB
[2023-02-02 10:17:52 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 222 training takes 0:11:52
[2023-02-02 10:17:52 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_222.pth saving......
[2023-02-02 10:17:54 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_222.pth saved !!!
[2023-02-02 10:17:55 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.883 (0.883)	Loss 0.8015 (0.8015)	Acc@1 80.469 (80.469)	Acc@5 95.117 (95.117)	Mem 17417MB
[2023-02-02 10:18:02 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.572 Acc@5 96.416
[2023-02-02 10:18:03 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.6%
[2023-02-02 10:18:04 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.147 (1.147)	Loss 0.7270 (0.7270)	Acc@1 82.617 (82.617)	Acc@5 97.266 (97.266)	Mem 17417MB
[2023-02-02 10:18:12 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.540 Acc@5 96.822
[2023-02-02 10:18:12 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.5%
[2023-02-02 10:18:12 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.54% at 222 epoch
[2023-02-02 10:18:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][0/1251]	eta 0:34:17 lr 0.000162	time 1.6450 (1.6450)	loss 3.0047 (3.0047)	grad_norm 1.7823 (1.7823)	mem 17417MB
[2023-02-02 10:18:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][50/1251]	eta 0:11:51 lr 0.000162	time 0.5558 (0.5921)	loss 2.9329 (2.7909)	grad_norm 2.4182 (2.0991)	mem 17417MB
[2023-02-02 10:19:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][100/1251]	eta 0:11:10 lr 0.000162	time 0.5513 (0.5821)	loss 2.2197 (2.8144)	grad_norm 2.1371 (2.1047)	mem 17417MB
[2023-02-02 10:19:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][150/1251]	eta 0:10:36 lr 0.000162	time 0.5548 (0.5782)	loss 2.7694 (2.7939)	grad_norm 2.0062 (2.1070)	mem 17417MB
[2023-02-02 10:20:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][200/1251]	eta 0:10:03 lr 0.000162	time 0.5505 (0.5747)	loss 3.1900 (2.8083)	grad_norm 1.9248 (2.1100)	mem 17417MB
[2023-02-02 10:20:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][250/1251]	eta 0:09:34 lr 0.000162	time 0.5562 (0.5743)	loss 2.8499 (2.8051)	grad_norm 2.1007 (2.1108)	mem 17417MB
[2023-02-02 10:21:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][300/1251]	eta 0:09:05 lr 0.000161	time 0.5621 (0.5736)	loss 2.9932 (2.7912)	grad_norm 2.2031 (2.1342)	mem 17417MB
[2023-02-02 10:21:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][350/1251]	eta 0:08:36 lr 0.000161	time 0.5624 (0.5732)	loss 2.6043 (2.8085)	grad_norm 2.0944 (2.1335)	mem 17417MB
[2023-02-02 10:22:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][400/1251]	eta 0:08:07 lr 0.000161	time 0.6372 (0.5725)	loss 3.1985 (2.8203)	grad_norm 2.0287 (2.1227)	mem 17417MB
[2023-02-02 10:22:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][450/1251]	eta 0:07:38 lr 0.000161	time 0.5591 (0.5724)	loss 2.0046 (2.8323)	grad_norm 2.1053 (2.1174)	mem 17417MB
[2023-02-02 10:22:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][500/1251]	eta 0:07:09 lr 0.000161	time 0.5535 (0.5718)	loss 3.0622 (2.8322)	grad_norm 2.1183 (2.1135)	mem 17417MB
[2023-02-02 10:23:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][550/1251]	eta 0:06:40 lr 0.000161	time 0.5645 (0.5718)	loss 3.3373 (2.8333)	grad_norm 2.4587 (2.1167)	mem 17417MB
[2023-02-02 10:23:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][600/1251]	eta 0:06:12 lr 0.000161	time 0.5542 (0.5715)	loss 3.0202 (2.8399)	grad_norm 2.0860 (2.1219)	mem 17417MB
[2023-02-02 10:24:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][650/1251]	eta 0:05:43 lr 0.000160	time 0.5577 (0.5715)	loss 3.1541 (2.8440)	grad_norm 1.9816 (2.1217)	mem 17417MB
[2023-02-02 10:24:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][700/1251]	eta 0:05:14 lr 0.000160	time 0.5525 (0.5712)	loss 3.3260 (2.8448)	grad_norm 2.1489 (2.1203)	mem 17417MB
[2023-02-02 10:25:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][750/1251]	eta 0:04:46 lr 0.000160	time 0.5559 (0.5712)	loss 3.1675 (2.8389)	grad_norm 2.0399 (2.1188)	mem 17417MB
[2023-02-02 10:25:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][800/1251]	eta 0:04:17 lr 0.000160	time 0.5534 (0.5709)	loss 3.1104 (2.8344)	grad_norm 2.1710 (2.1217)	mem 17417MB
[2023-02-02 10:26:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][850/1251]	eta 0:03:49 lr 0.000160	time 0.6248 (0.5713)	loss 2.7259 (2.8297)	grad_norm 1.8802 (2.1202)	mem 17417MB
[2023-02-02 10:26:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][900/1251]	eta 0:03:20 lr 0.000160	time 0.5621 (0.5709)	loss 3.1808 (2.8271)	grad_norm 2.3195 (2.1193)	mem 17417MB
[2023-02-02 10:27:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][950/1251]	eta 0:02:51 lr 0.000160	time 0.5539 (0.5709)	loss 2.1850 (2.8259)	grad_norm 1.9499 (2.1190)	mem 17417MB
[2023-02-02 10:27:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][1000/1251]	eta 0:02:23 lr 0.000159	time 0.6139 (0.5708)	loss 3.2021 (2.8320)	grad_norm 2.3183 (2.1216)	mem 17417MB
[2023-02-02 10:28:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][1050/1251]	eta 0:01:54 lr 0.000159	time 0.5580 (0.5708)	loss 2.3338 (2.8311)	grad_norm 2.0624 (2.1211)	mem 17417MB
[2023-02-02 10:28:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][1100/1251]	eta 0:01:26 lr 0.000159	time 0.5616 (0.5707)	loss 1.7419 (2.8306)	grad_norm 2.5771 (2.1215)	mem 17417MB
[2023-02-02 10:29:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][1150/1251]	eta 0:00:57 lr 0.000159	time 0.6202 (0.5707)	loss 2.7943 (2.8270)	grad_norm 2.1711 (2.1220)	mem 17417MB
[2023-02-02 10:29:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][1200/1251]	eta 0:00:29 lr 0.000159	time 0.5578 (0.5706)	loss 1.8753 (2.8229)	grad_norm 1.9843 (2.1218)	mem 17417MB
[2023-02-02 10:30:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [223/300][1250/1251]	eta 0:00:00 lr 0.000159	time 0.5501 (0.5706)	loss 2.4437 (2.8241)	grad_norm 1.9770 (2.1233)	mem 17417MB
[2023-02-02 10:30:06 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 223 training takes 0:11:53
[2023-02-02 10:30:06 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_223.pth saving......
[2023-02-02 10:30:08 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_223.pth saved !!!
[2023-02-02 10:30:08 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.862 (0.862)	Loss 0.7659 (0.7659)	Acc@1 80.762 (80.762)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 10:30:16 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.734 Acc@5 96.418
[2023-02-02 10:30:16 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.7%
[2023-02-02 10:30:18 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.227 (1.227)	Loss 0.7438 (0.7438)	Acc@1 84.375 (84.375)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-02 10:30:26 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.570 Acc@5 96.824
[2023-02-02 10:30:26 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.6%
[2023-02-02 10:30:26 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.57% at 223 epoch
[2023-02-02 10:30:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][0/1251]	eta 0:35:41 lr 0.000159	time 1.7120 (1.7120)	loss 2.6568 (2.6568)	grad_norm 1.9967 (1.9967)	mem 17417MB
[2023-02-02 10:30:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][50/1251]	eta 0:11:52 lr 0.000159	time 0.5565 (0.5936)	loss 2.4240 (2.8603)	grad_norm 2.0261 (2.1373)	mem 17417MB
[2023-02-02 10:31:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][100/1251]	eta 0:11:11 lr 0.000158	time 0.6209 (0.5834)	loss 3.3188 (2.8460)	grad_norm 1.9892 (2.1342)	mem 17417MB
[2023-02-02 10:31:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][150/1251]	eta 0:10:36 lr 0.000158	time 0.5559 (0.5781)	loss 1.9651 (2.8015)	grad_norm 1.8211 (2.1220)	mem 17417MB
[2023-02-02 10:32:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][200/1251]	eta 0:10:06 lr 0.000158	time 0.5526 (0.5767)	loss 2.5315 (2.7654)	grad_norm 1.9804 (2.1125)	mem 17417MB
[2023-02-02 10:32:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][250/1251]	eta 0:09:35 lr 0.000158	time 0.5606 (0.5752)	loss 3.0663 (2.7790)	grad_norm 2.2198 (2.1188)	mem 17417MB
[2023-02-02 10:33:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][300/1251]	eta 0:09:06 lr 0.000158	time 0.5568 (0.5748)	loss 3.6223 (2.7956)	grad_norm 2.1327 (2.1143)	mem 17417MB
[2023-02-02 10:33:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][350/1251]	eta 0:08:36 lr 0.000158	time 0.5551 (0.5737)	loss 2.0574 (2.8060)	grad_norm 2.2227 (2.1178)	mem 17417MB
[2023-02-02 10:34:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][400/1251]	eta 0:08:07 lr 0.000157	time 0.5563 (0.5732)	loss 2.6256 (2.8109)	grad_norm 2.0263 (2.1194)	mem 17417MB
[2023-02-02 10:34:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][450/1251]	eta 0:07:38 lr 0.000157	time 0.5491 (0.5724)	loss 3.4243 (2.8120)	grad_norm 1.9484 (2.1218)	mem 17417MB
[2023-02-02 10:35:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][500/1251]	eta 0:07:09 lr 0.000157	time 0.6358 (0.5722)	loss 2.2018 (2.8178)	grad_norm 2.2628 (2.1251)	mem 17417MB
[2023-02-02 10:35:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][550/1251]	eta 0:06:40 lr 0.000157	time 0.5533 (0.5719)	loss 2.1380 (2.8236)	grad_norm 2.3818 (2.1268)	mem 17417MB
[2023-02-02 10:36:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][600/1251]	eta 0:06:12 lr 0.000157	time 0.5559 (0.5719)	loss 3.3412 (2.8209)	grad_norm 2.1008 (2.1279)	mem 17417MB
[2023-02-02 10:36:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][650/1251]	eta 0:05:43 lr 0.000157	time 0.5568 (0.5717)	loss 2.6358 (2.8141)	grad_norm 2.1019 (2.1236)	mem 17417MB
[2023-02-02 10:37:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][700/1251]	eta 0:05:15 lr 0.000157	time 0.5583 (0.5718)	loss 3.0422 (2.8215)	grad_norm 2.2449 (2.1236)	mem 17417MB
[2023-02-02 10:37:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][750/1251]	eta 0:04:46 lr 0.000156	time 0.5579 (0.5717)	loss 3.0921 (2.8192)	grad_norm 3.1518 (2.1253)	mem 17417MB
[2023-02-02 10:38:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][800/1251]	eta 0:04:17 lr 0.000156	time 0.5532 (0.5717)	loss 2.1865 (2.8090)	grad_norm 2.5786 (2.1255)	mem 17417MB
[2023-02-02 10:38:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][850/1251]	eta 0:03:49 lr 0.000156	time 0.6070 (0.5713)	loss 3.3859 (2.8114)	grad_norm 1.9779 (2.1282)	mem 17417MB
[2023-02-02 10:39:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][900/1251]	eta 0:03:20 lr 0.000156	time 0.6283 (0.5712)	loss 2.8840 (2.8167)	grad_norm 2.1799 (2.1286)	mem 17417MB
[2023-02-02 10:39:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][950/1251]	eta 0:02:51 lr 0.000156	time 0.5575 (0.5710)	loss 3.2132 (2.8152)	grad_norm 2.0817 (2.1307)	mem 17417MB
[2023-02-02 10:39:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][1000/1251]	eta 0:02:23 lr 0.000156	time 0.5538 (0.5710)	loss 3.2861 (2.8176)	grad_norm 2.0077 (2.1320)	mem 17417MB
[2023-02-02 10:40:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][1050/1251]	eta 0:01:54 lr 0.000156	time 0.5571 (0.5711)	loss 3.0187 (2.8152)	grad_norm 1.9848 (2.1301)	mem 17417MB
[2023-02-02 10:40:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][1100/1251]	eta 0:01:26 lr 0.000155	time 0.5623 (0.5711)	loss 2.7553 (2.8141)	grad_norm 2.1126 (2.1309)	mem 17417MB
[2023-02-02 10:41:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][1150/1251]	eta 0:00:57 lr 0.000155	time 0.5560 (0.5711)	loss 2.6388 (2.8136)	grad_norm 2.4092 (2.1344)	mem 17417MB
[2023-02-02 10:41:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][1200/1251]	eta 0:00:29 lr 0.000155	time 0.5551 (0.5709)	loss 2.8689 (2.8140)	grad_norm 2.0413 (2.1349)	mem 17417MB
[2023-02-02 10:42:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [224/300][1250/1251]	eta 0:00:00 lr 0.000155	time 0.5514 (0.5708)	loss 2.2890 (2.8107)	grad_norm 2.7532 (2.1355)	mem 17417MB
[2023-02-02 10:42:20 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 224 training takes 0:11:54
[2023-02-02 10:42:20 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_224.pth saving......
[2023-02-02 10:42:22 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_224.pth saved !!!
[2023-02-02 10:42:23 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.883 (0.883)	Loss 0.7067 (0.7067)	Acc@1 83.398 (83.398)	Acc@5 96.582 (96.582)	Mem 17417MB
[2023-02-02 10:42:31 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.866 Acc@5 96.426
[2023-02-02 10:42:31 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.9%
[2023-02-02 10:42:32 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.282 (1.282)	Loss 0.7091 (0.7091)	Acc@1 83.691 (83.691)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-02 10:42:40 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.584 Acc@5 96.836
[2023-02-02 10:42:40 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.6%
[2023-02-02 10:42:40 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.58% at 224 epoch
[2023-02-02 10:42:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][0/1251]	eta 0:34:40 lr 0.000155	time 1.6633 (1.6633)	loss 2.1332 (2.1332)	grad_norm 2.4452 (2.4452)	mem 17417MB
[2023-02-02 10:43:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][50/1251]	eta 0:11:56 lr 0.000155	time 0.5570 (0.5970)	loss 2.4307 (2.6390)	grad_norm 2.1754 (2.1498)	mem 17417MB
[2023-02-02 10:43:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][100/1251]	eta 0:11:10 lr 0.000155	time 0.6213 (0.5826)	loss 2.7223 (2.7099)	grad_norm 2.1820 (2.1908)	mem 17417MB
[2023-02-02 10:44:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][150/1251]	eta 0:10:36 lr 0.000155	time 0.5604 (0.5779)	loss 2.7031 (2.7107)	grad_norm 2.2272 (2.1692)	mem 17417MB
[2023-02-02 10:44:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][200/1251]	eta 0:10:04 lr 0.000154	time 0.5533 (0.5756)	loss 2.7470 (2.7061)	grad_norm 1.8119 (2.1597)	mem 17417MB
[2023-02-02 10:45:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][250/1251]	eta 0:09:34 lr 0.000154	time 0.5558 (0.5738)	loss 2.8361 (2.7324)	grad_norm 1.8746 (2.1465)	mem 17417MB
[2023-02-02 10:45:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][300/1251]	eta 0:09:04 lr 0.000154	time 0.5624 (0.5728)	loss 2.1488 (2.7252)	grad_norm 1.9584 (2.1512)	mem 17417MB
[2023-02-02 10:46:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][350/1251]	eta 0:08:36 lr 0.000154	time 0.5607 (0.5728)	loss 3.0116 (2.7065)	grad_norm 2.5594 (2.1545)	mem 17417MB
[2023-02-02 10:46:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][400/1251]	eta 0:08:06 lr 0.000154	time 0.5553 (0.5719)	loss 3.2997 (2.7078)	grad_norm 2.1864 (2.1536)	mem 17417MB
[2023-02-02 10:46:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][450/1251]	eta 0:07:38 lr 0.000154	time 0.6180 (0.5719)	loss 3.2331 (2.7243)	grad_norm 1.9707 (2.1512)	mem 17417MB
[2023-02-02 10:47:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][500/1251]	eta 0:07:09 lr 0.000154	time 0.6117 (0.5715)	loss 3.0190 (2.7291)	grad_norm 2.0865 (2.1514)	mem 17417MB
[2023-02-02 10:47:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][550/1251]	eta 0:06:40 lr 0.000153	time 0.5817 (0.5709)	loss 2.7323 (2.7332)	grad_norm 1.9319 (2.1514)	mem 17417MB
[2023-02-02 10:48:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][600/1251]	eta 0:06:11 lr 0.000153	time 0.5566 (0.5709)	loss 2.5440 (2.7316)	grad_norm 2.4914 (inf)	mem 17417MB
[2023-02-02 10:48:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][650/1251]	eta 0:05:43 lr 0.000153	time 0.5562 (0.5708)	loss 2.7945 (2.7393)	grad_norm 2.3598 (inf)	mem 17417MB
[2023-02-02 10:49:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][700/1251]	eta 0:05:14 lr 0.000153	time 0.5540 (0.5705)	loss 1.8501 (2.7469)	grad_norm 2.1243 (inf)	mem 17417MB
[2023-02-02 10:49:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][750/1251]	eta 0:04:45 lr 0.000153	time 0.5578 (0.5705)	loss 2.5361 (2.7547)	grad_norm 2.1573 (inf)	mem 17417MB
[2023-02-02 10:50:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][800/1251]	eta 0:04:17 lr 0.000153	time 0.5567 (0.5702)	loss 2.8829 (2.7549)	grad_norm 2.0293 (inf)	mem 17417MB
[2023-02-02 10:50:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][850/1251]	eta 0:03:48 lr 0.000153	time 0.5508 (0.5704)	loss 2.9783 (2.7630)	grad_norm 2.0240 (inf)	mem 17417MB
[2023-02-02 10:51:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][900/1251]	eta 0:03:20 lr 0.000152	time 0.6302 (0.5703)	loss 2.1632 (2.7599)	grad_norm 2.0952 (inf)	mem 17417MB
[2023-02-02 10:51:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][950/1251]	eta 0:02:51 lr 0.000152	time 0.5559 (0.5700)	loss 2.3806 (2.7684)	grad_norm 2.3995 (inf)	mem 17417MB
[2023-02-02 10:52:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][1000/1251]	eta 0:02:23 lr 0.000152	time 0.5573 (0.5701)	loss 2.9221 (2.7711)	grad_norm 2.1940 (inf)	mem 17417MB
[2023-02-02 10:52:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][1050/1251]	eta 0:01:54 lr 0.000152	time 0.5590 (0.5700)	loss 2.6936 (2.7764)	grad_norm 1.9000 (inf)	mem 17417MB
[2023-02-02 10:53:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][1100/1251]	eta 0:01:26 lr 0.000152	time 0.6314 (0.5700)	loss 2.8816 (2.7806)	grad_norm 2.4823 (inf)	mem 17417MB
[2023-02-02 10:53:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][1150/1251]	eta 0:00:57 lr 0.000152	time 0.5558 (0.5699)	loss 3.3908 (2.7777)	grad_norm 2.2337 (inf)	mem 17417MB
[2023-02-02 10:54:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][1200/1251]	eta 0:00:29 lr 0.000151	time 0.5501 (0.5699)	loss 2.9712 (2.7799)	grad_norm 2.1627 (inf)	mem 17417MB
[2023-02-02 10:54:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [225/300][1250/1251]	eta 0:00:00 lr 0.000151	time 0.5495 (0.5700)	loss 2.9424 (2.7833)	grad_norm 2.1587 (inf)	mem 17417MB
[2023-02-02 10:54:34 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 225 training takes 0:11:53
[2023-02-02 10:54:34 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_225.pth saving......
[2023-02-02 10:54:36 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_225.pth saved !!!
[2023-02-02 10:54:36 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.878 (0.878)	Loss 0.7088 (0.7088)	Acc@1 82.910 (82.910)	Acc@5 96.973 (96.973)	Mem 17417MB
[2023-02-02 10:54:44 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.788 Acc@5 96.440
[2023-02-02 10:54:44 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.8%
[2023-02-02 10:54:46 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.192 (1.192)	Loss 0.6363 (0.6363)	Acc@1 85.547 (85.547)	Acc@5 97.656 (97.656)	Mem 17417MB
[2023-02-02 10:54:53 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.598 Acc@5 96.850
[2023-02-02 10:54:53 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.6%
[2023-02-02 10:54:53 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.60% at 225 epoch
[2023-02-02 10:54:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][0/1251]	eta 0:35:28 lr 0.000151	time 1.7014 (1.7014)	loss 3.0371 (3.0371)	grad_norm 1.8516 (1.8516)	mem 17417MB
[2023-02-02 10:55:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][50/1251]	eta 0:11:56 lr 0.000151	time 0.5659 (0.5962)	loss 3.1488 (2.7815)	grad_norm 2.3232 (2.1287)	mem 17417MB
[2023-02-02 10:55:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][100/1251]	eta 0:11:12 lr 0.000151	time 0.5639 (0.5844)	loss 2.2882 (2.7636)	grad_norm 2.0445 (2.1140)	mem 17417MB
[2023-02-02 10:56:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][150/1251]	eta 0:10:39 lr 0.000151	time 0.5589 (0.5806)	loss 2.0717 (2.7838)	grad_norm 1.8893 (2.1421)	mem 17417MB
[2023-02-02 10:56:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][200/1251]	eta 0:10:07 lr 0.000151	time 0.5582 (0.5781)	loss 3.2819 (2.7967)	grad_norm 1.8062 (2.1231)	mem 17417MB
[2023-02-02 10:57:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][250/1251]	eta 0:09:38 lr 0.000151	time 0.6169 (0.5779)	loss 2.8278 (2.7766)	grad_norm 2.0490 (2.1480)	mem 17417MB
[2023-02-02 10:57:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][300/1251]	eta 0:09:08 lr 0.000150	time 0.5894 (0.5770)	loss 2.8415 (2.7837)	grad_norm 1.9933 (2.1452)	mem 17417MB
[2023-02-02 10:58:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][350/1251]	eta 0:08:38 lr 0.000150	time 0.5537 (0.5760)	loss 3.3524 (2.7893)	grad_norm 2.0195 (2.1435)	mem 17417MB
[2023-02-02 10:58:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][400/1251]	eta 0:08:09 lr 0.000150	time 0.5630 (0.5754)	loss 2.7148 (2.7856)	grad_norm 2.3572 (2.1465)	mem 17417MB
[2023-02-02 10:59:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][450/1251]	eta 0:07:40 lr 0.000150	time 0.6230 (0.5751)	loss 2.4087 (2.7869)	grad_norm 1.8942 (2.1473)	mem 17417MB
[2023-02-02 10:59:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][500/1251]	eta 0:07:11 lr 0.000150	time 0.5573 (0.5747)	loss 2.7461 (2.7820)	grad_norm 2.2417 (2.1452)	mem 17417MB
[2023-02-02 11:00:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][550/1251]	eta 0:06:42 lr 0.000150	time 0.5567 (0.5745)	loss 2.8906 (2.7744)	grad_norm 2.0410 (2.1458)	mem 17417MB
[2023-02-02 11:00:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][600/1251]	eta 0:06:13 lr 0.000150	time 0.5540 (0.5741)	loss 3.2968 (2.7812)	grad_norm 2.2641 (2.1435)	mem 17417MB
[2023-02-02 11:01:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][650/1251]	eta 0:05:44 lr 0.000149	time 0.5536 (0.5738)	loss 2.7970 (2.7880)	grad_norm 2.0127 (2.1418)	mem 17417MB
[2023-02-02 11:01:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][700/1251]	eta 0:05:16 lr 0.000149	time 0.5503 (0.5737)	loss 2.8462 (2.7893)	grad_norm 1.9700 (2.1462)	mem 17417MB
[2023-02-02 11:02:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][750/1251]	eta 0:04:47 lr 0.000149	time 0.5564 (0.5736)	loss 2.8934 (2.7899)	grad_norm 2.3058 (2.1465)	mem 17417MB
[2023-02-02 11:02:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][800/1251]	eta 0:04:18 lr 0.000149	time 0.6256 (0.5734)	loss 3.4898 (2.8003)	grad_norm 2.1408 (2.1441)	mem 17417MB
[2023-02-02 11:03:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][850/1251]	eta 0:03:49 lr 0.000149	time 0.5553 (0.5732)	loss 3.1618 (2.8046)	grad_norm 2.0195 (2.1407)	mem 17417MB
[2023-02-02 11:03:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][900/1251]	eta 0:03:21 lr 0.000149	time 0.5460 (0.5732)	loss 2.6593 (2.8094)	grad_norm 2.1345 (2.1463)	mem 17417MB
[2023-02-02 11:03:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][950/1251]	eta 0:02:52 lr 0.000149	time 0.5591 (0.5731)	loss 2.6912 (2.8080)	grad_norm 2.8072 (2.1473)	mem 17417MB
[2023-02-02 11:04:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][1000/1251]	eta 0:02:23 lr 0.000148	time 0.5535 (0.5731)	loss 2.4721 (2.8080)	grad_norm 2.5338 (2.1492)	mem 17417MB
[2023-02-02 11:04:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][1050/1251]	eta 0:01:55 lr 0.000148	time 0.5559 (0.5729)	loss 3.1975 (2.8071)	grad_norm 2.1212 (2.1514)	mem 17417MB
[2023-02-02 11:05:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][1100/1251]	eta 0:01:26 lr 0.000148	time 0.6197 (0.5729)	loss 2.9947 (2.8062)	grad_norm 2.0718 (2.1538)	mem 17417MB
[2023-02-02 11:05:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][1150/1251]	eta 0:00:57 lr 0.000148	time 0.5554 (0.5726)	loss 3.3987 (2.8068)	grad_norm 2.4097 (2.1540)	mem 17417MB
[2023-02-02 11:06:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][1200/1251]	eta 0:00:29 lr 0.000148	time 0.5496 (0.5726)	loss 3.3681 (2.8079)	grad_norm 1.9531 (2.1524)	mem 17417MB
[2023-02-02 11:06:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [226/300][1250/1251]	eta 0:00:00 lr 0.000148	time 0.5522 (0.5724)	loss 2.9835 (2.8102)	grad_norm 2.1138 (2.1546)	mem 17417MB
[2023-02-02 11:06:50 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 226 training takes 0:11:56
[2023-02-02 11:06:50 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_226.pth saving......
[2023-02-02 11:06:52 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_226.pth saved !!!
[2023-02-02 11:06:53 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.848 (0.848)	Loss 0.7822 (0.7822)	Acc@1 81.641 (81.641)	Acc@5 95.508 (95.508)	Mem 17417MB
[2023-02-02 11:07:01 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.730 Acc@5 96.396
[2023-02-02 11:07:01 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.7%
[2023-02-02 11:07:02 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.226 (1.226)	Loss 0.7614 (0.7614)	Acc@1 82.715 (82.715)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-02 11:07:10 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.596 Acc@5 96.840
[2023-02-02 11:07:10 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.6%
[2023-02-02 11:07:10 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.60% at 225 epoch
[2023-02-02 11:07:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][0/1251]	eta 0:37:03 lr 0.000148	time 1.7775 (1.7775)	loss 2.0605 (2.0605)	grad_norm 2.1171 (2.1171)	mem 17417MB
[2023-02-02 11:07:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][50/1251]	eta 0:11:49 lr 0.000148	time 0.5638 (0.5910)	loss 3.4765 (2.7839)	grad_norm 2.1051 (2.1488)	mem 17417MB
[2023-02-02 11:08:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][100/1251]	eta 0:11:09 lr 0.000147	time 0.5556 (0.5818)	loss 2.7365 (2.8122)	grad_norm 1.9230 (2.1306)	mem 17417MB
[2023-02-02 11:08:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][150/1251]	eta 0:10:35 lr 0.000147	time 0.5580 (0.5771)	loss 3.0965 (2.8308)	grad_norm 2.2990 (2.1345)	mem 17417MB
[2023-02-02 11:09:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][200/1251]	eta 0:10:05 lr 0.000147	time 0.5513 (0.5759)	loss 2.9470 (2.8307)	grad_norm 2.1467 (2.1307)	mem 17417MB
[2023-02-02 11:09:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][250/1251]	eta 0:09:34 lr 0.000147	time 0.5521 (0.5740)	loss 2.3524 (2.8109)	grad_norm 1.7999 (2.1284)	mem 17417MB
[2023-02-02 11:10:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][300/1251]	eta 0:09:05 lr 0.000147	time 0.5551 (0.5733)	loss 2.5994 (2.8081)	grad_norm 2.1742 (2.1262)	mem 17417MB
[2023-02-02 11:10:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][350/1251]	eta 0:08:35 lr 0.000147	time 0.5596 (0.5726)	loss 3.2144 (2.8073)	grad_norm 2.0926 (2.1276)	mem 17417MB
[2023-02-02 11:11:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][400/1251]	eta 0:08:07 lr 0.000147	time 0.5712 (0.5727)	loss 2.3273 (2.7893)	grad_norm 2.5788 (2.1299)	mem 17417MB
[2023-02-02 11:11:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][450/1251]	eta 0:07:38 lr 0.000146	time 0.5507 (0.5722)	loss 2.9008 (2.7976)	grad_norm 1.8518 (2.1326)	mem 17417MB
[2023-02-02 11:11:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][500/1251]	eta 0:07:09 lr 0.000146	time 0.5555 (0.5718)	loss 2.9553 (2.7924)	grad_norm 2.3724 (2.1362)	mem 17417MB
[2023-02-02 11:12:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][550/1251]	eta 0:06:40 lr 0.000146	time 0.6318 (0.5716)	loss 1.8249 (2.7921)	grad_norm 1.9155 (2.1415)	mem 17417MB
[2023-02-02 11:12:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][600/1251]	eta 0:06:12 lr 0.000146	time 0.5542 (0.5717)	loss 3.0001 (2.7919)	grad_norm 2.0369 (2.1458)	mem 17417MB
[2023-02-02 11:13:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][650/1251]	eta 0:05:43 lr 0.000146	time 0.5564 (0.5714)	loss 2.6902 (2.7937)	grad_norm 2.0312 (2.1492)	mem 17417MB
[2023-02-02 11:13:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][700/1251]	eta 0:05:14 lr 0.000146	time 0.5518 (0.5715)	loss 3.4136 (2.7966)	grad_norm 3.6266 (2.1550)	mem 17417MB
[2023-02-02 11:14:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][750/1251]	eta 0:04:46 lr 0.000146	time 0.5604 (0.5711)	loss 3.2419 (2.7988)	grad_norm 2.1731 (2.1593)	mem 17417MB
[2023-02-02 11:14:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][800/1251]	eta 0:04:17 lr 0.000145	time 0.6150 (0.5712)	loss 3.1251 (2.8045)	grad_norm 2.1754 (2.1568)	mem 17417MB
[2023-02-02 11:15:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][850/1251]	eta 0:03:48 lr 0.000145	time 0.5624 (0.5710)	loss 2.3102 (2.8049)	grad_norm 1.8769 (2.1585)	mem 17417MB
[2023-02-02 11:15:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][900/1251]	eta 0:03:20 lr 0.000145	time 0.5623 (0.5710)	loss 3.2425 (2.8031)	grad_norm 2.1851 (2.1633)	mem 17417MB
[2023-02-02 11:16:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][950/1251]	eta 0:02:51 lr 0.000145	time 0.5632 (0.5709)	loss 2.3725 (2.7964)	grad_norm 1.9980 (2.1625)	mem 17417MB
[2023-02-02 11:16:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][1000/1251]	eta 0:02:23 lr 0.000145	time 0.5540 (0.5709)	loss 3.2701 (2.7948)	grad_norm 2.1980 (2.1599)	mem 17417MB
[2023-02-02 11:17:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][1050/1251]	eta 0:01:54 lr 0.000145	time 0.5493 (0.5707)	loss 3.1927 (2.7999)	grad_norm 2.1620 (2.1614)	mem 17417MB
[2023-02-02 11:17:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][1100/1251]	eta 0:01:26 lr 0.000145	time 0.6351 (0.5706)	loss 2.3037 (2.7961)	grad_norm 2.0750 (2.1630)	mem 17417MB
[2023-02-02 11:18:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][1150/1251]	eta 0:00:57 lr 0.000144	time 0.5551 (0.5706)	loss 2.9932 (2.7939)	grad_norm 1.9218 (2.1612)	mem 17417MB
[2023-02-02 11:18:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][1200/1251]	eta 0:00:29 lr 0.000144	time 0.5578 (0.5705)	loss 2.2356 (2.7958)	grad_norm 2.4892 (2.1636)	mem 17417MB
[2023-02-02 11:19:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [227/300][1250/1251]	eta 0:00:00 lr 0.000144	time 0.5500 (0.5706)	loss 1.8631 (2.7907)	grad_norm 1.7380 (2.1635)	mem 17417MB
[2023-02-02 11:19:04 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 227 training takes 0:11:53
[2023-02-02 11:19:04 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_227.pth saving......
[2023-02-02 11:19:06 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_227.pth saved !!!
[2023-02-02 11:19:07 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.907 (0.907)	Loss 0.7556 (0.7556)	Acc@1 82.520 (82.520)	Acc@5 95.605 (95.605)	Mem 17417MB
[2023-02-02 11:19:15 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.856 Acc@5 96.400
[2023-02-02 11:19:15 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.9%
[2023-02-02 11:19:16 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.292 (1.292)	Loss 0.7104 (0.7104)	Acc@1 82.422 (82.422)	Acc@5 97.461 (97.461)	Mem 17417MB
[2023-02-02 11:19:24 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.562 Acc@5 96.814
[2023-02-02 11:19:24 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.6%
[2023-02-02 11:19:24 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.60% at 225 epoch
[2023-02-02 11:19:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][0/1251]	eta 0:35:39 lr 0.000144	time 1.7098 (1.7098)	loss 3.3807 (3.3807)	grad_norm 1.9688 (1.9688)	mem 17417MB
[2023-02-02 11:19:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][50/1251]	eta 0:11:53 lr 0.000144	time 0.5591 (0.5941)	loss 2.0787 (2.8300)	grad_norm 2.3797 (2.1472)	mem 17417MB
[2023-02-02 11:20:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][100/1251]	eta 0:11:09 lr 0.000144	time 0.5541 (0.5814)	loss 3.1692 (2.8272)	grad_norm 2.3551 (2.1637)	mem 17417MB
[2023-02-02 11:20:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][150/1251]	eta 0:10:35 lr 0.000144	time 0.5564 (0.5769)	loss 1.6908 (2.7843)	grad_norm 2.2158 (2.1563)	mem 17417MB
[2023-02-02 11:21:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][200/1251]	eta 0:10:04 lr 0.000144	time 0.5558 (0.5752)	loss 2.2235 (2.7721)	grad_norm 2.1738 (2.1793)	mem 17417MB
[2023-02-02 11:21:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][250/1251]	eta 0:09:34 lr 0.000143	time 0.5554 (0.5735)	loss 2.3388 (2.7965)	grad_norm 2.0328 (2.1758)	mem 17417MB
[2023-02-02 11:22:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][300/1251]	eta 0:09:05 lr 0.000143	time 0.5522 (0.5731)	loss 3.3681 (2.8174)	grad_norm 2.1389 (2.1639)	mem 17417MB
[2023-02-02 11:22:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][350/1251]	eta 0:08:35 lr 0.000143	time 0.5555 (0.5724)	loss 3.1729 (2.8135)	grad_norm 2.1162 (2.1649)	mem 17417MB
[2023-02-02 11:23:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][400/1251]	eta 0:08:07 lr 0.000143	time 0.5707 (0.5724)	loss 3.3475 (2.8120)	grad_norm 2.2835 (2.1657)	mem 17417MB
[2023-02-02 11:23:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][450/1251]	eta 0:07:38 lr 0.000143	time 0.5566 (0.5720)	loss 2.9404 (2.8119)	grad_norm 2.1050 (2.1705)	mem 17417MB
[2023-02-02 11:24:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][500/1251]	eta 0:07:09 lr 0.000143	time 0.5546 (0.5718)	loss 2.7473 (2.8113)	grad_norm 2.1851 (2.1760)	mem 17417MB
[2023-02-02 11:24:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][550/1251]	eta 0:06:40 lr 0.000143	time 0.5627 (0.5715)	loss 2.5600 (2.8132)	grad_norm 1.9276 (2.1711)	mem 17417MB
[2023-02-02 11:25:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][600/1251]	eta 0:06:12 lr 0.000142	time 0.5591 (0.5717)	loss 3.1085 (2.8136)	grad_norm 1.9818 (2.1677)	mem 17417MB
[2023-02-02 11:25:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][650/1251]	eta 0:05:43 lr 0.000142	time 0.5542 (0.5714)	loss 3.0997 (2.8200)	grad_norm 1.9344 (2.1688)	mem 17417MB
[2023-02-02 11:26:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][700/1251]	eta 0:05:14 lr 0.000142	time 0.5588 (0.5715)	loss 3.0545 (2.8190)	grad_norm 2.2185 (2.1729)	mem 17417MB
[2023-02-02 11:26:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][750/1251]	eta 0:04:46 lr 0.000142	time 0.5650 (0.5710)	loss 2.3419 (2.8209)	grad_norm 1.9277 (2.1755)	mem 17417MB
[2023-02-02 11:27:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][800/1251]	eta 0:04:17 lr 0.000142	time 0.5635 (0.5711)	loss 3.2522 (2.8100)	grad_norm 2.0021 (2.1700)	mem 17417MB
[2023-02-02 11:27:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][850/1251]	eta 0:03:48 lr 0.000142	time 0.5635 (0.5709)	loss 2.9843 (2.8127)	grad_norm 2.0151 (nan)	mem 17417MB
[2023-02-02 11:27:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][900/1251]	eta 0:03:20 lr 0.000142	time 0.5635 (0.5709)	loss 1.7602 (2.8093)	grad_norm 2.1334 (nan)	mem 17417MB
[2023-02-02 11:28:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][950/1251]	eta 0:02:51 lr 0.000141	time 0.5585 (0.5707)	loss 2.7860 (2.8059)	grad_norm 2.0045 (nan)	mem 17417MB
[2023-02-02 11:28:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][1000/1251]	eta 0:02:23 lr 0.000141	time 0.5519 (0.5707)	loss 1.8568 (2.8103)	grad_norm 2.2175 (nan)	mem 17417MB
[2023-02-02 11:29:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][1050/1251]	eta 0:01:54 lr 0.000141	time 0.5578 (0.5705)	loss 3.2797 (2.8142)	grad_norm 2.3540 (nan)	mem 17417MB
[2023-02-02 11:29:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][1100/1251]	eta 0:01:26 lr 0.000141	time 0.6173 (0.5705)	loss 3.1609 (2.8165)	grad_norm 2.0341 (nan)	mem 17417MB
[2023-02-02 11:30:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][1150/1251]	eta 0:00:57 lr 0.000141	time 0.6161 (0.5702)	loss 3.2683 (2.8151)	grad_norm 2.0796 (nan)	mem 17417MB
[2023-02-02 11:30:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][1200/1251]	eta 0:00:29 lr 0.000141	time 0.6266 (0.5702)	loss 3.1089 (2.8173)	grad_norm 1.9213 (nan)	mem 17417MB
[2023-02-02 11:31:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [228/300][1250/1251]	eta 0:00:00 lr 0.000141	time 0.5513 (0.5703)	loss 3.1114 (2.8121)	grad_norm 2.3286 (nan)	mem 17417MB
[2023-02-02 11:31:18 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 228 training takes 0:11:53
[2023-02-02 11:31:18 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_228.pth saving......
[2023-02-02 11:31:19 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_228.pth saved !!!
[2023-02-02 11:31:20 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.863 (0.863)	Loss 0.7570 (0.7570)	Acc@1 81.250 (81.250)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-02 11:31:28 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.906 Acc@5 96.510
[2023-02-02 11:31:28 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.9%
[2023-02-02 11:31:29 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.189 (1.189)	Loss 0.6335 (0.6335)	Acc@1 84.863 (84.863)	Acc@5 97.363 (97.363)	Mem 17417MB
[2023-02-02 11:31:37 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.540 Acc@5 96.838
[2023-02-02 11:31:37 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.5%
[2023-02-02 11:31:37 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.60% at 225 epoch
[2023-02-02 11:31:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][0/1251]	eta 0:34:51 lr 0.000141	time 1.6717 (1.6717)	loss 1.7802 (1.7802)	grad_norm 2.0213 (2.0213)	mem 17417MB
[2023-02-02 11:32:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][50/1251]	eta 0:11:49 lr 0.000140	time 0.5520 (0.5912)	loss 2.6132 (2.7098)	grad_norm 1.9846 (2.1827)	mem 17417MB
[2023-02-02 11:32:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][100/1251]	eta 0:11:11 lr 0.000140	time 0.5522 (0.5836)	loss 2.5433 (2.7229)	grad_norm 1.9795 (2.1633)	mem 17417MB
[2023-02-02 11:33:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][150/1251]	eta 0:10:36 lr 0.000140	time 0.5523 (0.5780)	loss 2.7912 (2.7183)	grad_norm 1.9954 (2.1540)	mem 17417MB
[2023-02-02 11:33:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][200/1251]	eta 0:10:05 lr 0.000140	time 0.5594 (0.5761)	loss 2.9875 (2.7597)	grad_norm 2.5620 (2.1819)	mem 17417MB
[2023-02-02 11:34:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][250/1251]	eta 0:09:35 lr 0.000140	time 0.6445 (0.5747)	loss 3.3063 (2.7637)	grad_norm 1.9638 (2.1777)	mem 17417MB
[2023-02-02 11:34:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][300/1251]	eta 0:09:05 lr 0.000140	time 0.5534 (0.5741)	loss 2.9394 (2.7716)	grad_norm 2.3010 (2.1789)	mem 17417MB
[2023-02-02 11:34:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][350/1251]	eta 0:08:36 lr 0.000140	time 0.5571 (0.5733)	loss 2.8151 (2.7701)	grad_norm 2.1727 (2.1873)	mem 17417MB
[2023-02-02 11:35:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][400/1251]	eta 0:08:07 lr 0.000140	time 0.5534 (0.5733)	loss 2.4988 (2.7620)	grad_norm 2.3369 (2.1909)	mem 17417MB
[2023-02-02 11:35:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][450/1251]	eta 0:07:38 lr 0.000139	time 0.5567 (0.5728)	loss 1.9271 (2.7442)	grad_norm 2.2420 (2.1923)	mem 17417MB
[2023-02-02 11:36:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][500/1251]	eta 0:07:09 lr 0.000139	time 0.5523 (0.5725)	loss 2.3156 (2.7527)	grad_norm 2.0031 (2.1898)	mem 17417MB
[2023-02-02 11:36:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][550/1251]	eta 0:06:41 lr 0.000139	time 0.5527 (0.5721)	loss 2.5710 (2.7635)	grad_norm 2.1663 (2.1960)	mem 17417MB
[2023-02-02 11:37:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][600/1251]	eta 0:06:12 lr 0.000139	time 0.5607 (0.5717)	loss 2.8973 (2.7615)	grad_norm 2.1909 (2.1984)	mem 17417MB
[2023-02-02 11:37:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][650/1251]	eta 0:05:43 lr 0.000139	time 0.5559 (0.5717)	loss 3.2247 (2.7651)	grad_norm 2.2893 (2.1973)	mem 17417MB
[2023-02-02 11:38:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][700/1251]	eta 0:05:15 lr 0.000139	time 0.5566 (0.5717)	loss 2.9513 (2.7673)	grad_norm 2.1032 (2.2012)	mem 17417MB
[2023-02-02 11:38:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][750/1251]	eta 0:04:46 lr 0.000139	time 0.5502 (0.5713)	loss 1.7847 (2.7608)	grad_norm 2.2676 (2.1998)	mem 17417MB
[2023-02-02 11:39:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][800/1251]	eta 0:04:17 lr 0.000138	time 0.5583 (0.5713)	loss 2.4738 (2.7514)	grad_norm 2.4575 (2.2028)	mem 17417MB
[2023-02-02 11:39:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][850/1251]	eta 0:03:48 lr 0.000138	time 0.6219 (0.5710)	loss 3.2503 (2.7533)	grad_norm 2.3014 (2.1986)	mem 17417MB
[2023-02-02 11:40:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][900/1251]	eta 0:03:20 lr 0.000138	time 0.5527 (0.5711)	loss 2.6824 (2.7549)	grad_norm 2.2786 (2.2004)	mem 17417MB
[2023-02-02 11:40:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][950/1251]	eta 0:02:51 lr 0.000138	time 0.5576 (0.5709)	loss 2.7617 (2.7544)	grad_norm 2.4245 (2.1969)	mem 17417MB
[2023-02-02 11:41:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][1000/1251]	eta 0:02:23 lr 0.000138	time 0.5709 (0.5710)	loss 2.4622 (2.7549)	grad_norm 2.0005 (2.1960)	mem 17417MB
[2023-02-02 11:41:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][1050/1251]	eta 0:01:54 lr 0.000138	time 0.5571 (0.5709)	loss 3.5111 (2.7567)	grad_norm 2.2579 (2.1969)	mem 17417MB
[2023-02-02 11:42:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][1100/1251]	eta 0:01:26 lr 0.000138	time 0.6347 (0.5709)	loss 2.9591 (2.7626)	grad_norm 2.2195 (2.1965)	mem 17417MB
[2023-02-02 11:42:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][1150/1251]	eta 0:00:57 lr 0.000137	time 0.5533 (0.5708)	loss 1.5477 (2.7637)	grad_norm 2.0984 (2.1972)	mem 17417MB
[2023-02-02 11:43:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][1200/1251]	eta 0:00:29 lr 0.000137	time 0.5559 (0.5708)	loss 2.7408 (2.7700)	grad_norm 2.0418 (2.1980)	mem 17417MB
[2023-02-02 11:43:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [229/300][1250/1251]	eta 0:00:00 lr 0.000137	time 0.5476 (0.5708)	loss 2.2502 (2.7690)	grad_norm 2.2581 (2.1994)	mem 17417MB
[2023-02-02 11:43:32 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 229 training takes 0:11:54
[2023-02-02 11:43:32 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_229.pth saving......
[2023-02-02 11:43:34 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_229.pth saved !!!
[2023-02-02 11:43:34 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.873 (0.873)	Loss 0.7325 (0.7325)	Acc@1 81.641 (81.641)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-02 11:43:42 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.950 Acc@5 96.472
[2023-02-02 11:43:42 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.0%
[2023-02-02 11:43:44 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.203 (1.203)	Loss 0.6884 (0.6884)	Acc@1 84.082 (84.082)	Acc@5 96.582 (96.582)	Mem 17417MB
[2023-02-02 11:43:52 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.548 Acc@5 96.848
[2023-02-02 11:43:52 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.5%
[2023-02-02 11:43:52 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.60% at 225 epoch
[2023-02-02 11:43:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][0/1251]	eta 0:33:47 lr 0.000137	time 1.6206 (1.6206)	loss 3.3160 (3.3160)	grad_norm 2.2967 (2.2967)	mem 17417MB
[2023-02-02 11:44:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][50/1251]	eta 0:11:50 lr 0.000137	time 0.5577 (0.5915)	loss 3.0376 (2.7212)	grad_norm 2.2757 (2.1949)	mem 17417MB
[2023-02-02 11:44:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][100/1251]	eta 0:11:09 lr 0.000137	time 0.6414 (0.5816)	loss 2.2284 (2.7128)	grad_norm 2.1213 (2.2082)	mem 17417MB
[2023-02-02 11:45:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][150/1251]	eta 0:10:36 lr 0.000137	time 0.5554 (0.5784)	loss 2.8087 (2.7393)	grad_norm 2.2355 (2.1984)	mem 17417MB
[2023-02-02 11:45:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][200/1251]	eta 0:10:04 lr 0.000137	time 0.5687 (0.5755)	loss 3.3261 (2.7275)	grad_norm 2.5648 (2.1880)	mem 17417MB
[2023-02-02 11:46:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][250/1251]	eta 0:09:34 lr 0.000136	time 0.5586 (0.5740)	loss 2.7493 (2.7122)	grad_norm 1.9852 (2.1985)	mem 17417MB
[2023-02-02 11:46:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][300/1251]	eta 0:09:05 lr 0.000136	time 0.5678 (0.5735)	loss 2.6543 (2.7135)	grad_norm 2.1850 (2.2070)	mem 17417MB
[2023-02-02 11:47:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][350/1251]	eta 0:08:36 lr 0.000136	time 0.5554 (0.5732)	loss 1.6626 (2.7114)	grad_norm 2.0219 (2.2126)	mem 17417MB
[2023-02-02 11:47:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][400/1251]	eta 0:08:07 lr 0.000136	time 0.5632 (0.5727)	loss 2.6961 (2.7126)	grad_norm 1.7854 (2.2048)	mem 17417MB
[2023-02-02 11:48:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][450/1251]	eta 0:07:38 lr 0.000136	time 0.5644 (0.5725)	loss 2.0530 (2.7087)	grad_norm 1.7793 (2.2009)	mem 17417MB
[2023-02-02 11:48:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][500/1251]	eta 0:07:09 lr 0.000136	time 0.6233 (0.5716)	loss 3.1991 (2.7237)	grad_norm 2.3732 (2.2035)	mem 17417MB
[2023-02-02 11:49:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][550/1251]	eta 0:06:40 lr 0.000136	time 0.5539 (0.5719)	loss 2.9768 (2.7338)	grad_norm 2.5303 (2.2022)	mem 17417MB
[2023-02-02 11:49:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][600/1251]	eta 0:06:12 lr 0.000135	time 0.5570 (0.5716)	loss 2.7227 (2.7428)	grad_norm 2.3569 (2.2049)	mem 17417MB
[2023-02-02 11:50:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][650/1251]	eta 0:05:43 lr 0.000135	time 0.5555 (0.5715)	loss 2.7937 (2.7438)	grad_norm 2.5779 (2.2061)	mem 17417MB
[2023-02-02 11:50:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][700/1251]	eta 0:05:14 lr 0.000135	time 0.5529 (0.5714)	loss 3.1028 (2.7362)	grad_norm 2.3234 (2.2082)	mem 17417MB
[2023-02-02 11:51:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][750/1251]	eta 0:04:46 lr 0.000135	time 0.6270 (0.5712)	loss 2.8608 (2.7461)	grad_norm 2.1534 (2.2097)	mem 17417MB
[2023-02-02 11:51:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][800/1251]	eta 0:04:17 lr 0.000135	time 0.5486 (0.5709)	loss 2.4980 (2.7401)	grad_norm 2.1144 (2.2067)	mem 17417MB
[2023-02-02 11:51:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][850/1251]	eta 0:03:48 lr 0.000135	time 0.5552 (0.5709)	loss 2.3656 (2.7407)	grad_norm 2.2056 (2.2048)	mem 17417MB
[2023-02-02 11:52:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][900/1251]	eta 0:03:20 lr 0.000135	time 0.6073 (0.5709)	loss 3.2069 (2.7388)	grad_norm 2.0528 (2.2039)	mem 17417MB
[2023-02-02 11:52:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][950/1251]	eta 0:02:51 lr 0.000135	time 0.5587 (0.5709)	loss 2.9873 (2.7413)	grad_norm 1.9879 (2.2070)	mem 17417MB
[2023-02-02 11:53:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][1000/1251]	eta 0:02:23 lr 0.000134	time 0.6258 (0.5707)	loss 2.8889 (2.7443)	grad_norm 1.8968 (2.2069)	mem 17417MB
[2023-02-02 11:53:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][1050/1251]	eta 0:01:54 lr 0.000134	time 0.5613 (0.5707)	loss 2.2829 (2.7429)	grad_norm 2.2827 (2.2054)	mem 17417MB
[2023-02-02 11:54:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][1100/1251]	eta 0:01:26 lr 0.000134	time 0.5561 (0.5706)	loss 2.8038 (2.7435)	grad_norm 2.1732 (2.2053)	mem 17417MB
[2023-02-02 11:54:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][1150/1251]	eta 0:00:57 lr 0.000134	time 0.5530 (0.5706)	loss 3.1006 (2.7428)	grad_norm 2.1479 (2.2084)	mem 17417MB
[2023-02-02 11:55:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][1200/1251]	eta 0:00:29 lr 0.000134	time 0.5574 (0.5705)	loss 3.4078 (2.7459)	grad_norm 2.2543 (2.2100)	mem 17417MB
[2023-02-02 11:55:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [230/300][1250/1251]	eta 0:00:00 lr 0.000134	time 0.6092 (0.5706)	loss 3.0518 (2.7515)	grad_norm 2.3202 (2.2104)	mem 17417MB
[2023-02-02 11:55:46 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 230 training takes 0:11:53
[2023-02-02 11:55:46 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_230.pth saving......
[2023-02-02 11:55:48 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_230.pth saved !!!
[2023-02-02 11:55:48 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.923 (0.923)	Loss 0.7503 (0.7503)	Acc@1 82.520 (82.520)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-02 11:55:56 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.946 Acc@5 96.404
[2023-02-02 11:55:56 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 82.9%
[2023-02-02 11:55:58 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.340 (1.340)	Loss 0.7853 (0.7853)	Acc@1 80.859 (80.859)	Acc@5 95.410 (95.410)	Mem 17417MB
[2023-02-02 11:56:06 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.576 Acc@5 96.844
[2023-02-02 11:56:06 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.6%
[2023-02-02 11:56:06 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.60% at 225 epoch
[2023-02-02 11:56:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][0/1251]	eta 0:35:40 lr 0.000134	time 1.7110 (1.7110)	loss 2.1485 (2.1485)	grad_norm 2.2289 (2.2289)	mem 17417MB
[2023-02-02 11:56:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][50/1251]	eta 0:11:53 lr 0.000134	time 0.5601 (0.5943)	loss 3.0675 (2.7937)	grad_norm 2.1607 (2.1936)	mem 17417MB
[2023-02-02 11:57:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][100/1251]	eta 0:11:11 lr 0.000133	time 0.5571 (0.5835)	loss 3.2588 (2.8468)	grad_norm 2.3255 (2.2096)	mem 17417MB
[2023-02-02 11:57:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][150/1251]	eta 0:10:37 lr 0.000133	time 0.5550 (0.5790)	loss 3.4471 (2.8122)	grad_norm 2.1881 (2.2377)	mem 17417MB
[2023-02-02 11:58:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][200/1251]	eta 0:10:06 lr 0.000133	time 0.5587 (0.5773)	loss 2.5959 (2.8331)	grad_norm 2.0578 (2.2361)	mem 17417MB
[2023-02-02 11:58:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][250/1251]	eta 0:09:36 lr 0.000133	time 0.5611 (0.5755)	loss 2.2795 (2.8078)	grad_norm 2.0273 (2.2267)	mem 17417MB
[2023-02-02 11:58:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][300/1251]	eta 0:09:07 lr 0.000133	time 0.5649 (0.5754)	loss 2.7064 (2.7897)	grad_norm 1.8157 (2.2255)	mem 17417MB
[2023-02-02 11:59:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][350/1251]	eta 0:08:37 lr 0.000133	time 0.5572 (0.5740)	loss 3.4214 (2.7803)	grad_norm 2.2848 (2.2194)	mem 17417MB
[2023-02-02 11:59:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][400/1251]	eta 0:08:08 lr 0.000133	time 0.5540 (0.5735)	loss 2.9159 (2.7893)	grad_norm 2.1319 (2.2192)	mem 17417MB
[2023-02-02 12:00:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][450/1251]	eta 0:07:38 lr 0.000132	time 0.6167 (0.5729)	loss 2.8003 (2.7901)	grad_norm 2.0565 (2.2178)	mem 17417MB
[2023-02-02 12:00:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][500/1251]	eta 0:07:10 lr 0.000132	time 0.5519 (0.5728)	loss 3.3044 (2.7860)	grad_norm 2.1878 (2.2183)	mem 17417MB
[2023-02-02 12:01:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][550/1251]	eta 0:06:41 lr 0.000132	time 0.5565 (0.5725)	loss 2.9192 (2.7877)	grad_norm 2.0818 (2.2176)	mem 17417MB
[2023-02-02 12:01:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][600/1251]	eta 0:06:12 lr 0.000132	time 0.5535 (0.5722)	loss 3.1048 (2.7859)	grad_norm 2.0836 (inf)	mem 17417MB
[2023-02-02 12:02:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][650/1251]	eta 0:05:43 lr 0.000132	time 0.5582 (0.5721)	loss 3.0485 (2.7898)	grad_norm 2.6284 (inf)	mem 17417MB
[2023-02-02 12:02:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][700/1251]	eta 0:05:15 lr 0.000132	time 0.5567 (0.5721)	loss 2.6086 (2.7820)	grad_norm 2.0228 (inf)	mem 17417MB
[2023-02-02 12:03:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][750/1251]	eta 0:04:46 lr 0.000132	time 0.5526 (0.5718)	loss 3.4456 (2.7820)	grad_norm 2.3800 (inf)	mem 17417MB
[2023-02-02 12:03:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][800/1251]	eta 0:04:17 lr 0.000132	time 0.5660 (0.5717)	loss 2.6977 (2.7854)	grad_norm 1.9527 (inf)	mem 17417MB
[2023-02-02 12:04:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][850/1251]	eta 0:03:49 lr 0.000131	time 0.5527 (0.5715)	loss 3.0174 (2.7864)	grad_norm 2.0087 (inf)	mem 17417MB
[2023-02-02 12:04:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][900/1251]	eta 0:03:20 lr 0.000131	time 0.6223 (0.5716)	loss 2.7244 (2.7815)	grad_norm 2.5680 (inf)	mem 17417MB
[2023-02-02 12:05:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][950/1251]	eta 0:02:51 lr 0.000131	time 0.5599 (0.5714)	loss 3.0020 (2.7808)	grad_norm 2.1287 (inf)	mem 17417MB
[2023-02-02 12:05:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][1000/1251]	eta 0:02:23 lr 0.000131	time 0.5547 (0.5713)	loss 2.8300 (2.7802)	grad_norm 2.2888 (inf)	mem 17417MB
[2023-02-02 12:06:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][1050/1251]	eta 0:01:54 lr 0.000131	time 0.5540 (0.5712)	loss 3.4487 (2.7763)	grad_norm 2.2567 (inf)	mem 17417MB
[2023-02-02 12:06:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][1100/1251]	eta 0:01:26 lr 0.000131	time 0.5567 (0.5713)	loss 2.0273 (2.7792)	grad_norm 2.2604 (inf)	mem 17417MB
[2023-02-02 12:07:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][1150/1251]	eta 0:00:57 lr 0.000131	time 0.5553 (0.5712)	loss 3.2322 (2.7821)	grad_norm 2.1712 (inf)	mem 17417MB
[2023-02-02 12:07:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][1200/1251]	eta 0:00:29 lr 0.000130	time 0.5697 (0.5711)	loss 3.1222 (2.7841)	grad_norm 2.1464 (inf)	mem 17417MB
[2023-02-02 12:08:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [231/300][1250/1251]	eta 0:00:00 lr 0.000130	time 0.5509 (0.5711)	loss 3.1041 (2.7865)	grad_norm 2.0855 (inf)	mem 17417MB
[2023-02-02 12:08:00 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 231 training takes 0:11:54
[2023-02-02 12:08:00 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_231.pth saving......
[2023-02-02 12:08:02 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_231.pth saved !!!
[2023-02-02 12:08:03 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.840 (0.840)	Loss 0.6882 (0.6882)	Acc@1 83.398 (83.398)	Acc@5 97.461 (97.461)	Mem 17417MB
[2023-02-02 12:08:11 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.952 Acc@5 96.474
[2023-02-02 12:08:11 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.0%
[2023-02-02 12:08:12 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.197 (1.197)	Loss 0.6414 (0.6414)	Acc@1 84.375 (84.375)	Acc@5 97.656 (97.656)	Mem 17417MB
[2023-02-02 12:08:20 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.588 Acc@5 96.826
[2023-02-02 12:08:20 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.6%
[2023-02-02 12:08:20 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.60% at 225 epoch
[2023-02-02 12:08:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][0/1251]	eta 0:33:52 lr 0.000130	time 1.6250 (1.6250)	loss 2.8728 (2.8728)	grad_norm 2.2051 (2.2051)	mem 17417MB
[2023-02-02 12:08:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][50/1251]	eta 0:11:48 lr 0.000130	time 0.5554 (0.5903)	loss 2.5852 (2.8679)	grad_norm 2.0228 (2.1913)	mem 17417MB
[2023-02-02 12:09:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][100/1251]	eta 0:11:08 lr 0.000130	time 0.5536 (0.5806)	loss 2.8989 (2.8303)	grad_norm 2.1401 (2.2424)	mem 17417MB
[2023-02-02 12:09:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][150/1251]	eta 0:10:33 lr 0.000130	time 0.5513 (0.5758)	loss 2.3056 (2.8060)	grad_norm 2.0381 (2.2476)	mem 17417MB
[2023-02-02 12:10:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][200/1251]	eta 0:10:03 lr 0.000130	time 0.5511 (0.5746)	loss 3.4362 (2.7869)	grad_norm 2.1816 (2.2441)	mem 17417MB
[2023-02-02 12:10:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][250/1251]	eta 0:09:33 lr 0.000130	time 0.5618 (0.5732)	loss 3.3060 (2.7858)	grad_norm 2.5481 (2.2530)	mem 17417MB
[2023-02-02 12:11:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][300/1251]	eta 0:09:04 lr 0.000129	time 0.5515 (0.5727)	loss 1.5990 (2.7807)	grad_norm 2.2646 (2.2540)	mem 17417MB
[2023-02-02 12:11:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][350/1251]	eta 0:08:35 lr 0.000129	time 0.5602 (0.5720)	loss 1.6502 (2.7694)	grad_norm 2.1332 (2.2566)	mem 17417MB
[2023-02-02 12:12:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][400/1251]	eta 0:08:06 lr 0.000129	time 0.6279 (0.5717)	loss 2.4396 (2.7692)	grad_norm 2.0657 (2.2538)	mem 17417MB
[2023-02-02 12:12:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][450/1251]	eta 0:07:37 lr 0.000129	time 0.5540 (0.5713)	loss 2.7306 (2.7676)	grad_norm 1.9346 (2.2527)	mem 17417MB
[2023-02-02 12:13:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][500/1251]	eta 0:07:08 lr 0.000129	time 0.5504 (0.5708)	loss 3.0075 (2.7637)	grad_norm 2.0183 (2.2525)	mem 17417MB
[2023-02-02 12:13:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][550/1251]	eta 0:06:40 lr 0.000129	time 0.5489 (0.5706)	loss 3.0332 (2.7701)	grad_norm 2.1760 (2.2587)	mem 17417MB
[2023-02-02 12:14:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][600/1251]	eta 0:06:11 lr 0.000129	time 0.5546 (0.5707)	loss 2.9231 (2.7652)	grad_norm 2.0531 (2.2578)	mem 17417MB
[2023-02-02 12:14:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][650/1251]	eta 0:05:42 lr 0.000129	time 0.5542 (0.5706)	loss 2.8521 (2.7691)	grad_norm 2.1866 (2.2533)	mem 17417MB
[2023-02-02 12:15:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][700/1251]	eta 0:05:14 lr 0.000128	time 0.5677 (0.5704)	loss 3.0911 (2.7713)	grad_norm 2.3528 (2.2511)	mem 17417MB
[2023-02-02 12:15:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][750/1251]	eta 0:04:45 lr 0.000128	time 0.6444 (0.5705)	loss 3.2605 (2.7680)	grad_norm 1.9986 (2.2504)	mem 17417MB
[2023-02-02 12:15:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][800/1251]	eta 0:04:17 lr 0.000128	time 0.6272 (0.5702)	loss 2.9107 (2.7650)	grad_norm 2.0120 (2.2524)	mem 17417MB
[2023-02-02 12:16:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][850/1251]	eta 0:03:48 lr 0.000128	time 0.5737 (0.5702)	loss 2.8698 (2.7620)	grad_norm 2.1122 (2.2514)	mem 17417MB
[2023-02-02 12:16:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][900/1251]	eta 0:03:20 lr 0.000128	time 0.5518 (0.5703)	loss 2.1264 (2.7554)	grad_norm 2.1138 (2.2503)	mem 17417MB
[2023-02-02 12:17:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][950/1251]	eta 0:02:51 lr 0.000128	time 0.5546 (0.5701)	loss 3.1463 (2.7621)	grad_norm 2.2208 (2.2476)	mem 17417MB
[2023-02-02 12:17:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][1000/1251]	eta 0:02:23 lr 0.000128	time 0.5487 (0.5701)	loss 3.0421 (2.7622)	grad_norm 1.9667 (2.2462)	mem 17417MB
[2023-02-02 12:18:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][1050/1251]	eta 0:01:54 lr 0.000127	time 0.5525 (0.5702)	loss 2.8256 (2.7653)	grad_norm 2.0188 (2.2469)	mem 17417MB
[2023-02-02 12:18:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][1100/1251]	eta 0:01:26 lr 0.000127	time 0.6310 (0.5700)	loss 2.5953 (2.7605)	grad_norm 2.2688 (2.2476)	mem 17417MB
[2023-02-02 12:19:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][1150/1251]	eta 0:00:57 lr 0.000127	time 0.5616 (0.5701)	loss 3.0797 (2.7608)	grad_norm 2.2272 (2.2440)	mem 17417MB
[2023-02-02 12:19:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][1200/1251]	eta 0:00:29 lr 0.000127	time 0.5570 (0.5699)	loss 3.1896 (2.7553)	grad_norm 2.1806 (2.2466)	mem 17417MB
[2023-02-02 12:20:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [232/300][1250/1251]	eta 0:00:00 lr 0.000127	time 0.5499 (0.5700)	loss 3.4157 (2.7567)	grad_norm 2.2281 (2.2445)	mem 17417MB
[2023-02-02 12:20:13 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 232 training takes 0:11:53
[2023-02-02 12:20:14 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_232.pth saving......
[2023-02-02 12:20:15 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_232.pth saved !!!
[2023-02-02 12:20:16 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.887 (0.887)	Loss 0.7039 (0.7039)	Acc@1 83.008 (83.008)	Acc@5 96.973 (96.973)	Mem 17417MB
[2023-02-02 12:20:24 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 82.984 Acc@5 96.512
[2023-02-02 12:20:24 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.0%
[2023-02-02 12:20:26 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.323 (1.323)	Loss 0.6749 (0.6749)	Acc@1 83.594 (83.594)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-02 12:20:34 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.600 Acc@5 96.832
[2023-02-02 12:20:34 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.6%
[2023-02-02 12:20:34 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.60% at 232 epoch
[2023-02-02 12:20:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][0/1251]	eta 0:37:42 lr 0.000127	time 1.8083 (1.8083)	loss 2.6851 (2.6851)	grad_norm 2.3447 (2.3447)	mem 17417MB
[2023-02-02 12:21:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][50/1251]	eta 0:11:52 lr 0.000127	time 0.5573 (0.5934)	loss 2.9576 (2.8641)	grad_norm 2.3837 (inf)	mem 17417MB
[2023-02-02 12:21:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][100/1251]	eta 0:11:09 lr 0.000127	time 0.5604 (0.5820)	loss 1.9509 (2.8057)	grad_norm 2.2748 (inf)	mem 17417MB
[2023-02-02 12:22:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][150/1251]	eta 0:10:35 lr 0.000127	time 0.5615 (0.5771)	loss 2.5366 (2.8292)	grad_norm 2.5509 (inf)	mem 17417MB
[2023-02-02 12:22:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][200/1251]	eta 0:10:03 lr 0.000126	time 0.5517 (0.5746)	loss 3.2609 (2.8208)	grad_norm 2.1403 (inf)	mem 17417MB
[2023-02-02 12:22:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][250/1251]	eta 0:09:34 lr 0.000126	time 0.5521 (0.5737)	loss 2.8674 (2.8152)	grad_norm 2.3155 (inf)	mem 17417MB
[2023-02-02 12:23:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][300/1251]	eta 0:09:05 lr 0.000126	time 0.5619 (0.5733)	loss 2.9743 (2.8006)	grad_norm 2.1878 (inf)	mem 17417MB
[2023-02-02 12:23:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][350/1251]	eta 0:08:35 lr 0.000126	time 0.5550 (0.5727)	loss 3.3558 (2.8015)	grad_norm 2.0931 (inf)	mem 17417MB
[2023-02-02 12:24:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][400/1251]	eta 0:08:06 lr 0.000126	time 0.5537 (0.5722)	loss 3.4896 (2.8144)	grad_norm 2.3876 (inf)	mem 17417MB
[2023-02-02 12:24:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][450/1251]	eta 0:07:37 lr 0.000126	time 0.5572 (0.5717)	loss 3.6378 (2.8176)	grad_norm 2.1922 (inf)	mem 17417MB
[2023-02-02 12:25:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][500/1251]	eta 0:07:09 lr 0.000126	time 0.5542 (0.5713)	loss 2.8384 (2.8215)	grad_norm 2.3039 (inf)	mem 17417MB
[2023-02-02 12:25:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][550/1251]	eta 0:06:40 lr 0.000125	time 0.5601 (0.5714)	loss 3.3428 (2.8293)	grad_norm 2.7345 (inf)	mem 17417MB
[2023-02-02 12:26:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][600/1251]	eta 0:06:11 lr 0.000125	time 0.5583 (0.5712)	loss 2.8102 (2.8193)	grad_norm 2.4549 (inf)	mem 17417MB
[2023-02-02 12:26:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][650/1251]	eta 0:05:43 lr 0.000125	time 0.5537 (0.5713)	loss 3.1799 (2.8087)	grad_norm 2.7222 (inf)	mem 17417MB
[2023-02-02 12:27:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][700/1251]	eta 0:05:14 lr 0.000125	time 0.5574 (0.5708)	loss 2.8521 (2.8052)	grad_norm 2.4285 (inf)	mem 17417MB
[2023-02-02 12:27:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][750/1251]	eta 0:04:45 lr 0.000125	time 0.5544 (0.5706)	loss 2.2462 (2.8020)	grad_norm 2.5661 (inf)	mem 17417MB
[2023-02-02 12:28:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][800/1251]	eta 0:04:17 lr 0.000125	time 0.5594 (0.5704)	loss 2.6957 (2.7916)	grad_norm 2.0524 (inf)	mem 17417MB
[2023-02-02 12:28:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][850/1251]	eta 0:03:48 lr 0.000125	time 0.5600 (0.5702)	loss 2.6878 (2.7941)	grad_norm 2.1373 (inf)	mem 17417MB
[2023-02-02 12:29:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][900/1251]	eta 0:03:20 lr 0.000125	time 0.5483 (0.5700)	loss 2.8976 (2.7892)	grad_norm 2.1170 (inf)	mem 17417MB
[2023-02-02 12:29:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][950/1251]	eta 0:02:51 lr 0.000124	time 0.5489 (0.5698)	loss 2.2052 (2.7892)	grad_norm 2.1038 (inf)	mem 17417MB
[2023-02-02 12:30:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][1000/1251]	eta 0:02:23 lr 0.000124	time 0.5530 (0.5697)	loss 2.1495 (2.7910)	grad_norm 2.2983 (inf)	mem 17417MB
[2023-02-02 12:30:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][1050/1251]	eta 0:01:54 lr 0.000124	time 0.5586 (0.5698)	loss 1.8715 (2.7958)	grad_norm 1.9994 (inf)	mem 17417MB
[2023-02-02 12:31:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][1100/1251]	eta 0:01:26 lr 0.000124	time 0.6307 (0.5699)	loss 2.7781 (2.7984)	grad_norm 2.0889 (inf)	mem 17417MB
[2023-02-02 12:31:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][1150/1251]	eta 0:00:57 lr 0.000124	time 0.5613 (0.5697)	loss 1.9846 (2.7979)	grad_norm 1.7710 (inf)	mem 17417MB
[2023-02-02 12:31:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][1200/1251]	eta 0:00:29 lr 0.000124	time 0.5529 (0.5696)	loss 2.9512 (2.7992)	grad_norm 2.3416 (inf)	mem 17417MB
[2023-02-02 12:32:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [233/300][1250/1251]	eta 0:00:00 lr 0.000124	time 0.5498 (0.5696)	loss 3.2152 (2.8016)	grad_norm 2.3507 (inf)	mem 17417MB
[2023-02-02 12:32:26 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 233 training takes 0:11:52
[2023-02-02 12:32:26 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_233.pth saving......
[2023-02-02 12:32:28 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_233.pth saved !!!
[2023-02-02 12:32:29 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.039 (1.039)	Loss 0.6717 (0.6717)	Acc@1 84.180 (84.180)	Acc@5 97.168 (97.168)	Mem 17417MB
[2023-02-02 12:32:37 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.082 Acc@5 96.494
[2023-02-02 12:32:37 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.1%
[2023-02-02 12:32:39 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.207 (1.207)	Loss 0.6416 (0.6416)	Acc@1 84.375 (84.375)	Acc@5 97.363 (97.363)	Mem 17417MB
[2023-02-02 12:32:47 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.632 Acc@5 96.818
[2023-02-02 12:32:47 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.6%
[2023-02-02 12:32:47 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.63% at 233 epoch
[2023-02-02 12:32:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][0/1251]	eta 0:35:56 lr 0.000124	time 1.7242 (1.7242)	loss 2.9502 (2.9502)	grad_norm 1.8792 (1.8792)	mem 17417MB
[2023-02-02 12:33:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][50/1251]	eta 0:11:49 lr 0.000123	time 0.5607 (0.5910)	loss 3.1204 (2.9272)	grad_norm 2.3279 (2.2919)	mem 17417MB
[2023-02-02 12:33:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][100/1251]	eta 0:11:12 lr 0.000123	time 0.6147 (0.5846)	loss 2.9397 (2.8608)	grad_norm 2.0742 (2.2615)	mem 17417MB
[2023-02-02 12:34:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][150/1251]	eta 0:10:35 lr 0.000123	time 0.5815 (0.5775)	loss 2.0371 (2.8197)	grad_norm 2.5579 (2.2411)	mem 17417MB
[2023-02-02 12:34:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][200/1251]	eta 0:10:05 lr 0.000123	time 0.5537 (0.5757)	loss 2.5604 (2.7936)	grad_norm 2.4080 (2.2615)	mem 17417MB
[2023-02-02 12:35:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][250/1251]	eta 0:09:35 lr 0.000123	time 0.5567 (0.5745)	loss 3.3765 (2.7942)	grad_norm 2.1675 (2.2587)	mem 17417MB
[2023-02-02 12:35:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][300/1251]	eta 0:09:05 lr 0.000123	time 0.5502 (0.5733)	loss 3.0627 (2.7846)	grad_norm 2.0479 (2.2691)	mem 17417MB
[2023-02-02 12:36:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][350/1251]	eta 0:08:36 lr 0.000123	time 0.5598 (0.5728)	loss 2.2575 (2.7869)	grad_norm 2.2649 (2.2668)	mem 17417MB
[2023-02-02 12:36:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][400/1251]	eta 0:08:07 lr 0.000123	time 0.6499 (0.5725)	loss 2.4053 (2.7812)	grad_norm 2.3642 (2.2602)	mem 17417MB
[2023-02-02 12:37:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][450/1251]	eta 0:07:38 lr 0.000122	time 0.5526 (0.5719)	loss 2.9930 (2.7702)	grad_norm 2.2193 (2.2535)	mem 17417MB
[2023-02-02 12:37:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][500/1251]	eta 0:07:09 lr 0.000122	time 0.6264 (0.5717)	loss 3.0447 (2.7681)	grad_norm 2.0073 (2.2528)	mem 17417MB
[2023-02-02 12:38:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][550/1251]	eta 0:06:40 lr 0.000122	time 0.5520 (0.5712)	loss 2.9608 (2.7704)	grad_norm 2.2796 (2.2489)	mem 17417MB
[2023-02-02 12:38:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][600/1251]	eta 0:06:11 lr 0.000122	time 0.5582 (0.5711)	loss 3.0778 (2.7723)	grad_norm 2.4396 (2.2478)	mem 17417MB
[2023-02-02 12:38:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][650/1251]	eta 0:05:43 lr 0.000122	time 0.5516 (0.5711)	loss 2.5597 (2.7676)	grad_norm 1.9322 (2.2444)	mem 17417MB
[2023-02-02 12:39:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][700/1251]	eta 0:05:14 lr 0.000122	time 0.5497 (0.5706)	loss 2.4962 (2.7662)	grad_norm 2.2419 (2.2424)	mem 17417MB
[2023-02-02 12:39:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][750/1251]	eta 0:04:45 lr 0.000122	time 0.5532 (0.5707)	loss 3.0064 (2.7655)	grad_norm 2.1980 (2.2486)	mem 17417MB
[2023-02-02 12:40:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][800/1251]	eta 0:04:17 lr 0.000121	time 0.5781 (0.5705)	loss 2.2365 (2.7697)	grad_norm 2.1582 (2.2490)	mem 17417MB
[2023-02-02 12:40:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][850/1251]	eta 0:03:48 lr 0.000121	time 0.5525 (0.5703)	loss 2.8500 (2.7693)	grad_norm 2.1484 (2.2480)	mem 17417MB
[2023-02-02 12:41:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][900/1251]	eta 0:03:20 lr 0.000121	time 0.6373 (0.5703)	loss 2.8509 (2.7707)	grad_norm 2.2005 (2.2469)	mem 17417MB
[2023-02-02 12:41:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][950/1251]	eta 0:02:51 lr 0.000121	time 0.5559 (0.5701)	loss 2.1284 (2.7694)	grad_norm 2.4153 (2.2468)	mem 17417MB
[2023-02-02 12:42:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][1000/1251]	eta 0:02:23 lr 0.000121	time 0.5498 (0.5700)	loss 3.1026 (2.7664)	grad_norm 2.4551 (2.2449)	mem 17417MB
[2023-02-02 12:42:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][1050/1251]	eta 0:01:54 lr 0.000121	time 0.5614 (0.5701)	loss 2.4948 (2.7674)	grad_norm 2.3155 (2.2490)	mem 17417MB
[2023-02-02 12:43:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][1100/1251]	eta 0:01:26 lr 0.000121	time 0.6499 (0.5700)	loss 2.9796 (2.7696)	grad_norm 2.7299 (2.2482)	mem 17417MB
[2023-02-02 12:43:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][1150/1251]	eta 0:00:57 lr 0.000121	time 0.6250 (0.5699)	loss 3.0150 (2.7669)	grad_norm 1.9972 (2.2513)	mem 17417MB
[2023-02-02 12:44:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][1200/1251]	eta 0:00:29 lr 0.000120	time 0.5607 (0.5698)	loss 3.2509 (2.7657)	grad_norm 2.0623 (2.2503)	mem 17417MB
[2023-02-02 12:44:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [234/300][1250/1251]	eta 0:00:00 lr 0.000120	time 0.5518 (0.5697)	loss 3.0058 (2.7648)	grad_norm 1.9171 (2.2524)	mem 17417MB
[2023-02-02 12:44:40 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 234 training takes 0:11:52
[2023-02-02 12:44:40 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_234.pth saving......
[2023-02-02 12:44:42 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_234.pth saved !!!
[2023-02-02 12:44:42 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.884 (0.884)	Loss 0.7472 (0.7472)	Acc@1 83.496 (83.496)	Acc@5 95.215 (95.215)	Mem 17417MB
[2023-02-02 12:44:50 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.012 Acc@5 96.464
[2023-02-02 12:44:50 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.0%
[2023-02-02 12:44:52 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.213 (1.213)	Loss 0.6628 (0.6628)	Acc@1 83.984 (83.984)	Acc@5 97.266 (97.266)	Mem 17417MB
[2023-02-02 12:45:00 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.640 Acc@5 96.810
[2023-02-02 12:45:00 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.6%
[2023-02-02 12:45:00 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.64% at 234 epoch
[2023-02-02 12:45:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][0/1251]	eta 0:37:35 lr 0.000120	time 1.8026 (1.8026)	loss 2.8292 (2.8292)	grad_norm 2.7986 (2.7986)	mem 17417MB
[2023-02-02 12:45:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][50/1251]	eta 0:11:57 lr 0.000120	time 0.5574 (0.5974)	loss 3.2511 (2.8239)	grad_norm 2.2046 (2.2914)	mem 17417MB
[2023-02-02 12:45:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][100/1251]	eta 0:11:12 lr 0.000120	time 0.5517 (0.5843)	loss 3.2944 (2.7268)	grad_norm 2.7267 (2.3052)	mem 17417MB
[2023-02-02 12:46:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][150/1251]	eta 0:10:36 lr 0.000120	time 0.5540 (0.5784)	loss 3.3888 (2.7240)	grad_norm 2.5729 (2.2776)	mem 17417MB
[2023-02-02 12:46:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][200/1251]	eta 0:10:04 lr 0.000120	time 0.5634 (0.5754)	loss 2.2650 (2.7613)	grad_norm 1.9709 (2.2690)	mem 17417MB
[2023-02-02 12:47:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][250/1251]	eta 0:09:34 lr 0.000120	time 0.5605 (0.5744)	loss 2.6266 (2.7427)	grad_norm 2.4237 (2.2599)	mem 17417MB
[2023-02-02 12:47:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][300/1251]	eta 0:09:05 lr 0.000120	time 0.5534 (0.5735)	loss 2.9142 (2.7563)	grad_norm 2.4848 (2.2555)	mem 17417MB
[2023-02-02 12:48:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][350/1251]	eta 0:08:36 lr 0.000119	time 0.5560 (0.5733)	loss 2.2170 (2.7485)	grad_norm 2.1512 (2.2640)	mem 17417MB
[2023-02-02 12:48:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][400/1251]	eta 0:08:06 lr 0.000119	time 0.5597 (0.5721)	loss 2.7517 (2.7438)	grad_norm 2.0684 (2.2586)	mem 17417MB
[2023-02-02 12:49:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][450/1251]	eta 0:07:38 lr 0.000119	time 0.6294 (0.5723)	loss 2.7531 (2.7472)	grad_norm 2.0367 (2.2622)	mem 17417MB
[2023-02-02 12:49:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][500/1251]	eta 0:07:09 lr 0.000119	time 0.5608 (0.5717)	loss 2.1648 (2.7418)	grad_norm 2.1339 (2.2592)	mem 17417MB
[2023-02-02 12:50:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][550/1251]	eta 0:06:40 lr 0.000119	time 0.5521 (0.5717)	loss 3.0411 (2.7483)	grad_norm 2.0614 (2.2588)	mem 17417MB
[2023-02-02 12:50:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][600/1251]	eta 0:06:12 lr 0.000119	time 0.5598 (0.5714)	loss 3.1582 (2.7520)	grad_norm 2.7489 (2.2610)	mem 17417MB
[2023-02-02 12:51:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][650/1251]	eta 0:05:43 lr 0.000119	time 0.5550 (0.5712)	loss 3.0291 (2.7566)	grad_norm 2.1763 (2.2559)	mem 17417MB
[2023-02-02 12:51:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][700/1251]	eta 0:05:14 lr 0.000118	time 0.5487 (0.5710)	loss 2.9958 (2.7557)	grad_norm 1.9351 (2.2638)	mem 17417MB
[2023-02-02 12:52:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][750/1251]	eta 0:04:45 lr 0.000118	time 0.5593 (0.5708)	loss 2.3406 (2.7520)	grad_norm 2.2834 (2.2626)	mem 17417MB
[2023-02-02 12:52:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][800/1251]	eta 0:04:17 lr 0.000118	time 0.5525 (0.5709)	loss 2.9094 (2.7538)	grad_norm 3.7518 (2.2665)	mem 17417MB
[2023-02-02 12:53:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][850/1251]	eta 0:03:48 lr 0.000118	time 0.6221 (0.5709)	loss 2.4074 (2.7558)	grad_norm 2.4520 (2.2715)	mem 17417MB
[2023-02-02 12:53:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][900/1251]	eta 0:03:20 lr 0.000118	time 0.5682 (0.5708)	loss 3.5056 (2.7551)	grad_norm 2.2631 (2.2713)	mem 17417MB
[2023-02-02 12:54:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][950/1251]	eta 0:02:51 lr 0.000118	time 0.5610 (0.5706)	loss 2.4549 (2.7534)	grad_norm 2.9433 (2.2721)	mem 17417MB
[2023-02-02 12:54:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][1000/1251]	eta 0:02:23 lr 0.000118	time 0.6195 (0.5706)	loss 2.4772 (2.7573)	grad_norm 2.5868 (2.2699)	mem 17417MB
[2023-02-02 12:55:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][1050/1251]	eta 0:01:54 lr 0.000118	time 0.5561 (0.5707)	loss 3.1655 (2.7601)	grad_norm 2.0948 (2.2732)	mem 17417MB
[2023-02-02 12:55:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][1100/1251]	eta 0:01:26 lr 0.000117	time 0.5494 (0.5705)	loss 2.8572 (2.7579)	grad_norm 2.2378 (2.2733)	mem 17417MB
[2023-02-02 12:55:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][1150/1251]	eta 0:00:57 lr 0.000117	time 0.5551 (0.5705)	loss 2.6053 (2.7572)	grad_norm 1.9271 (2.2704)	mem 17417MB
[2023-02-02 12:56:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][1200/1251]	eta 0:00:29 lr 0.000117	time 0.5625 (0.5704)	loss 2.2299 (2.7560)	grad_norm 2.3910 (2.2690)	mem 17417MB
[2023-02-02 12:56:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [235/300][1250/1251]	eta 0:00:00 lr 0.000117	time 0.5530 (0.5704)	loss 2.8805 (2.7506)	grad_norm 2.2953 (2.2681)	mem 17417MB
[2023-02-02 12:56:53 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 235 training takes 0:11:53
[2023-02-02 12:56:54 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_235.pth saving......
[2023-02-02 12:56:55 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_235.pth saved !!!
[2023-02-02 12:56:56 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.872 (0.872)	Loss 0.7458 (0.7458)	Acc@1 83.789 (83.789)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-02 12:57:04 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.234 Acc@5 96.498
[2023-02-02 12:57:04 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.2%
[2023-02-02 12:57:05 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.280 (1.280)	Loss 0.6366 (0.6366)	Acc@1 84.473 (84.473)	Acc@5 97.266 (97.266)	Mem 17417MB
[2023-02-02 12:57:13 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.686 Acc@5 96.822
[2023-02-02 12:57:13 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.7%
[2023-02-02 12:57:13 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.69% at 235 epoch
[2023-02-02 12:57:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][0/1251]	eta 0:34:42 lr 0.000117	time 1.6646 (1.6646)	loss 3.3874 (3.3874)	grad_norm 2.0356 (2.0356)	mem 17417MB
[2023-02-02 12:57:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][50/1251]	eta 0:11:49 lr 0.000117	time 0.5534 (0.5908)	loss 3.0223 (2.7882)	grad_norm 2.1392 (2.3382)	mem 17417MB
[2023-02-02 12:58:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][100/1251]	eta 0:11:09 lr 0.000117	time 0.6284 (0.5816)	loss 2.5841 (2.7717)	grad_norm 2.2223 (2.3387)	mem 17417MB
[2023-02-02 12:58:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][150/1251]	eta 0:10:35 lr 0.000117	time 0.5533 (0.5774)	loss 2.7778 (2.7671)	grad_norm 2.5820 (2.3255)	mem 17417MB
[2023-02-02 12:59:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][200/1251]	eta 0:10:04 lr 0.000117	time 0.5620 (0.5754)	loss 3.3433 (2.7515)	grad_norm 2.3268 (2.3183)	mem 17417MB
[2023-02-02 12:59:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][250/1251]	eta 0:09:34 lr 0.000116	time 0.5636 (0.5742)	loss 3.0329 (2.7289)	grad_norm 2.2671 (2.3190)	mem 17417MB
[2023-02-02 13:00:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][300/1251]	eta 0:09:04 lr 0.000116	time 0.5606 (0.5730)	loss 3.2327 (2.7405)	grad_norm 2.4181 (inf)	mem 17417MB
[2023-02-02 13:00:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][350/1251]	eta 0:08:35 lr 0.000116	time 0.5647 (0.5723)	loss 3.0778 (2.7431)	grad_norm 2.2596 (inf)	mem 17417MB
[2023-02-02 13:01:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][400/1251]	eta 0:08:06 lr 0.000116	time 0.5479 (0.5722)	loss 2.7412 (2.7419)	grad_norm 2.6271 (inf)	mem 17417MB
[2023-02-02 13:01:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][450/1251]	eta 0:07:37 lr 0.000116	time 0.5490 (0.5716)	loss 3.2062 (2.7473)	grad_norm 1.9342 (inf)	mem 17417MB
[2023-02-02 13:02:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][500/1251]	eta 0:07:09 lr 0.000116	time 0.6203 (0.5716)	loss 2.3453 (2.7436)	grad_norm 2.0955 (inf)	mem 17417MB
[2023-02-02 13:02:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][550/1251]	eta 0:06:40 lr 0.000116	time 0.5634 (0.5712)	loss 2.6880 (2.7490)	grad_norm 2.0260 (inf)	mem 17417MB
[2023-02-02 13:02:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][600/1251]	eta 0:06:11 lr 0.000116	time 0.5605 (0.5710)	loss 3.0319 (2.7443)	grad_norm 2.4767 (inf)	mem 17417MB
[2023-02-02 13:03:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][650/1251]	eta 0:05:43 lr 0.000115	time 0.5685 (0.5709)	loss 3.0272 (2.7411)	grad_norm 2.0298 (inf)	mem 17417MB
[2023-02-02 13:03:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][700/1251]	eta 0:05:14 lr 0.000115	time 0.5593 (0.5709)	loss 3.0022 (2.7366)	grad_norm 2.1439 (inf)	mem 17417MB
[2023-02-02 13:04:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][750/1251]	eta 0:04:45 lr 0.000115	time 0.5608 (0.5708)	loss 2.7602 (2.7441)	grad_norm 2.0973 (inf)	mem 17417MB
[2023-02-02 13:04:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][800/1251]	eta 0:04:17 lr 0.000115	time 0.6260 (0.5708)	loss 2.8504 (2.7405)	grad_norm 2.3367 (inf)	mem 17417MB
[2023-02-02 13:05:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][850/1251]	eta 0:03:48 lr 0.000115	time 0.5695 (0.5706)	loss 2.9965 (2.7389)	grad_norm 2.4957 (inf)	mem 17417MB
[2023-02-02 13:05:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][900/1251]	eta 0:03:20 lr 0.000115	time 0.6188 (0.5706)	loss 2.5242 (2.7366)	grad_norm 2.2755 (inf)	mem 17417MB
[2023-02-02 13:06:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][950/1251]	eta 0:02:51 lr 0.000115	time 0.5568 (0.5706)	loss 2.9958 (2.7385)	grad_norm 2.6997 (inf)	mem 17417MB
[2023-02-02 13:06:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][1000/1251]	eta 0:02:23 lr 0.000115	time 0.5678 (0.5705)	loss 3.1670 (2.7348)	grad_norm 2.3881 (inf)	mem 17417MB
[2023-02-02 13:07:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][1050/1251]	eta 0:01:54 lr 0.000114	time 0.5535 (0.5705)	loss 3.1560 (2.7348)	grad_norm 2.2217 (inf)	mem 17417MB
[2023-02-02 13:07:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][1100/1251]	eta 0:01:26 lr 0.000114	time 0.5545 (0.5704)	loss 2.6120 (2.7347)	grad_norm 2.3947 (inf)	mem 17417MB
[2023-02-02 13:08:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][1150/1251]	eta 0:00:57 lr 0.000114	time 0.5585 (0.5703)	loss 2.7994 (2.7352)	grad_norm 2.4059 (inf)	mem 17417MB
[2023-02-02 13:08:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][1200/1251]	eta 0:00:29 lr 0.000114	time 0.5483 (0.5703)	loss 3.1405 (2.7350)	grad_norm 1.9761 (inf)	mem 17417MB
[2023-02-02 13:09:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [236/300][1250/1251]	eta 0:00:00 lr 0.000114	time 0.5510 (0.5703)	loss 3.0853 (2.7383)	grad_norm 2.3027 (inf)	mem 17417MB
[2023-02-02 13:09:07 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 236 training takes 0:11:53
[2023-02-02 13:09:07 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_236.pth saving......
[2023-02-02 13:09:09 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_236.pth saved !!!
[2023-02-02 13:09:10 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.926 (0.926)	Loss 0.6994 (0.6994)	Acc@1 83.105 (83.105)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-02 13:09:18 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.254 Acc@5 96.518
[2023-02-02 13:09:18 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.3%
[2023-02-02 13:09:19 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.520 (1.520)	Loss 0.6812 (0.6812)	Acc@1 82.324 (82.324)	Acc@5 96.582 (96.582)	Mem 17417MB
[2023-02-02 13:09:27 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.704 Acc@5 96.814
[2023-02-02 13:09:27 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.7%
[2023-02-02 13:09:27 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.70% at 236 epoch
[2023-02-02 13:09:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][0/1251]	eta 0:37:25 lr 0.000114	time 1.7947 (1.7947)	loss 2.6349 (2.6349)	grad_norm 2.2791 (2.2791)	mem 17417MB
[2023-02-02 13:09:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][50/1251]	eta 0:11:55 lr 0.000114	time 0.5492 (0.5960)	loss 3.0044 (2.7183)	grad_norm 2.4795 (2.2482)	mem 17417MB
[2023-02-02 13:10:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][100/1251]	eta 0:11:10 lr 0.000114	time 0.5524 (0.5822)	loss 2.2607 (2.6735)	grad_norm 2.1544 (2.2911)	mem 17417MB
[2023-02-02 13:10:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][150/1251]	eta 0:10:36 lr 0.000113	time 0.5506 (0.5783)	loss 3.3712 (2.6500)	grad_norm 2.0565 (2.2822)	mem 17417MB
[2023-02-02 13:11:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][200/1251]	eta 0:10:05 lr 0.000113	time 0.5679 (0.5759)	loss 2.7770 (2.6874)	grad_norm 2.1709 (2.2927)	mem 17417MB
[2023-02-02 13:11:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][250/1251]	eta 0:09:34 lr 0.000113	time 0.5571 (0.5744)	loss 2.9246 (2.6950)	grad_norm 1.9987 (2.3064)	mem 17417MB
[2023-02-02 13:12:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][300/1251]	eta 0:09:05 lr 0.000113	time 0.5537 (0.5736)	loss 3.5624 (2.7063)	grad_norm 2.5306 (2.2847)	mem 17417MB
[2023-02-02 13:12:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][350/1251]	eta 0:08:36 lr 0.000113	time 0.5653 (0.5728)	loss 2.4661 (2.7060)	grad_norm 2.3874 (2.2830)	mem 17417MB
[2023-02-02 13:13:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][400/1251]	eta 0:08:06 lr 0.000113	time 0.5610 (0.5720)	loss 2.8100 (2.7184)	grad_norm 2.1330 (2.2889)	mem 17417MB
[2023-02-02 13:13:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][450/1251]	eta 0:07:38 lr 0.000113	time 0.6301 (0.5719)	loss 3.0353 (2.7279)	grad_norm 2.0786 (2.2917)	mem 17417MB
[2023-02-02 13:14:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][500/1251]	eta 0:07:08 lr 0.000113	time 0.5533 (0.5712)	loss 2.7829 (2.7270)	grad_norm 2.1131 (2.2955)	mem 17417MB
[2023-02-02 13:14:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][550/1251]	eta 0:06:40 lr 0.000112	time 0.5580 (0.5711)	loss 2.3042 (2.7251)	grad_norm 1.9906 (2.3010)	mem 17417MB
[2023-02-02 13:15:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][600/1251]	eta 0:06:11 lr 0.000112	time 0.5586 (0.5711)	loss 3.1431 (2.7338)	grad_norm 2.3435 (2.3056)	mem 17417MB
[2023-02-02 13:15:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][650/1251]	eta 0:05:43 lr 0.000112	time 0.5573 (0.5710)	loss 2.8655 (2.7354)	grad_norm 2.4874 (2.3036)	mem 17417MB
[2023-02-02 13:16:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][700/1251]	eta 0:05:14 lr 0.000112	time 0.5859 (0.5709)	loss 3.2488 (2.7331)	grad_norm 2.0250 (2.2954)	mem 17417MB
[2023-02-02 13:16:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][750/1251]	eta 0:04:45 lr 0.000112	time 0.5500 (0.5707)	loss 3.1468 (2.7279)	grad_norm 2.1083 (2.2923)	mem 17417MB
[2023-02-02 13:17:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][800/1251]	eta 0:04:17 lr 0.000112	time 0.5594 (0.5703)	loss 2.9515 (2.7301)	grad_norm 3.1453 (2.2893)	mem 17417MB
[2023-02-02 13:17:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][850/1251]	eta 0:03:48 lr 0.000112	time 0.5578 (0.5705)	loss 2.8191 (2.7297)	grad_norm 2.0885 (2.2908)	mem 17417MB
[2023-02-02 13:18:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][900/1251]	eta 0:03:20 lr 0.000112	time 0.5530 (0.5702)	loss 2.2616 (2.7318)	grad_norm 2.2335 (2.2905)	mem 17417MB
[2023-02-02 13:18:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][950/1251]	eta 0:02:51 lr 0.000111	time 0.5577 (0.5702)	loss 3.4474 (2.7329)	grad_norm 2.3787 (2.2911)	mem 17417MB
[2023-02-02 13:18:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][1000/1251]	eta 0:02:23 lr 0.000111	time 0.5594 (0.5700)	loss 2.6275 (2.7340)	grad_norm 2.3026 (2.2922)	mem 17417MB
[2023-02-02 13:19:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][1050/1251]	eta 0:01:54 lr 0.000111	time 0.5593 (0.5700)	loss 2.6746 (2.7339)	grad_norm 2.2832 (2.2938)	mem 17417MB
[2023-02-02 13:19:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][1100/1251]	eta 0:01:26 lr 0.000111	time 0.6140 (0.5700)	loss 2.6731 (2.7314)	grad_norm 2.0955 (2.2938)	mem 17417MB
[2023-02-02 13:20:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][1150/1251]	eta 0:00:57 lr 0.000111	time 0.5520 (0.5699)	loss 2.3650 (2.7322)	grad_norm 2.3071 (2.2948)	mem 17417MB
[2023-02-02 13:20:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][1200/1251]	eta 0:00:29 lr 0.000111	time 0.5571 (0.5698)	loss 3.1495 (2.7309)	grad_norm 2.6377 (2.2943)	mem 17417MB
[2023-02-02 13:21:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [237/300][1250/1251]	eta 0:00:00 lr 0.000111	time 0.5512 (0.5698)	loss 2.8546 (2.7335)	grad_norm 2.1899 (2.2955)	mem 17417MB
[2023-02-02 13:21:20 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 237 training takes 0:11:52
[2023-02-02 13:21:20 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_237.pth saving......
[2023-02-02 13:21:22 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_237.pth saved !!!
[2023-02-02 13:21:23 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.059 (1.059)	Loss 0.7238 (0.7238)	Acc@1 83.789 (83.789)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-02 13:21:31 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.372 Acc@5 96.598
[2023-02-02 13:21:31 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.4%
[2023-02-02 13:21:32 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.186 (1.186)	Loss 0.7065 (0.7065)	Acc@1 83.203 (83.203)	Acc@5 96.875 (96.875)	Mem 17417MB
[2023-02-02 13:21:40 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.714 Acc@5 96.828
[2023-02-02 13:21:40 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.7%
[2023-02-02 13:21:40 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.71% at 237 epoch
[2023-02-02 13:21:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][0/1251]	eta 0:33:09 lr 0.000111	time 1.5906 (1.5906)	loss 2.8991 (2.8991)	grad_norm 2.4397 (2.4397)	mem 17417MB
[2023-02-02 13:22:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][50/1251]	eta 0:11:45 lr 0.000111	time 0.5608 (0.5878)	loss 2.9849 (2.8411)	grad_norm 2.9836 (nan)	mem 17417MB
[2023-02-02 13:22:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][100/1251]	eta 0:11:06 lr 0.000110	time 0.5517 (0.5794)	loss 3.0050 (2.8091)	grad_norm 2.2175 (nan)	mem 17417MB
[2023-02-02 13:23:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][150/1251]	eta 0:10:33 lr 0.000110	time 0.5548 (0.5754)	loss 1.8667 (2.7782)	grad_norm 2.0390 (nan)	mem 17417MB
[2023-02-02 13:23:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][200/1251]	eta 0:10:03 lr 0.000110	time 0.5568 (0.5742)	loss 2.6205 (2.7917)	grad_norm 2.1155 (nan)	mem 17417MB
[2023-02-02 13:24:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][250/1251]	eta 0:09:33 lr 0.000110	time 0.5579 (0.5729)	loss 1.9049 (2.7824)	grad_norm 2.1424 (nan)	mem 17417MB
[2023-02-02 13:24:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][300/1251]	eta 0:09:04 lr 0.000110	time 0.5486 (0.5728)	loss 3.1518 (2.7730)	grad_norm 2.1549 (nan)	mem 17417MB
[2023-02-02 13:25:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][350/1251]	eta 0:08:35 lr 0.000110	time 0.5528 (0.5716)	loss 3.3768 (2.7728)	grad_norm 2.3455 (nan)	mem 17417MB
[2023-02-02 13:25:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][400/1251]	eta 0:08:06 lr 0.000110	time 0.5594 (0.5713)	loss 3.0129 (2.7821)	grad_norm 2.1692 (nan)	mem 17417MB
[2023-02-02 13:25:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][450/1251]	eta 0:07:37 lr 0.000110	time 0.5566 (0.5708)	loss 2.9461 (2.7697)	grad_norm 2.2469 (nan)	mem 17417MB
[2023-02-02 13:26:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][500/1251]	eta 0:07:08 lr 0.000109	time 0.5820 (0.5708)	loss 2.8465 (2.7571)	grad_norm 2.6575 (nan)	mem 17417MB
[2023-02-02 13:26:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][550/1251]	eta 0:06:40 lr 0.000109	time 0.5478 (0.5707)	loss 2.6692 (2.7632)	grad_norm 2.2082 (nan)	mem 17417MB
[2023-02-02 13:27:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][600/1251]	eta 0:06:11 lr 0.000109	time 0.5467 (0.5705)	loss 2.0100 (2.7642)	grad_norm 2.0779 (nan)	mem 17417MB
[2023-02-02 13:27:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][650/1251]	eta 0:05:42 lr 0.000109	time 0.5590 (0.5703)	loss 2.8086 (2.7650)	grad_norm 2.1717 (nan)	mem 17417MB
[2023-02-02 13:28:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][700/1251]	eta 0:05:14 lr 0.000109	time 0.5544 (0.5703)	loss 3.0975 (2.7568)	grad_norm 2.1990 (nan)	mem 17417MB
[2023-02-02 13:28:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][750/1251]	eta 0:04:45 lr 0.000109	time 0.5550 (0.5700)	loss 2.2190 (2.7568)	grad_norm 2.3446 (nan)	mem 17417MB
[2023-02-02 13:29:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][800/1251]	eta 0:04:16 lr 0.000109	time 0.6141 (0.5698)	loss 2.8993 (2.7589)	grad_norm 2.3731 (nan)	mem 17417MB
[2023-02-02 13:29:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][850/1251]	eta 0:03:48 lr 0.000109	time 0.5759 (0.5697)	loss 2.6976 (2.7581)	grad_norm 2.2491 (nan)	mem 17417MB
[2023-02-02 13:30:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][900/1251]	eta 0:03:19 lr 0.000108	time 0.5580 (0.5697)	loss 2.6919 (2.7580)	grad_norm 2.2362 (nan)	mem 17417MB
[2023-02-02 13:30:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][950/1251]	eta 0:02:51 lr 0.000108	time 0.5532 (0.5695)	loss 2.9957 (2.7623)	grad_norm 2.1855 (nan)	mem 17417MB
[2023-02-02 13:31:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][1000/1251]	eta 0:02:22 lr 0.000108	time 0.5570 (0.5695)	loss 3.0785 (2.7639)	grad_norm 2.2262 (nan)	mem 17417MB
[2023-02-02 13:31:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][1050/1251]	eta 0:01:54 lr 0.000108	time 0.5600 (0.5694)	loss 3.0013 (2.7661)	grad_norm 2.6734 (nan)	mem 17417MB
[2023-02-02 13:32:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][1100/1251]	eta 0:01:25 lr 0.000108	time 0.6228 (0.5694)	loss 3.7025 (2.7648)	grad_norm 3.0869 (nan)	mem 17417MB
[2023-02-02 13:32:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][1150/1251]	eta 0:00:57 lr 0.000108	time 0.5553 (0.5692)	loss 3.2688 (2.7633)	grad_norm 2.1660 (nan)	mem 17417MB
[2023-02-02 13:33:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][1200/1251]	eta 0:00:29 lr 0.000108	time 0.5562 (0.5691)	loss 2.6312 (2.7625)	grad_norm 2.1519 (nan)	mem 17417MB
[2023-02-02 13:33:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [238/300][1250/1251]	eta 0:00:00 lr 0.000108	time 0.5510 (0.5692)	loss 3.1616 (2.7585)	grad_norm 2.8729 (nan)	mem 17417MB
[2023-02-02 13:33:33 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 238 training takes 0:11:52
[2023-02-02 13:33:33 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_238.pth saving......
[2023-02-02 13:33:34 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_238.pth saved !!!
[2023-02-02 13:33:35 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.975 (0.975)	Loss 0.7481 (0.7481)	Acc@1 82.520 (82.520)	Acc@5 95.898 (95.898)	Mem 17417MB
[2023-02-02 13:33:43 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.088 Acc@5 96.534
[2023-02-02 13:33:43 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.1%
[2023-02-02 13:33:45 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.264 (1.264)	Loss 0.7263 (0.7263)	Acc@1 82.520 (82.520)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-02 13:33:53 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.752 Acc@5 96.824
[2023-02-02 13:33:53 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.8%
[2023-02-02 13:33:53 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.75% at 238 epoch
[2023-02-02 13:33:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][0/1251]	eta 0:33:52 lr 0.000108	time 1.6247 (1.6247)	loss 3.1240 (3.1240)	grad_norm 2.4412 (2.4412)	mem 17417MB
[2023-02-02 13:34:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][50/1251]	eta 0:11:49 lr 0.000107	time 0.5514 (0.5905)	loss 3.3724 (2.6676)	grad_norm 2.2100 (2.3021)	mem 17417MB
[2023-02-02 13:34:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][100/1251]	eta 0:11:07 lr 0.000107	time 0.5553 (0.5797)	loss 2.1603 (2.6726)	grad_norm 2.1006 (2.3084)	mem 17417MB
[2023-02-02 13:35:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][150/1251]	eta 0:10:33 lr 0.000107	time 0.5686 (0.5752)	loss 3.1326 (2.7147)	grad_norm 2.2183 (2.3253)	mem 17417MB
[2023-02-02 13:35:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][200/1251]	eta 0:10:03 lr 0.000107	time 0.5629 (0.5740)	loss 2.2616 (2.7461)	grad_norm 2.2506 (2.3184)	mem 17417MB
[2023-02-02 13:36:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][250/1251]	eta 0:09:32 lr 0.000107	time 0.6257 (0.5721)	loss 2.6675 (2.7618)	grad_norm 2.0221 (2.3279)	mem 17417MB
[2023-02-02 13:36:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][300/1251]	eta 0:09:03 lr 0.000107	time 0.5568 (0.5719)	loss 2.8993 (2.7579)	grad_norm 2.5522 (2.3281)	mem 17417MB
[2023-02-02 13:37:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][350/1251]	eta 0:08:34 lr 0.000107	time 0.5626 (0.5712)	loss 2.4912 (2.7618)	grad_norm 2.0953 (2.3170)	mem 17417MB
[2023-02-02 13:37:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][400/1251]	eta 0:08:05 lr 0.000107	time 0.5655 (0.5710)	loss 3.1506 (2.7644)	grad_norm 2.4154 (2.3236)	mem 17417MB
[2023-02-02 13:38:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][450/1251]	eta 0:07:37 lr 0.000106	time 0.5622 (0.5707)	loss 1.9706 (2.7573)	grad_norm 2.4339 (2.3159)	mem 17417MB
[2023-02-02 13:38:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][500/1251]	eta 0:07:08 lr 0.000106	time 0.5588 (0.5702)	loss 2.6181 (2.7591)	grad_norm 2.4040 (2.3090)	mem 17417MB
[2023-02-02 13:39:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][550/1251]	eta 0:06:39 lr 0.000106	time 0.5520 (0.5699)	loss 2.9659 (2.7537)	grad_norm 2.1086 (2.3168)	mem 17417MB
[2023-02-02 13:39:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][600/1251]	eta 0:06:11 lr 0.000106	time 0.5513 (0.5701)	loss 3.7358 (2.7588)	grad_norm 1.9487 (2.3165)	mem 17417MB
[2023-02-02 13:40:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][650/1251]	eta 0:05:42 lr 0.000106	time 0.5586 (0.5697)	loss 2.0607 (2.7570)	grad_norm 2.0876 (2.3193)	mem 17417MB
[2023-02-02 13:40:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][700/1251]	eta 0:05:13 lr 0.000106	time 0.5527 (0.5699)	loss 3.3664 (2.7560)	grad_norm 2.2873 (2.3167)	mem 17417MB
[2023-02-02 13:41:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][750/1251]	eta 0:04:45 lr 0.000106	time 0.5535 (0.5696)	loss 3.0632 (2.7537)	grad_norm 2.8387 (2.3153)	mem 17417MB
[2023-02-02 13:41:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][800/1251]	eta 0:04:16 lr 0.000106	time 0.5520 (0.5694)	loss 2.9964 (2.7532)	grad_norm 2.4863 (2.3178)	mem 17417MB
[2023-02-02 13:41:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][850/1251]	eta 0:03:48 lr 0.000106	time 0.5561 (0.5694)	loss 2.4907 (2.7522)	grad_norm 2.2268 (2.3159)	mem 17417MB
[2023-02-02 13:42:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][900/1251]	eta 0:03:19 lr 0.000105	time 0.5562 (0.5694)	loss 1.7244 (2.7484)	grad_norm 2.3285 (2.3150)	mem 17417MB
[2023-02-02 13:42:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][950/1251]	eta 0:02:51 lr 0.000105	time 0.5527 (0.5692)	loss 2.4974 (2.7445)	grad_norm 2.2853 (2.3126)	mem 17417MB
[2023-02-02 13:43:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][1000/1251]	eta 0:02:22 lr 0.000105	time 0.6180 (0.5692)	loss 3.0989 (2.7353)	grad_norm 2.5162 (2.3174)	mem 17417MB
[2023-02-02 13:43:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][1050/1251]	eta 0:01:54 lr 0.000105	time 0.6297 (0.5691)	loss 3.4598 (2.7339)	grad_norm 2.4170 (2.3183)	mem 17417MB
[2023-02-02 13:44:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][1100/1251]	eta 0:01:25 lr 0.000105	time 0.6310 (0.5691)	loss 3.0190 (2.7339)	grad_norm 2.1489 (2.3190)	mem 17417MB
[2023-02-02 13:44:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][1150/1251]	eta 0:00:57 lr 0.000105	time 0.5482 (0.5691)	loss 2.9037 (2.7376)	grad_norm 1.9381 (2.3218)	mem 17417MB
[2023-02-02 13:45:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][1200/1251]	eta 0:00:29 lr 0.000105	time 0.5618 (0.5689)	loss 2.7302 (2.7393)	grad_norm 1.9784 (2.3248)	mem 17417MB
[2023-02-02 13:45:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [239/300][1250/1251]	eta 0:00:00 lr 0.000105	time 0.5529 (0.5691)	loss 3.1131 (2.7396)	grad_norm 2.2710 (2.3232)	mem 17417MB
[2023-02-02 13:45:45 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 239 training takes 0:11:52
[2023-02-02 13:45:45 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_239.pth saving......
[2023-02-02 13:45:47 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_239.pth saved !!!
[2023-02-02 13:45:48 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.890 (0.890)	Loss 0.7533 (0.7533)	Acc@1 83.008 (83.008)	Acc@5 95.898 (95.898)	Mem 17417MB
[2023-02-02 13:45:56 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.166 Acc@5 96.574
[2023-02-02 13:45:56 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.2%
[2023-02-02 13:45:57 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.223 (1.223)	Loss 0.7120 (0.7120)	Acc@1 82.227 (82.227)	Acc@5 96.875 (96.875)	Mem 17417MB
[2023-02-02 13:46:05 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.780 Acc@5 96.804
[2023-02-02 13:46:05 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.8%
[2023-02-02 13:46:05 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.78% at 239 epoch
[2023-02-02 13:46:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][0/1251]	eta 0:35:55 lr 0.000105	time 1.7228 (1.7228)	loss 2.0788 (2.0788)	grad_norm 1.9635 (1.9635)	mem 17417MB
[2023-02-02 13:46:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][50/1251]	eta 0:11:54 lr 0.000104	time 0.5552 (0.5948)	loss 2.6446 (2.7373)	grad_norm 2.3940 (2.2978)	mem 17417MB
[2023-02-02 13:47:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][100/1251]	eta 0:11:09 lr 0.000104	time 0.5471 (0.5816)	loss 2.9785 (2.7548)	grad_norm 2.4292 (2.3595)	mem 17417MB
[2023-02-02 13:47:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][150/1251]	eta 0:10:35 lr 0.000104	time 0.5506 (0.5770)	loss 2.7188 (2.7532)	grad_norm 2.2213 (2.3612)	mem 17417MB
[2023-02-02 13:48:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][200/1251]	eta 0:10:02 lr 0.000104	time 0.5473 (0.5736)	loss 2.9805 (2.7214)	grad_norm 2.2240 (2.3498)	mem 17417MB
[2023-02-02 13:48:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][250/1251]	eta 0:09:33 lr 0.000104	time 0.5515 (0.5732)	loss 3.2159 (2.7293)	grad_norm 2.2992 (2.3478)	mem 17417MB
[2023-02-02 13:48:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][300/1251]	eta 0:09:04 lr 0.000104	time 0.5524 (0.5728)	loss 2.5440 (2.7417)	grad_norm 2.0566 (2.3480)	mem 17417MB
[2023-02-02 13:49:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][350/1251]	eta 0:08:35 lr 0.000104	time 0.5593 (0.5719)	loss 3.0169 (2.7325)	grad_norm 2.3607 (2.3509)	mem 17417MB
[2023-02-02 13:49:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][400/1251]	eta 0:08:06 lr 0.000104	time 0.5563 (0.5717)	loss 3.0919 (2.7362)	grad_norm 2.4456 (2.3658)	mem 17417MB
[2023-02-02 13:50:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][450/1251]	eta 0:07:37 lr 0.000103	time 0.5584 (0.5711)	loss 2.1226 (2.7393)	grad_norm 2.1876 (2.3595)	mem 17417MB
[2023-02-02 13:50:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][500/1251]	eta 0:07:08 lr 0.000103	time 0.5480 (0.5708)	loss 2.0473 (2.7474)	grad_norm 2.5636 (2.3615)	mem 17417MB
[2023-02-02 13:51:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][550/1251]	eta 0:06:40 lr 0.000103	time 0.5542 (0.5707)	loss 2.9221 (2.7348)	grad_norm 2.2333 (2.3616)	mem 17417MB
[2023-02-02 13:51:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][600/1251]	eta 0:06:11 lr 0.000103	time 0.5600 (0.5706)	loss 2.5775 (2.7315)	grad_norm 2.2381 (2.3621)	mem 17417MB
[2023-02-02 13:52:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][650/1251]	eta 0:05:42 lr 0.000103	time 0.5592 (0.5705)	loss 2.6444 (2.7375)	grad_norm 2.1643 (2.3542)	mem 17417MB
[2023-02-02 13:52:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][700/1251]	eta 0:05:14 lr 0.000103	time 0.5549 (0.5702)	loss 2.1222 (2.7367)	grad_norm 2.2902 (2.3582)	mem 17417MB
[2023-02-02 13:53:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][750/1251]	eta 0:04:45 lr 0.000103	time 0.5538 (0.5697)	loss 2.7722 (2.7343)	grad_norm 2.5858 (2.3562)	mem 17417MB
[2023-02-02 13:53:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][800/1251]	eta 0:04:17 lr 0.000103	time 0.5620 (0.5699)	loss 1.8518 (2.7325)	grad_norm 2.5837 (2.3570)	mem 17417MB
[2023-02-02 13:54:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][850/1251]	eta 0:03:48 lr 0.000102	time 0.5497 (0.5696)	loss 3.5263 (2.7363)	grad_norm 2.2556 (nan)	mem 17417MB
[2023-02-02 13:54:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][900/1251]	eta 0:03:19 lr 0.000102	time 0.5555 (0.5695)	loss 2.9512 (2.7403)	grad_norm 2.2748 (nan)	mem 17417MB
[2023-02-02 13:55:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][950/1251]	eta 0:02:51 lr 0.000102	time 0.5561 (0.5694)	loss 2.9092 (2.7344)	grad_norm 2.6196 (nan)	mem 17417MB
[2023-02-02 13:55:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][1000/1251]	eta 0:02:22 lr 0.000102	time 0.5493 (0.5692)	loss 3.4193 (2.7391)	grad_norm 2.1067 (nan)	mem 17417MB
[2023-02-02 13:56:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][1050/1251]	eta 0:01:54 lr 0.000102	time 0.5571 (0.5691)	loss 1.8336 (2.7386)	grad_norm 3.1992 (nan)	mem 17417MB
[2023-02-02 13:56:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][1100/1251]	eta 0:01:25 lr 0.000102	time 0.6239 (0.5691)	loss 3.0170 (2.7338)	grad_norm 2.4036 (nan)	mem 17417MB
[2023-02-02 13:57:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][1150/1251]	eta 0:00:57 lr 0.000102	time 0.6185 (0.5688)	loss 1.8726 (2.7312)	grad_norm 2.3089 (nan)	mem 17417MB
[2023-02-02 13:57:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][1200/1251]	eta 0:00:29 lr 0.000102	time 0.5582 (0.5688)	loss 2.4995 (2.7316)	grad_norm 2.5874 (nan)	mem 17417MB
[2023-02-02 13:57:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [240/300][1250/1251]	eta 0:00:00 lr 0.000102	time 0.5628 (0.5687)	loss 2.3006 (2.7307)	grad_norm 2.2430 (nan)	mem 17417MB
[2023-02-02 13:57:56 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 240 training takes 0:11:51
[2023-02-02 13:57:57 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_240.pth saving......
[2023-02-02 13:57:58 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_240.pth saved !!!
[2023-02-02 13:57:59 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.865 (0.865)	Loss 0.7724 (0.7724)	Acc@1 82.324 (82.324)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-02 13:58:07 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.324 Acc@5 96.580
[2023-02-02 13:58:07 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.3%
[2023-02-02 13:58:08 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.155 (1.155)	Loss 0.6557 (0.6557)	Acc@1 85.059 (85.059)	Acc@5 96.875 (96.875)	Mem 17417MB
[2023-02-02 13:58:16 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.780 Acc@5 96.800
[2023-02-02 13:58:16 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.8%
[2023-02-02 13:58:16 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.78% at 240 epoch
[2023-02-02 13:58:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][0/1251]	eta 0:34:51 lr 0.000102	time 1.6720 (1.6720)	loss 2.6920 (2.6920)	grad_norm 2.1697 (2.1697)	mem 17417MB
[2023-02-02 13:58:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][50/1251]	eta 0:11:47 lr 0.000101	time 0.5560 (0.5895)	loss 2.7240 (2.6840)	grad_norm 2.3909 (2.4341)	mem 17417MB
[2023-02-02 13:59:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][100/1251]	eta 0:11:08 lr 0.000101	time 0.5549 (0.5812)	loss 2.9315 (2.7283)	grad_norm 2.3207 (2.3784)	mem 17417MB
[2023-02-02 13:59:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][150/1251]	eta 0:10:35 lr 0.000101	time 0.5514 (0.5768)	loss 3.0091 (2.7367)	grad_norm 2.2728 (2.3519)	mem 17417MB
[2023-02-02 14:00:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][200/1251]	eta 0:10:03 lr 0.000101	time 0.5569 (0.5747)	loss 3.0236 (2.7331)	grad_norm 2.5937 (2.3484)	mem 17417MB
[2023-02-02 14:00:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][250/1251]	eta 0:09:33 lr 0.000101	time 0.6284 (0.5734)	loss 2.7475 (2.7511)	grad_norm 2.0374 (2.3526)	mem 17417MB
[2023-02-02 14:01:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][300/1251]	eta 0:09:04 lr 0.000101	time 0.5557 (0.5724)	loss 2.5326 (2.7412)	grad_norm 2.6789 (2.3422)	mem 17417MB
[2023-02-02 14:01:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][350/1251]	eta 0:08:35 lr 0.000101	time 0.5555 (0.5717)	loss 2.5796 (2.7303)	grad_norm 2.8019 (2.3533)	mem 17417MB
[2023-02-02 14:02:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][400/1251]	eta 0:08:06 lr 0.000101	time 0.5503 (0.5717)	loss 3.1180 (2.7340)	grad_norm 2.6708 (2.3613)	mem 17417MB
[2023-02-02 14:02:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][450/1251]	eta 0:07:37 lr 0.000100	time 0.5569 (0.5712)	loss 3.0471 (2.7451)	grad_norm 2.2436 (2.3627)	mem 17417MB
[2023-02-02 14:03:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][500/1251]	eta 0:07:08 lr 0.000100	time 0.5511 (0.5709)	loss 2.3511 (2.7492)	grad_norm 2.6522 (2.3638)	mem 17417MB
[2023-02-02 14:03:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][550/1251]	eta 0:06:40 lr 0.000100	time 0.5594 (0.5706)	loss 2.8299 (2.7400)	grad_norm 1.9246 (2.3599)	mem 17417MB
[2023-02-02 14:03:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][600/1251]	eta 0:06:11 lr 0.000100	time 0.5506 (0.5703)	loss 2.9382 (2.7464)	grad_norm 2.9846 (2.3570)	mem 17417MB
[2023-02-02 14:04:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][650/1251]	eta 0:05:42 lr 0.000100	time 0.5569 (0.5704)	loss 2.1224 (2.7394)	grad_norm 2.5688 (2.3643)	mem 17417MB
[2023-02-02 14:04:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][700/1251]	eta 0:05:14 lr 0.000100	time 0.5522 (0.5704)	loss 2.4026 (2.7319)	grad_norm 2.1527 (2.3634)	mem 17417MB
[2023-02-02 14:05:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][750/1251]	eta 0:04:45 lr 0.000100	time 0.5746 (0.5702)	loss 2.6361 (2.7381)	grad_norm 1.8486 (2.3647)	mem 17417MB
[2023-02-02 14:05:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][800/1251]	eta 0:04:17 lr 0.000100	time 0.5568 (0.5700)	loss 3.1097 (2.7397)	grad_norm 2.0090 (2.3638)	mem 17417MB
[2023-02-02 14:06:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][850/1251]	eta 0:03:48 lr 0.000099	time 0.6179 (0.5699)	loss 2.9707 (2.7347)	grad_norm 2.5875 (2.3635)	mem 17417MB
[2023-02-02 14:06:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][900/1251]	eta 0:03:20 lr 0.000099	time 0.5574 (0.5700)	loss 2.9385 (2.7427)	grad_norm 2.1079 (2.3620)	mem 17417MB
[2023-02-02 14:07:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][950/1251]	eta 0:02:51 lr 0.000099	time 0.5594 (0.5697)	loss 2.0227 (2.7436)	grad_norm 2.4114 (2.3620)	mem 17417MB
[2023-02-02 14:07:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][1000/1251]	eta 0:02:22 lr 0.000099	time 0.6307 (0.5696)	loss 2.0893 (2.7424)	grad_norm 2.0639 (2.3589)	mem 17417MB
[2023-02-02 14:08:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][1050/1251]	eta 0:01:54 lr 0.000099	time 0.5578 (0.5696)	loss 3.0176 (2.7411)	grad_norm 2.1293 (2.3577)	mem 17417MB
[2023-02-02 14:08:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][1100/1251]	eta 0:01:25 lr 0.000099	time 0.6292 (0.5694)	loss 3.0285 (2.7395)	grad_norm 2.8846 (2.3545)	mem 17417MB
[2023-02-02 14:09:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][1150/1251]	eta 0:00:57 lr 0.000099	time 0.5558 (0.5695)	loss 2.6594 (2.7387)	grad_norm 2.1913 (2.3536)	mem 17417MB
[2023-02-02 14:09:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][1200/1251]	eta 0:00:29 lr 0.000099	time 0.5569 (0.5693)	loss 2.9955 (2.7404)	grad_norm 2.2058 (2.3533)	mem 17417MB
[2023-02-02 14:10:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [241/300][1250/1251]	eta 0:00:00 lr 0.000099	time 0.5672 (0.5694)	loss 2.9342 (2.7429)	grad_norm 2.2440 (2.3518)	mem 17417MB
[2023-02-02 14:10:09 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 241 training takes 0:11:52
[2023-02-02 14:10:09 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_241.pth saving......
[2023-02-02 14:10:11 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_241.pth saved !!!
[2023-02-02 14:10:12 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.873 (0.873)	Loss 0.8797 (0.8797)	Acc@1 79.883 (79.883)	Acc@5 95.410 (95.410)	Mem 17417MB
[2023-02-02 14:10:20 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.160 Acc@5 96.632
[2023-02-02 14:10:20 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.2%
[2023-02-02 14:10:21 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.177 (1.177)	Loss 0.6251 (0.6251)	Acc@1 86.230 (86.230)	Acc@5 97.266 (97.266)	Mem 17417MB
[2023-02-02 14:10:29 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.812 Acc@5 96.810
[2023-02-02 14:10:29 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.8%
[2023-02-02 14:10:29 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.81% at 241 epoch
[2023-02-02 14:10:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][0/1251]	eta 0:37:57 lr 0.000099	time 1.8204 (1.8204)	loss 3.2741 (3.2741)	grad_norm 2.4493 (2.4493)	mem 17417MB
[2023-02-02 14:10:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][50/1251]	eta 0:11:56 lr 0.000098	time 0.5563 (0.5964)	loss 2.1100 (2.6901)	grad_norm 2.5864 (2.3362)	mem 17417MB
[2023-02-02 14:11:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][100/1251]	eta 0:11:12 lr 0.000098	time 0.6189 (0.5840)	loss 2.8648 (2.7005)	grad_norm 2.4447 (2.3253)	mem 17417MB
[2023-02-02 14:11:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][150/1251]	eta 0:10:37 lr 0.000098	time 0.5580 (0.5788)	loss 2.7873 (2.6920)	grad_norm 2.2678 (2.3407)	mem 17417MB
[2023-02-02 14:12:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][200/1251]	eta 0:10:04 lr 0.000098	time 0.5540 (0.5752)	loss 2.9489 (2.6879)	grad_norm 2.8481 (2.3428)	mem 17417MB
[2023-02-02 14:12:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][250/1251]	eta 0:09:35 lr 0.000098	time 0.5744 (0.5748)	loss 2.9849 (2.7039)	grad_norm 2.1659 (2.3571)	mem 17417MB
[2023-02-02 14:13:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][300/1251]	eta 0:09:05 lr 0.000098	time 0.5519 (0.5739)	loss 3.0616 (2.7053)	grad_norm 2.0155 (2.3644)	mem 17417MB
[2023-02-02 14:13:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][350/1251]	eta 0:08:36 lr 0.000098	time 0.5604 (0.5729)	loss 2.5565 (2.7031)	grad_norm 2.4728 (2.3698)	mem 17417MB
[2023-02-02 14:14:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][400/1251]	eta 0:08:06 lr 0.000098	time 0.5528 (0.5722)	loss 3.3992 (2.6994)	grad_norm 2.4288 (2.3747)	mem 17417MB
[2023-02-02 14:14:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][450/1251]	eta 0:07:38 lr 0.000097	time 0.6359 (0.5719)	loss 2.6077 (2.7139)	grad_norm 2.5726 (2.3780)	mem 17417MB
[2023-02-02 14:15:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][500/1251]	eta 0:07:09 lr 0.000097	time 0.6238 (0.5714)	loss 2.6457 (2.7147)	grad_norm 2.8732 (2.3795)	mem 17417MB
[2023-02-02 14:15:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][550/1251]	eta 0:06:40 lr 0.000097	time 0.5796 (0.5713)	loss 1.6954 (2.7184)	grad_norm 2.2598 (2.3774)	mem 17417MB
[2023-02-02 14:16:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][600/1251]	eta 0:06:11 lr 0.000097	time 0.5585 (0.5712)	loss 3.0123 (2.7196)	grad_norm 1.9934 (2.3819)	mem 17417MB
[2023-02-02 14:16:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][650/1251]	eta 0:05:43 lr 0.000097	time 0.5557 (0.5711)	loss 2.7372 (2.7216)	grad_norm 2.3190 (2.3787)	mem 17417MB
[2023-02-02 14:17:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][700/1251]	eta 0:05:14 lr 0.000097	time 0.5518 (0.5709)	loss 3.4077 (2.7207)	grad_norm 2.4341 (2.3783)	mem 17417MB
[2023-02-02 14:17:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][750/1251]	eta 0:04:45 lr 0.000097	time 0.5611 (0.5707)	loss 2.9631 (2.7203)	grad_norm 2.3383 (2.3766)	mem 17417MB
[2023-02-02 14:18:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][800/1251]	eta 0:04:17 lr 0.000097	time 0.5565 (0.5705)	loss 3.3338 (2.7240)	grad_norm 2.6189 (2.3761)	mem 17417MB
[2023-02-02 14:18:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][850/1251]	eta 0:03:48 lr 0.000097	time 0.5556 (0.5706)	loss 2.8874 (2.7200)	grad_norm 2.8687 (2.3779)	mem 17417MB
[2023-02-02 14:19:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][900/1251]	eta 0:03:20 lr 0.000096	time 0.6162 (0.5705)	loss 2.1810 (2.7164)	grad_norm 2.7859 (2.3761)	mem 17417MB
[2023-02-02 14:19:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][950/1251]	eta 0:02:51 lr 0.000096	time 0.5550 (0.5704)	loss 3.3463 (2.7152)	grad_norm 2.3656 (2.3774)	mem 17417MB
[2023-02-02 14:19:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][1000/1251]	eta 0:02:23 lr 0.000096	time 0.5589 (0.5700)	loss 2.9412 (2.7175)	grad_norm 2.4605 (2.3750)	mem 17417MB
[2023-02-02 14:20:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][1050/1251]	eta 0:01:54 lr 0.000096	time 0.5553 (0.5701)	loss 2.2504 (2.7137)	grad_norm 1.9734 (2.3726)	mem 17417MB
[2023-02-02 14:20:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][1100/1251]	eta 0:01:26 lr 0.000096	time 0.5584 (0.5700)	loss 1.8891 (2.7113)	grad_norm 2.2472 (2.3715)	mem 17417MB
[2023-02-02 14:21:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][1150/1251]	eta 0:00:57 lr 0.000096	time 0.5643 (0.5699)	loss 1.9820 (2.7062)	grad_norm 2.3510 (2.3688)	mem 17417MB
[2023-02-02 14:21:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][1200/1251]	eta 0:00:29 lr 0.000096	time 0.5641 (0.5699)	loss 3.0194 (2.7031)	grad_norm 3.5532 (2.3706)	mem 17417MB
[2023-02-02 14:22:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [242/300][1250/1251]	eta 0:00:00 lr 0.000096	time 0.5500 (0.5698)	loss 2.6910 (2.7020)	grad_norm 2.0650 (2.3698)	mem 17417MB
[2023-02-02 14:22:22 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 242 training takes 0:11:52
[2023-02-02 14:22:22 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_242.pth saving......
[2023-02-02 14:22:24 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_242.pth saved !!!
[2023-02-02 14:22:25 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.877 (0.877)	Loss 0.7382 (0.7382)	Acc@1 82.520 (82.520)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-02 14:22:32 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.420 Acc@5 96.618
[2023-02-02 14:22:32 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.4%
[2023-02-02 14:22:34 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.217 (1.217)	Loss 0.7029 (0.7029)	Acc@1 82.715 (82.715)	Acc@5 97.949 (97.949)	Mem 17417MB
[2023-02-02 14:22:42 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.816 Acc@5 96.824
[2023-02-02 14:22:42 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.8%
[2023-02-02 14:22:42 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.82% at 242 epoch
[2023-02-02 14:22:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][0/1251]	eta 0:36:30 lr 0.000096	time 1.7507 (1.7507)	loss 2.5506 (2.5506)	grad_norm 2.1250 (2.1250)	mem 17417MB
[2023-02-02 14:23:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][50/1251]	eta 0:11:48 lr 0.000095	time 0.5509 (0.5902)	loss 3.1884 (2.8271)	grad_norm 2.6522 (2.3869)	mem 17417MB
[2023-02-02 14:23:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][100/1251]	eta 0:11:11 lr 0.000095	time 0.6502 (0.5830)	loss 2.6162 (2.7599)	grad_norm 2.1393 (2.4007)	mem 17417MB
[2023-02-02 14:24:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][150/1251]	eta 0:10:35 lr 0.000095	time 0.5568 (0.5768)	loss 2.2304 (2.7325)	grad_norm 2.4598 (2.3867)	mem 17417MB
[2023-02-02 14:24:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][200/1251]	eta 0:10:04 lr 0.000095	time 0.5515 (0.5754)	loss 2.1271 (2.7182)	grad_norm 2.1357 (2.3794)	mem 17417MB
[2023-02-02 14:25:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][250/1251]	eta 0:09:34 lr 0.000095	time 0.5625 (0.5739)	loss 3.2639 (2.7175)	grad_norm 3.0301 (2.4036)	mem 17417MB
[2023-02-02 14:25:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][300/1251]	eta 0:09:04 lr 0.000095	time 0.5555 (0.5728)	loss 3.2598 (2.7200)	grad_norm 2.2530 (2.4040)	mem 17417MB
[2023-02-02 14:26:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][350/1251]	eta 0:08:35 lr 0.000095	time 0.5615 (0.5724)	loss 2.9369 (2.7204)	grad_norm 2.8492 (2.4045)	mem 17417MB
[2023-02-02 14:26:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][400/1251]	eta 0:08:06 lr 0.000095	time 0.5527 (0.5720)	loss 3.0978 (2.7317)	grad_norm 2.1037 (2.4032)	mem 17417MB
[2023-02-02 14:26:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][450/1251]	eta 0:07:37 lr 0.000095	time 0.6218 (0.5715)	loss 2.9045 (2.7245)	grad_norm 2.6735 (2.4018)	mem 17417MB
[2023-02-02 14:27:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][500/1251]	eta 0:07:08 lr 0.000094	time 0.5520 (0.5711)	loss 2.7969 (2.7277)	grad_norm 2.5740 (2.4038)	mem 17417MB
[2023-02-02 14:27:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][550/1251]	eta 0:06:40 lr 0.000094	time 0.5509 (0.5709)	loss 2.2005 (2.7374)	grad_norm 2.1258 (2.3937)	mem 17417MB
[2023-02-02 14:28:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][600/1251]	eta 0:06:11 lr 0.000094	time 0.5549 (0.5709)	loss 2.4256 (2.7308)	grad_norm 2.7496 (2.3945)	mem 17417MB
[2023-02-02 14:28:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][650/1251]	eta 0:05:43 lr 0.000094	time 0.5749 (0.5709)	loss 2.7351 (2.7242)	grad_norm 2.2875 (2.3920)	mem 17417MB
[2023-02-02 14:29:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][700/1251]	eta 0:05:14 lr 0.000094	time 0.5616 (0.5706)	loss 1.5094 (2.7213)	grad_norm 3.3452 (2.3968)	mem 17417MB
[2023-02-02 14:29:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][750/1251]	eta 0:04:45 lr 0.000094	time 0.5560 (0.5705)	loss 2.0672 (2.7125)	grad_norm 2.4346 (2.3929)	mem 17417MB
[2023-02-02 14:30:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][800/1251]	eta 0:04:17 lr 0.000094	time 0.5483 (0.5706)	loss 3.0471 (2.7152)	grad_norm 2.5475 (2.3910)	mem 17417MB
[2023-02-02 14:30:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][850/1251]	eta 0:03:48 lr 0.000094	time 0.5497 (0.5704)	loss 3.1971 (2.7156)	grad_norm 2.2916 (2.3860)	mem 17417MB
[2023-02-02 14:31:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][900/1251]	eta 0:03:20 lr 0.000094	time 0.5705 (0.5704)	loss 2.3931 (2.7114)	grad_norm 2.2117 (2.3865)	mem 17417MB
[2023-02-02 14:31:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][950/1251]	eta 0:02:51 lr 0.000093	time 0.5592 (0.5701)	loss 1.7846 (2.7164)	grad_norm 2.2789 (2.3827)	mem 17417MB
[2023-02-02 14:32:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][1000/1251]	eta 0:02:23 lr 0.000093	time 0.5676 (0.5701)	loss 2.7355 (2.7193)	grad_norm 2.5625 (2.3832)	mem 17417MB
[2023-02-02 14:32:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][1050/1251]	eta 0:01:54 lr 0.000093	time 0.5596 (0.5700)	loss 2.3236 (2.7248)	grad_norm 2.1770 (2.3838)	mem 17417MB
[2023-02-02 14:33:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][1100/1251]	eta 0:01:26 lr 0.000093	time 0.5606 (0.5699)	loss 2.5913 (2.7251)	grad_norm 2.3547 (2.3823)	mem 17417MB
[2023-02-02 14:33:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][1150/1251]	eta 0:00:57 lr 0.000093	time 0.5564 (0.5699)	loss 2.6627 (2.7220)	grad_norm 2.1176 (nan)	mem 17417MB
[2023-02-02 14:34:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][1200/1251]	eta 0:00:29 lr 0.000093	time 0.5562 (0.5699)	loss 2.4734 (2.7128)	grad_norm 2.4570 (nan)	mem 17417MB
[2023-02-02 14:34:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [243/300][1250/1251]	eta 0:00:00 lr 0.000093	time 0.5652 (0.5698)	loss 2.9921 (2.7132)	grad_norm 2.3791 (nan)	mem 17417MB
[2023-02-02 14:34:35 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 243 training takes 0:11:52
[2023-02-02 14:34:35 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_243.pth saving......
[2023-02-02 14:34:37 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_243.pth saved !!!
[2023-02-02 14:34:37 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.853 (0.853)	Loss 0.5911 (0.5911)	Acc@1 85.156 (85.156)	Acc@5 97.656 (97.656)	Mem 17417MB
[2023-02-02 14:34:45 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.344 Acc@5 96.572
[2023-02-02 14:34:45 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.3%
[2023-02-02 14:34:47 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.286 (1.286)	Loss 0.7937 (0.7937)	Acc@1 83.594 (83.594)	Acc@5 95.410 (95.410)	Mem 17417MB
[2023-02-02 14:34:55 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.828 Acc@5 96.806
[2023-02-02 14:34:55 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.8%
[2023-02-02 14:34:55 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.83% at 243 epoch
[2023-02-02 14:34:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][0/1251]	eta 0:34:44 lr 0.000093	time 1.6662 (1.6662)	loss 2.5217 (2.5217)	grad_norm 2.2624 (2.2624)	mem 17417MB
[2023-02-02 14:35:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][50/1251]	eta 0:11:51 lr 0.000093	time 0.5582 (0.5923)	loss 2.9638 (2.7721)	grad_norm 2.3531 (2.4329)	mem 17417MB
[2023-02-02 14:35:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][100/1251]	eta 0:11:08 lr 0.000092	time 0.6451 (0.5810)	loss 2.3113 (2.7988)	grad_norm 2.4020 (2.4417)	mem 17417MB
[2023-02-02 14:36:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][150/1251]	eta 0:10:35 lr 0.000092	time 0.5665 (0.5774)	loss 1.9236 (2.7708)	grad_norm 2.7165 (2.4156)	mem 17417MB
[2023-02-02 14:36:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][200/1251]	eta 0:10:03 lr 0.000092	time 0.5638 (0.5745)	loss 1.9452 (2.7525)	grad_norm 2.5749 (2.4106)	mem 17417MB
[2023-02-02 14:37:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][250/1251]	eta 0:09:33 lr 0.000092	time 0.5621 (0.5733)	loss 2.2501 (2.7346)	grad_norm 2.1633 (2.3966)	mem 17417MB
[2023-02-02 14:37:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][300/1251]	eta 0:09:04 lr 0.000092	time 0.5577 (0.5725)	loss 3.2051 (2.7407)	grad_norm 2.4297 (2.4031)	mem 17417MB
[2023-02-02 14:38:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][350/1251]	eta 0:08:35 lr 0.000092	time 0.5727 (0.5720)	loss 2.6010 (2.7364)	grad_norm 2.4914 (2.3997)	mem 17417MB
[2023-02-02 14:38:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][400/1251]	eta 0:08:06 lr 0.000092	time 0.5552 (0.5715)	loss 2.8055 (2.7278)	grad_norm 2.5893 (2.4039)	mem 17417MB
[2023-02-02 14:39:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][450/1251]	eta 0:07:37 lr 0.000092	time 0.5601 (0.5711)	loss 1.7831 (2.7275)	grad_norm 2.0464 (nan)	mem 17417MB
[2023-02-02 14:39:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][500/1251]	eta 0:07:08 lr 0.000092	time 0.5518 (0.5704)	loss 2.5134 (2.7207)	grad_norm 2.3031 (nan)	mem 17417MB
[2023-02-02 14:40:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][550/1251]	eta 0:06:39 lr 0.000091	time 0.5536 (0.5704)	loss 3.0786 (2.7161)	grad_norm 2.6773 (nan)	mem 17417MB
[2023-02-02 14:40:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][600/1251]	eta 0:06:11 lr 0.000091	time 0.5514 (0.5702)	loss 2.9704 (2.7144)	grad_norm 2.2908 (nan)	mem 17417MB
[2023-02-02 14:41:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][650/1251]	eta 0:05:42 lr 0.000091	time 0.5546 (0.5703)	loss 3.2227 (2.7098)	grad_norm 2.6070 (nan)	mem 17417MB
[2023-02-02 14:41:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][700/1251]	eta 0:05:14 lr 0.000091	time 0.5681 (0.5701)	loss 2.8977 (2.7098)	grad_norm 2.8379 (nan)	mem 17417MB
[2023-02-02 14:42:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][750/1251]	eta 0:04:45 lr 0.000091	time 0.6526 (0.5702)	loss 2.5266 (2.6991)	grad_norm 1.9629 (nan)	mem 17417MB
[2023-02-02 14:42:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][800/1251]	eta 0:04:17 lr 0.000091	time 0.6182 (0.5699)	loss 2.4797 (2.7009)	grad_norm 2.5949 (nan)	mem 17417MB
[2023-02-02 14:43:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][850/1251]	eta 0:03:48 lr 0.000091	time 0.5470 (0.5698)	loss 2.9826 (2.7031)	grad_norm 2.0411 (nan)	mem 17417MB
[2023-02-02 14:43:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][900/1251]	eta 0:03:19 lr 0.000091	time 0.5499 (0.5697)	loss 3.0055 (2.7017)	grad_norm 2.2314 (nan)	mem 17417MB
[2023-02-02 14:43:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][950/1251]	eta 0:02:51 lr 0.000091	time 0.5575 (0.5697)	loss 3.0462 (2.7048)	grad_norm 2.1164 (nan)	mem 17417MB
[2023-02-02 14:44:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][1000/1251]	eta 0:02:22 lr 0.000090	time 0.5520 (0.5695)	loss 3.0033 (2.7081)	grad_norm 2.5431 (nan)	mem 17417MB
[2023-02-02 14:44:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][1050/1251]	eta 0:01:54 lr 0.000090	time 0.5533 (0.5694)	loss 1.9356 (2.7062)	grad_norm 2.4742 (nan)	mem 17417MB
[2023-02-02 14:45:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][1100/1251]	eta 0:01:25 lr 0.000090	time 0.6222 (0.5692)	loss 3.1079 (2.7069)	grad_norm 2.2819 (nan)	mem 17417MB
[2023-02-02 14:45:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][1150/1251]	eta 0:00:57 lr 0.000090	time 0.6163 (0.5692)	loss 2.8282 (2.7088)	grad_norm 2.3513 (nan)	mem 17417MB
[2023-02-02 14:46:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][1200/1251]	eta 0:00:29 lr 0.000090	time 0.5554 (0.5690)	loss 2.9136 (2.7097)	grad_norm 1.9916 (nan)	mem 17417MB
[2023-02-02 14:46:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [244/300][1250/1251]	eta 0:00:00 lr 0.000090	time 0.6356 (0.5690)	loss 2.6600 (2.7106)	grad_norm 1.9021 (nan)	mem 17417MB
[2023-02-02 14:46:47 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 244 training takes 0:11:51
[2023-02-02 14:46:47 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_244.pth saving......
[2023-02-02 14:46:48 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_244.pth saved !!!
[2023-02-02 14:46:49 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.864 (0.864)	Loss 0.7715 (0.7715)	Acc@1 82.812 (82.812)	Acc@5 95.996 (95.996)	Mem 17417MB
[2023-02-02 14:46:57 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.386 Acc@5 96.594
[2023-02-02 14:46:57 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.4%
[2023-02-02 14:46:59 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.295 (1.295)	Loss 0.6458 (0.6458)	Acc@1 85.254 (85.254)	Acc@5 97.754 (97.754)	Mem 17417MB
[2023-02-02 14:47:07 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.838 Acc@5 96.808
[2023-02-02 14:47:07 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.8%
[2023-02-02 14:47:07 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.84% at 244 epoch
[2023-02-02 14:47:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][0/1251]	eta 0:36:27 lr 0.000090	time 1.7483 (1.7483)	loss 2.3898 (2.3898)	grad_norm 2.0750 (2.0750)	mem 17417MB
[2023-02-02 14:47:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][50/1251]	eta 0:11:51 lr 0.000090	time 0.5738 (0.5921)	loss 2.8846 (2.7924)	grad_norm 2.2439 (2.3610)	mem 17417MB
[2023-02-02 14:48:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][100/1251]	eta 0:11:08 lr 0.000090	time 0.5501 (0.5808)	loss 2.5471 (2.7616)	grad_norm 2.0762 (2.3722)	mem 17417MB
[2023-02-02 14:48:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][150/1251]	eta 0:10:35 lr 0.000090	time 0.5525 (0.5768)	loss 2.6729 (2.7200)	grad_norm 2.5950 (2.3759)	mem 17417MB
[2023-02-02 14:49:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][200/1251]	eta 0:10:04 lr 0.000089	time 0.5564 (0.5754)	loss 3.1363 (2.7117)	grad_norm 2.6402 (2.3883)	mem 17417MB
[2023-02-02 14:49:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][250/1251]	eta 0:09:34 lr 0.000089	time 0.5535 (0.5742)	loss 2.1221 (2.6889)	grad_norm 2.3462 (2.4004)	mem 17417MB
[2023-02-02 14:50:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][300/1251]	eta 0:09:05 lr 0.000089	time 0.5577 (0.5739)	loss 3.2269 (2.6970)	grad_norm 2.4540 (2.3971)	mem 17417MB
[2023-02-02 14:50:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][350/1251]	eta 0:08:36 lr 0.000089	time 0.5559 (0.5728)	loss 2.2713 (2.6958)	grad_norm 2.2286 (2.3989)	mem 17417MB
[2023-02-02 14:50:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][400/1251]	eta 0:08:07 lr 0.000089	time 0.5523 (0.5723)	loss 3.1998 (2.6985)	grad_norm 2.5326 (2.3960)	mem 17417MB
[2023-02-02 14:51:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][450/1251]	eta 0:07:38 lr 0.000089	time 0.5491 (0.5721)	loss 2.3021 (2.6954)	grad_norm 2.2750 (2.4045)	mem 17417MB
[2023-02-02 14:51:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][500/1251]	eta 0:07:09 lr 0.000089	time 0.5499 (0.5717)	loss 2.9751 (2.7018)	grad_norm 2.3612 (2.3984)	mem 17417MB
[2023-02-02 14:52:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][550/1251]	eta 0:06:40 lr 0.000089	time 0.5541 (0.5718)	loss 2.8674 (2.6976)	grad_norm 2.3556 (2.3963)	mem 17417MB
[2023-02-02 14:52:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][600/1251]	eta 0:06:12 lr 0.000089	time 0.5529 (0.5716)	loss 2.5776 (2.6947)	grad_norm 2.6824 (2.3977)	mem 17417MB
[2023-02-02 14:53:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][650/1251]	eta 0:05:43 lr 0.000088	time 0.5628 (0.5713)	loss 2.8074 (2.6965)	grad_norm 2.4563 (2.4025)	mem 17417MB
[2023-02-02 14:53:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][700/1251]	eta 0:05:14 lr 0.000088	time 0.5597 (0.5711)	loss 2.8726 (2.7039)	grad_norm 2.8207 (2.4058)	mem 17417MB
[2023-02-02 14:54:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][750/1251]	eta 0:04:45 lr 0.000088	time 0.5605 (0.5708)	loss 2.9408 (2.7069)	grad_norm 2.1978 (2.4003)	mem 17417MB
[2023-02-02 14:54:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][800/1251]	eta 0:04:17 lr 0.000088	time 0.5666 (0.5708)	loss 1.9376 (2.6987)	grad_norm 2.2936 (2.4007)	mem 17417MB
[2023-02-02 14:55:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][850/1251]	eta 0:03:48 lr 0.000088	time 0.6155 (0.5706)	loss 2.6775 (2.7011)	grad_norm 2.0975 (2.4002)	mem 17417MB
[2023-02-02 14:55:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][900/1251]	eta 0:03:20 lr 0.000088	time 0.5578 (0.5703)	loss 2.2192 (2.7005)	grad_norm 2.3838 (2.3988)	mem 17417MB
[2023-02-02 14:56:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][950/1251]	eta 0:02:51 lr 0.000088	time 0.5535 (0.5703)	loss 3.2602 (2.7025)	grad_norm 2.9243 (2.3990)	mem 17417MB
[2023-02-02 14:56:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][1000/1251]	eta 0:02:23 lr 0.000088	time 0.5542 (0.5702)	loss 3.0072 (2.6997)	grad_norm 2.3381 (2.4035)	mem 17417MB
[2023-02-02 14:57:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][1050/1251]	eta 0:01:54 lr 0.000088	time 0.5581 (0.5701)	loss 2.9751 (2.7040)	grad_norm 2.4786 (2.4009)	mem 17417MB
[2023-02-02 14:57:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][1100/1251]	eta 0:01:26 lr 0.000087	time 0.6228 (0.5701)	loss 3.1334 (2.7011)	grad_norm 2.5392 (2.3998)	mem 17417MB
[2023-02-02 14:58:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][1150/1251]	eta 0:00:57 lr 0.000087	time 0.5463 (0.5698)	loss 3.0508 (2.7001)	grad_norm 2.4669 (2.4015)	mem 17417MB
[2023-02-02 14:58:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][1200/1251]	eta 0:00:29 lr 0.000087	time 0.5530 (0.5698)	loss 2.9785 (2.7025)	grad_norm 2.2676 (2.3995)	mem 17417MB
[2023-02-02 14:59:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [245/300][1250/1251]	eta 0:00:00 lr 0.000087	time 0.5499 (0.5698)	loss 2.0150 (2.7038)	grad_norm 2.3132 (2.3991)	mem 17417MB
[2023-02-02 14:59:00 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 245 training takes 0:11:52
[2023-02-02 14:59:00 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_245.pth saving......
[2023-02-02 14:59:02 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_245.pth saved !!!
[2023-02-02 14:59:03 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.880 (0.880)	Loss 0.7653 (0.7653)	Acc@1 82.227 (82.227)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-02 14:59:10 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.266 Acc@5 96.550
[2023-02-02 14:59:10 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.3%
[2023-02-02 14:59:12 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.218 (1.218)	Loss 0.7644 (0.7644)	Acc@1 82.715 (82.715)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-02 14:59:20 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.838 Acc@5 96.802
[2023-02-02 14:59:20 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.8%
[2023-02-02 14:59:20 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.84% at 244 epoch
[2023-02-02 14:59:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][0/1251]	eta 0:35:27 lr 0.000087	time 1.7005 (1.7005)	loss 3.1715 (3.1715)	grad_norm 2.5334 (2.5334)	mem 17417MB
[2023-02-02 14:59:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][50/1251]	eta 0:11:53 lr 0.000087	time 0.6548 (0.5940)	loss 1.7048 (2.7693)	grad_norm 2.4787 (2.4048)	mem 17417MB
[2023-02-02 15:00:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][100/1251]	eta 0:11:09 lr 0.000087	time 0.6365 (0.5820)	loss 2.7652 (2.6995)	grad_norm 2.5652 (2.3942)	mem 17417MB
[2023-02-02 15:00:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][150/1251]	eta 0:10:34 lr 0.000087	time 0.5552 (0.5762)	loss 2.7566 (2.6699)	grad_norm 2.1624 (2.3960)	mem 17417MB
[2023-02-02 15:01:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][200/1251]	eta 0:10:03 lr 0.000087	time 0.5696 (0.5746)	loss 2.7662 (2.6693)	grad_norm 2.1531 (2.4064)	mem 17417MB
[2023-02-02 15:01:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][250/1251]	eta 0:09:34 lr 0.000087	time 0.5538 (0.5735)	loss 3.1424 (2.6916)	grad_norm 2.4299 (2.4231)	mem 17417MB
[2023-02-02 15:02:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][300/1251]	eta 0:09:04 lr 0.000086	time 0.5568 (0.5725)	loss 2.6444 (2.6946)	grad_norm 2.3598 (2.4226)	mem 17417MB
[2023-02-02 15:02:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][350/1251]	eta 0:08:35 lr 0.000086	time 0.5488 (0.5720)	loss 2.7696 (2.7029)	grad_norm 2.3710 (2.4219)	mem 17417MB
[2023-02-02 15:03:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][400/1251]	eta 0:08:06 lr 0.000086	time 0.5541 (0.5715)	loss 1.9940 (2.7124)	grad_norm 3.4598 (2.4209)	mem 17417MB
[2023-02-02 15:03:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][450/1251]	eta 0:07:37 lr 0.000086	time 0.5623 (0.5712)	loss 2.8530 (2.7193)	grad_norm 2.6494 (2.4254)	mem 17417MB
[2023-02-02 15:04:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][500/1251]	eta 0:07:08 lr 0.000086	time 0.6128 (0.5709)	loss 2.5957 (2.7288)	grad_norm 2.0934 (2.4286)	mem 17417MB
[2023-02-02 15:04:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][550/1251]	eta 0:06:40 lr 0.000086	time 0.5782 (0.5706)	loss 2.6728 (2.7183)	grad_norm 2.4962 (2.4258)	mem 17417MB
[2023-02-02 15:05:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][600/1251]	eta 0:06:11 lr 0.000086	time 0.5536 (0.5704)	loss 3.1032 (2.7078)	grad_norm 2.4377 (2.4229)	mem 17417MB
[2023-02-02 15:05:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][650/1251]	eta 0:05:42 lr 0.000086	time 0.5580 (0.5704)	loss 2.6896 (2.7148)	grad_norm 2.4694 (2.4281)	mem 17417MB
[2023-02-02 15:05:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][700/1251]	eta 0:05:14 lr 0.000086	time 0.5530 (0.5701)	loss 2.1744 (2.6997)	grad_norm 2.4047 (2.4320)	mem 17417MB
[2023-02-02 15:06:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][750/1251]	eta 0:04:45 lr 0.000085	time 0.5571 (0.5701)	loss 2.4023 (2.6946)	grad_norm 2.5502 (2.4305)	mem 17417MB
[2023-02-02 15:06:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][800/1251]	eta 0:04:17 lr 0.000085	time 0.5543 (0.5701)	loss 2.9298 (2.6961)	grad_norm 2.4331 (2.4288)	mem 17417MB
[2023-02-02 15:07:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][850/1251]	eta 0:03:48 lr 0.000085	time 0.5557 (0.5700)	loss 2.1430 (2.6940)	grad_norm 2.2283 (2.4279)	mem 17417MB
[2023-02-02 15:07:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][900/1251]	eta 0:03:20 lr 0.000085	time 0.6195 (0.5701)	loss 2.8168 (2.6963)	grad_norm 2.8798 (2.4277)	mem 17417MB
[2023-02-02 15:08:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][950/1251]	eta 0:02:51 lr 0.000085	time 0.5603 (0.5698)	loss 2.7461 (2.6999)	grad_norm 2.2052 (2.4304)	mem 17417MB
[2023-02-02 15:08:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][1000/1251]	eta 0:02:23 lr 0.000085	time 0.5586 (0.5700)	loss 2.6919 (2.6998)	grad_norm 2.3028 (2.4292)	mem 17417MB
[2023-02-02 15:09:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][1050/1251]	eta 0:01:54 lr 0.000085	time 0.5582 (0.5700)	loss 2.9563 (2.6982)	grad_norm 2.6101 (2.4269)	mem 17417MB
[2023-02-02 15:09:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][1100/1251]	eta 0:01:26 lr 0.000085	time 0.6217 (0.5700)	loss 2.3691 (2.6939)	grad_norm 2.3324 (2.4311)	mem 17417MB
[2023-02-02 15:10:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][1150/1251]	eta 0:00:57 lr 0.000085	time 0.6215 (0.5698)	loss 2.3969 (2.6977)	grad_norm 2.2257 (2.4314)	mem 17417MB
[2023-02-02 15:10:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][1200/1251]	eta 0:00:29 lr 0.000084	time 0.5551 (0.5696)	loss 2.8195 (2.7021)	grad_norm 2.3111 (2.4295)	mem 17417MB
[2023-02-02 15:11:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [246/300][1250/1251]	eta 0:00:00 lr 0.000084	time 0.5508 (0.5696)	loss 2.7098 (2.7028)	grad_norm 2.5597 (2.4257)	mem 17417MB
[2023-02-02 15:11:12 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 246 training takes 0:11:52
[2023-02-02 15:11:12 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_246.pth saving......
[2023-02-02 15:11:14 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_246.pth saved !!!
[2023-02-02 15:11:15 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.835 (0.835)	Loss 0.6917 (0.6917)	Acc@1 83.789 (83.789)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 15:11:23 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.252 Acc@5 96.560
[2023-02-02 15:11:23 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.3%
[2023-02-02 15:11:24 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.183 (1.183)	Loss 0.6834 (0.6834)	Acc@1 83.887 (83.887)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-02 15:11:32 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.892 Acc@5 96.804
[2023-02-02 15:11:32 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 15:11:32 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.89% at 246 epoch
[2023-02-02 15:11:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][0/1251]	eta 0:34:57 lr 0.000084	time 1.6770 (1.6770)	loss 2.5660 (2.5660)	grad_norm 2.6549 (2.6549)	mem 17417MB
[2023-02-02 15:12:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][50/1251]	eta 0:11:54 lr 0.000084	time 0.6394 (0.5947)	loss 3.0727 (2.6887)	grad_norm 2.2437 (2.4209)	mem 17417MB
[2023-02-02 15:12:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][100/1251]	eta 0:11:10 lr 0.000084	time 0.5531 (0.5827)	loss 3.1698 (2.6649)	grad_norm 2.3055 (2.3980)	mem 17417MB
[2023-02-02 15:13:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][150/1251]	eta 0:10:36 lr 0.000084	time 0.5553 (0.5783)	loss 2.9241 (2.6847)	grad_norm 2.2430 (2.4323)	mem 17417MB
[2023-02-02 15:13:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][200/1251]	eta 0:10:04 lr 0.000084	time 0.5588 (0.5753)	loss 2.4160 (2.6818)	grad_norm 2.1699 (2.4342)	mem 17417MB
[2023-02-02 15:13:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][250/1251]	eta 0:09:34 lr 0.000084	time 0.5525 (0.5743)	loss 2.9249 (2.6897)	grad_norm 2.5453 (2.4504)	mem 17417MB
[2023-02-02 15:14:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][300/1251]	eta 0:09:05 lr 0.000084	time 0.5537 (0.5734)	loss 2.2685 (2.6844)	grad_norm 2.6439 (2.4486)	mem 17417MB
[2023-02-02 15:14:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][350/1251]	eta 0:08:36 lr 0.000084	time 0.5554 (0.5731)	loss 2.7190 (2.6967)	grad_norm 2.7756 (2.4452)	mem 17417MB
[2023-02-02 15:15:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][400/1251]	eta 0:08:07 lr 0.000083	time 0.5516 (0.5726)	loss 2.9490 (2.6951)	grad_norm 2.3626 (2.4424)	mem 17417MB
[2023-02-02 15:15:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][450/1251]	eta 0:07:38 lr 0.000083	time 0.6245 (0.5726)	loss 2.0306 (2.6786)	grad_norm 3.7034 (2.4472)	mem 17417MB
[2023-02-02 15:16:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][500/1251]	eta 0:07:09 lr 0.000083	time 0.5665 (0.5720)	loss 3.2383 (2.6709)	grad_norm 2.4971 (2.4445)	mem 17417MB
[2023-02-02 15:16:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][550/1251]	eta 0:06:40 lr 0.000083	time 0.6342 (0.5717)	loss 2.9430 (2.6802)	grad_norm 2.5220 (2.4470)	mem 17417MB
[2023-02-02 15:17:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][600/1251]	eta 0:06:12 lr 0.000083	time 0.5563 (0.5715)	loss 1.9869 (2.6811)	grad_norm 2.3475 (2.4486)	mem 17417MB
[2023-02-02 15:17:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][650/1251]	eta 0:05:43 lr 0.000083	time 0.5603 (0.5714)	loss 3.2233 (2.6832)	grad_norm 2.3010 (2.4499)	mem 17417MB
[2023-02-02 15:18:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][700/1251]	eta 0:05:14 lr 0.000083	time 0.5555 (0.5712)	loss 2.1597 (2.6835)	grad_norm 2.3611 (inf)	mem 17417MB
[2023-02-02 15:18:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][750/1251]	eta 0:04:46 lr 0.000083	time 0.5572 (0.5711)	loss 2.4913 (2.6871)	grad_norm 2.2771 (inf)	mem 17417MB
[2023-02-02 15:19:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][800/1251]	eta 0:04:17 lr 0.000083	time 0.5546 (0.5711)	loss 2.1181 (2.6921)	grad_norm 2.2024 (inf)	mem 17417MB
[2023-02-02 15:19:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][850/1251]	eta 0:03:48 lr 0.000082	time 0.6175 (0.5709)	loss 2.7879 (2.6978)	grad_norm 2.3379 (inf)	mem 17417MB
[2023-02-02 15:20:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][900/1251]	eta 0:03:20 lr 0.000082	time 0.5556 (0.5708)	loss 1.9291 (2.7034)	grad_norm 2.3377 (inf)	mem 17417MB
[2023-02-02 15:20:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][950/1251]	eta 0:02:51 lr 0.000082	time 0.5537 (0.5707)	loss 2.6000 (2.7039)	grad_norm 2.2565 (inf)	mem 17417MB
[2023-02-02 15:21:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][1000/1251]	eta 0:02:23 lr 0.000082	time 0.6173 (0.5708)	loss 2.8658 (2.6990)	grad_norm 2.3101 (inf)	mem 17417MB
[2023-02-02 15:21:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][1050/1251]	eta 0:01:54 lr 0.000082	time 0.5484 (0.5706)	loss 2.7239 (2.7003)	grad_norm 2.5850 (inf)	mem 17417MB
[2023-02-02 15:22:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][1100/1251]	eta 0:01:26 lr 0.000082	time 0.5549 (0.5706)	loss 2.8069 (2.7001)	grad_norm 2.4502 (inf)	mem 17417MB
[2023-02-02 15:22:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][1150/1251]	eta 0:00:57 lr 0.000082	time 0.5559 (0.5705)	loss 3.1973 (2.6999)	grad_norm 2.1933 (inf)	mem 17417MB
[2023-02-02 15:22:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][1200/1251]	eta 0:00:29 lr 0.000082	time 0.5537 (0.5706)	loss 3.4533 (2.6994)	grad_norm 2.4196 (inf)	mem 17417MB
[2023-02-02 15:23:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [247/300][1250/1251]	eta 0:00:00 lr 0.000082	time 0.5776 (0.5706)	loss 1.5635 (2.7004)	grad_norm 3.0889 (inf)	mem 17417MB
[2023-02-02 15:23:26 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 247 training takes 0:11:53
[2023-02-02 15:23:26 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_247.pth saving......
[2023-02-02 15:23:28 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_247.pth saved !!!
[2023-02-02 15:23:29 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.924 (0.924)	Loss 0.8035 (0.8035)	Acc@1 81.445 (81.445)	Acc@5 95.605 (95.605)	Mem 17417MB
[2023-02-02 15:23:37 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.262 Acc@5 96.576
[2023-02-02 15:23:37 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.3%
[2023-02-02 15:23:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.141 (1.141)	Loss 0.6651 (0.6651)	Acc@1 84.766 (84.766)	Acc@5 96.484 (96.484)	Mem 17417MB
[2023-02-02 15:23:46 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.884 Acc@5 96.816
[2023-02-02 15:23:46 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 15:23:46 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.89% at 246 epoch
[2023-02-02 15:23:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][0/1251]	eta 0:36:04 lr 0.000082	time 1.7301 (1.7301)	loss 2.0599 (2.0599)	grad_norm 2.5199 (2.5199)	mem 17417MB
[2023-02-02 15:24:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][50/1251]	eta 0:11:53 lr 0.000081	time 0.5560 (0.5944)	loss 1.7903 (2.6352)	grad_norm 2.3255 (2.5334)	mem 17417MB
[2023-02-02 15:24:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][100/1251]	eta 0:11:09 lr 0.000081	time 0.6236 (0.5817)	loss 2.0419 (2.6860)	grad_norm 2.3720 (2.4411)	mem 17417MB
[2023-02-02 15:25:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][150/1251]	eta 0:10:36 lr 0.000081	time 0.5543 (0.5780)	loss 1.8518 (2.6834)	grad_norm 2.9011 (2.4265)	mem 17417MB
[2023-02-02 15:25:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][200/1251]	eta 0:10:04 lr 0.000081	time 0.5478 (0.5754)	loss 2.7778 (2.7095)	grad_norm 2.6206 (2.4412)	mem 17417MB
[2023-02-02 15:26:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][250/1251]	eta 0:09:34 lr 0.000081	time 0.5485 (0.5738)	loss 2.0101 (2.7028)	grad_norm 2.1550 (2.4417)	mem 17417MB
[2023-02-02 15:26:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][300/1251]	eta 0:09:05 lr 0.000081	time 0.5519 (0.5732)	loss 2.0367 (2.6946)	grad_norm 2.5695 (2.4319)	mem 17417MB
[2023-02-02 15:27:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][350/1251]	eta 0:08:36 lr 0.000081	time 0.5553 (0.5728)	loss 2.2898 (2.6961)	grad_norm 2.4412 (2.4314)	mem 17417MB
[2023-02-02 15:27:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][400/1251]	eta 0:08:07 lr 0.000081	time 0.5735 (0.5726)	loss 2.8650 (2.6993)	grad_norm 2.5206 (2.4363)	mem 17417MB
[2023-02-02 15:28:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][450/1251]	eta 0:07:38 lr 0.000081	time 0.5677 (0.5723)	loss 2.4550 (2.7057)	grad_norm 2.6013 (2.4397)	mem 17417MB
[2023-02-02 15:28:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][500/1251]	eta 0:07:09 lr 0.000081	time 0.6270 (0.5718)	loss 3.2501 (2.7101)	grad_norm 2.7456 (2.4375)	mem 17417MB
[2023-02-02 15:29:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][550/1251]	eta 0:06:40 lr 0.000080	time 0.5525 (0.5717)	loss 1.8826 (2.7147)	grad_norm 2.7105 (2.4399)	mem 17417MB
[2023-02-02 15:29:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][600/1251]	eta 0:06:12 lr 0.000080	time 0.5689 (0.5717)	loss 3.0798 (2.7156)	grad_norm 2.5309 (2.4388)	mem 17417MB
[2023-02-02 15:29:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][650/1251]	eta 0:05:43 lr 0.000080	time 0.5562 (0.5716)	loss 2.9136 (2.7129)	grad_norm 2.5588 (2.4335)	mem 17417MB
[2023-02-02 15:30:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][700/1251]	eta 0:05:14 lr 0.000080	time 0.5538 (0.5716)	loss 3.3323 (2.7105)	grad_norm 2.2935 (2.4317)	mem 17417MB
[2023-02-02 15:30:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][750/1251]	eta 0:04:46 lr 0.000080	time 0.5544 (0.5713)	loss 3.2436 (2.6995)	grad_norm 2.6172 (2.4297)	mem 17417MB
[2023-02-02 15:31:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][800/1251]	eta 0:04:17 lr 0.000080	time 0.6176 (0.5712)	loss 2.5315 (2.6976)	grad_norm 2.7078 (2.4300)	mem 17417MB
[2023-02-02 15:31:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][850/1251]	eta 0:03:48 lr 0.000080	time 0.5612 (0.5709)	loss 3.1568 (2.7015)	grad_norm 2.8590 (2.4377)	mem 17417MB
[2023-02-02 15:32:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][900/1251]	eta 0:03:20 lr 0.000080	time 0.6234 (0.5709)	loss 2.7922 (2.6981)	grad_norm 2.3456 (2.4413)	mem 17417MB
[2023-02-02 15:32:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][950/1251]	eta 0:02:51 lr 0.000080	time 0.5525 (0.5709)	loss 2.3318 (2.6982)	grad_norm 2.0576 (2.4405)	mem 17417MB
[2023-02-02 15:33:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][1000/1251]	eta 0:02:23 lr 0.000079	time 0.5665 (0.5708)	loss 2.6795 (2.7034)	grad_norm 2.4181 (2.4412)	mem 17417MB
[2023-02-02 15:33:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][1050/1251]	eta 0:01:54 lr 0.000079	time 0.5548 (0.5706)	loss 2.8980 (2.7057)	grad_norm 2.4272 (2.4467)	mem 17417MB
[2023-02-02 15:34:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][1100/1251]	eta 0:01:26 lr 0.000079	time 0.5624 (0.5706)	loss 2.9599 (2.7156)	grad_norm 2.6975 (2.4491)	mem 17417MB
[2023-02-02 15:34:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][1150/1251]	eta 0:00:57 lr 0.000079	time 0.5746 (0.5706)	loss 2.4542 (2.7146)	grad_norm 2.6962 (2.4481)	mem 17417MB
[2023-02-02 15:35:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][1200/1251]	eta 0:00:29 lr 0.000079	time 0.5609 (0.5706)	loss 2.9108 (2.7083)	grad_norm 2.3524 (2.4481)	mem 17417MB
[2023-02-02 15:35:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [248/300][1250/1251]	eta 0:00:00 lr 0.000079	time 0.5505 (0.5707)	loss 2.7399 (2.7086)	grad_norm 2.1975 (2.4455)	mem 17417MB
[2023-02-02 15:35:40 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 248 training takes 0:11:54
[2023-02-02 15:35:40 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_248.pth saving......
[2023-02-02 15:35:42 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_248.pth saved !!!
[2023-02-02 15:35:43 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.972 (0.972)	Loss 0.5783 (0.5783)	Acc@1 86.328 (86.328)	Acc@5 98.047 (98.047)	Mem 17417MB
[2023-02-02 15:35:51 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.442 Acc@5 96.654
[2023-02-02 15:35:51 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.4%
[2023-02-02 15:35:52 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.426 (1.426)	Loss 0.7859 (0.7859)	Acc@1 81.738 (81.738)	Acc@5 96.484 (96.484)	Mem 17417MB
[2023-02-02 15:36:00 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.888 Acc@5 96.820
[2023-02-02 15:36:00 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 15:36:00 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.89% at 246 epoch
[2023-02-02 15:36:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][0/1251]	eta 0:34:30 lr 0.000079	time 1.6551 (1.6551)	loss 2.4272 (2.4272)	grad_norm 2.5865 (2.5865)	mem 17417MB
[2023-02-02 15:36:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][50/1251]	eta 0:11:54 lr 0.000079	time 0.5643 (0.5952)	loss 3.5199 (2.5672)	grad_norm 2.2623 (2.3243)	mem 17417MB
[2023-02-02 15:36:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][100/1251]	eta 0:11:09 lr 0.000079	time 0.5636 (0.5818)	loss 2.9262 (2.5621)	grad_norm 2.5681 (2.3926)	mem 17417MB
[2023-02-02 15:37:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][150/1251]	eta 0:10:35 lr 0.000079	time 0.5568 (0.5775)	loss 2.8397 (2.5519)	grad_norm 2.3101 (2.4262)	mem 17417MB
[2023-02-02 15:37:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][200/1251]	eta 0:10:04 lr 0.000079	time 0.5527 (0.5750)	loss 3.3831 (2.5981)	grad_norm 2.4370 (2.4111)	mem 17417MB
[2023-02-02 15:38:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][250/1251]	eta 0:09:33 lr 0.000078	time 0.5590 (0.5731)	loss 2.5208 (2.6269)	grad_norm 2.8399 (2.4097)	mem 17417MB
[2023-02-02 15:38:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][300/1251]	eta 0:09:04 lr 0.000078	time 0.5514 (0.5725)	loss 2.4803 (2.6317)	grad_norm 2.6859 (2.4252)	mem 17417MB
[2023-02-02 15:39:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][350/1251]	eta 0:08:34 lr 0.000078	time 0.5517 (0.5713)	loss 3.2539 (2.6360)	grad_norm 2.7826 (2.4268)	mem 17417MB
[2023-02-02 15:39:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][400/1251]	eta 0:08:06 lr 0.000078	time 0.5559 (0.5715)	loss 2.2840 (2.6254)	grad_norm 2.4038 (2.4266)	mem 17417MB
[2023-02-02 15:40:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][450/1251]	eta 0:07:37 lr 0.000078	time 0.6240 (0.5710)	loss 2.5832 (2.6227)	grad_norm 2.2998 (2.4318)	mem 17417MB
[2023-02-02 15:40:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][500/1251]	eta 0:07:08 lr 0.000078	time 0.5609 (0.5705)	loss 1.5077 (2.6286)	grad_norm 2.7054 (2.4436)	mem 17417MB
[2023-02-02 15:41:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][550/1251]	eta 0:06:39 lr 0.000078	time 0.5535 (0.5703)	loss 2.7262 (2.6433)	grad_norm 2.2754 (2.4611)	mem 17417MB
[2023-02-02 15:41:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][600/1251]	eta 0:06:11 lr 0.000078	time 0.5649 (0.5703)	loss 3.3018 (2.6503)	grad_norm 2.4744 (2.4568)	mem 17417MB
[2023-02-02 15:42:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][650/1251]	eta 0:05:42 lr 0.000078	time 0.5525 (0.5700)	loss 3.0009 (2.6462)	grad_norm 2.3585 (2.4541)	mem 17417MB
[2023-02-02 15:42:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][700/1251]	eta 0:05:14 lr 0.000077	time 0.5632 (0.5700)	loss 2.9534 (2.6516)	grad_norm 2.1020 (2.4559)	mem 17417MB
[2023-02-02 15:43:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][750/1251]	eta 0:04:45 lr 0.000077	time 0.6171 (0.5696)	loss 2.9121 (2.6532)	grad_norm 2.3396 (2.4529)	mem 17417MB
[2023-02-02 15:43:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][800/1251]	eta 0:04:16 lr 0.000077	time 0.5511 (0.5695)	loss 2.1945 (2.6567)	grad_norm 2.3849 (2.4523)	mem 17417MB
[2023-02-02 15:44:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][850/1251]	eta 0:03:48 lr 0.000077	time 0.5523 (0.5695)	loss 2.4079 (2.6598)	grad_norm 2.5131 (2.4487)	mem 17417MB
[2023-02-02 15:44:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][900/1251]	eta 0:03:19 lr 0.000077	time 0.5559 (0.5693)	loss 2.8029 (2.6645)	grad_norm 2.0927 (2.4481)	mem 17417MB
[2023-02-02 15:45:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][950/1251]	eta 0:02:51 lr 0.000077	time 0.5508 (0.5693)	loss 2.7759 (2.6700)	grad_norm 2.3409 (2.4513)	mem 17417MB
[2023-02-02 15:45:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][1000/1251]	eta 0:02:22 lr 0.000077	time 0.5551 (0.5693)	loss 1.9053 (2.6619)	grad_norm 2.4827 (2.4530)	mem 17417MB
[2023-02-02 15:45:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][1050/1251]	eta 0:01:54 lr 0.000077	time 0.5552 (0.5692)	loss 2.7989 (2.6651)	grad_norm 2.4053 (2.4513)	mem 17417MB
[2023-02-02 15:46:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][1100/1251]	eta 0:01:25 lr 0.000077	time 0.6253 (0.5693)	loss 2.8545 (2.6668)	grad_norm 2.4942 (2.4531)	mem 17417MB
[2023-02-02 15:46:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][1150/1251]	eta 0:00:57 lr 0.000077	time 0.5534 (0.5691)	loss 1.7983 (2.6677)	grad_norm 2.3147 (2.4510)	mem 17417MB
[2023-02-02 15:47:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][1200/1251]	eta 0:00:29 lr 0.000076	time 0.5607 (0.5691)	loss 1.4911 (2.6684)	grad_norm 2.2742 (2.4526)	mem 17417MB
[2023-02-02 15:47:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [249/300][1250/1251]	eta 0:00:00 lr 0.000076	time 0.5534 (0.5692)	loss 2.8867 (2.6675)	grad_norm 2.5574 (2.4496)	mem 17417MB
[2023-02-02 15:47:52 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 249 training takes 0:11:52
[2023-02-02 15:47:52 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_249.pth saving......
[2023-02-02 15:47:54 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_249.pth saved !!!
[2023-02-02 15:47:55 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.900 (0.900)	Loss 0.6838 (0.6838)	Acc@1 83.301 (83.301)	Acc@5 97.461 (97.461)	Mem 17417MB
[2023-02-02 15:48:03 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.432 Acc@5 96.634
[2023-02-02 15:48:03 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.4%
[2023-02-02 15:48:04 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.266 (1.266)	Loss 0.7334 (0.7334)	Acc@1 83.887 (83.887)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 15:48:12 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.886 Acc@5 96.832
[2023-02-02 15:48:12 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 15:48:12 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.89% at 246 epoch
[2023-02-02 15:48:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][0/1251]	eta 0:37:46 lr 0.000076	time 1.8116 (1.8116)	loss 1.7224 (1.7224)	grad_norm 2.1610 (2.1610)	mem 17417MB
[2023-02-02 15:48:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][50/1251]	eta 0:11:54 lr 0.000076	time 0.5643 (0.5951)	loss 3.0836 (2.6567)	grad_norm 2.5579 (2.4361)	mem 17417MB
[2023-02-02 15:49:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][100/1251]	eta 0:11:13 lr 0.000076	time 0.5566 (0.5850)	loss 3.0103 (2.6673)	grad_norm 2.4241 (2.4673)	mem 17417MB
[2023-02-02 15:49:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][150/1251]	eta 0:10:37 lr 0.000076	time 0.5550 (0.5788)	loss 3.0704 (2.6818)	grad_norm 2.8122 (2.4451)	mem 17417MB
[2023-02-02 15:50:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][200/1251]	eta 0:10:07 lr 0.000076	time 0.5627 (0.5776)	loss 2.7028 (2.7070)	grad_norm 2.2831 (2.4375)	mem 17417MB
[2023-02-02 15:50:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][250/1251]	eta 0:09:36 lr 0.000076	time 0.5606 (0.5758)	loss 3.1231 (2.7100)	grad_norm 2.9155 (2.4433)	mem 17417MB
[2023-02-02 15:51:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][300/1251]	eta 0:09:06 lr 0.000076	time 0.5517 (0.5748)	loss 2.9340 (2.7010)	grad_norm 2.5017 (2.4467)	mem 17417MB
[2023-02-02 15:51:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][350/1251]	eta 0:08:36 lr 0.000076	time 0.5586 (0.5737)	loss 2.8183 (2.6953)	grad_norm 2.7492 (inf)	mem 17417MB
[2023-02-02 15:52:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][400/1251]	eta 0:08:07 lr 0.000075	time 0.5706 (0.5733)	loss 2.9451 (2.6995)	grad_norm 2.6639 (inf)	mem 17417MB
[2023-02-02 15:52:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][450/1251]	eta 0:07:38 lr 0.000075	time 0.5569 (0.5727)	loss 3.1539 (2.7022)	grad_norm 2.6935 (inf)	mem 17417MB
[2023-02-02 15:52:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][500/1251]	eta 0:07:09 lr 0.000075	time 0.5507 (0.5725)	loss 2.6709 (2.6963)	grad_norm 2.2331 (inf)	mem 17417MB
[2023-02-02 15:53:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][550/1251]	eta 0:06:40 lr 0.000075	time 0.5522 (0.5720)	loss 2.1562 (2.6922)	grad_norm 2.6826 (inf)	mem 17417MB
[2023-02-02 15:53:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][600/1251]	eta 0:06:12 lr 0.000075	time 0.5574 (0.5720)	loss 2.6899 (2.6938)	grad_norm 2.6962 (inf)	mem 17417MB
[2023-02-02 15:54:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][650/1251]	eta 0:05:43 lr 0.000075	time 0.5589 (0.5720)	loss 3.1081 (2.6987)	grad_norm 2.1319 (inf)	mem 17417MB
[2023-02-02 15:54:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][700/1251]	eta 0:05:15 lr 0.000075	time 0.5521 (0.5718)	loss 2.0790 (2.6971)	grad_norm 2.4068 (inf)	mem 17417MB
[2023-02-02 15:55:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][750/1251]	eta 0:04:46 lr 0.000075	time 0.5611 (0.5716)	loss 2.9901 (2.6931)	grad_norm 2.5287 (inf)	mem 17417MB
[2023-02-02 15:55:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][800/1251]	eta 0:04:17 lr 0.000075	time 0.6238 (0.5714)	loss 3.1126 (2.7010)	grad_norm 2.9811 (inf)	mem 17417MB
[2023-02-02 15:56:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][850/1251]	eta 0:03:49 lr 0.000075	time 0.5595 (0.5712)	loss 3.2182 (2.7016)	grad_norm 2.4843 (inf)	mem 17417MB
[2023-02-02 15:56:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][900/1251]	eta 0:03:20 lr 0.000074	time 0.5657 (0.5713)	loss 3.1166 (2.7021)	grad_norm 2.2253 (inf)	mem 17417MB
[2023-02-02 15:57:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][950/1251]	eta 0:02:51 lr 0.000074	time 0.5540 (0.5712)	loss 2.3135 (2.7029)	grad_norm 2.4673 (inf)	mem 17417MB
[2023-02-02 15:57:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][1000/1251]	eta 0:02:23 lr 0.000074	time 0.5597 (0.5713)	loss 2.9344 (2.7000)	grad_norm 2.6829 (inf)	mem 17417MB
[2023-02-02 15:58:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][1050/1251]	eta 0:01:54 lr 0.000074	time 0.5552 (0.5711)	loss 2.0148 (2.6955)	grad_norm 2.3211 (inf)	mem 17417MB
[2023-02-02 15:58:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][1100/1251]	eta 0:01:26 lr 0.000074	time 0.6280 (0.5711)	loss 2.7380 (2.6933)	grad_norm 2.1828 (inf)	mem 17417MB
[2023-02-02 15:59:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][1150/1251]	eta 0:00:57 lr 0.000074	time 0.5544 (0.5710)	loss 2.8672 (2.6938)	grad_norm 2.6434 (inf)	mem 17417MB
[2023-02-02 15:59:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][1200/1251]	eta 0:00:29 lr 0.000074	time 0.5534 (0.5707)	loss 2.5062 (2.6894)	grad_norm 2.6272 (inf)	mem 17417MB
[2023-02-02 16:00:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [250/300][1250/1251]	eta 0:00:00 lr 0.000074	time 0.5529 (0.5708)	loss 2.3704 (2.6864)	grad_norm 2.3741 (inf)	mem 17417MB
[2023-02-02 16:00:07 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 250 training takes 0:11:54
[2023-02-02 16:00:07 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_250.pth saving......
[2023-02-02 16:00:08 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_250.pth saved !!!
[2023-02-02 16:00:09 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.851 (0.851)	Loss 0.7821 (0.7821)	Acc@1 83.008 (83.008)	Acc@5 95.703 (95.703)	Mem 17417MB
[2023-02-02 16:00:17 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.492 Acc@5 96.626
[2023-02-02 16:00:17 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.5%
[2023-02-02 16:00:18 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.168 (1.168)	Loss 0.7244 (0.7244)	Acc@1 82.910 (82.910)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-02 16:00:27 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.884 Acc@5 96.826
[2023-02-02 16:00:27 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 16:00:27 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.89% at 246 epoch
[2023-02-02 16:00:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][0/1251]	eta 0:34:10 lr 0.000074	time 1.6390 (1.6390)	loss 3.0533 (3.0533)	grad_norm 2.2950 (2.2950)	mem 17417MB
[2023-02-02 16:00:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][50/1251]	eta 0:11:53 lr 0.000074	time 0.5540 (0.5940)	loss 3.0501 (2.6223)	grad_norm 2.7682 (2.4074)	mem 17417MB
[2023-02-02 16:01:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][100/1251]	eta 0:11:08 lr 0.000074	time 0.5574 (0.5810)	loss 2.5143 (2.6290)	grad_norm 3.0813 (2.4266)	mem 17417MB
[2023-02-02 16:01:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][150/1251]	eta 0:10:35 lr 0.000073	time 0.5528 (0.5772)	loss 2.4058 (2.6462)	grad_norm 2.3758 (2.4320)	mem 17417MB
[2023-02-02 16:02:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][200/1251]	eta 0:10:03 lr 0.000073	time 0.5505 (0.5743)	loss 2.0107 (2.6603)	grad_norm 2.3679 (2.4505)	mem 17417MB
[2023-02-02 16:02:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][250/1251]	eta 0:09:33 lr 0.000073	time 0.5571 (0.5724)	loss 1.9420 (2.6394)	grad_norm 2.2009 (2.4615)	mem 17417MB
[2023-02-02 16:03:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][300/1251]	eta 0:09:03 lr 0.000073	time 0.5619 (0.5719)	loss 2.6634 (2.6528)	grad_norm 1.9426 (2.4541)	mem 17417MB
[2023-02-02 16:03:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][350/1251]	eta 0:08:35 lr 0.000073	time 0.5660 (0.5716)	loss 3.1253 (2.6495)	grad_norm 2.5152 (2.4489)	mem 17417MB
[2023-02-02 16:04:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][400/1251]	eta 0:08:06 lr 0.000073	time 0.6402 (0.5716)	loss 2.4431 (2.6487)	grad_norm 2.3215 (2.4541)	mem 17417MB
[2023-02-02 16:04:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][450/1251]	eta 0:07:37 lr 0.000073	time 0.5548 (0.5715)	loss 2.0342 (2.6543)	grad_norm 2.4305 (2.4727)	mem 17417MB
[2023-02-02 16:05:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][500/1251]	eta 0:07:08 lr 0.000073	time 0.5570 (0.5709)	loss 2.9646 (2.6502)	grad_norm 2.4276 (2.4692)	mem 17417MB
[2023-02-02 16:05:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][550/1251]	eta 0:06:40 lr 0.000073	time 0.5566 (0.5709)	loss 3.0805 (2.6568)	grad_norm 2.3001 (2.4716)	mem 17417MB
[2023-02-02 16:06:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][600/1251]	eta 0:06:11 lr 0.000073	time 0.5506 (0.5707)	loss 2.7339 (2.6554)	grad_norm 2.4647 (2.4729)	mem 17417MB
[2023-02-02 16:06:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][650/1251]	eta 0:05:43 lr 0.000072	time 0.5622 (0.5708)	loss 3.0032 (2.6581)	grad_norm 2.3640 (2.4760)	mem 17417MB
[2023-02-02 16:07:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][700/1251]	eta 0:05:14 lr 0.000072	time 0.5574 (0.5706)	loss 3.2023 (2.6564)	grad_norm 2.5283 (2.4851)	mem 17417MB
[2023-02-02 16:07:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][750/1251]	eta 0:04:45 lr 0.000072	time 0.5549 (0.5703)	loss 1.8708 (2.6551)	grad_norm 2.4862 (2.4865)	mem 17417MB
[2023-02-02 16:08:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][800/1251]	eta 0:04:17 lr 0.000072	time 0.5591 (0.5702)	loss 1.7603 (2.6571)	grad_norm 2.1197 (2.4823)	mem 17417MB
[2023-02-02 16:08:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][850/1251]	eta 0:03:48 lr 0.000072	time 0.5576 (0.5702)	loss 3.1779 (2.6624)	grad_norm 2.6111 (2.4843)	mem 17417MB
[2023-02-02 16:09:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][900/1251]	eta 0:03:20 lr 0.000072	time 0.5632 (0.5700)	loss 1.7959 (2.6623)	grad_norm 2.5081 (2.4813)	mem 17417MB
[2023-02-02 16:09:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][950/1251]	eta 0:02:51 lr 0.000072	time 0.5573 (0.5698)	loss 2.8903 (2.6581)	grad_norm 2.4167 (2.4807)	mem 17417MB
[2023-02-02 16:09:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][1000/1251]	eta 0:02:23 lr 0.000072	time 0.6146 (0.5698)	loss 2.1850 (2.6572)	grad_norm 2.9964 (inf)	mem 17417MB
[2023-02-02 16:10:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][1050/1251]	eta 0:01:54 lr 0.000072	time 0.5506 (0.5697)	loss 2.5369 (2.6588)	grad_norm 2.1882 (inf)	mem 17417MB
[2023-02-02 16:10:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][1100/1251]	eta 0:01:26 lr 0.000072	time 0.5523 (0.5698)	loss 2.4013 (2.6630)	grad_norm 3.1930 (inf)	mem 17417MB
[2023-02-02 16:11:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][1150/1251]	eta 0:00:57 lr 0.000071	time 0.5651 (0.5696)	loss 3.1248 (2.6625)	grad_norm 2.5624 (inf)	mem 17417MB
[2023-02-02 16:11:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][1200/1251]	eta 0:00:29 lr 0.000071	time 0.5530 (0.5697)	loss 2.7083 (2.6586)	grad_norm 2.7168 (inf)	mem 17417MB
[2023-02-02 16:12:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [251/300][1250/1251]	eta 0:00:00 lr 0.000071	time 0.5496 (0.5697)	loss 3.2564 (2.6561)	grad_norm 2.9180 (inf)	mem 17417MB
[2023-02-02 16:12:19 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 251 training takes 0:11:52
[2023-02-02 16:12:19 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_251.pth saving......
[2023-02-02 16:12:21 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_251.pth saved !!!
[2023-02-02 16:12:22 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.916 (0.916)	Loss 0.7138 (0.7138)	Acc@1 83.594 (83.594)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-02 16:12:30 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.530 Acc@5 96.620
[2023-02-02 16:12:30 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.5%
[2023-02-02 16:12:31 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.345 (1.345)	Loss 0.6386 (0.6386)	Acc@1 85.645 (85.645)	Acc@5 96.875 (96.875)	Mem 17417MB
[2023-02-02 16:12:40 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.882 Acc@5 96.822
[2023-02-02 16:12:40 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 16:12:40 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.89% at 246 epoch
[2023-02-02 16:12:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][0/1251]	eta 0:36:39 lr 0.000071	time 1.7585 (1.7585)	loss 3.1272 (3.1272)	grad_norm 2.4430 (2.4430)	mem 17417MB
[2023-02-02 16:13:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][50/1251]	eta 0:11:48 lr 0.000071	time 0.5588 (0.5897)	loss 2.4183 (2.5816)	grad_norm 2.2364 (2.5263)	mem 17417MB
[2023-02-02 16:13:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][100/1251]	eta 0:11:08 lr 0.000071	time 0.5568 (0.5810)	loss 3.0495 (2.6251)	grad_norm 2.6982 (2.5358)	mem 17417MB
[2023-02-02 16:14:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][150/1251]	eta 0:10:34 lr 0.000071	time 0.5512 (0.5765)	loss 3.0065 (2.6347)	grad_norm 2.5585 (2.5215)	mem 17417MB
[2023-02-02 16:14:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][200/1251]	eta 0:10:03 lr 0.000071	time 0.5556 (0.5745)	loss 3.1017 (2.6727)	grad_norm 2.2592 (2.5320)	mem 17417MB
[2023-02-02 16:15:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][250/1251]	eta 0:09:33 lr 0.000071	time 0.5565 (0.5730)	loss 2.6831 (2.6671)	grad_norm 2.1960 (2.5446)	mem 17417MB
[2023-02-02 16:15:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][300/1251]	eta 0:09:04 lr 0.000071	time 0.6475 (0.5725)	loss 2.5047 (2.6771)	grad_norm 2.4324 (2.5305)	mem 17417MB
[2023-02-02 16:16:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][350/1251]	eta 0:08:35 lr 0.000071	time 0.5612 (0.5719)	loss 2.3109 (2.6827)	grad_norm 2.6154 (2.5375)	mem 17417MB
[2023-02-02 16:16:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][400/1251]	eta 0:08:06 lr 0.000070	time 0.5552 (0.5717)	loss 2.9540 (2.6763)	grad_norm 2.4014 (2.5414)	mem 17417MB
[2023-02-02 16:16:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][450/1251]	eta 0:07:37 lr 0.000070	time 0.5573 (0.5714)	loss 2.4068 (2.6697)	grad_norm 2.4057 (2.5306)	mem 17417MB
[2023-02-02 16:17:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][500/1251]	eta 0:07:09 lr 0.000070	time 0.5508 (0.5713)	loss 2.8670 (2.6658)	grad_norm 2.6858 (2.5339)	mem 17417MB
[2023-02-02 16:17:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][550/1251]	eta 0:06:40 lr 0.000070	time 0.6179 (0.5710)	loss 3.1602 (2.6645)	grad_norm 2.9332 (2.5328)	mem 17417MB
[2023-02-02 16:18:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][600/1251]	eta 0:06:11 lr 0.000070	time 0.5644 (0.5707)	loss 2.6040 (2.6618)	grad_norm 2.5809 (2.5310)	mem 17417MB
[2023-02-02 16:18:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][650/1251]	eta 0:05:42 lr 0.000070	time 0.5574 (0.5706)	loss 2.8196 (2.6612)	grad_norm 2.2408 (2.5257)	mem 17417MB
[2023-02-02 16:19:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][700/1251]	eta 0:05:14 lr 0.000070	time 0.5526 (0.5706)	loss 2.9165 (2.6574)	grad_norm 2.1958 (2.5214)	mem 17417MB
[2023-02-02 16:19:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][750/1251]	eta 0:04:45 lr 0.000070	time 0.5570 (0.5703)	loss 3.0455 (2.6646)	grad_norm 2.5115 (2.5155)	mem 17417MB
[2023-02-02 16:20:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][800/1251]	eta 0:04:17 lr 0.000070	time 0.5538 (0.5705)	loss 2.2113 (2.6692)	grad_norm 2.2340 (2.5113)	mem 17417MB
[2023-02-02 16:20:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][850/1251]	eta 0:03:48 lr 0.000070	time 0.5543 (0.5701)	loss 3.0534 (2.6734)	grad_norm 2.6200 (2.5138)	mem 17417MB
[2023-02-02 16:21:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][900/1251]	eta 0:03:20 lr 0.000069	time 0.5575 (0.5702)	loss 3.0112 (2.6730)	grad_norm 2.2770 (2.5154)	mem 17417MB
[2023-02-02 16:21:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][950/1251]	eta 0:02:51 lr 0.000069	time 0.5525 (0.5700)	loss 2.5876 (2.6708)	grad_norm 2.4895 (2.5153)	mem 17417MB
[2023-02-02 16:22:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][1000/1251]	eta 0:02:23 lr 0.000069	time 0.5609 (0.5699)	loss 2.3007 (2.6700)	grad_norm 2.2913 (2.5178)	mem 17417MB
[2023-02-02 16:22:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][1050/1251]	eta 0:01:54 lr 0.000069	time 0.5513 (0.5699)	loss 2.3794 (2.6716)	grad_norm 2.2915 (2.5138)	mem 17417MB
[2023-02-02 16:23:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][1100/1251]	eta 0:01:26 lr 0.000069	time 0.6280 (0.5699)	loss 1.9843 (2.6730)	grad_norm 2.6342 (2.5126)	mem 17417MB
[2023-02-02 16:23:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][1150/1251]	eta 0:00:57 lr 0.000069	time 0.6229 (0.5698)	loss 3.1986 (2.6743)	grad_norm 2.3126 (2.5104)	mem 17417MB
[2023-02-02 16:24:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][1200/1251]	eta 0:00:29 lr 0.000069	time 0.6190 (0.5700)	loss 2.9965 (2.6731)	grad_norm 2.5450 (2.5113)	mem 17417MB
[2023-02-02 16:24:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [252/300][1250/1251]	eta 0:00:00 lr 0.000069	time 0.5578 (0.5699)	loss 3.0161 (2.6697)	grad_norm 2.4543 (2.5133)	mem 17417MB
[2023-02-02 16:24:33 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 252 training takes 0:11:53
[2023-02-02 16:24:33 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_252.pth saving......
[2023-02-02 16:24:35 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_252.pth saved !!!
[2023-02-02 16:24:35 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.871 (0.871)	Loss 0.6908 (0.6908)	Acc@1 84.082 (84.082)	Acc@5 97.168 (97.168)	Mem 17417MB
[2023-02-02 16:24:43 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.492 Acc@5 96.646
[2023-02-02 16:24:43 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.5%
[2023-02-02 16:24:45 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.180 (1.180)	Loss 0.6963 (0.6963)	Acc@1 83.984 (83.984)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 16:24:53 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.898 Acc@5 96.818
[2023-02-02 16:24:53 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 16:24:53 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.90% at 252 epoch
[2023-02-02 16:24:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][0/1251]	eta 0:37:13 lr 0.000069	time 1.7854 (1.7854)	loss 3.1166 (3.1166)	grad_norm 2.5190 (2.5190)	mem 17417MB
[2023-02-02 16:25:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][50/1251]	eta 0:11:50 lr 0.000069	time 0.5611 (0.5914)	loss 3.2181 (2.6342)	grad_norm 2.9636 (2.5639)	mem 17417MB
[2023-02-02 16:25:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][100/1251]	eta 0:11:09 lr 0.000069	time 0.5539 (0.5814)	loss 3.0375 (2.6403)	grad_norm 2.5291 (2.5806)	mem 17417MB
[2023-02-02 16:26:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][150/1251]	eta 0:10:36 lr 0.000068	time 0.5554 (0.5779)	loss 1.8748 (2.6498)	grad_norm 2.6923 (2.5553)	mem 17417MB
[2023-02-02 16:26:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][200/1251]	eta 0:10:05 lr 0.000068	time 0.5573 (0.5759)	loss 1.8016 (2.6582)	grad_norm 2.5152 (2.5403)	mem 17417MB
[2023-02-02 16:27:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][250/1251]	eta 0:09:34 lr 0.000068	time 0.5522 (0.5741)	loss 3.0930 (2.6477)	grad_norm 2.4397 (2.5217)	mem 17417MB
[2023-02-02 16:27:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][300/1251]	eta 0:09:05 lr 0.000068	time 0.6183 (0.5737)	loss 3.1787 (2.6708)	grad_norm 2.1874 (2.5321)	mem 17417MB
[2023-02-02 16:28:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][350/1251]	eta 0:08:36 lr 0.000068	time 0.5542 (0.5728)	loss 1.6675 (2.6675)	grad_norm 3.0216 (2.5389)	mem 17417MB
[2023-02-02 16:28:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][400/1251]	eta 0:08:06 lr 0.000068	time 0.5551 (0.5723)	loss 2.5947 (2.6776)	grad_norm 2.5918 (2.5320)	mem 17417MB
[2023-02-02 16:29:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][450/1251]	eta 0:07:38 lr 0.000068	time 0.5551 (0.5719)	loss 3.1042 (2.6804)	grad_norm 2.2954 (2.5212)	mem 17417MB
[2023-02-02 16:29:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][500/1251]	eta 0:07:09 lr 0.000068	time 0.5561 (0.5714)	loss 3.3332 (2.6834)	grad_norm 2.1880 (2.5161)	mem 17417MB
[2023-02-02 16:30:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][550/1251]	eta 0:06:40 lr 0.000068	time 0.5662 (0.5717)	loss 2.5987 (2.6816)	grad_norm 2.4146 (2.5184)	mem 17417MB
[2023-02-02 16:30:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][600/1251]	eta 0:06:11 lr 0.000068	time 0.5602 (0.5713)	loss 3.1305 (2.6879)	grad_norm 2.6252 (2.5170)	mem 17417MB
[2023-02-02 16:31:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][650/1251]	eta 0:05:43 lr 0.000067	time 0.5571 (0.5712)	loss 2.7574 (2.6876)	grad_norm 2.4434 (2.5164)	mem 17417MB
[2023-02-02 16:31:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][700/1251]	eta 0:05:14 lr 0.000067	time 0.5531 (0.5713)	loss 3.0092 (2.6936)	grad_norm 2.6457 (2.5158)	mem 17417MB
[2023-02-02 16:32:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][750/1251]	eta 0:04:46 lr 0.000067	time 0.5725 (0.5710)	loss 2.4789 (2.6881)	grad_norm 2.4700 (2.5053)	mem 17417MB
[2023-02-02 16:32:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][800/1251]	eta 0:04:17 lr 0.000067	time 0.5539 (0.5708)	loss 2.2031 (2.6792)	grad_norm 2.4467 (2.4965)	mem 17417MB
[2023-02-02 16:32:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][850/1251]	eta 0:03:48 lr 0.000067	time 0.6176 (0.5708)	loss 2.5924 (2.6847)	grad_norm 2.3434 (2.4954)	mem 17417MB
[2023-02-02 16:33:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][900/1251]	eta 0:03:20 lr 0.000067	time 0.5544 (0.5708)	loss 1.9307 (2.6822)	grad_norm 2.2925 (2.4944)	mem 17417MB
[2023-02-02 16:33:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][950/1251]	eta 0:02:51 lr 0.000067	time 0.5654 (0.5709)	loss 2.7794 (2.6745)	grad_norm 2.6176 (2.4987)	mem 17417MB
[2023-02-02 16:34:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][1000/1251]	eta 0:02:23 lr 0.000067	time 0.5608 (0.5708)	loss 1.6932 (2.6751)	grad_norm 2.4831 (2.4994)	mem 17417MB
[2023-02-02 16:34:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][1050/1251]	eta 0:01:54 lr 0.000067	time 0.5696 (0.5707)	loss 1.5526 (2.6763)	grad_norm 2.5475 (2.4985)	mem 17417MB
[2023-02-02 16:35:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][1100/1251]	eta 0:01:26 lr 0.000067	time 0.6183 (0.5707)	loss 2.8246 (2.6741)	grad_norm 2.3748 (2.4962)	mem 17417MB
[2023-02-02 16:35:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][1150/1251]	eta 0:00:57 lr 0.000067	time 0.5512 (0.5705)	loss 1.7863 (2.6686)	grad_norm 2.3582 (2.4987)	mem 17417MB
[2023-02-02 16:36:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][1200/1251]	eta 0:00:29 lr 0.000066	time 0.5488 (0.5705)	loss 2.3112 (2.6664)	grad_norm 2.2311 (2.5026)	mem 17417MB
[2023-02-02 16:36:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [253/300][1250/1251]	eta 0:00:00 lr 0.000066	time 0.5495 (0.5705)	loss 3.2910 (2.6619)	grad_norm 3.0818 (2.5065)	mem 17417MB
[2023-02-02 16:36:46 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 253 training takes 0:11:53
[2023-02-02 16:36:47 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_253.pth saving......
[2023-02-02 16:36:48 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_253.pth saved !!!
[2023-02-02 16:36:49 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.869 (0.869)	Loss 0.6670 (0.6670)	Acc@1 83.105 (83.105)	Acc@5 97.168 (97.168)	Mem 17417MB
[2023-02-02 16:36:57 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.466 Acc@5 96.676
[2023-02-02 16:36:57 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.5%
[2023-02-02 16:36:58 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.204 (1.204)	Loss 0.6654 (0.6654)	Acc@1 85.156 (85.156)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-02 16:37:06 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.918 Acc@5 96.842
[2023-02-02 16:37:06 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 16:37:06 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.92% at 253 epoch
[2023-02-02 16:37:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][0/1251]	eta 0:35:05 lr 0.000066	time 1.6832 (1.6832)	loss 3.1530 (3.1530)	grad_norm 2.3787 (2.3787)	mem 17417MB
[2023-02-02 16:37:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][50/1251]	eta 0:11:49 lr 0.000066	time 0.5156 (0.5908)	loss 2.7311 (2.7441)	grad_norm inf (inf)	mem 17417MB
[2023-02-02 16:38:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][100/1251]	eta 0:11:07 lr 0.000066	time 0.6193 (0.5802)	loss 2.8087 (2.7259)	grad_norm 2.6579 (inf)	mem 17417MB
[2023-02-02 16:38:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][150/1251]	eta 0:10:35 lr 0.000066	time 0.5536 (0.5768)	loss 2.6151 (2.7098)	grad_norm 2.1524 (inf)	mem 17417MB
[2023-02-02 16:39:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][200/1251]	eta 0:10:04 lr 0.000066	time 0.6317 (0.5750)	loss 2.7726 (2.6728)	grad_norm 2.4969 (inf)	mem 17417MB
[2023-02-02 16:39:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][250/1251]	eta 0:09:33 lr 0.000066	time 0.5562 (0.5729)	loss 2.8764 (2.6399)	grad_norm 2.6377 (inf)	mem 17417MB
[2023-02-02 16:39:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][300/1251]	eta 0:09:04 lr 0.000066	time 0.5501 (0.5729)	loss 1.9223 (2.6426)	grad_norm 2.2738 (inf)	mem 17417MB
[2023-02-02 16:40:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][350/1251]	eta 0:08:34 lr 0.000066	time 0.5525 (0.5716)	loss 1.6313 (2.6384)	grad_norm 2.1988 (inf)	mem 17417MB
[2023-02-02 16:40:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][400/1251]	eta 0:08:06 lr 0.000066	time 0.6352 (0.5712)	loss 2.5430 (2.6382)	grad_norm 3.2621 (inf)	mem 17417MB
[2023-02-02 16:41:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][450/1251]	eta 0:07:37 lr 0.000065	time 0.5526 (0.5706)	loss 2.1815 (2.6377)	grad_norm 2.6894 (inf)	mem 17417MB
[2023-02-02 16:41:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][500/1251]	eta 0:07:08 lr 0.000065	time 0.6237 (0.5703)	loss 2.6635 (2.6341)	grad_norm 2.3389 (inf)	mem 17417MB
[2023-02-02 16:42:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][550/1251]	eta 0:06:39 lr 0.000065	time 0.5557 (0.5702)	loss 2.2958 (2.6291)	grad_norm 2.4166 (inf)	mem 17417MB
[2023-02-02 16:42:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][600/1251]	eta 0:06:11 lr 0.000065	time 0.6354 (0.5702)	loss 3.0128 (2.6305)	grad_norm 2.3011 (inf)	mem 17417MB
[2023-02-02 16:43:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][650/1251]	eta 0:05:42 lr 0.000065	time 0.5626 (0.5700)	loss 2.8932 (2.6323)	grad_norm 2.7307 (inf)	mem 17417MB
[2023-02-02 16:43:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][700/1251]	eta 0:05:14 lr 0.000065	time 0.5566 (0.5699)	loss 2.6561 (2.6310)	grad_norm 2.4816 (inf)	mem 17417MB
[2023-02-02 16:44:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][750/1251]	eta 0:04:45 lr 0.000065	time 0.5606 (0.5698)	loss 1.8474 (2.6252)	grad_norm 2.3052 (inf)	mem 17417MB
[2023-02-02 16:44:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][800/1251]	eta 0:04:16 lr 0.000065	time 0.5575 (0.5696)	loss 2.8866 (2.6238)	grad_norm 2.2472 (inf)	mem 17417MB
[2023-02-02 16:45:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][850/1251]	eta 0:03:48 lr 0.000065	time 0.5599 (0.5697)	loss 1.9021 (2.6263)	grad_norm 2.1952 (inf)	mem 17417MB
[2023-02-02 16:45:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][900/1251]	eta 0:03:19 lr 0.000065	time 0.6111 (0.5696)	loss 2.6660 (2.6322)	grad_norm 2.7129 (inf)	mem 17417MB
[2023-02-02 16:46:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][950/1251]	eta 0:02:51 lr 0.000065	time 0.5547 (0.5695)	loss 3.0457 (2.6352)	grad_norm 2.6216 (inf)	mem 17417MB
[2023-02-02 16:46:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][1000/1251]	eta 0:02:22 lr 0.000064	time 0.6540 (0.5696)	loss 3.1801 (2.6393)	grad_norm 2.3831 (inf)	mem 17417MB
[2023-02-02 16:47:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][1050/1251]	eta 0:01:54 lr 0.000064	time 0.5535 (0.5695)	loss 2.0677 (2.6400)	grad_norm 2.3364 (inf)	mem 17417MB
[2023-02-02 16:47:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][1100/1251]	eta 0:01:25 lr 0.000064	time 0.5585 (0.5694)	loss 2.1090 (2.6396)	grad_norm 2.7480 (inf)	mem 17417MB
[2023-02-02 16:48:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][1150/1251]	eta 0:00:57 lr 0.000064	time 0.5570 (0.5694)	loss 2.6174 (2.6394)	grad_norm 2.4549 (inf)	mem 17417MB
[2023-02-02 16:48:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][1200/1251]	eta 0:00:29 lr 0.000064	time 0.6167 (0.5693)	loss 2.5739 (2.6403)	grad_norm 2.5892 (inf)	mem 17417MB
[2023-02-02 16:48:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [254/300][1250/1251]	eta 0:00:00 lr 0.000064	time 0.6251 (0.5693)	loss 2.0326 (2.6419)	grad_norm 2.8197 (inf)	mem 17417MB
[2023-02-02 16:48:59 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 254 training takes 0:11:52
[2023-02-02 16:48:59 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_254.pth saving......
[2023-02-02 16:49:01 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_254.pth saved !!!
[2023-02-02 16:49:02 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.851 (0.851)	Loss 0.6870 (0.6870)	Acc@1 83.887 (83.887)	Acc@5 97.266 (97.266)	Mem 17417MB
[2023-02-02 16:49:09 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.522 Acc@5 96.664
[2023-02-02 16:49:09 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.5%
[2023-02-02 16:49:11 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.228 (1.228)	Loss 0.7530 (0.7530)	Acc@1 83.496 (83.496)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-02 16:49:19 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.894 Acc@5 96.848
[2023-02-02 16:49:19 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 16:49:19 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.92% at 253 epoch
[2023-02-02 16:49:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][0/1251]	eta 0:34:40 lr 0.000064	time 1.6633 (1.6633)	loss 3.0351 (3.0351)	grad_norm 2.3122 (2.3122)	mem 17417MB
[2023-02-02 16:49:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][50/1251]	eta 0:11:53 lr 0.000064	time 0.5540 (0.5937)	loss 2.1013 (2.7017)	grad_norm 2.2276 (2.5954)	mem 17417MB
[2023-02-02 16:50:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][100/1251]	eta 0:11:10 lr 0.000064	time 0.5455 (0.5822)	loss 3.0679 (2.7265)	grad_norm 2.9322 (2.6117)	mem 17417MB
[2023-02-02 16:50:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][150/1251]	eta 0:10:34 lr 0.000064	time 0.5616 (0.5764)	loss 2.5062 (2.7080)	grad_norm 2.5632 (2.5814)	mem 17417MB
[2023-02-02 16:51:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][200/1251]	eta 0:10:04 lr 0.000064	time 0.6244 (0.5752)	loss 1.7875 (2.6761)	grad_norm 2.0735 (2.5736)	mem 17417MB
[2023-02-02 16:51:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][250/1251]	eta 0:09:34 lr 0.000063	time 0.5520 (0.5735)	loss 3.2701 (2.6818)	grad_norm 2.5982 (2.5793)	mem 17417MB
[2023-02-02 16:52:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][300/1251]	eta 0:09:05 lr 0.000063	time 0.5548 (0.5732)	loss 2.1399 (2.6655)	grad_norm 2.9265 (2.5794)	mem 17417MB
[2023-02-02 16:52:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][350/1251]	eta 0:08:35 lr 0.000063	time 0.5524 (0.5721)	loss 2.8553 (2.6691)	grad_norm 3.2473 (2.5732)	mem 17417MB
[2023-02-02 16:53:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][400/1251]	eta 0:08:06 lr 0.000063	time 0.5584 (0.5720)	loss 2.5473 (2.6707)	grad_norm 3.0767 (2.5707)	mem 17417MB
[2023-02-02 16:53:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][450/1251]	eta 0:07:37 lr 0.000063	time 0.6189 (0.5715)	loss 2.8458 (2.6590)	grad_norm 2.5717 (2.5662)	mem 17417MB
[2023-02-02 16:54:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][500/1251]	eta 0:07:08 lr 0.000063	time 0.5630 (0.5710)	loss 2.8163 (2.6527)	grad_norm 2.4214 (2.5614)	mem 17417MB
[2023-02-02 16:54:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][550/1251]	eta 0:06:40 lr 0.000063	time 0.5598 (0.5706)	loss 2.8495 (2.6602)	grad_norm 2.3762 (2.5546)	mem 17417MB
[2023-02-02 16:55:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][600/1251]	eta 0:06:11 lr 0.000063	time 0.6284 (0.5710)	loss 3.1043 (2.6573)	grad_norm 2.3681 (2.5553)	mem 17417MB
[2023-02-02 16:55:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][650/1251]	eta 0:05:42 lr 0.000063	time 0.5552 (0.5707)	loss 2.0290 (2.6506)	grad_norm 2.6099 (2.5587)	mem 17417MB
[2023-02-02 16:55:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][700/1251]	eta 0:05:14 lr 0.000063	time 0.5570 (0.5705)	loss 2.8401 (2.6481)	grad_norm 3.2218 (2.5552)	mem 17417MB
[2023-02-02 16:56:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][750/1251]	eta 0:04:45 lr 0.000063	time 0.5527 (0.5703)	loss 1.7579 (2.6526)	grad_norm 2.7117 (2.5571)	mem 17417MB
[2023-02-02 16:56:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][800/1251]	eta 0:04:17 lr 0.000062	time 0.5617 (0.5703)	loss 3.1955 (2.6476)	grad_norm 2.7069 (2.5544)	mem 17417MB
[2023-02-02 16:57:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][850/1251]	eta 0:03:48 lr 0.000062	time 0.5605 (0.5704)	loss 2.7320 (2.6480)	grad_norm 2.4926 (2.5538)	mem 17417MB
[2023-02-02 16:57:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][900/1251]	eta 0:03:20 lr 0.000062	time 0.5557 (0.5704)	loss 2.9133 (2.6487)	grad_norm 2.4639 (2.5564)	mem 17417MB
[2023-02-02 16:58:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][950/1251]	eta 0:02:51 lr 0.000062	time 0.5561 (0.5701)	loss 2.5138 (2.6546)	grad_norm 2.7343 (2.5554)	mem 17417MB
[2023-02-02 16:58:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][1000/1251]	eta 0:02:23 lr 0.000062	time 0.6220 (0.5702)	loss 1.7089 (2.6545)	grad_norm 2.5981 (2.5567)	mem 17417MB
[2023-02-02 16:59:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][1050/1251]	eta 0:01:54 lr 0.000062	time 0.5578 (0.5702)	loss 2.7287 (2.6543)	grad_norm 3.1411 (2.5577)	mem 17417MB
[2023-02-02 16:59:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][1100/1251]	eta 0:01:26 lr 0.000062	time 0.5547 (0.5701)	loss 3.2387 (2.6548)	grad_norm 2.5544 (2.5545)	mem 17417MB
[2023-02-02 17:00:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][1150/1251]	eta 0:00:57 lr 0.000062	time 0.5608 (0.5703)	loss 2.9143 (2.6597)	grad_norm 2.2101 (2.5527)	mem 17417MB
[2023-02-02 17:00:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][1200/1251]	eta 0:00:29 lr 0.000062	time 0.5485 (0.5702)	loss 2.7651 (2.6627)	grad_norm 2.6941 (2.5540)	mem 17417MB
[2023-02-02 17:01:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [255/300][1250/1251]	eta 0:00:00 lr 0.000062	time 0.5498 (0.5703)	loss 3.2820 (2.6632)	grad_norm 2.2765 (2.5540)	mem 17417MB
[2023-02-02 17:01:12 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 255 training takes 0:11:53
[2023-02-02 17:01:12 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_255.pth saving......
[2023-02-02 17:01:14 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_255.pth saved !!!
[2023-02-02 17:01:15 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.941 (0.941)	Loss 0.6930 (0.6930)	Acc@1 83.594 (83.594)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 17:01:23 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.442 Acc@5 96.624
[2023-02-02 17:01:23 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.4%
[2023-02-02 17:01:24 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.154 (1.154)	Loss 0.6520 (0.6520)	Acc@1 83.789 (83.789)	Acc@5 97.461 (97.461)	Mem 17417MB
[2023-02-02 17:01:32 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.900 Acc@5 96.852
[2023-02-02 17:01:32 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 17:01:32 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.92% at 253 epoch
[2023-02-02 17:01:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][0/1251]	eta 0:35:07 lr 0.000062	time 1.6844 (1.6844)	loss 3.1558 (3.1558)	grad_norm 2.8107 (2.8107)	mem 17417MB
[2023-02-02 17:02:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][50/1251]	eta 0:11:52 lr 0.000062	time 0.5648 (0.5936)	loss 1.9743 (2.6138)	grad_norm 2.5846 (2.5018)	mem 17417MB
[2023-02-02 17:02:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][100/1251]	eta 0:11:08 lr 0.000061	time 0.5594 (0.5810)	loss 2.7724 (2.5817)	grad_norm 2.4458 (2.5184)	mem 17417MB
[2023-02-02 17:02:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][150/1251]	eta 0:10:35 lr 0.000061	time 0.5546 (0.5775)	loss 2.7347 (2.6055)	grad_norm 2.5864 (2.5390)	mem 17417MB
[2023-02-02 17:03:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][200/1251]	eta 0:10:04 lr 0.000061	time 0.5550 (0.5752)	loss 2.3655 (2.6186)	grad_norm 2.9321 (2.5464)	mem 17417MB
[2023-02-02 17:03:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][250/1251]	eta 0:09:34 lr 0.000061	time 0.5564 (0.5738)	loss 2.3719 (2.6062)	grad_norm 2.3888 (2.5629)	mem 17417MB
[2023-02-02 17:04:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][300/1251]	eta 0:09:05 lr 0.000061	time 0.5464 (0.5734)	loss 2.4724 (2.6172)	grad_norm 2.2946 (2.5545)	mem 17417MB
[2023-02-02 17:04:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][350/1251]	eta 0:08:35 lr 0.000061	time 0.5557 (0.5724)	loss 3.1251 (2.6354)	grad_norm 2.3228 (2.5553)	mem 17417MB
[2023-02-02 17:05:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][400/1251]	eta 0:08:06 lr 0.000061	time 0.5510 (0.5720)	loss 2.1322 (2.6421)	grad_norm 2.3336 (2.5552)	mem 17417MB
[2023-02-02 17:05:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][450/1251]	eta 0:07:37 lr 0.000061	time 0.5554 (0.5714)	loss 2.6100 (2.6498)	grad_norm 2.3687 (2.5508)	mem 17417MB
[2023-02-02 17:06:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][500/1251]	eta 0:07:08 lr 0.000061	time 0.5550 (0.5709)	loss 2.8219 (2.6533)	grad_norm 2.4742 (2.5518)	mem 17417MB
[2023-02-02 17:06:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][550/1251]	eta 0:06:39 lr 0.000061	time 0.5482 (0.5706)	loss 2.7658 (2.6438)	grad_norm 2.7334 (2.5499)	mem 17417MB
[2023-02-02 17:07:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][600/1251]	eta 0:06:11 lr 0.000061	time 0.5542 (0.5709)	loss 3.0955 (2.6434)	grad_norm 2.3373 (2.5550)	mem 17417MB
[2023-02-02 17:07:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][650/1251]	eta 0:05:42 lr 0.000060	time 0.5603 (0.5707)	loss 3.1127 (2.6442)	grad_norm 2.5680 (2.5559)	mem 17417MB
[2023-02-02 17:08:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][700/1251]	eta 0:05:14 lr 0.000060	time 0.5626 (0.5707)	loss 2.8549 (2.6433)	grad_norm 2.6738 (2.5540)	mem 17417MB
[2023-02-02 17:08:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][750/1251]	eta 0:04:45 lr 0.000060	time 0.5511 (0.5705)	loss 2.4501 (2.6414)	grad_norm 2.4067 (2.5508)	mem 17417MB
[2023-02-02 17:09:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][800/1251]	eta 0:04:17 lr 0.000060	time 0.6146 (0.5705)	loss 2.3836 (2.6409)	grad_norm 2.3195 (2.5481)	mem 17417MB
[2023-02-02 17:09:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][850/1251]	eta 0:03:48 lr 0.000060	time 0.5496 (0.5704)	loss 1.9621 (2.6399)	grad_norm 2.2240 (2.5508)	mem 17417MB
[2023-02-02 17:10:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][900/1251]	eta 0:03:20 lr 0.000060	time 0.5663 (0.5705)	loss 2.8294 (2.6429)	grad_norm 2.5922 (2.5513)	mem 17417MB
[2023-02-02 17:10:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][950/1251]	eta 0:02:51 lr 0.000060	time 0.5543 (0.5702)	loss 2.9350 (2.6391)	grad_norm 2.4082 (2.5492)	mem 17417MB
[2023-02-02 17:11:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][1000/1251]	eta 0:02:23 lr 0.000060	time 0.5510 (0.5704)	loss 2.5283 (2.6406)	grad_norm 2.7416 (2.5498)	mem 17417MB
[2023-02-02 17:11:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][1050/1251]	eta 0:01:54 lr 0.000060	time 0.5532 (0.5702)	loss 2.7247 (2.6441)	grad_norm 2.4039 (2.5476)	mem 17417MB
[2023-02-02 17:12:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][1100/1251]	eta 0:01:26 lr 0.000060	time 0.6142 (0.5703)	loss 3.0862 (2.6452)	grad_norm 2.6162 (2.5467)	mem 17417MB
[2023-02-02 17:12:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][1150/1251]	eta 0:00:57 lr 0.000060	time 0.6507 (0.5704)	loss 2.5463 (2.6444)	grad_norm 2.6995 (2.5472)	mem 17417MB
[2023-02-02 17:12:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][1200/1251]	eta 0:00:29 lr 0.000059	time 0.6349 (0.5704)	loss 3.0858 (2.6466)	grad_norm 2.6595 (2.5476)	mem 17417MB
[2023-02-02 17:13:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [256/300][1250/1251]	eta 0:00:00 lr 0.000059	time 0.5500 (0.5703)	loss 1.9501 (2.6512)	grad_norm 2.3261 (2.5476)	mem 17417MB
[2023-02-02 17:13:26 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 256 training takes 0:11:53
[2023-02-02 17:13:26 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_256.pth saving......
[2023-02-02 17:13:28 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_256.pth saved !!!
[2023-02-02 17:13:29 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.899 (0.899)	Loss 0.7350 (0.7350)	Acc@1 83.496 (83.496)	Acc@5 96.582 (96.582)	Mem 17417MB
[2023-02-02 17:13:37 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.560 Acc@5 96.694
[2023-02-02 17:13:37 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.6%
[2023-02-02 17:13:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.252 (1.252)	Loss 0.6854 (0.6854)	Acc@1 83.789 (83.789)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 17:13:46 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.910 Acc@5 96.848
[2023-02-02 17:13:46 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 17:13:46 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.92% at 253 epoch
[2023-02-02 17:13:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][0/1251]	eta 0:35:42 lr 0.000059	time 1.7128 (1.7128)	loss 3.1674 (3.1674)	grad_norm 2.6642 (2.6642)	mem 17417MB
[2023-02-02 17:14:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][50/1251]	eta 0:11:51 lr 0.000059	time 0.5637 (0.5923)	loss 2.8030 (2.6117)	grad_norm 2.2455 (2.5502)	mem 17417MB
[2023-02-02 17:14:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][100/1251]	eta 0:11:07 lr 0.000059	time 0.5538 (0.5802)	loss 3.5785 (2.6368)	grad_norm 2.3741 (2.5584)	mem 17417MB
[2023-02-02 17:15:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][150/1251]	eta 0:10:35 lr 0.000059	time 0.5632 (0.5771)	loss 2.6532 (2.6261)	grad_norm 2.6347 (2.5573)	mem 17417MB
[2023-02-02 17:15:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][200/1251]	eta 0:10:03 lr 0.000059	time 0.5486 (0.5745)	loss 1.9153 (2.6095)	grad_norm 2.4788 (2.5343)	mem 17417MB
[2023-02-02 17:16:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][250/1251]	eta 0:09:33 lr 0.000059	time 0.5632 (0.5727)	loss 2.5625 (2.6118)	grad_norm 2.2281 (2.5436)	mem 17417MB
[2023-02-02 17:16:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][300/1251]	eta 0:09:04 lr 0.000059	time 0.5573 (0.5723)	loss 2.6878 (2.6273)	grad_norm 2.6108 (2.5315)	mem 17417MB
[2023-02-02 17:17:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][350/1251]	eta 0:08:34 lr 0.000059	time 0.5599 (0.5712)	loss 2.7917 (2.6275)	grad_norm 3.2466 (2.5274)	mem 17417MB
[2023-02-02 17:17:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][400/1251]	eta 0:08:06 lr 0.000059	time 0.5517 (0.5714)	loss 3.0844 (2.6234)	grad_norm 3.1867 (2.5382)	mem 17417MB
[2023-02-02 17:18:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][450/1251]	eta 0:07:37 lr 0.000059	time 0.5584 (0.5709)	loss 2.9510 (2.6293)	grad_norm 2.5230 (nan)	mem 17417MB
[2023-02-02 17:18:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][500/1251]	eta 0:07:08 lr 0.000058	time 0.5574 (0.5705)	loss 2.6837 (2.6354)	grad_norm 2.7858 (nan)	mem 17417MB
[2023-02-02 17:19:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][550/1251]	eta 0:06:39 lr 0.000058	time 0.5587 (0.5704)	loss 3.0334 (2.6397)	grad_norm 2.4351 (nan)	mem 17417MB
[2023-02-02 17:19:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][600/1251]	eta 0:06:11 lr 0.000058	time 0.5562 (0.5703)	loss 2.7493 (2.6423)	grad_norm 2.1976 (nan)	mem 17417MB
[2023-02-02 17:19:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][650/1251]	eta 0:05:42 lr 0.000058	time 0.5576 (0.5699)	loss 3.1330 (2.6386)	grad_norm 2.5940 (nan)	mem 17417MB
[2023-02-02 17:20:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][700/1251]	eta 0:05:14 lr 0.000058	time 0.5611 (0.5700)	loss 3.1249 (2.6479)	grad_norm 2.6708 (nan)	mem 17417MB
[2023-02-02 17:20:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][750/1251]	eta 0:04:45 lr 0.000058	time 0.5527 (0.5697)	loss 2.8272 (2.6494)	grad_norm 2.7738 (nan)	mem 17417MB
[2023-02-02 17:21:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][800/1251]	eta 0:04:16 lr 0.000058	time 0.5544 (0.5696)	loss 2.7406 (2.6546)	grad_norm 2.5371 (nan)	mem 17417MB
[2023-02-02 17:21:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][850/1251]	eta 0:03:48 lr 0.000058	time 0.6107 (0.5696)	loss 2.2430 (2.6546)	grad_norm 2.6116 (nan)	mem 17417MB
[2023-02-02 17:22:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][900/1251]	eta 0:03:19 lr 0.000058	time 0.5589 (0.5693)	loss 2.8339 (2.6590)	grad_norm 2.6752 (nan)	mem 17417MB
[2023-02-02 17:22:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][950/1251]	eta 0:02:51 lr 0.000058	time 0.5541 (0.5693)	loss 2.0630 (2.6566)	grad_norm 2.8782 (nan)	mem 17417MB
[2023-02-02 17:23:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][1000/1251]	eta 0:02:22 lr 0.000058	time 0.5536 (0.5691)	loss 3.1069 (2.6527)	grad_norm 2.6844 (nan)	mem 17417MB
[2023-02-02 17:23:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][1050/1251]	eta 0:01:54 lr 0.000057	time 0.5598 (0.5691)	loss 2.7544 (2.6514)	grad_norm 2.6740 (nan)	mem 17417MB
[2023-02-02 17:24:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][1100/1251]	eta 0:01:25 lr 0.000057	time 0.6309 (0.5692)	loss 2.6711 (2.6498)	grad_norm 2.9433 (nan)	mem 17417MB
[2023-02-02 17:24:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][1150/1251]	eta 0:00:57 lr 0.000057	time 0.5489 (0.5688)	loss 2.8492 (2.6501)	grad_norm 2.4929 (nan)	mem 17417MB
[2023-02-02 17:25:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][1200/1251]	eta 0:00:29 lr 0.000057	time 0.5711 (0.5689)	loss 3.2838 (2.6532)	grad_norm 2.7825 (nan)	mem 17417MB
[2023-02-02 17:25:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [257/300][1250/1251]	eta 0:00:00 lr 0.000057	time 0.5492 (0.5689)	loss 2.6712 (2.6560)	grad_norm 2.5312 (nan)	mem 17417MB
[2023-02-02 17:25:38 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 257 training takes 0:11:51
[2023-02-02 17:25:38 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_257.pth saving......
[2023-02-02 17:25:40 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_257.pth saved !!!
[2023-02-02 17:25:41 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.991 (0.991)	Loss 0.6947 (0.6947)	Acc@1 83.594 (83.594)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 17:25:49 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.668 Acc@5 96.668
[2023-02-02 17:25:49 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.7%
[2023-02-02 17:25:50 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.196 (1.196)	Loss 0.7059 (0.7059)	Acc@1 83.496 (83.496)	Acc@5 97.461 (97.461)	Mem 17417MB
[2023-02-02 17:25:58 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.922 Acc@5 96.836
[2023-02-02 17:25:58 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 17:25:58 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.92% at 257 epoch
[2023-02-02 17:26:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][0/1251]	eta 0:36:10 lr 0.000057	time 1.7351 (1.7351)	loss 2.6595 (2.6595)	grad_norm 2.5252 (2.5252)	mem 17417MB
[2023-02-02 17:26:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][50/1251]	eta 0:11:48 lr 0.000057	time 0.5509 (0.5897)	loss 3.4596 (2.6669)	grad_norm 2.7566 (2.5959)	mem 17417MB
[2023-02-02 17:26:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][100/1251]	eta 0:11:09 lr 0.000057	time 0.6083 (0.5820)	loss 3.0826 (2.6205)	grad_norm 2.8084 (2.6178)	mem 17417MB
[2023-02-02 17:27:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][150/1251]	eta 0:10:35 lr 0.000057	time 0.5525 (0.5771)	loss 2.9157 (2.6268)	grad_norm 2.5512 (2.5942)	mem 17417MB
[2023-02-02 17:27:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][200/1251]	eta 0:10:04 lr 0.000057	time 0.5549 (0.5755)	loss 2.8698 (2.6523)	grad_norm 2.4066 (2.6062)	mem 17417MB
[2023-02-02 17:28:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][250/1251]	eta 0:09:33 lr 0.000057	time 0.6358 (0.5733)	loss 2.4949 (2.6487)	grad_norm 2.9694 (2.6082)	mem 17417MB
[2023-02-02 17:28:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][300/1251]	eta 0:09:04 lr 0.000057	time 0.5637 (0.5728)	loss 2.7080 (2.6436)	grad_norm 2.6181 (2.6057)	mem 17417MB
[2023-02-02 17:29:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][350/1251]	eta 0:08:35 lr 0.000056	time 0.6413 (0.5720)	loss 2.7886 (2.6468)	grad_norm 2.3921 (2.6126)	mem 17417MB
[2023-02-02 17:29:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][400/1251]	eta 0:08:06 lr 0.000056	time 0.5550 (0.5715)	loss 3.0044 (2.6223)	grad_norm 2.7310 (2.6084)	mem 17417MB
[2023-02-02 17:30:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][450/1251]	eta 0:07:37 lr 0.000056	time 0.5519 (0.5711)	loss 2.3595 (2.6202)	grad_norm 2.6476 (2.6093)	mem 17417MB
[2023-02-02 17:30:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][500/1251]	eta 0:07:08 lr 0.000056	time 0.6369 (0.5709)	loss 2.1305 (2.6240)	grad_norm 2.5877 (2.6108)	mem 17417MB
[2023-02-02 17:31:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][550/1251]	eta 0:06:40 lr 0.000056	time 0.5575 (0.5707)	loss 2.1779 (2.6239)	grad_norm 2.5712 (2.6101)	mem 17417MB
[2023-02-02 17:31:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][600/1251]	eta 0:06:11 lr 0.000056	time 0.5689 (0.5705)	loss 3.0817 (2.6259)	grad_norm 2.5437 (2.6045)	mem 17417MB
[2023-02-02 17:32:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][650/1251]	eta 0:05:42 lr 0.000056	time 0.5532 (0.5706)	loss 2.4551 (2.6294)	grad_norm 2.6711 (2.6144)	mem 17417MB
[2023-02-02 17:32:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][700/1251]	eta 0:05:14 lr 0.000056	time 0.5572 (0.5704)	loss 3.0690 (2.6289)	grad_norm 2.6307 (2.6132)	mem 17417MB
[2023-02-02 17:33:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][750/1251]	eta 0:04:45 lr 0.000056	time 0.5623 (0.5703)	loss 3.0273 (2.6270)	grad_norm 3.3376 (2.6083)	mem 17417MB
[2023-02-02 17:33:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][800/1251]	eta 0:04:17 lr 0.000056	time 0.5504 (0.5702)	loss 2.4442 (2.6266)	grad_norm 2.3590 (2.6081)	mem 17417MB
[2023-02-02 17:34:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][850/1251]	eta 0:03:48 lr 0.000056	time 0.5574 (0.5702)	loss 2.4540 (2.6290)	grad_norm 3.2571 (2.6062)	mem 17417MB
[2023-02-02 17:34:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][900/1251]	eta 0:03:20 lr 0.000056	time 0.6267 (0.5703)	loss 2.8981 (2.6308)	grad_norm 2.3366 (2.6079)	mem 17417MB
[2023-02-02 17:35:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][950/1251]	eta 0:02:51 lr 0.000055	time 0.5606 (0.5701)	loss 2.2376 (2.6318)	grad_norm 2.4327 (2.6064)	mem 17417MB
[2023-02-02 17:35:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][1000/1251]	eta 0:02:23 lr 0.000055	time 0.5573 (0.5701)	loss 2.7583 (2.6340)	grad_norm 2.4728 (2.6044)	mem 17417MB
[2023-02-02 17:35:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][1050/1251]	eta 0:01:54 lr 0.000055	time 0.5547 (0.5701)	loss 2.8769 (2.6364)	grad_norm 2.3537 (2.6041)	mem 17417MB
[2023-02-02 17:36:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][1100/1251]	eta 0:01:26 lr 0.000055	time 0.6293 (0.5702)	loss 3.0500 (2.6394)	grad_norm 2.3618 (2.6061)	mem 17417MB
[2023-02-02 17:36:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][1150/1251]	eta 0:00:57 lr 0.000055	time 0.6290 (0.5700)	loss 2.8022 (2.6369)	grad_norm 2.5669 (2.6080)	mem 17417MB
[2023-02-02 17:37:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][1200/1251]	eta 0:00:29 lr 0.000055	time 0.5566 (0.5699)	loss 3.0746 (2.6347)	grad_norm 2.6632 (2.6104)	mem 17417MB
[2023-02-02 17:37:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [258/300][1250/1251]	eta 0:00:00 lr 0.000055	time 0.5498 (0.5700)	loss 1.9457 (2.6364)	grad_norm 2.5871 (2.6074)	mem 17417MB
[2023-02-02 17:37:51 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 258 training takes 0:11:53
[2023-02-02 17:37:51 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_258.pth saving......
[2023-02-02 17:37:53 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_258.pth saved !!!
[2023-02-02 17:37:54 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.905 (0.905)	Loss 0.7195 (0.7195)	Acc@1 84.473 (84.473)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 17:38:02 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.612 Acc@5 96.630
[2023-02-02 17:38:02 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.6%
[2023-02-02 17:38:03 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.212 (1.212)	Loss 0.7297 (0.7297)	Acc@1 83.594 (83.594)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-02 17:38:11 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.940 Acc@5 96.862
[2023-02-02 17:38:11 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 17:38:11 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.94% at 258 epoch
[2023-02-02 17:38:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][0/1251]	eta 0:36:25 lr 0.000055	time 1.7467 (1.7467)	loss 2.2192 (2.2192)	grad_norm 2.3203 (2.3203)	mem 17417MB
[2023-02-02 17:38:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][50/1251]	eta 0:11:52 lr 0.000055	time 0.5633 (0.5936)	loss 2.9270 (2.6214)	grad_norm 2.3635 (2.5794)	mem 17417MB
[2023-02-02 17:39:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][100/1251]	eta 0:11:11 lr 0.000055	time 0.5516 (0.5834)	loss 2.9341 (2.6323)	grad_norm 2.6211 (2.5891)	mem 17417MB
[2023-02-02 17:39:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][150/1251]	eta 0:10:37 lr 0.000055	time 0.5628 (0.5790)	loss 2.3053 (2.6482)	grad_norm 2.2004 (2.5710)	mem 17417MB
[2023-02-02 17:40:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][200/1251]	eta 0:10:05 lr 0.000055	time 0.5583 (0.5764)	loss 1.7775 (2.6418)	grad_norm 2.3971 (2.5686)	mem 17417MB
[2023-02-02 17:40:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][250/1251]	eta 0:09:34 lr 0.000054	time 0.5801 (0.5744)	loss 1.6670 (2.6279)	grad_norm 2.7570 (nan)	mem 17417MB
[2023-02-02 17:41:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][300/1251]	eta 0:09:06 lr 0.000054	time 0.5617 (0.5745)	loss 2.5200 (2.6221)	grad_norm 2.6312 (nan)	mem 17417MB
[2023-02-02 17:41:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][350/1251]	eta 0:08:37 lr 0.000054	time 0.6223 (0.5738)	loss 2.2836 (2.6284)	grad_norm 2.4156 (nan)	mem 17417MB
[2023-02-02 17:42:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][400/1251]	eta 0:08:07 lr 0.000054	time 0.6226 (0.5732)	loss 2.9005 (2.6224)	grad_norm 2.6193 (nan)	mem 17417MB
[2023-02-02 17:42:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][450/1251]	eta 0:07:38 lr 0.000054	time 0.5545 (0.5729)	loss 2.8334 (2.6250)	grad_norm 2.2718 (nan)	mem 17417MB
[2023-02-02 17:42:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][500/1251]	eta 0:07:09 lr 0.000054	time 0.6291 (0.5725)	loss 3.2361 (2.6256)	grad_norm 2.4740 (nan)	mem 17417MB
[2023-02-02 17:43:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][550/1251]	eta 0:06:40 lr 0.000054	time 0.5562 (0.5720)	loss 2.6039 (2.6177)	grad_norm 2.7641 (nan)	mem 17417MB
[2023-02-02 17:43:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][600/1251]	eta 0:06:12 lr 0.000054	time 0.5513 (0.5720)	loss 2.8794 (2.6176)	grad_norm 2.4817 (nan)	mem 17417MB
[2023-02-02 17:44:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][650/1251]	eta 0:05:43 lr 0.000054	time 0.5600 (0.5718)	loss 2.3281 (2.6082)	grad_norm 3.3473 (nan)	mem 17417MB
[2023-02-02 17:44:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][700/1251]	eta 0:05:15 lr 0.000054	time 0.5538 (0.5717)	loss 2.7613 (2.6111)	grad_norm 2.2912 (nan)	mem 17417MB
[2023-02-02 17:45:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][750/1251]	eta 0:04:46 lr 0.000054	time 0.5522 (0.5714)	loss 2.5433 (2.6098)	grad_norm 2.5223 (nan)	mem 17417MB
[2023-02-02 17:45:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][800/1251]	eta 0:04:17 lr 0.000054	time 0.5585 (0.5713)	loss 1.9344 (2.6083)	grad_norm 2.3262 (nan)	mem 17417MB
[2023-02-02 17:46:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][850/1251]	eta 0:03:49 lr 0.000053	time 0.6122 (0.5713)	loss 2.2315 (2.6108)	grad_norm 2.4684 (nan)	mem 17417MB
[2023-02-02 17:46:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][900/1251]	eta 0:03:20 lr 0.000053	time 0.5550 (0.5711)	loss 1.7798 (2.6115)	grad_norm 2.2869 (nan)	mem 17417MB
[2023-02-02 17:47:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][950/1251]	eta 0:02:51 lr 0.000053	time 0.5564 (0.5710)	loss 2.6390 (2.6143)	grad_norm 2.6286 (nan)	mem 17417MB
[2023-02-02 17:47:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][1000/1251]	eta 0:02:23 lr 0.000053	time 0.6241 (0.5710)	loss 2.6311 (2.6168)	grad_norm 2.4666 (nan)	mem 17417MB
[2023-02-02 17:48:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][1050/1251]	eta 0:01:54 lr 0.000053	time 0.5648 (0.5709)	loss 2.4561 (2.6207)	grad_norm 2.6068 (nan)	mem 17417MB
[2023-02-02 17:48:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][1100/1251]	eta 0:01:26 lr 0.000053	time 0.5536 (0.5708)	loss 2.3178 (2.6188)	grad_norm 2.8856 (nan)	mem 17417MB
[2023-02-02 17:49:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][1150/1251]	eta 0:00:57 lr 0.000053	time 0.5571 (0.5708)	loss 2.5606 (2.6205)	grad_norm 2.5011 (nan)	mem 17417MB
[2023-02-02 17:49:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][1200/1251]	eta 0:00:29 lr 0.000053	time 0.5576 (0.5707)	loss 2.0400 (2.6251)	grad_norm 2.3414 (nan)	mem 17417MB
[2023-02-02 17:50:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [259/300][1250/1251]	eta 0:00:00 lr 0.000053	time 0.5446 (0.5708)	loss 2.3347 (2.6221)	grad_norm 2.6827 (nan)	mem 17417MB
[2023-02-02 17:50:05 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 259 training takes 0:11:54
[2023-02-02 17:50:05 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_259.pth saving......
[2023-02-02 17:50:07 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_259.pth saved !!!
[2023-02-02 17:50:08 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.862 (0.862)	Loss 0.7853 (0.7853)	Acc@1 81.836 (81.836)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-02 17:50:16 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.624 Acc@5 96.672
[2023-02-02 17:50:16 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.6%
[2023-02-02 17:50:17 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.265 (1.265)	Loss 0.6545 (0.6545)	Acc@1 84.277 (84.277)	Acc@5 97.266 (97.266)	Mem 17417MB
[2023-02-02 17:50:25 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.958 Acc@5 96.862
[2023-02-02 17:50:25 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 17:50:25 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.96% at 259 epoch
[2023-02-02 17:50:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][0/1251]	eta 0:35:22 lr 0.000053	time 1.6969 (1.6969)	loss 3.1419 (3.1419)	grad_norm 2.2997 (2.2997)	mem 17417MB
[2023-02-02 17:50:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][50/1251]	eta 0:11:49 lr 0.000053	time 0.5543 (0.5908)	loss 3.0701 (2.6589)	grad_norm 2.7829 (2.5521)	mem 17417MB
[2023-02-02 17:51:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][100/1251]	eta 0:11:08 lr 0.000053	time 0.6248 (0.5809)	loss 2.9658 (2.6858)	grad_norm 2.9693 (2.6005)	mem 17417MB
[2023-02-02 17:51:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][150/1251]	eta 0:10:35 lr 0.000053	time 0.5564 (0.5772)	loss 2.9632 (2.6908)	grad_norm 2.8868 (2.5888)	mem 17417MB
[2023-02-02 17:52:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][200/1251]	eta 0:10:04 lr 0.000052	time 0.5584 (0.5751)	loss 2.9636 (2.6680)	grad_norm 2.5391 (2.5928)	mem 17417MB
[2023-02-02 17:52:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][250/1251]	eta 0:09:34 lr 0.000052	time 0.5561 (0.5737)	loss 2.8233 (2.6690)	grad_norm 2.4335 (2.6063)	mem 17417MB
[2023-02-02 17:53:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][300/1251]	eta 0:09:05 lr 0.000052	time 0.5588 (0.5735)	loss 1.7292 (2.6561)	grad_norm 2.4804 (2.6109)	mem 17417MB
[2023-02-02 17:53:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][350/1251]	eta 0:08:35 lr 0.000052	time 0.5536 (0.5723)	loss 2.1326 (2.6471)	grad_norm 2.1990 (2.6129)	mem 17417MB
[2023-02-02 17:54:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][400/1251]	eta 0:08:06 lr 0.000052	time 0.5574 (0.5716)	loss 2.5042 (2.6497)	grad_norm 2.0983 (2.5976)	mem 17417MB
[2023-02-02 17:54:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][450/1251]	eta 0:07:37 lr 0.000052	time 0.5571 (0.5712)	loss 2.7457 (2.6520)	grad_norm 2.7845 (2.5946)	mem 17417MB
[2023-02-02 17:55:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][500/1251]	eta 0:07:08 lr 0.000052	time 0.5473 (0.5709)	loss 2.0886 (2.6504)	grad_norm 2.7775 (2.6033)	mem 17417MB
[2023-02-02 17:55:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][550/1251]	eta 0:06:39 lr 0.000052	time 0.5508 (0.5706)	loss 2.9222 (2.6508)	grad_norm 2.9127 (2.6047)	mem 17417MB
[2023-02-02 17:56:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][600/1251]	eta 0:06:11 lr 0.000052	time 0.5537 (0.5708)	loss 2.5570 (2.6514)	grad_norm 2.4821 (2.6138)	mem 17417MB
[2023-02-02 17:56:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][650/1251]	eta 0:05:42 lr 0.000052	time 0.5547 (0.5703)	loss 1.7753 (2.6424)	grad_norm 3.4246 (2.6192)	mem 17417MB
[2023-02-02 17:57:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][700/1251]	eta 0:05:14 lr 0.000052	time 0.5715 (0.5705)	loss 2.8178 (2.6502)	grad_norm 2.4169 (2.6190)	mem 17417MB
[2023-02-02 17:57:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][750/1251]	eta 0:04:45 lr 0.000052	time 0.5576 (0.5701)	loss 2.2274 (2.6514)	grad_norm 2.6557 (2.6240)	mem 17417MB
[2023-02-02 17:58:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][800/1251]	eta 0:04:17 lr 0.000051	time 0.5607 (0.5702)	loss 2.5573 (2.6558)	grad_norm 2.2442 (2.6249)	mem 17417MB
[2023-02-02 17:58:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][850/1251]	eta 0:03:48 lr 0.000051	time 0.5570 (0.5700)	loss 3.0967 (2.6533)	grad_norm 2.2983 (2.6285)	mem 17417MB
[2023-02-02 17:58:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][900/1251]	eta 0:03:20 lr 0.000051	time 0.6161 (0.5699)	loss 1.9008 (2.6476)	grad_norm 2.7660 (2.6237)	mem 17417MB
[2023-02-02 17:59:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][950/1251]	eta 0:02:51 lr 0.000051	time 0.5527 (0.5698)	loss 2.7113 (2.6468)	grad_norm 2.2825 (2.6234)	mem 17417MB
[2023-02-02 17:59:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][1000/1251]	eta 0:02:23 lr 0.000051	time 0.6486 (0.5698)	loss 2.5323 (2.6434)	grad_norm 2.3585 (2.6253)	mem 17417MB
[2023-02-02 18:00:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][1050/1251]	eta 0:01:54 lr 0.000051	time 0.5533 (0.5696)	loss 2.9715 (2.6467)	grad_norm 2.7492 (2.6253)	mem 17417MB
[2023-02-02 18:00:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][1100/1251]	eta 0:01:26 lr 0.000051	time 0.5524 (0.5696)	loss 1.7542 (2.6449)	grad_norm 2.9920 (2.6259)	mem 17417MB
[2023-02-02 18:01:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][1150/1251]	eta 0:00:57 lr 0.000051	time 0.5556 (0.5695)	loss 2.9961 (2.6412)	grad_norm 2.5324 (2.6229)	mem 17417MB
[2023-02-02 18:01:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][1200/1251]	eta 0:00:29 lr 0.000051	time 0.5529 (0.5695)	loss 2.6542 (2.6410)	grad_norm 2.4089 (2.6222)	mem 17417MB
[2023-02-02 18:02:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [260/300][1250/1251]	eta 0:00:00 lr 0.000051	time 0.5477 (0.5695)	loss 1.9158 (2.6422)	grad_norm 2.5409 (2.6216)	mem 17417MB
[2023-02-02 18:02:18 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 260 training takes 0:11:52
[2023-02-02 18:02:18 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_260.pth saving......
[2023-02-02 18:02:20 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_260.pth saved !!!
[2023-02-02 18:02:21 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.849 (0.849)	Loss 0.7896 (0.7896)	Acc@1 82.324 (82.324)	Acc@5 94.922 (94.922)	Mem 17417MB
[2023-02-02 18:02:28 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.758 Acc@5 96.668
[2023-02-02 18:02:29 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.8%
[2023-02-02 18:02:30 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.183 (1.183)	Loss 0.7416 (0.7416)	Acc@1 82.324 (82.324)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-02 18:02:38 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.916 Acc@5 96.852
[2023-02-02 18:02:38 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 18:02:38 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.96% at 259 epoch
[2023-02-02 18:02:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][0/1251]	eta 0:34:24 lr 0.000051	time 1.6507 (1.6507)	loss 3.2561 (3.2561)	grad_norm 2.5371 (2.5371)	mem 17417MB
[2023-02-02 18:03:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][50/1251]	eta 0:11:51 lr 0.000051	time 0.5577 (0.5925)	loss 2.6133 (2.6103)	grad_norm 2.6591 (2.6453)	mem 17417MB
[2023-02-02 18:03:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][100/1251]	eta 0:11:10 lr 0.000051	time 0.5640 (0.5825)	loss 2.7976 (2.5720)	grad_norm 3.0408 (2.6438)	mem 17417MB
[2023-02-02 18:04:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][150/1251]	eta 0:10:36 lr 0.000050	time 0.5527 (0.5781)	loss 2.7384 (2.6032)	grad_norm 2.4115 (2.6544)	mem 17417MB
[2023-02-02 18:04:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][200/1251]	eta 0:10:05 lr 0.000050	time 0.5479 (0.5761)	loss 2.7536 (2.6114)	grad_norm 2.5272 (2.6425)	mem 17417MB
[2023-02-02 18:05:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][250/1251]	eta 0:09:35 lr 0.000050	time 0.6447 (0.5749)	loss 2.0373 (2.6107)	grad_norm 2.2510 (2.6430)	mem 17417MB
[2023-02-02 18:05:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][300/1251]	eta 0:09:05 lr 0.000050	time 0.5514 (0.5738)	loss 2.4145 (2.6123)	grad_norm 2.5321 (2.6454)	mem 17417MB
[2023-02-02 18:05:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][350/1251]	eta 0:08:36 lr 0.000050	time 0.5577 (0.5730)	loss 3.1121 (2.6122)	grad_norm 2.3107 (2.6364)	mem 17417MB
[2023-02-02 18:06:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][400/1251]	eta 0:08:07 lr 0.000050	time 0.5651 (0.5729)	loss 2.3705 (2.6103)	grad_norm 2.7363 (2.6272)	mem 17417MB
[2023-02-02 18:06:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][450/1251]	eta 0:07:38 lr 0.000050	time 0.6452 (0.5721)	loss 3.0256 (2.6112)	grad_norm 2.4621 (2.6241)	mem 17417MB
[2023-02-02 18:07:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][500/1251]	eta 0:07:09 lr 0.000050	time 0.5490 (0.5717)	loss 2.9066 (2.6077)	grad_norm 2.6348 (2.6229)	mem 17417MB
[2023-02-02 18:07:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][550/1251]	eta 0:06:40 lr 0.000050	time 0.5686 (0.5711)	loss 1.3834 (2.6089)	grad_norm 2.4834 (2.6237)	mem 17417MB
[2023-02-02 18:08:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][600/1251]	eta 0:06:11 lr 0.000050	time 0.5514 (0.5711)	loss 2.3113 (2.6116)	grad_norm 2.4222 (2.6295)	mem 17417MB
[2023-02-02 18:08:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][650/1251]	eta 0:05:43 lr 0.000050	time 0.5605 (0.5711)	loss 1.7647 (2.6128)	grad_norm 2.4588 (2.6354)	mem 17417MB
[2023-02-02 18:09:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][700/1251]	eta 0:05:14 lr 0.000050	time 0.5512 (0.5711)	loss 2.8925 (2.6122)	grad_norm 2.4320 (2.6387)	mem 17417MB
[2023-02-02 18:09:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][750/1251]	eta 0:04:45 lr 0.000049	time 0.5501 (0.5708)	loss 2.5303 (2.6132)	grad_norm 2.2056 (2.6350)	mem 17417MB
[2023-02-02 18:10:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][800/1251]	eta 0:04:17 lr 0.000049	time 0.5557 (0.5707)	loss 3.0196 (2.6129)	grad_norm 3.4163 (2.6420)	mem 17417MB
[2023-02-02 18:10:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][850/1251]	eta 0:03:48 lr 0.000049	time 0.5594 (0.5706)	loss 3.3951 (2.6203)	grad_norm 2.4482 (2.6445)	mem 17417MB
[2023-02-02 18:11:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][900/1251]	eta 0:03:20 lr 0.000049	time 0.5514 (0.5707)	loss 3.0026 (2.6176)	grad_norm 2.7505 (2.6436)	mem 17417MB
[2023-02-02 18:11:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][950/1251]	eta 0:02:51 lr 0.000049	time 0.5569 (0.5704)	loss 2.0668 (2.6193)	grad_norm 2.7367 (inf)	mem 17417MB
[2023-02-02 18:12:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][1000/1251]	eta 0:02:23 lr 0.000049	time 0.6347 (0.5704)	loss 2.9106 (2.6229)	grad_norm 2.3878 (inf)	mem 17417MB
[2023-02-02 18:12:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][1050/1251]	eta 0:01:54 lr 0.000049	time 0.5539 (0.5704)	loss 3.0949 (2.6205)	grad_norm 2.5483 (inf)	mem 17417MB
[2023-02-02 18:13:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][1100/1251]	eta 0:01:26 lr 0.000049	time 0.6278 (0.5702)	loss 2.1546 (2.6250)	grad_norm 2.7228 (inf)	mem 17417MB
[2023-02-02 18:13:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][1150/1251]	eta 0:00:57 lr 0.000049	time 0.5634 (0.5701)	loss 2.1843 (2.6230)	grad_norm 2.5770 (inf)	mem 17417MB
[2023-02-02 18:14:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][1200/1251]	eta 0:00:29 lr 0.000049	time 0.5545 (0.5701)	loss 2.7841 (2.6267)	grad_norm 3.3492 (inf)	mem 17417MB
[2023-02-02 18:14:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [261/300][1250/1251]	eta 0:00:00 lr 0.000049	time 0.5539 (0.5700)	loss 2.7772 (2.6290)	grad_norm 2.6567 (inf)	mem 17417MB
[2023-02-02 18:14:31 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 261 training takes 0:11:53
[2023-02-02 18:14:31 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_261.pth saving......
[2023-02-02 18:14:33 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_261.pth saved !!!
[2023-02-02 18:14:34 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.922 (0.922)	Loss 0.7507 (0.7507)	Acc@1 81.055 (81.055)	Acc@5 96.973 (96.973)	Mem 17417MB
[2023-02-02 18:14:42 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.712 Acc@5 96.658
[2023-02-02 18:14:42 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.7%
[2023-02-02 18:14:43 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.413 (1.413)	Loss 0.6661 (0.6661)	Acc@1 84.668 (84.668)	Acc@5 97.266 (97.266)	Mem 17417MB
[2023-02-02 18:14:51 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.956 Acc@5 96.854
[2023-02-02 18:14:51 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 18:14:51 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.96% at 259 epoch
[2023-02-02 18:14:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][0/1251]	eta 0:35:43 lr 0.000049	time 1.7130 (1.7130)	loss 2.5826 (2.5826)	grad_norm 2.3757 (2.3757)	mem 17417MB
[2023-02-02 18:15:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][50/1251]	eta 0:11:55 lr 0.000049	time 0.5486 (0.5956)	loss 2.8722 (2.6233)	grad_norm 2.5579 (2.6047)	mem 17417MB
[2023-02-02 18:15:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][100/1251]	eta 0:11:12 lr 0.000049	time 0.5554 (0.5844)	loss 3.0496 (2.5907)	grad_norm 2.6903 (2.6191)	mem 17417MB
[2023-02-02 18:16:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][150/1251]	eta 0:10:38 lr 0.000048	time 0.5603 (0.5801)	loss 3.3319 (2.5750)	grad_norm 2.8719 (2.6559)	mem 17417MB
[2023-02-02 18:16:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][200/1251]	eta 0:10:06 lr 0.000048	time 0.5448 (0.5774)	loss 2.9458 (2.5984)	grad_norm 2.5864 (2.6397)	mem 17417MB
[2023-02-02 18:17:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][250/1251]	eta 0:09:36 lr 0.000048	time 0.5520 (0.5761)	loss 2.7848 (2.5806)	grad_norm 3.2414 (2.6447)	mem 17417MB
[2023-02-02 18:17:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][300/1251]	eta 0:09:06 lr 0.000048	time 0.5579 (0.5748)	loss 1.7020 (2.5967)	grad_norm 2.3798 (2.6462)	mem 17417MB
[2023-02-02 18:18:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][350/1251]	eta 0:08:37 lr 0.000048	time 0.5542 (0.5742)	loss 2.8527 (2.5938)	grad_norm 3.0651 (2.6422)	mem 17417MB
[2023-02-02 18:18:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][400/1251]	eta 0:08:08 lr 0.000048	time 0.5578 (0.5736)	loss 2.1330 (2.5964)	grad_norm 2.5253 (2.6489)	mem 17417MB
[2023-02-02 18:19:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][450/1251]	eta 0:07:39 lr 0.000048	time 0.6244 (0.5732)	loss 1.6881 (2.6072)	grad_norm 3.1937 (2.6544)	mem 17417MB
[2023-02-02 18:19:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][500/1251]	eta 0:07:09 lr 0.000048	time 0.5524 (0.5724)	loss 2.7972 (2.6098)	grad_norm 2.7000 (2.6489)	mem 17417MB
[2023-02-02 18:20:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][550/1251]	eta 0:06:41 lr 0.000048	time 0.5545 (0.5723)	loss 2.7532 (2.6086)	grad_norm 2.5677 (2.6448)	mem 17417MB
[2023-02-02 18:20:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][600/1251]	eta 0:06:12 lr 0.000048	time 0.5563 (0.5722)	loss 2.4248 (2.6168)	grad_norm 2.7515 (2.6500)	mem 17417MB
[2023-02-02 18:21:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][650/1251]	eta 0:05:43 lr 0.000048	time 0.5614 (0.5719)	loss 1.8789 (2.6143)	grad_norm 2.5256 (2.6451)	mem 17417MB
[2023-02-02 18:21:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][700/1251]	eta 0:05:15 lr 0.000048	time 0.5518 (0.5718)	loss 2.4991 (2.6146)	grad_norm 4.1326 (2.6462)	mem 17417MB
[2023-02-02 18:22:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][750/1251]	eta 0:04:46 lr 0.000047	time 0.6144 (0.5716)	loss 3.0329 (2.6110)	grad_norm 2.2664 (2.6438)	mem 17417MB
[2023-02-02 18:22:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][800/1251]	eta 0:04:17 lr 0.000047	time 0.6236 (0.5715)	loss 3.0728 (2.6169)	grad_norm 2.4998 (2.6435)	mem 17417MB
[2023-02-02 18:22:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][850/1251]	eta 0:03:49 lr 0.000047	time 0.5640 (0.5714)	loss 3.0810 (2.6215)	grad_norm 2.5185 (2.6481)	mem 17417MB
[2023-02-02 18:23:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][900/1251]	eta 0:03:20 lr 0.000047	time 0.5536 (0.5713)	loss 2.9728 (2.6228)	grad_norm 2.3347 (2.6484)	mem 17417MB
[2023-02-02 18:23:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][950/1251]	eta 0:02:51 lr 0.000047	time 0.5577 (0.5714)	loss 3.0938 (2.6256)	grad_norm 3.0913 (2.6499)	mem 17417MB
[2023-02-02 18:24:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][1000/1251]	eta 0:02:23 lr 0.000047	time 0.5505 (0.5712)	loss 2.3164 (2.6287)	grad_norm 2.8909 (2.6548)	mem 17417MB
[2023-02-02 18:24:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][1050/1251]	eta 0:01:54 lr 0.000047	time 0.5551 (0.5710)	loss 2.4035 (2.6339)	grad_norm 2.3471 (2.6495)	mem 17417MB
[2023-02-02 18:25:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][1100/1251]	eta 0:01:26 lr 0.000047	time 0.7054 (0.5710)	loss 2.2454 (2.6291)	grad_norm 3.2375 (2.6512)	mem 17417MB
[2023-02-02 18:25:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][1150/1251]	eta 0:00:57 lr 0.000047	time 0.5593 (0.5707)	loss 2.6992 (2.6323)	grad_norm 2.2637 (2.6506)	mem 17417MB
[2023-02-02 18:26:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][1200/1251]	eta 0:00:29 lr 0.000047	time 0.5526 (0.5706)	loss 2.2531 (2.6310)	grad_norm 2.6969 (2.6465)	mem 17417MB
[2023-02-02 18:26:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [262/300][1250/1251]	eta 0:00:00 lr 0.000047	time 0.5488 (0.5705)	loss 2.5544 (2.6314)	grad_norm 2.6619 (2.6459)	mem 17417MB
[2023-02-02 18:26:45 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 262 training takes 0:11:53
[2023-02-02 18:26:45 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_262.pth saving......
[2023-02-02 18:26:47 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_262.pth saved !!!
[2023-02-02 18:26:48 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.903 (0.903)	Loss 0.6824 (0.6824)	Acc@1 84.375 (84.375)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-02 18:26:56 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.730 Acc@5 96.690
[2023-02-02 18:26:56 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.7%
[2023-02-02 18:26:57 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.277 (1.277)	Loss 0.7625 (0.7625)	Acc@1 82.227 (82.227)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-02 18:27:05 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.958 Acc@5 96.872
[2023-02-02 18:27:05 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 18:27:05 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.96% at 259 epoch
[2023-02-02 18:27:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][0/1251]	eta 0:35:27 lr 0.000047	time 1.7008 (1.7008)	loss 3.0102 (3.0102)	grad_norm 2.7497 (2.7497)	mem 17417MB
[2023-02-02 18:27:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][50/1251]	eta 0:11:47 lr 0.000047	time 0.5594 (0.5891)	loss 2.7294 (2.6340)	grad_norm 2.6740 (2.6644)	mem 17417MB
[2023-02-02 18:28:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][100/1251]	eta 0:11:07 lr 0.000047	time 0.6475 (0.5800)	loss 2.6393 (2.6153)	grad_norm 2.7018 (2.6550)	mem 17417MB
[2023-02-02 18:28:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][150/1251]	eta 0:10:34 lr 0.000046	time 0.5548 (0.5762)	loss 2.7100 (2.6045)	grad_norm 3.3328 (2.6501)	mem 17417MB
[2023-02-02 18:29:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][200/1251]	eta 0:10:03 lr 0.000046	time 0.5772 (0.5746)	loss 2.7109 (2.6092)	grad_norm 2.1814 (2.6663)	mem 17417MB
[2023-02-02 18:29:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][250/1251]	eta 0:09:33 lr 0.000046	time 0.5506 (0.5728)	loss 2.5529 (2.6063)	grad_norm 2.4787 (2.6652)	mem 17417MB
[2023-02-02 18:29:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][300/1251]	eta 0:09:04 lr 0.000046	time 0.5541 (0.5725)	loss 2.7342 (2.6108)	grad_norm 2.9317 (2.6752)	mem 17417MB
[2023-02-02 18:30:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][350/1251]	eta 0:08:34 lr 0.000046	time 0.5598 (0.5715)	loss 2.9934 (2.6285)	grad_norm 2.4960 (2.6789)	mem 17417MB
[2023-02-02 18:30:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][400/1251]	eta 0:08:06 lr 0.000046	time 0.5649 (0.5711)	loss 2.6345 (2.6293)	grad_norm 2.3521 (2.6694)	mem 17417MB
[2023-02-02 18:31:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][450/1251]	eta 0:07:37 lr 0.000046	time 0.5561 (0.5705)	loss 2.7511 (2.6245)	grad_norm 2.4833 (2.6617)	mem 17417MB
[2023-02-02 18:31:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][500/1251]	eta 0:07:08 lr 0.000046	time 0.6172 (0.5703)	loss 2.7647 (2.6258)	grad_norm 2.4961 (2.6682)	mem 17417MB
[2023-02-02 18:32:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][550/1251]	eta 0:06:39 lr 0.000046	time 0.5551 (0.5700)	loss 2.8442 (2.6227)	grad_norm 2.7047 (inf)	mem 17417MB
[2023-02-02 18:32:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][600/1251]	eta 0:06:11 lr 0.000046	time 0.5569 (0.5702)	loss 1.9488 (2.6237)	grad_norm 2.5019 (inf)	mem 17417MB
[2023-02-02 18:33:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][650/1251]	eta 0:05:42 lr 0.000046	time 0.5624 (0.5701)	loss 2.7167 (2.6262)	grad_norm 3.5049 (inf)	mem 17417MB
[2023-02-02 18:33:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][700/1251]	eta 0:05:14 lr 0.000046	time 0.5557 (0.5702)	loss 2.1047 (2.6329)	grad_norm 2.2682 (inf)	mem 17417MB
[2023-02-02 18:34:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][750/1251]	eta 0:04:45 lr 0.000046	time 0.5576 (0.5701)	loss 2.3215 (2.6355)	grad_norm 2.9093 (inf)	mem 17417MB
[2023-02-02 18:34:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][800/1251]	eta 0:04:17 lr 0.000045	time 0.5584 (0.5702)	loss 2.4707 (2.6342)	grad_norm 2.2952 (inf)	mem 17417MB
[2023-02-02 18:35:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][850/1251]	eta 0:03:48 lr 0.000045	time 0.5481 (0.5702)	loss 3.1659 (2.6282)	grad_norm 2.6457 (inf)	mem 17417MB
[2023-02-02 18:35:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][900/1251]	eta 0:03:20 lr 0.000045	time 0.6345 (0.5700)	loss 2.1474 (2.6277)	grad_norm 2.6878 (inf)	mem 17417MB
[2023-02-02 18:36:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][950/1251]	eta 0:02:51 lr 0.000045	time 0.5596 (0.5701)	loss 3.0763 (2.6274)	grad_norm 2.6878 (inf)	mem 17417MB
[2023-02-02 18:36:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][1000/1251]	eta 0:02:23 lr 0.000045	time 0.6271 (0.5700)	loss 2.8005 (2.6296)	grad_norm 2.3207 (inf)	mem 17417MB
[2023-02-02 18:37:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][1050/1251]	eta 0:01:54 lr 0.000045	time 0.5540 (0.5699)	loss 1.9950 (2.6239)	grad_norm 2.3814 (inf)	mem 17417MB
[2023-02-02 18:37:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][1100/1251]	eta 0:01:26 lr 0.000045	time 0.5550 (0.5697)	loss 2.7332 (2.6252)	grad_norm 2.7637 (inf)	mem 17417MB
[2023-02-02 18:38:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][1150/1251]	eta 0:00:57 lr 0.000045	time 0.5528 (0.5696)	loss 3.0223 (2.6216)	grad_norm 2.3840 (inf)	mem 17417MB
[2023-02-02 18:38:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][1200/1251]	eta 0:00:29 lr 0.000045	time 0.6523 (0.5696)	loss 2.8144 (2.6241)	grad_norm 2.3866 (inf)	mem 17417MB
[2023-02-02 18:38:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [263/300][1250/1251]	eta 0:00:00 lr 0.000045	time 0.5501 (0.5696)	loss 2.1071 (2.6265)	grad_norm 2.4940 (inf)	mem 17417MB
[2023-02-02 18:38:58 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 263 training takes 0:11:52
[2023-02-02 18:38:58 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_263.pth saving......
[2023-02-02 18:39:00 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_263.pth saved !!!
[2023-02-02 18:39:01 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.986 (0.986)	Loss 0.8058 (0.8058)	Acc@1 82.520 (82.520)	Acc@5 95.215 (95.215)	Mem 17417MB
[2023-02-02 18:39:08 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.766 Acc@5 96.712
[2023-02-02 18:39:08 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.8%
[2023-02-02 18:39:10 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.315 (1.315)	Loss 0.7295 (0.7295)	Acc@1 83.496 (83.496)	Acc@5 97.168 (97.168)	Mem 17417MB
[2023-02-02 18:39:18 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.990 Acc@5 96.874
[2023-02-02 18:39:18 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 18:39:18 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 83.99% at 263 epoch
[2023-02-02 18:39:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][0/1251]	eta 0:35:25 lr 0.000045	time 1.6994 (1.6994)	loss 2.5580 (2.5580)	grad_norm 2.3915 (2.3915)	mem 17417MB
[2023-02-02 18:39:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][50/1251]	eta 0:11:50 lr 0.000045	time 0.5534 (0.5914)	loss 2.9732 (2.5570)	grad_norm 2.5471 (2.7025)	mem 17417MB
[2023-02-02 18:40:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][100/1251]	eta 0:11:09 lr 0.000045	time 0.6347 (0.5821)	loss 2.2442 (2.5788)	grad_norm 2.2513 (2.6661)	mem 17417MB
[2023-02-02 18:40:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][150/1251]	eta 0:10:34 lr 0.000045	time 0.5516 (0.5766)	loss 2.2258 (2.5952)	grad_norm 2.4087 (2.6532)	mem 17417MB
[2023-02-02 18:41:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][200/1251]	eta 0:10:03 lr 0.000044	time 0.5540 (0.5743)	loss 2.9885 (2.6124)	grad_norm 2.5307 (2.6388)	mem 17417MB
[2023-02-02 18:41:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][250/1251]	eta 0:09:33 lr 0.000044	time 0.5638 (0.5726)	loss 3.5404 (2.6198)	grad_norm 2.6700 (2.6606)	mem 17417MB
[2023-02-02 18:42:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][300/1251]	eta 0:09:03 lr 0.000044	time 0.5522 (0.5720)	loss 2.4768 (2.6128)	grad_norm 2.7961 (2.6547)	mem 17417MB
[2023-02-02 18:42:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][350/1251]	eta 0:08:34 lr 0.000044	time 0.5521 (0.5714)	loss 2.8902 (2.6123)	grad_norm 2.4914 (2.6555)	mem 17417MB
[2023-02-02 18:43:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][400/1251]	eta 0:08:06 lr 0.000044	time 0.5512 (0.5711)	loss 2.6208 (2.6258)	grad_norm 2.2530 (2.6534)	mem 17417MB
[2023-02-02 18:43:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][450/1251]	eta 0:07:37 lr 0.000044	time 0.6157 (0.5712)	loss 2.4780 (2.6252)	grad_norm 2.4361 (2.6577)	mem 17417MB
[2023-02-02 18:44:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][500/1251]	eta 0:07:08 lr 0.000044	time 0.5556 (0.5707)	loss 2.6385 (2.6145)	grad_norm 2.5092 (2.6581)	mem 17417MB
[2023-02-02 18:44:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][550/1251]	eta 0:06:39 lr 0.000044	time 0.5560 (0.5705)	loss 2.1566 (2.6126)	grad_norm 2.4724 (2.6657)	mem 17417MB
[2023-02-02 18:45:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][600/1251]	eta 0:06:11 lr 0.000044	time 0.5624 (0.5704)	loss 2.0423 (2.6173)	grad_norm 2.5133 (2.6649)	mem 17417MB
[2023-02-02 18:45:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][650/1251]	eta 0:05:42 lr 0.000044	time 0.5525 (0.5702)	loss 2.5721 (2.6201)	grad_norm 2.4849 (2.6635)	mem 17417MB
[2023-02-02 18:45:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][700/1251]	eta 0:05:14 lr 0.000044	time 0.5592 (0.5701)	loss 2.9511 (2.6159)	grad_norm 3.5177 (2.6625)	mem 17417MB
[2023-02-02 18:46:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][750/1251]	eta 0:04:45 lr 0.000044	time 0.5559 (0.5698)	loss 2.8816 (2.6123)	grad_norm 2.4446 (2.6583)	mem 17417MB
[2023-02-02 18:46:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][800/1251]	eta 0:04:17 lr 0.000044	time 0.5583 (0.5700)	loss 2.3314 (2.6091)	grad_norm 2.5461 (2.6603)	mem 17417MB
[2023-02-02 18:47:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][850/1251]	eta 0:03:48 lr 0.000043	time 0.5554 (0.5697)	loss 2.6041 (2.6084)	grad_norm 2.8349 (2.6635)	mem 17417MB
[2023-02-02 18:47:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][900/1251]	eta 0:03:19 lr 0.000043	time 0.5578 (0.5696)	loss 2.9996 (2.6108)	grad_norm 2.4730 (2.6614)	mem 17417MB
[2023-02-02 18:48:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][950/1251]	eta 0:02:51 lr 0.000043	time 0.5607 (0.5695)	loss 2.9121 (2.6158)	grad_norm 2.4624 (2.6610)	mem 17417MB
[2023-02-02 18:48:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][1000/1251]	eta 0:02:22 lr 0.000043	time 0.5519 (0.5694)	loss 2.7162 (2.6161)	grad_norm 2.7594 (2.6637)	mem 17417MB
[2023-02-02 18:49:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][1050/1251]	eta 0:01:54 lr 0.000043	time 0.5524 (0.5694)	loss 2.3614 (2.6158)	grad_norm 2.9809 (2.6665)	mem 17417MB
[2023-02-02 18:49:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][1100/1251]	eta 0:01:25 lr 0.000043	time 0.6280 (0.5695)	loss 2.8487 (2.6182)	grad_norm 2.6560 (2.6723)	mem 17417MB
[2023-02-02 18:50:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][1150/1251]	eta 0:00:57 lr 0.000043	time 0.5564 (0.5693)	loss 2.6301 (2.6190)	grad_norm 2.6422 (2.6695)	mem 17417MB
[2023-02-02 18:50:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][1200/1251]	eta 0:00:29 lr 0.000043	time 0.5569 (0.5693)	loss 3.0408 (2.6191)	grad_norm 2.5391 (2.6685)	mem 17417MB
[2023-02-02 18:51:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [264/300][1250/1251]	eta 0:00:00 lr 0.000043	time 0.5491 (0.5693)	loss 3.1481 (2.6197)	grad_norm 3.0151 (2.6670)	mem 17417MB
[2023-02-02 18:51:10 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 264 training takes 0:11:52
[2023-02-02 18:51:10 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_264.pth saving......
[2023-02-02 18:51:12 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_264.pth saved !!!
[2023-02-02 18:51:13 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.869 (0.869)	Loss 0.6745 (0.6745)	Acc@1 85.352 (85.352)	Acc@5 97.266 (97.266)	Mem 17417MB
[2023-02-02 18:51:21 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.746 Acc@5 96.706
[2023-02-02 18:51:21 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.7%
[2023-02-02 18:51:22 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.190 (1.190)	Loss 0.7277 (0.7277)	Acc@1 84.375 (84.375)	Acc@5 97.168 (97.168)	Mem 17417MB
[2023-02-02 18:51:30 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 84.018 Acc@5 96.890
[2023-02-02 18:51:30 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 18:51:30 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.02% at 264 epoch
[2023-02-02 18:51:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][0/1251]	eta 0:35:19 lr 0.000043	time 1.6943 (1.6943)	loss 2.8827 (2.8827)	grad_norm 2.9713 (2.9713)	mem 17417MB
[2023-02-02 18:52:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][50/1251]	eta 0:11:48 lr 0.000043	time 0.5515 (0.5897)	loss 2.8232 (2.6757)	grad_norm 2.5923 (2.6626)	mem 17417MB
[2023-02-02 18:52:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][100/1251]	eta 0:11:08 lr 0.000043	time 0.6549 (0.5805)	loss 2.7214 (2.6297)	grad_norm 2.7139 (2.7141)	mem 17417MB
[2023-02-02 18:52:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][150/1251]	eta 0:10:34 lr 0.000043	time 0.5639 (0.5767)	loss 1.8521 (2.6085)	grad_norm 2.3793 (2.7259)	mem 17417MB
[2023-02-02 18:53:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][200/1251]	eta 0:10:03 lr 0.000043	time 0.5540 (0.5741)	loss 2.7774 (2.6014)	grad_norm 2.4234 (2.7309)	mem 17417MB
[2023-02-02 18:53:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][250/1251]	eta 0:09:34 lr 0.000043	time 0.5557 (0.5738)	loss 2.9466 (2.5953)	grad_norm 2.7832 (2.7324)	mem 17417MB
[2023-02-02 18:54:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][300/1251]	eta 0:09:04 lr 0.000042	time 0.5619 (0.5723)	loss 2.2834 (2.6069)	grad_norm 2.9599 (2.7235)	mem 17417MB
[2023-02-02 18:54:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][350/1251]	eta 0:08:35 lr 0.000042	time 0.5518 (0.5719)	loss 2.2545 (2.6166)	grad_norm 2.8711 (2.7217)	mem 17417MB
[2023-02-02 18:55:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][400/1251]	eta 0:08:06 lr 0.000042	time 0.6248 (0.5714)	loss 2.7033 (2.6252)	grad_norm 2.8818 (2.7227)	mem 17417MB
[2023-02-02 18:55:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][450/1251]	eta 0:07:37 lr 0.000042	time 0.5525 (0.5713)	loss 2.5517 (2.6112)	grad_norm 2.5949 (inf)	mem 17417MB
[2023-02-02 18:56:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][500/1251]	eta 0:07:08 lr 0.000042	time 0.5526 (0.5710)	loss 1.8550 (2.6055)	grad_norm 2.2478 (inf)	mem 17417MB
[2023-02-02 18:56:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][550/1251]	eta 0:06:40 lr 0.000042	time 0.5588 (0.5707)	loss 2.8599 (2.5978)	grad_norm 2.9351 (inf)	mem 17417MB
[2023-02-02 18:57:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][600/1251]	eta 0:06:11 lr 0.000042	time 0.5575 (0.5706)	loss 2.9498 (2.5964)	grad_norm 2.8732 (inf)	mem 17417MB
[2023-02-02 18:57:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][650/1251]	eta 0:05:42 lr 0.000042	time 0.5596 (0.5704)	loss 3.1109 (2.5994)	grad_norm 2.9946 (inf)	mem 17417MB
[2023-02-02 18:58:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][700/1251]	eta 0:05:14 lr 0.000042	time 0.5635 (0.5704)	loss 3.2086 (2.5996)	grad_norm 2.6138 (inf)	mem 17417MB
[2023-02-02 18:58:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][750/1251]	eta 0:04:45 lr 0.000042	time 0.5586 (0.5702)	loss 2.0584 (2.5959)	grad_norm 2.5299 (inf)	mem 17417MB
[2023-02-02 18:59:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][800/1251]	eta 0:04:17 lr 0.000042	time 0.6084 (0.5701)	loss 2.7839 (2.5955)	grad_norm 2.7180 (inf)	mem 17417MB
[2023-02-02 18:59:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][850/1251]	eta 0:03:48 lr 0.000042	time 0.5616 (0.5700)	loss 1.8679 (2.5957)	grad_norm 2.4779 (inf)	mem 17417MB
[2023-02-02 19:00:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][900/1251]	eta 0:03:20 lr 0.000042	time 0.5566 (0.5698)	loss 2.3274 (2.5959)	grad_norm 2.6592 (inf)	mem 17417MB
[2023-02-02 19:00:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][950/1251]	eta 0:02:51 lr 0.000041	time 0.5613 (0.5699)	loss 2.7707 (2.5948)	grad_norm 2.4683 (inf)	mem 17417MB
[2023-02-02 19:01:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][1000/1251]	eta 0:02:23 lr 0.000041	time 0.6284 (0.5699)	loss 2.5378 (2.5992)	grad_norm 2.9003 (inf)	mem 17417MB
[2023-02-02 19:01:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][1050/1251]	eta 0:01:54 lr 0.000041	time 0.5583 (0.5700)	loss 3.0110 (2.5991)	grad_norm 3.3160 (inf)	mem 17417MB
[2023-02-02 19:01:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][1100/1251]	eta 0:01:26 lr 0.000041	time 0.6259 (0.5700)	loss 2.7845 (2.6008)	grad_norm 3.0961 (inf)	mem 17417MB
[2023-02-02 19:02:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][1150/1251]	eta 0:00:57 lr 0.000041	time 0.5584 (0.5698)	loss 2.7264 (2.6026)	grad_norm 3.0814 (inf)	mem 17417MB
[2023-02-02 19:02:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][1200/1251]	eta 0:00:29 lr 0.000041	time 0.6197 (0.5698)	loss 3.2299 (2.6073)	grad_norm 2.5134 (inf)	mem 17417MB
[2023-02-02 19:03:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [265/300][1250/1251]	eta 0:00:00 lr 0.000041	time 0.5485 (0.5698)	loss 2.2179 (2.6077)	grad_norm 3.5882 (inf)	mem 17417MB
[2023-02-02 19:03:23 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 265 training takes 0:11:52
[2023-02-02 19:03:23 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_265.pth saving......
[2023-02-02 19:03:25 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_265.pth saved !!!
[2023-02-02 19:03:26 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.922 (0.922)	Loss 0.6297 (0.6297)	Acc@1 85.059 (85.059)	Acc@5 97.754 (97.754)	Mem 17417MB
[2023-02-02 19:03:34 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.768 Acc@5 96.658
[2023-02-02 19:03:34 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.8%
[2023-02-02 19:03:35 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.237 (1.237)	Loss 0.6795 (0.6795)	Acc@1 84.375 (84.375)	Acc@5 97.852 (97.852)	Mem 17417MB
[2023-02-02 19:03:43 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 84.048 Acc@5 96.878
[2023-02-02 19:03:43 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 19:03:43 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.05% at 265 epoch
[2023-02-02 19:03:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][0/1251]	eta 0:35:18 lr 0.000041	time 1.6936 (1.6936)	loss 3.0042 (3.0042)	grad_norm 2.6836 (2.6836)	mem 17417MB
[2023-02-02 19:04:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][50/1251]	eta 0:11:53 lr 0.000041	time 0.6448 (0.5943)	loss 2.6816 (2.6278)	grad_norm 3.2615 (2.7749)	mem 17417MB
[2023-02-02 19:04:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][100/1251]	eta 0:11:09 lr 0.000041	time 0.5518 (0.5819)	loss 2.7202 (2.5922)	grad_norm 2.3186 (2.7671)	mem 17417MB
[2023-02-02 19:05:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][150/1251]	eta 0:10:35 lr 0.000041	time 0.5547 (0.5773)	loss 2.8272 (2.6244)	grad_norm 3.1785 (2.7294)	mem 17417MB
[2023-02-02 19:05:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][200/1251]	eta 0:10:04 lr 0.000041	time 0.5527 (0.5753)	loss 2.6238 (2.6255)	grad_norm 2.5114 (2.6979)	mem 17417MB
[2023-02-02 19:06:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][250/1251]	eta 0:09:34 lr 0.000041	time 0.6119 (0.5741)	loss 3.2867 (2.6434)	grad_norm 2.8095 (2.6747)	mem 17417MB
[2023-02-02 19:06:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][300/1251]	eta 0:09:05 lr 0.000041	time 0.5503 (0.5731)	loss 2.3508 (2.6294)	grad_norm 2.5492 (2.6733)	mem 17417MB
[2023-02-02 19:07:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][350/1251]	eta 0:08:35 lr 0.000041	time 0.5717 (0.5724)	loss 2.4663 (2.6274)	grad_norm 3.7091 (2.6977)	mem 17417MB
[2023-02-02 19:07:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][400/1251]	eta 0:08:06 lr 0.000040	time 0.5547 (0.5717)	loss 2.8297 (2.6265)	grad_norm 2.7360 (2.7084)	mem 17417MB
[2023-02-02 19:08:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][450/1251]	eta 0:07:37 lr 0.000040	time 0.5489 (0.5712)	loss 3.2906 (2.6295)	grad_norm 3.1539 (2.7053)	mem 17417MB
[2023-02-02 19:08:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][500/1251]	eta 0:07:08 lr 0.000040	time 0.5530 (0.5711)	loss 2.5338 (2.6087)	grad_norm 2.2130 (2.7020)	mem 17417MB
[2023-02-02 19:08:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][550/1251]	eta 0:06:40 lr 0.000040	time 0.5596 (0.5710)	loss 2.0545 (2.6023)	grad_norm 2.7543 (2.7010)	mem 17417MB
[2023-02-02 19:09:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][600/1251]	eta 0:06:11 lr 0.000040	time 0.5572 (0.5708)	loss 2.5632 (2.5966)	grad_norm 2.6495 (2.7107)	mem 17417MB
[2023-02-02 19:09:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][650/1251]	eta 0:05:42 lr 0.000040	time 0.6238 (0.5705)	loss 2.8340 (2.5943)	grad_norm 2.4180 (2.7078)	mem 17417MB
[2023-02-02 19:10:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][700/1251]	eta 0:05:14 lr 0.000040	time 0.5559 (0.5703)	loss 3.0276 (2.5947)	grad_norm 2.4577 (2.7017)	mem 17417MB
[2023-02-02 19:10:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][750/1251]	eta 0:04:45 lr 0.000040	time 0.5499 (0.5702)	loss 2.5794 (2.5941)	grad_norm 2.5202 (2.6973)	mem 17417MB
[2023-02-02 19:11:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][800/1251]	eta 0:04:17 lr 0.000040	time 0.5531 (0.5701)	loss 2.5595 (2.5881)	grad_norm 2.8470 (2.6919)	mem 17417MB
[2023-02-02 19:11:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][850/1251]	eta 0:03:48 lr 0.000040	time 0.5518 (0.5701)	loss 1.7698 (2.5940)	grad_norm 2.6528 (2.6959)	mem 17417MB
[2023-02-02 19:12:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][900/1251]	eta 0:03:20 lr 0.000040	time 0.6403 (0.5702)	loss 2.9132 (2.6010)	grad_norm 3.1262 (2.6987)	mem 17417MB
[2023-02-02 19:12:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][950/1251]	eta 0:02:51 lr 0.000040	time 0.5584 (0.5699)	loss 3.0068 (2.6034)	grad_norm 2.2170 (2.6938)	mem 17417MB
[2023-02-02 19:13:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][1000/1251]	eta 0:02:23 lr 0.000040	time 0.5593 (0.5700)	loss 1.7606 (2.6003)	grad_norm 3.7890 (2.7079)	mem 17417MB
[2023-02-02 19:13:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][1050/1251]	eta 0:01:54 lr 0.000040	time 0.6222 (0.5699)	loss 2.8242 (2.6002)	grad_norm 2.5137 (2.7061)	mem 17417MB
[2023-02-02 19:14:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][1100/1251]	eta 0:01:26 lr 0.000039	time 0.5639 (0.5700)	loss 2.7160 (2.6028)	grad_norm 2.5074 (2.7081)	mem 17417MB
[2023-02-02 19:14:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][1150/1251]	eta 0:00:57 lr 0.000039	time 0.5554 (0.5699)	loss 2.7633 (2.6056)	grad_norm 2.4507 (2.7106)	mem 17417MB
[2023-02-02 19:15:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][1200/1251]	eta 0:00:29 lr 0.000039	time 0.6078 (0.5697)	loss 2.6609 (2.6089)	grad_norm 2.5257 (inf)	mem 17417MB
[2023-02-02 19:15:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [266/300][1250/1251]	eta 0:00:00 lr 0.000039	time 0.5504 (0.5696)	loss 2.4821 (2.6068)	grad_norm 2.6334 (inf)	mem 17417MB
[2023-02-02 19:15:36 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 266 training takes 0:11:52
[2023-02-02 19:15:36 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_266.pth saving......
[2023-02-02 19:15:37 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_266.pth saved !!!
[2023-02-02 19:15:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.857 (0.857)	Loss 0.6592 (0.6592)	Acc@1 86.035 (86.035)	Acc@5 96.484 (96.484)	Mem 17417MB
[2023-02-02 19:15:46 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.834 Acc@5 96.706
[2023-02-02 19:15:46 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.8%
[2023-02-02 19:15:47 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.221 (1.221)	Loss 0.7690 (0.7690)	Acc@1 82.910 (82.910)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-02 19:15:55 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 84.070 Acc@5 96.872
[2023-02-02 19:15:55 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.1%
[2023-02-02 19:15:55 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.07% at 266 epoch
[2023-02-02 19:15:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][0/1251]	eta 0:35:58 lr 0.000039	time 1.7255 (1.7255)	loss 2.7914 (2.7914)	grad_norm 2.3957 (2.3957)	mem 17417MB
[2023-02-02 19:16:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][50/1251]	eta 0:11:56 lr 0.000039	time 0.6342 (0.5965)	loss 3.0957 (2.6216)	grad_norm 2.7824 (2.7247)	mem 17417MB
[2023-02-02 19:16:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][100/1251]	eta 0:11:10 lr 0.000039	time 0.5561 (0.5828)	loss 2.6939 (2.6379)	grad_norm 2.6790 (2.7519)	mem 17417MB
[2023-02-02 19:17:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][150/1251]	eta 0:10:35 lr 0.000039	time 0.5552 (0.5776)	loss 2.2886 (2.6380)	grad_norm 3.2141 (2.7604)	mem 17417MB
[2023-02-02 19:17:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][200/1251]	eta 0:10:05 lr 0.000039	time 0.5553 (0.5765)	loss 3.1792 (2.6243)	grad_norm 2.5933 (2.7405)	mem 17417MB
[2023-02-02 19:18:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][250/1251]	eta 0:09:35 lr 0.000039	time 0.5606 (0.5745)	loss 3.0496 (2.6387)	grad_norm 2.6900 (2.7556)	mem 17417MB
[2023-02-02 19:18:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][300/1251]	eta 0:09:05 lr 0.000039	time 0.5539 (0.5739)	loss 2.5845 (2.6214)	grad_norm 2.5191 (2.7430)	mem 17417MB
[2023-02-02 19:19:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][350/1251]	eta 0:08:36 lr 0.000039	time 0.5604 (0.5732)	loss 3.1389 (2.6213)	grad_norm 2.5661 (2.7235)	mem 17417MB
[2023-02-02 19:19:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][400/1251]	eta 0:08:07 lr 0.000039	time 0.5615 (0.5726)	loss 2.0351 (2.6024)	grad_norm 2.6475 (2.7270)	mem 17417MB
[2023-02-02 19:20:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][450/1251]	eta 0:07:38 lr 0.000039	time 0.5568 (0.5722)	loss 3.2476 (2.6057)	grad_norm 2.7497 (2.7227)	mem 17417MB
[2023-02-02 19:20:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][500/1251]	eta 0:07:09 lr 0.000039	time 0.5562 (0.5716)	loss 2.5871 (2.6036)	grad_norm 2.5194 (2.7155)	mem 17417MB
[2023-02-02 19:21:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][550/1251]	eta 0:06:40 lr 0.000038	time 0.5547 (0.5712)	loss 3.2034 (2.6150)	grad_norm 3.5395 (2.7170)	mem 17417MB
[2023-02-02 19:21:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][600/1251]	eta 0:06:11 lr 0.000038	time 0.5739 (0.5713)	loss 2.8552 (2.6233)	grad_norm 2.4730 (2.7163)	mem 17417MB
[2023-02-02 19:22:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][650/1251]	eta 0:05:43 lr 0.000038	time 0.5507 (0.5711)	loss 2.6753 (2.6260)	grad_norm 2.4382 (2.7177)	mem 17417MB
[2023-02-02 19:22:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][700/1251]	eta 0:05:14 lr 0.000038	time 0.5533 (0.5708)	loss 2.7175 (2.6281)	grad_norm 3.0290 (2.7211)	mem 17417MB
[2023-02-02 19:23:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][750/1251]	eta 0:04:45 lr 0.000038	time 0.5554 (0.5708)	loss 3.0173 (2.6238)	grad_norm 2.9945 (2.7235)	mem 17417MB
[2023-02-02 19:23:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][800/1251]	eta 0:04:17 lr 0.000038	time 0.5747 (0.5706)	loss 3.1634 (2.6267)	grad_norm 3.2937 (2.7251)	mem 17417MB
[2023-02-02 19:24:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][850/1251]	eta 0:03:48 lr 0.000038	time 0.5461 (0.5705)	loss 3.2971 (2.6295)	grad_norm 2.8793 (2.7197)	mem 17417MB
[2023-02-02 19:24:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][900/1251]	eta 0:03:20 lr 0.000038	time 0.5608 (0.5704)	loss 2.8653 (2.6263)	grad_norm 3.2066 (2.7170)	mem 17417MB
[2023-02-02 19:24:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][950/1251]	eta 0:02:51 lr 0.000038	time 0.5563 (0.5703)	loss 2.9320 (2.6265)	grad_norm 2.9313 (2.7165)	mem 17417MB
[2023-02-02 19:25:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][1000/1251]	eta 0:02:23 lr 0.000038	time 0.5650 (0.5703)	loss 3.2972 (2.6268)	grad_norm 2.7097 (2.7174)	mem 17417MB
[2023-02-02 19:25:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][1050/1251]	eta 0:01:54 lr 0.000038	time 0.5497 (0.5702)	loss 2.9164 (2.6334)	grad_norm 2.6302 (2.7206)	mem 17417MB
[2023-02-02 19:26:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][1100/1251]	eta 0:01:26 lr 0.000038	time 0.5514 (0.5700)	loss 2.3819 (2.6316)	grad_norm 3.0829 (2.7215)	mem 17417MB
[2023-02-02 19:26:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][1150/1251]	eta 0:00:57 lr 0.000038	time 0.5540 (0.5701)	loss 1.9578 (2.6296)	grad_norm 2.4630 (2.7196)	mem 17417MB
[2023-02-02 19:27:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][1200/1251]	eta 0:00:29 lr 0.000038	time 0.5502 (0.5700)	loss 2.8499 (2.6304)	grad_norm 2.4891 (2.7200)	mem 17417MB
[2023-02-02 19:27:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [267/300][1250/1251]	eta 0:00:00 lr 0.000038	time 0.5490 (0.5700)	loss 2.5775 (2.6277)	grad_norm 2.4290 (2.7203)	mem 17417MB
[2023-02-02 19:27:49 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 267 training takes 0:11:53
[2023-02-02 19:27:49 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_267.pth saving......
[2023-02-02 19:27:50 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_267.pth saved !!!
[2023-02-02 19:27:51 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.841 (0.841)	Loss 0.6759 (0.6759)	Acc@1 85.352 (85.352)	Acc@5 96.484 (96.484)	Mem 17417MB
[2023-02-02 19:27:59 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.732 Acc@5 96.668
[2023-02-02 19:27:59 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.7%
[2023-02-02 19:28:00 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.209 (1.209)	Loss 0.7050 (0.7050)	Acc@1 84.766 (84.766)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 19:28:09 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 84.076 Acc@5 96.862
[2023-02-02 19:28:09 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.1%
[2023-02-02 19:28:09 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 267 epoch
[2023-02-02 19:28:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][0/1251]	eta 0:36:14 lr 0.000038	time 1.7378 (1.7378)	loss 2.7629 (2.7629)	grad_norm 2.3430 (2.3430)	mem 17417MB
[2023-02-02 19:28:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][50/1251]	eta 0:11:55 lr 0.000037	time 0.5487 (0.5959)	loss 2.2291 (2.6483)	grad_norm 2.5965 (2.6476)	mem 17417MB
[2023-02-02 19:29:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][100/1251]	eta 0:11:10 lr 0.000037	time 0.6289 (0.5826)	loss 2.0130 (2.5808)	grad_norm 2.9245 (2.6641)	mem 17417MB
[2023-02-02 19:29:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][150/1251]	eta 0:10:35 lr 0.000037	time 0.5612 (0.5771)	loss 2.1672 (2.5942)	grad_norm 2.2404 (2.6903)	mem 17417MB
[2023-02-02 19:30:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][200/1251]	eta 0:10:04 lr 0.000037	time 0.6238 (0.5752)	loss 2.1589 (2.5855)	grad_norm 2.5644 (2.7342)	mem 17417MB
[2023-02-02 19:30:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][250/1251]	eta 0:09:33 lr 0.000037	time 0.5549 (0.5734)	loss 2.7472 (2.5853)	grad_norm 2.8925 (2.7361)	mem 17417MB
[2023-02-02 19:31:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][300/1251]	eta 0:09:04 lr 0.000037	time 0.5589 (0.5728)	loss 1.9875 (2.5984)	grad_norm 2.3452 (2.7592)	mem 17417MB
[2023-02-02 19:31:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][350/1251]	eta 0:08:35 lr 0.000037	time 0.5595 (0.5722)	loss 2.2840 (2.6066)	grad_norm 2.5671 (2.7515)	mem 17417MB
[2023-02-02 19:31:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][400/1251]	eta 0:08:06 lr 0.000037	time 0.5569 (0.5716)	loss 3.1312 (2.6184)	grad_norm 2.4652 (2.7549)	mem 17417MB
[2023-02-02 19:32:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][450/1251]	eta 0:07:37 lr 0.000037	time 0.5589 (0.5716)	loss 2.8747 (2.6114)	grad_norm 2.4633 (2.7574)	mem 17417MB
[2023-02-02 19:32:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][500/1251]	eta 0:07:08 lr 0.000037	time 0.5580 (0.5707)	loss 2.9267 (2.6088)	grad_norm 3.0772 (2.7704)	mem 17417MB
[2023-02-02 19:33:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][550/1251]	eta 0:06:40 lr 0.000037	time 0.5552 (0.5708)	loss 2.4505 (2.6106)	grad_norm 2.7946 (2.7693)	mem 17417MB
[2023-02-02 19:33:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][600/1251]	eta 0:06:11 lr 0.000037	time 0.6170 (0.5707)	loss 2.5271 (2.6070)	grad_norm 2.8920 (2.7694)	mem 17417MB
[2023-02-02 19:34:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][650/1251]	eta 0:05:42 lr 0.000037	time 0.5542 (0.5707)	loss 3.0022 (2.6173)	grad_norm 2.3029 (2.7653)	mem 17417MB
[2023-02-02 19:34:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][700/1251]	eta 0:05:14 lr 0.000037	time 0.5626 (0.5705)	loss 2.8492 (2.6143)	grad_norm 2.5688 (2.7662)	mem 17417MB
[2023-02-02 19:35:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][750/1251]	eta 0:04:45 lr 0.000037	time 0.5511 (0.5702)	loss 3.2272 (2.6191)	grad_norm 2.3270 (2.7621)	mem 17417MB
[2023-02-02 19:35:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][800/1251]	eta 0:04:17 lr 0.000036	time 0.5557 (0.5702)	loss 3.1646 (2.6160)	grad_norm 2.9027 (2.7627)	mem 17417MB
[2023-02-02 19:36:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][850/1251]	eta 0:03:48 lr 0.000036	time 0.5558 (0.5703)	loss 3.0027 (2.6122)	grad_norm 2.8257 (2.7621)	mem 17417MB
[2023-02-02 19:36:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][900/1251]	eta 0:03:20 lr 0.000036	time 0.5597 (0.5701)	loss 2.6109 (2.6119)	grad_norm 2.5007 (2.7606)	mem 17417MB
[2023-02-02 19:37:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][950/1251]	eta 0:02:51 lr 0.000036	time 0.5568 (0.5701)	loss 2.1247 (2.6069)	grad_norm 2.4945 (2.7610)	mem 17417MB
[2023-02-02 19:37:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][1000/1251]	eta 0:02:23 lr 0.000036	time 0.6263 (0.5702)	loss 2.2581 (2.6043)	grad_norm 3.0243 (2.7615)	mem 17417MB
[2023-02-02 19:38:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][1050/1251]	eta 0:01:54 lr 0.000036	time 0.5538 (0.5701)	loss 2.7896 (2.6042)	grad_norm 2.3825 (2.7624)	mem 17417MB
[2023-02-02 19:38:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][1100/1251]	eta 0:01:26 lr 0.000036	time 0.6319 (0.5702)	loss 3.1280 (2.6037)	grad_norm 2.4395 (2.7605)	mem 17417MB
[2023-02-02 19:39:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][1150/1251]	eta 0:00:57 lr 0.000036	time 0.5641 (0.5701)	loss 3.0561 (2.6068)	grad_norm 2.5022 (2.7575)	mem 17417MB
[2023-02-02 19:39:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][1200/1251]	eta 0:00:29 lr 0.000036	time 0.6227 (0.5702)	loss 2.7773 (2.6020)	grad_norm 2.6786 (2.7546)	mem 17417MB
[2023-02-02 19:40:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [268/300][1250/1251]	eta 0:00:00 lr 0.000036	time 0.5506 (0.5700)	loss 2.4778 (2.6028)	grad_norm 3.1063 (2.7559)	mem 17417MB
[2023-02-02 19:40:02 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 268 training takes 0:11:53
[2023-02-02 19:40:02 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_268.pth saving......
[2023-02-02 19:40:04 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_268.pth saved !!!
[2023-02-02 19:40:05 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.867 (0.867)	Loss 0.7007 (0.7007)	Acc@1 82.617 (82.617)	Acc@5 96.973 (96.973)	Mem 17417MB
[2023-02-02 19:40:13 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.822 Acc@5 96.644
[2023-02-02 19:40:13 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.8%
[2023-02-02 19:40:14 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.243 (1.243)	Loss 0.6894 (0.6894)	Acc@1 83.594 (83.594)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-02 19:40:22 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 84.082 Acc@5 96.858
[2023-02-02 19:40:22 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.1%
[2023-02-02 19:40:22 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 19:40:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][0/1251]	eta 0:35:10 lr 0.000036	time 1.6870 (1.6870)	loss 2.8461 (2.8461)	grad_norm 2.8443 (2.8443)	mem 17417MB
[2023-02-02 19:40:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][50/1251]	eta 0:11:47 lr 0.000036	time 0.5657 (0.5891)	loss 2.7466 (2.6215)	grad_norm 2.5606 (2.6811)	mem 17417MB
[2023-02-02 19:41:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][100/1251]	eta 0:11:06 lr 0.000036	time 0.5553 (0.5794)	loss 3.1817 (2.6155)	grad_norm 2.8448 (2.7177)	mem 17417MB
[2023-02-02 19:41:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][150/1251]	eta 0:10:34 lr 0.000036	time 0.5530 (0.5761)	loss 2.0805 (2.6253)	grad_norm 2.3161 (2.7164)	mem 17417MB
[2023-02-02 19:42:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][200/1251]	eta 0:10:03 lr 0.000036	time 0.5490 (0.5741)	loss 2.4543 (2.6203)	grad_norm 2.4847 (2.7020)	mem 17417MB
[2023-02-02 19:42:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][250/1251]	eta 0:09:33 lr 0.000036	time 0.5554 (0.5732)	loss 2.2822 (2.6255)	grad_norm 2.8736 (2.7215)	mem 17417MB
[2023-02-02 19:43:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][300/1251]	eta 0:09:04 lr 0.000035	time 0.5570 (0.5729)	loss 2.9889 (2.5965)	grad_norm 3.2257 (2.7358)	mem 17417MB
[2023-02-02 19:43:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][350/1251]	eta 0:08:35 lr 0.000035	time 0.5821 (0.5720)	loss 3.0434 (2.5845)	grad_norm 2.5901 (2.7200)	mem 17417MB
[2023-02-02 19:44:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][400/1251]	eta 0:08:06 lr 0.000035	time 0.5484 (0.5720)	loss 1.8962 (2.5804)	grad_norm 2.9166 (2.7090)	mem 17417MB
[2023-02-02 19:44:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][450/1251]	eta 0:07:37 lr 0.000035	time 0.5558 (0.5715)	loss 1.9235 (2.5843)	grad_norm 3.5676 (2.7049)	mem 17417MB
[2023-02-02 19:45:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][500/1251]	eta 0:07:08 lr 0.000035	time 0.5474 (0.5712)	loss 2.7140 (2.5874)	grad_norm 3.1818 (2.7038)	mem 17417MB
[2023-02-02 19:45:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][550/1251]	eta 0:06:40 lr 0.000035	time 0.5692 (0.5712)	loss 3.4165 (2.5892)	grad_norm 2.8510 (2.7039)	mem 17417MB
[2023-02-02 19:46:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][600/1251]	eta 0:06:11 lr 0.000035	time 0.5497 (0.5709)	loss 2.6382 (2.5920)	grad_norm 2.2528 (2.7026)	mem 17417MB
[2023-02-02 19:46:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][650/1251]	eta 0:05:42 lr 0.000035	time 0.5572 (0.5706)	loss 2.3907 (2.5975)	grad_norm 3.1216 (2.7054)	mem 17417MB
[2023-02-02 19:47:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][700/1251]	eta 0:05:14 lr 0.000035	time 0.5546 (0.5706)	loss 2.6275 (2.6023)	grad_norm 3.0404 (2.7053)	mem 17417MB
[2023-02-02 19:47:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][750/1251]	eta 0:04:45 lr 0.000035	time 0.5581 (0.5702)	loss 2.5598 (2.6081)	grad_norm 2.4148 (2.7109)	mem 17417MB
[2023-02-02 19:47:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][800/1251]	eta 0:04:17 lr 0.000035	time 0.5567 (0.5703)	loss 2.1378 (2.6055)	grad_norm 2.4604 (2.7123)	mem 17417MB
[2023-02-02 19:48:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][850/1251]	eta 0:03:48 lr 0.000035	time 0.5633 (0.5699)	loss 2.5850 (2.6055)	grad_norm 2.8013 (2.7116)	mem 17417MB
[2023-02-02 19:48:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][900/1251]	eta 0:03:20 lr 0.000035	time 0.6213 (0.5698)	loss 2.0135 (2.6038)	grad_norm 2.6189 (2.7105)	mem 17417MB
[2023-02-02 19:49:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][950/1251]	eta 0:02:51 lr 0.000035	time 0.5523 (0.5698)	loss 2.7972 (2.6072)	grad_norm 2.5748 (2.7143)	mem 17417MB
[2023-02-02 19:49:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][1000/1251]	eta 0:02:22 lr 0.000035	time 0.5540 (0.5697)	loss 2.4573 (2.6020)	grad_norm 3.7150 (2.7155)	mem 17417MB
[2023-02-02 19:50:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][1050/1251]	eta 0:01:54 lr 0.000034	time 0.5468 (0.5698)	loss 1.9504 (2.6002)	grad_norm 2.4257 (2.7160)	mem 17417MB
[2023-02-02 19:50:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][1100/1251]	eta 0:01:26 lr 0.000034	time 0.6316 (0.5697)	loss 2.3732 (2.6040)	grad_norm 2.4687 (2.7153)	mem 17417MB
[2023-02-02 19:51:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][1150/1251]	eta 0:00:57 lr 0.000034	time 0.5621 (0.5696)	loss 2.8906 (2.6017)	grad_norm 3.2580 (2.7133)	mem 17417MB
[2023-02-02 19:51:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][1200/1251]	eta 0:00:29 lr 0.000034	time 0.5576 (0.5697)	loss 2.9641 (2.6035)	grad_norm 2.6078 (2.7124)	mem 17417MB
[2023-02-02 19:52:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [269/300][1250/1251]	eta 0:00:00 lr 0.000034	time 0.5494 (0.5698)	loss 2.8608 (2.6046)	grad_norm 2.8591 (2.7105)	mem 17417MB
[2023-02-02 19:52:15 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 269 training takes 0:11:52
[2023-02-02 19:52:15 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_269.pth saving......
[2023-02-02 19:52:17 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_269.pth saved !!!
[2023-02-02 19:52:18 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.844 (0.844)	Loss 0.6884 (0.6884)	Acc@1 84.570 (84.570)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-02 19:52:26 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.842 Acc@5 96.618
[2023-02-02 19:52:26 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.8%
[2023-02-02 19:52:27 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.187 (1.187)	Loss 0.6153 (0.6153)	Acc@1 86.328 (86.328)	Acc@5 97.266 (97.266)	Mem 17417MB
[2023-02-02 19:52:35 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 84.070 Acc@5 96.842
[2023-02-02 19:52:35 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.1%
[2023-02-02 19:52:35 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 19:52:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][0/1251]	eta 0:37:26 lr 0.000034	time 1.7960 (1.7960)	loss 2.8502 (2.8502)	grad_norm 3.0210 (3.0210)	mem 17417MB
[2023-02-02 19:53:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][50/1251]	eta 0:11:55 lr 0.000034	time 0.5510 (0.5959)	loss 2.6329 (2.6493)	grad_norm 2.5364 (2.7927)	mem 17417MB
[2023-02-02 19:53:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][100/1251]	eta 0:11:11 lr 0.000034	time 0.5534 (0.5837)	loss 2.9281 (2.6409)	grad_norm 3.1546 (2.7449)	mem 17417MB
[2023-02-02 19:54:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][150/1251]	eta 0:10:35 lr 0.000034	time 0.5484 (0.5775)	loss 2.5190 (2.6176)	grad_norm 2.6857 (2.7247)	mem 17417MB
[2023-02-02 19:54:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][200/1251]	eta 0:10:05 lr 0.000034	time 0.5607 (0.5761)	loss 2.5831 (2.6242)	grad_norm 3.0949 (2.7194)	mem 17417MB
[2023-02-02 19:54:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][250/1251]	eta 0:09:34 lr 0.000034	time 0.5641 (0.5744)	loss 2.6345 (2.6110)	grad_norm 2.9618 (2.7208)	mem 17417MB
[2023-02-02 19:55:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][300/1251]	eta 0:09:05 lr 0.000034	time 0.5548 (0.5734)	loss 2.1477 (2.6103)	grad_norm 2.7924 (nan)	mem 17417MB
[2023-02-02 19:55:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][350/1251]	eta 0:08:36 lr 0.000034	time 0.5531 (0.5731)	loss 2.4429 (2.6075)	grad_norm 2.6797 (nan)	mem 17417MB
[2023-02-02 19:56:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][400/1251]	eta 0:08:07 lr 0.000034	time 0.5516 (0.5723)	loss 2.7465 (2.6190)	grad_norm 2.7049 (nan)	mem 17417MB
[2023-02-02 19:56:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][450/1251]	eta 0:07:38 lr 0.000034	time 0.5584 (0.5721)	loss 2.8556 (2.6205)	grad_norm 2.8123 (nan)	mem 17417MB
[2023-02-02 19:57:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][500/1251]	eta 0:07:09 lr 0.000034	time 0.5513 (0.5720)	loss 2.5146 (2.6062)	grad_norm 2.9179 (nan)	mem 17417MB
[2023-02-02 19:57:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][550/1251]	eta 0:06:40 lr 0.000034	time 0.5498 (0.5711)	loss 2.7419 (2.5930)	grad_norm 2.3786 (nan)	mem 17417MB
[2023-02-02 19:58:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][600/1251]	eta 0:06:12 lr 0.000033	time 0.5572 (0.5715)	loss 2.8757 (2.6018)	grad_norm 2.8443 (nan)	mem 17417MB
[2023-02-02 19:58:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][650/1251]	eta 0:05:43 lr 0.000033	time 0.5609 (0.5713)	loss 2.7167 (2.6061)	grad_norm 3.2205 (nan)	mem 17417MB
[2023-02-02 19:59:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][700/1251]	eta 0:05:14 lr 0.000033	time 0.5535 (0.5710)	loss 2.3004 (2.6014)	grad_norm 2.4258 (nan)	mem 17417MB
[2023-02-02 19:59:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][750/1251]	eta 0:04:46 lr 0.000033	time 0.5571 (0.5710)	loss 3.2256 (2.6063)	grad_norm 2.8628 (nan)	mem 17417MB
[2023-02-02 20:00:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][800/1251]	eta 0:04:17 lr 0.000033	time 0.5600 (0.5707)	loss 2.5438 (2.6080)	grad_norm 2.5769 (nan)	mem 17417MB
[2023-02-02 20:00:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][850/1251]	eta 0:03:48 lr 0.000033	time 0.5509 (0.5708)	loss 2.0783 (2.6096)	grad_norm 2.5080 (nan)	mem 17417MB
[2023-02-02 20:01:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][900/1251]	eta 0:03:20 lr 0.000033	time 0.5586 (0.5707)	loss 2.4405 (2.6083)	grad_norm 2.8342 (nan)	mem 17417MB
[2023-02-02 20:01:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][950/1251]	eta 0:02:51 lr 0.000033	time 0.5597 (0.5706)	loss 2.4046 (2.6116)	grad_norm 2.6267 (nan)	mem 17417MB
[2023-02-02 20:02:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][1000/1251]	eta 0:02:23 lr 0.000033	time 0.5569 (0.5706)	loss 1.6180 (2.6059)	grad_norm 2.5096 (nan)	mem 17417MB
[2023-02-02 20:02:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][1050/1251]	eta 0:01:54 lr 0.000033	time 0.5567 (0.5705)	loss 3.1563 (2.6068)	grad_norm 2.8692 (nan)	mem 17417MB
[2023-02-02 20:03:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][1100/1251]	eta 0:01:26 lr 0.000033	time 0.6260 (0.5702)	loss 2.4555 (2.6078)	grad_norm 2.2466 (nan)	mem 17417MB
[2023-02-02 20:03:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][1150/1251]	eta 0:00:57 lr 0.000033	time 0.6236 (0.5704)	loss 1.9021 (2.6079)	grad_norm 2.6808 (nan)	mem 17417MB
[2023-02-02 20:03:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][1200/1251]	eta 0:00:29 lr 0.000033	time 0.5548 (0.5700)	loss 2.7079 (2.6095)	grad_norm 2.4430 (nan)	mem 17417MB
[2023-02-02 20:04:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [270/300][1250/1251]	eta 0:00:00 lr 0.000033	time 0.5497 (0.5700)	loss 2.7372 (2.6087)	grad_norm 3.8032 (nan)	mem 17417MB
[2023-02-02 20:04:28 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 270 training takes 0:11:53
[2023-02-02 20:04:28 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_270.pth saving......
[2023-02-02 20:04:30 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_270.pth saved !!!
[2023-02-02 20:04:31 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.844 (0.844)	Loss 0.6552 (0.6552)	Acc@1 84.961 (84.961)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-02 20:04:39 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.828 Acc@5 96.706
[2023-02-02 20:04:39 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.8%
[2023-02-02 20:04:40 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.217 (1.217)	Loss 0.7017 (0.7017)	Acc@1 83.398 (83.398)	Acc@5 96.875 (96.875)	Mem 17417MB
[2023-02-02 20:04:48 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 84.072 Acc@5 96.842
[2023-02-02 20:04:48 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.1%
[2023-02-02 20:04:48 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 20:04:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][0/1251]	eta 0:35:13 lr 0.000033	time 1.6895 (1.6895)	loss 3.1209 (3.1209)	grad_norm 2.8722 (2.8722)	mem 17417MB
[2023-02-02 20:05:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][50/1251]	eta 0:11:54 lr 0.000033	time 0.5545 (0.5948)	loss 2.6293 (2.5684)	grad_norm 3.0791 (2.7944)	mem 17417MB
[2023-02-02 20:05:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][100/1251]	eta 0:11:08 lr 0.000033	time 0.5506 (0.5808)	loss 3.0839 (2.6025)	grad_norm 2.6324 (2.7938)	mem 17417MB
[2023-02-02 20:06:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][150/1251]	eta 0:10:35 lr 0.000032	time 0.5555 (0.5773)	loss 2.4572 (2.6170)	grad_norm 2.7359 (2.7824)	mem 17417MB
[2023-02-02 20:06:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][200/1251]	eta 0:10:04 lr 0.000032	time 0.5531 (0.5749)	loss 3.0551 (2.6034)	grad_norm 2.5963 (2.7969)	mem 17417MB
[2023-02-02 20:07:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][250/1251]	eta 0:09:34 lr 0.000032	time 0.5579 (0.5738)	loss 2.8983 (2.6130)	grad_norm 3.0335 (2.7704)	mem 17417MB
[2023-02-02 20:07:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][300/1251]	eta 0:09:05 lr 0.000032	time 0.5590 (0.5731)	loss 2.7623 (2.5977)	grad_norm 2.5193 (2.7650)	mem 17417MB
[2023-02-02 20:08:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][350/1251]	eta 0:08:35 lr 0.000032	time 0.5566 (0.5721)	loss 1.8996 (2.6010)	grad_norm 2.6142 (2.7586)	mem 17417MB
[2023-02-02 20:08:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][400/1251]	eta 0:08:06 lr 0.000032	time 0.5587 (0.5714)	loss 2.1934 (2.5930)	grad_norm 2.9747 (2.7597)	mem 17417MB
[2023-02-02 20:09:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][450/1251]	eta 0:07:37 lr 0.000032	time 0.5711 (0.5713)	loss 2.4267 (2.5984)	grad_norm 2.5655 (2.7605)	mem 17417MB
[2023-02-02 20:09:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][500/1251]	eta 0:07:08 lr 0.000032	time 0.5560 (0.5708)	loss 2.9698 (2.5911)	grad_norm 2.3754 (2.7545)	mem 17417MB
[2023-02-02 20:10:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][550/1251]	eta 0:06:40 lr 0.000032	time 0.5592 (0.5708)	loss 2.3401 (2.5926)	grad_norm 3.5214 (2.7578)	mem 17417MB
[2023-02-02 20:10:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][600/1251]	eta 0:06:11 lr 0.000032	time 0.5641 (0.5709)	loss 2.7926 (2.5990)	grad_norm 3.0667 (2.7537)	mem 17417MB
[2023-02-02 20:10:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][650/1251]	eta 0:05:43 lr 0.000032	time 0.5544 (0.5708)	loss 3.3642 (2.5978)	grad_norm 3.5969 (2.7614)	mem 17417MB
[2023-02-02 20:11:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][700/1251]	eta 0:05:14 lr 0.000032	time 0.5528 (0.5707)	loss 2.3821 (2.6064)	grad_norm 2.5343 (2.7657)	mem 17417MB
[2023-02-02 20:11:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][750/1251]	eta 0:04:45 lr 0.000032	time 0.5565 (0.5704)	loss 2.3322 (2.6034)	grad_norm 2.5713 (2.7644)	mem 17417MB
[2023-02-02 20:12:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][800/1251]	eta 0:04:17 lr 0.000032	time 0.6349 (0.5705)	loss 2.2405 (2.6019)	grad_norm 2.6346 (2.7690)	mem 17417MB
[2023-02-02 20:12:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][850/1251]	eta 0:03:48 lr 0.000032	time 0.6221 (0.5705)	loss 2.3390 (2.6033)	grad_norm 2.2987 (2.7696)	mem 17417MB
[2023-02-02 20:13:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][900/1251]	eta 0:03:20 lr 0.000032	time 0.5541 (0.5704)	loss 3.0955 (2.5987)	grad_norm 2.6332 (2.7687)	mem 17417MB
[2023-02-02 20:13:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][950/1251]	eta 0:02:51 lr 0.000031	time 0.5569 (0.5702)	loss 2.7144 (2.5970)	grad_norm 2.5310 (2.7684)	mem 17417MB
[2023-02-02 20:14:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][1000/1251]	eta 0:02:23 lr 0.000031	time 0.5585 (0.5704)	loss 1.8570 (2.5907)	grad_norm 2.9711 (2.7662)	mem 17417MB
[2023-02-02 20:14:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][1050/1251]	eta 0:01:54 lr 0.000031	time 0.5611 (0.5702)	loss 2.7455 (2.5891)	grad_norm 3.3632 (2.7723)	mem 17417MB
[2023-02-02 20:15:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][1100/1251]	eta 0:01:26 lr 0.000031	time 0.5592 (0.5702)	loss 2.7646 (2.5905)	grad_norm 2.6352 (inf)	mem 17417MB
[2023-02-02 20:15:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][1150/1251]	eta 0:00:57 lr 0.000031	time 0.5458 (0.5701)	loss 2.7015 (2.5873)	grad_norm 2.6316 (inf)	mem 17417MB
[2023-02-02 20:16:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][1200/1251]	eta 0:00:29 lr 0.000031	time 0.5558 (0.5701)	loss 3.0584 (2.5857)	grad_norm 2.7210 (inf)	mem 17417MB
[2023-02-02 20:16:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [271/300][1250/1251]	eta 0:00:00 lr 0.000031	time 0.5490 (0.5701)	loss 2.9703 (2.5844)	grad_norm 2.8269 (inf)	mem 17417MB
[2023-02-02 20:16:41 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 271 training takes 0:11:53
[2023-02-02 20:16:41 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_271.pth saving......
[2023-02-02 20:16:43 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_271.pth saved !!!
[2023-02-02 20:16:44 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.908 (0.908)	Loss 0.6142 (0.6142)	Acc@1 85.547 (85.547)	Acc@5 96.973 (96.973)	Mem 17417MB
[2023-02-02 20:16:52 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.848 Acc@5 96.762
[2023-02-02 20:16:52 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.8%
[2023-02-02 20:16:53 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.380 (1.380)	Loss 0.7496 (0.7496)	Acc@1 82.812 (82.812)	Acc@5 96.582 (96.582)	Mem 17417MB
[2023-02-02 20:17:01 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 84.042 Acc@5 96.830
[2023-02-02 20:17:01 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 20:17:01 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 20:17:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][0/1251]	eta 0:35:08 lr 0.000031	time 1.6856 (1.6856)	loss 2.8318 (2.8318)	grad_norm 2.7302 (2.7302)	mem 17417MB
[2023-02-02 20:17:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][50/1251]	eta 0:11:49 lr 0.000031	time 0.5573 (0.5905)	loss 1.7624 (2.6045)	grad_norm 2.5538 (2.6987)	mem 17417MB
[2023-02-02 20:18:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][100/1251]	eta 0:11:08 lr 0.000031	time 0.6294 (0.5811)	loss 2.7396 (2.5554)	grad_norm 2.5754 (2.7630)	mem 17417MB
[2023-02-02 20:18:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][150/1251]	eta 0:10:35 lr 0.000031	time 0.5596 (0.5771)	loss 2.8025 (2.5695)	grad_norm 2.7950 (2.7637)	mem 17417MB
[2023-02-02 20:18:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][200/1251]	eta 0:10:04 lr 0.000031	time 0.5580 (0.5756)	loss 2.3923 (2.5766)	grad_norm 2.6788 (2.7434)	mem 17417MB
[2023-02-02 20:19:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][250/1251]	eta 0:09:34 lr 0.000031	time 0.5525 (0.5741)	loss 1.8082 (2.5992)	grad_norm 2.4922 (2.7470)	mem 17417MB
[2023-02-02 20:19:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][300/1251]	eta 0:09:05 lr 0.000031	time 0.6436 (0.5733)	loss 3.0606 (2.5956)	grad_norm 2.5032 (2.7569)	mem 17417MB
[2023-02-02 20:20:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][350/1251]	eta 0:08:35 lr 0.000031	time 0.5606 (0.5726)	loss 3.0875 (2.6123)	grad_norm 2.5825 (2.7507)	mem 17417MB
[2023-02-02 20:20:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][400/1251]	eta 0:08:07 lr 0.000031	time 0.5801 (0.5725)	loss 2.8574 (2.6055)	grad_norm 2.8345 (2.7556)	mem 17417MB
[2023-02-02 20:21:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][450/1251]	eta 0:07:38 lr 0.000031	time 0.5602 (0.5719)	loss 2.9911 (2.6062)	grad_norm 3.1735 (2.7505)	mem 17417MB
[2023-02-02 20:21:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][500/1251]	eta 0:07:09 lr 0.000031	time 0.6294 (0.5718)	loss 2.5323 (2.6139)	grad_norm 2.3083 (2.7639)	mem 17417MB
[2023-02-02 20:22:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][550/1251]	eta 0:06:40 lr 0.000030	time 0.5612 (0.5714)	loss 2.4739 (2.6125)	grad_norm 2.5942 (2.7628)	mem 17417MB
[2023-02-02 20:22:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][600/1251]	eta 0:06:11 lr 0.000030	time 0.5709 (0.5712)	loss 1.7860 (2.6098)	grad_norm 2.4596 (2.7679)	mem 17417MB
[2023-02-02 20:23:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][650/1251]	eta 0:05:43 lr 0.000030	time 0.5548 (0.5711)	loss 2.0381 (2.6045)	grad_norm 2.7762 (2.7730)	mem 17417MB
[2023-02-02 20:23:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][700/1251]	eta 0:05:14 lr 0.000030	time 0.5632 (0.5710)	loss 2.4398 (2.6005)	grad_norm 2.6751 (2.7777)	mem 17417MB
[2023-02-02 20:24:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][750/1251]	eta 0:04:45 lr 0.000030	time 0.5609 (0.5708)	loss 1.7685 (2.5983)	grad_norm 2.4280 (nan)	mem 17417MB
[2023-02-02 20:24:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][800/1251]	eta 0:04:17 lr 0.000030	time 0.6241 (0.5707)	loss 3.1000 (2.5923)	grad_norm 2.3519 (nan)	mem 17417MB
[2023-02-02 20:25:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][850/1251]	eta 0:03:48 lr 0.000030	time 0.5587 (0.5704)	loss 2.9838 (2.5879)	grad_norm 2.9429 (nan)	mem 17417MB
[2023-02-02 20:25:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][900/1251]	eta 0:03:20 lr 0.000030	time 0.6100 (0.5705)	loss 2.8389 (2.5863)	grad_norm 2.3892 (nan)	mem 17417MB
[2023-02-02 20:26:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][950/1251]	eta 0:02:51 lr 0.000030	time 0.5560 (0.5704)	loss 2.1155 (2.5884)	grad_norm 3.1942 (nan)	mem 17417MB
[2023-02-02 20:26:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][1000/1251]	eta 0:02:23 lr 0.000030	time 0.5596 (0.5704)	loss 1.7948 (2.5894)	grad_norm 2.7354 (nan)	mem 17417MB
[2023-02-02 20:27:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][1050/1251]	eta 0:01:54 lr 0.000030	time 0.5522 (0.5702)	loss 2.1397 (2.5889)	grad_norm 3.7904 (nan)	mem 17417MB
[2023-02-02 20:27:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][1100/1251]	eta 0:01:26 lr 0.000030	time 0.5705 (0.5701)	loss 1.6828 (2.5911)	grad_norm 2.5895 (nan)	mem 17417MB
[2023-02-02 20:27:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][1150/1251]	eta 0:00:57 lr 0.000030	time 0.5565 (0.5699)	loss 1.9461 (2.5910)	grad_norm 2.3858 (nan)	mem 17417MB
[2023-02-02 20:28:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][1200/1251]	eta 0:00:29 lr 0.000030	time 0.5470 (0.5699)	loss 2.8694 (2.5891)	grad_norm 2.8639 (nan)	mem 17417MB
[2023-02-02 20:28:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [272/300][1250/1251]	eta 0:00:00 lr 0.000030	time 0.5478 (0.5698)	loss 2.1473 (2.5857)	grad_norm 3.4230 (nan)	mem 17417MB
[2023-02-02 20:28:54 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 272 training takes 0:11:52
[2023-02-02 20:28:54 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_272.pth saving......
[2023-02-02 20:28:56 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_272.pth saved !!!
[2023-02-02 20:28:57 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.985 (0.985)	Loss 0.7110 (0.7110)	Acc@1 83.594 (83.594)	Acc@5 95.996 (95.996)	Mem 17417MB
[2023-02-02 20:29:05 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.802 Acc@5 96.760
[2023-02-02 20:29:05 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.8%
[2023-02-02 20:29:06 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.309 (1.309)	Loss 0.7498 (0.7498)	Acc@1 82.910 (82.910)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-02 20:29:14 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 84.030 Acc@5 96.834
[2023-02-02 20:29:14 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 20:29:14 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 20:29:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][0/1251]	eta 0:35:00 lr 0.000030	time 1.6794 (1.6794)	loss 2.7336 (2.7336)	grad_norm 2.5562 (2.5562)	mem 17417MB
[2023-02-02 20:29:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][50/1251]	eta 0:11:54 lr 0.000030	time 0.5563 (0.5953)	loss 2.2848 (2.5796)	grad_norm 2.6245 (2.8587)	mem 17417MB
[2023-02-02 20:30:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][100/1251]	eta 0:11:08 lr 0.000030	time 0.5734 (0.5808)	loss 2.2305 (2.5920)	grad_norm 3.2479 (2.8094)	mem 17417MB
[2023-02-02 20:30:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][150/1251]	eta 0:10:36 lr 0.000029	time 0.5609 (0.5780)	loss 2.3314 (2.5949)	grad_norm 3.0301 (2.7779)	mem 17417MB
[2023-02-02 20:31:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][200/1251]	eta 0:10:04 lr 0.000029	time 0.5581 (0.5755)	loss 3.1413 (2.5751)	grad_norm 2.7736 (2.7707)	mem 17417MB
[2023-02-02 20:31:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][250/1251]	eta 0:09:34 lr 0.000029	time 0.5524 (0.5741)	loss 1.8858 (2.5839)	grad_norm 2.6605 (2.7537)	mem 17417MB
[2023-02-02 20:32:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][300/1251]	eta 0:09:05 lr 0.000029	time 0.7076 (0.5737)	loss 2.9596 (2.5867)	grad_norm 2.6593 (2.7640)	mem 17417MB
[2023-02-02 20:32:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][350/1251]	eta 0:08:35 lr 0.000029	time 0.5513 (0.5727)	loss 2.8628 (2.5919)	grad_norm 2.8240 (2.7706)	mem 17417MB
[2023-02-02 20:33:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][400/1251]	eta 0:08:07 lr 0.000029	time 0.6363 (0.5723)	loss 2.7875 (2.5860)	grad_norm 2.9471 (2.7692)	mem 17417MB
[2023-02-02 20:33:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][450/1251]	eta 0:07:38 lr 0.000029	time 0.6259 (0.5720)	loss 2.9628 (2.5804)	grad_norm 2.7498 (2.7581)	mem 17417MB
[2023-02-02 20:34:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][500/1251]	eta 0:07:08 lr 0.000029	time 0.6300 (0.5712)	loss 2.7326 (2.5862)	grad_norm 2.1966 (2.7558)	mem 17417MB
[2023-02-02 20:34:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][550/1251]	eta 0:06:40 lr 0.000029	time 0.5589 (0.5709)	loss 2.1133 (2.5878)	grad_norm 2.9273 (2.7602)	mem 17417MB
[2023-02-02 20:34:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][600/1251]	eta 0:06:11 lr 0.000029	time 0.5510 (0.5706)	loss 2.9369 (2.5821)	grad_norm 2.6219 (2.7665)	mem 17417MB
[2023-02-02 20:35:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][650/1251]	eta 0:05:42 lr 0.000029	time 0.5495 (0.5705)	loss 2.4699 (2.5827)	grad_norm 2.8932 (2.7662)	mem 17417MB
[2023-02-02 20:35:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][700/1251]	eta 0:05:14 lr 0.000029	time 0.5602 (0.5705)	loss 2.2733 (2.5796)	grad_norm 3.4021 (2.7709)	mem 17417MB
[2023-02-02 20:36:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][750/1251]	eta 0:04:45 lr 0.000029	time 0.6448 (0.5702)	loss 2.9190 (2.5800)	grad_norm 2.6618 (2.7702)	mem 17417MB
[2023-02-02 20:36:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][800/1251]	eta 0:04:17 lr 0.000029	time 0.5456 (0.5699)	loss 3.0719 (2.5731)	grad_norm 2.6302 (2.7724)	mem 17417MB
[2023-02-02 20:37:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][850/1251]	eta 0:03:48 lr 0.000029	time 0.5623 (0.5699)	loss 3.2319 (2.5742)	grad_norm 2.9011 (2.7710)	mem 17417MB
[2023-02-02 20:37:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][900/1251]	eta 0:03:19 lr 0.000029	time 0.5507 (0.5698)	loss 2.3762 (2.5811)	grad_norm 2.6986 (2.7757)	mem 17417MB
[2023-02-02 20:38:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][950/1251]	eta 0:02:51 lr 0.000029	time 0.5524 (0.5698)	loss 2.6512 (2.5837)	grad_norm 3.3056 (2.7740)	mem 17417MB
[2023-02-02 20:38:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][1000/1251]	eta 0:02:22 lr 0.000029	time 0.5529 (0.5695)	loss 2.6390 (2.5834)	grad_norm 3.1764 (2.7761)	mem 17417MB
[2023-02-02 20:39:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][1050/1251]	eta 0:01:54 lr 0.000028	time 0.5508 (0.5695)	loss 2.5898 (2.5832)	grad_norm 2.9264 (2.7759)	mem 17417MB
[2023-02-02 20:39:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][1100/1251]	eta 0:01:25 lr 0.000028	time 0.6309 (0.5695)	loss 2.8074 (2.5855)	grad_norm 2.5043 (2.7787)	mem 17417MB
[2023-02-02 20:40:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][1150/1251]	eta 0:00:57 lr 0.000028	time 0.5544 (0.5694)	loss 2.4745 (2.5810)	grad_norm 2.7192 (2.7822)	mem 17417MB
[2023-02-02 20:40:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][1200/1251]	eta 0:00:29 lr 0.000028	time 0.5550 (0.5693)	loss 2.9235 (2.5830)	grad_norm 3.1855 (2.7828)	mem 17417MB
[2023-02-02 20:41:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [273/300][1250/1251]	eta 0:00:00 lr 0.000028	time 0.6101 (0.5695)	loss 2.9994 (2.5851)	grad_norm 2.5154 (2.7822)	mem 17417MB
[2023-02-02 20:41:07 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 273 training takes 0:11:52
[2023-02-02 20:41:07 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_273.pth saving......
[2023-02-02 20:41:09 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_273.pth saved !!!
[2023-02-02 20:41:09 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.870 (0.870)	Loss 0.6666 (0.6666)	Acc@1 83.496 (83.496)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 20:41:17 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.838 Acc@5 96.734
[2023-02-02 20:41:17 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.8%
[2023-02-02 20:41:19 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.289 (1.289)	Loss 0.6811 (0.6811)	Acc@1 83.398 (83.398)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-02 20:41:27 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 84.042 Acc@5 96.808
[2023-02-02 20:41:27 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 20:41:27 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 20:41:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][0/1251]	eta 0:35:30 lr 0.000028	time 1.7032 (1.7032)	loss 2.7644 (2.7644)	grad_norm 2.3970 (2.3970)	mem 17417MB
[2023-02-02 20:41:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][50/1251]	eta 0:11:55 lr 0.000028	time 0.5565 (0.5958)	loss 2.8607 (2.5441)	grad_norm 2.5891 (2.7545)	mem 17417MB
[2023-02-02 20:42:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][100/1251]	eta 0:11:10 lr 0.000028	time 0.5476 (0.5821)	loss 2.8720 (2.5534)	grad_norm 2.5199 (2.8037)	mem 17417MB
[2023-02-02 20:42:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][150/1251]	eta 0:10:35 lr 0.000028	time 0.5594 (0.5770)	loss 2.8578 (2.5251)	grad_norm 2.8256 (2.7959)	mem 17417MB
[2023-02-02 20:43:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][200/1251]	eta 0:10:04 lr 0.000028	time 0.6461 (0.5753)	loss 2.4329 (2.5242)	grad_norm 2.5114 (2.7921)	mem 17417MB
[2023-02-02 20:43:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][250/1251]	eta 0:09:34 lr 0.000028	time 0.5583 (0.5735)	loss 2.9597 (2.5571)	grad_norm 2.5505 (2.7954)	mem 17417MB
[2023-02-02 20:44:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][300/1251]	eta 0:09:05 lr 0.000028	time 0.5462 (0.5734)	loss 2.9284 (2.5559)	grad_norm 3.1675 (2.7990)	mem 17417MB
[2023-02-02 20:44:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][350/1251]	eta 0:08:35 lr 0.000028	time 0.5594 (0.5722)	loss 2.9546 (2.5709)	grad_norm 2.9757 (2.7897)	mem 17417MB
[2023-02-02 20:45:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][400/1251]	eta 0:08:06 lr 0.000028	time 0.5536 (0.5718)	loss 2.7638 (2.5801)	grad_norm 2.8340 (2.7953)	mem 17417MB
[2023-02-02 20:45:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][450/1251]	eta 0:07:37 lr 0.000028	time 0.5468 (0.5715)	loss 1.7402 (2.5870)	grad_norm 2.7786 (2.8058)	mem 17417MB
[2023-02-02 20:46:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][500/1251]	eta 0:07:08 lr 0.000028	time 0.5566 (0.5712)	loss 2.1486 (2.5907)	grad_norm 2.6641 (2.8004)	mem 17417MB
[2023-02-02 20:46:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][550/1251]	eta 0:06:40 lr 0.000028	time 0.5450 (0.5710)	loss 1.8920 (2.5967)	grad_norm 2.4072 (2.7937)	mem 17417MB
[2023-02-02 20:47:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][600/1251]	eta 0:06:11 lr 0.000028	time 0.6423 (0.5711)	loss 2.6412 (2.5925)	grad_norm 3.0457 (2.7952)	mem 17417MB
[2023-02-02 20:47:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][650/1251]	eta 0:05:43 lr 0.000028	time 0.5560 (0.5708)	loss 2.5943 (2.5903)	grad_norm 2.7766 (2.8028)	mem 17417MB
[2023-02-02 20:48:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][700/1251]	eta 0:05:14 lr 0.000027	time 0.5569 (0.5706)	loss 3.0422 (2.5879)	grad_norm 2.5761 (2.8014)	mem 17417MB
[2023-02-02 20:48:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][750/1251]	eta 0:04:45 lr 0.000027	time 0.5534 (0.5704)	loss 3.0390 (2.5926)	grad_norm 2.4339 (2.8016)	mem 17417MB
[2023-02-02 20:49:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][800/1251]	eta 0:04:17 lr 0.000027	time 0.6312 (0.5705)	loss 2.8285 (2.5972)	grad_norm 2.7214 (2.8052)	mem 17417MB
[2023-02-02 20:49:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][850/1251]	eta 0:03:48 lr 0.000027	time 0.5474 (0.5705)	loss 2.1669 (2.6014)	grad_norm 2.4011 (2.8069)	mem 17417MB
[2023-02-02 20:50:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][900/1251]	eta 0:03:20 lr 0.000027	time 0.5554 (0.5704)	loss 2.2887 (2.6008)	grad_norm 2.6121 (2.8078)	mem 17417MB
[2023-02-02 20:50:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][950/1251]	eta 0:02:51 lr 0.000027	time 0.5546 (0.5703)	loss 2.7612 (2.6008)	grad_norm 3.0368 (2.8076)	mem 17417MB
[2023-02-02 20:50:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][1000/1251]	eta 0:02:23 lr 0.000027	time 0.6486 (0.5703)	loss 2.5302 (2.6007)	grad_norm 2.7733 (2.8114)	mem 17417MB
[2023-02-02 20:51:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][1050/1251]	eta 0:01:54 lr 0.000027	time 0.5549 (0.5702)	loss 3.2756 (2.6024)	grad_norm 2.8043 (2.8134)	mem 17417MB
[2023-02-02 20:51:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][1100/1251]	eta 0:01:26 lr 0.000027	time 0.5567 (0.5701)	loss 1.6505 (2.5958)	grad_norm 2.6424 (2.8124)	mem 17417MB
[2023-02-02 20:52:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][1150/1251]	eta 0:00:57 lr 0.000027	time 0.5554 (0.5701)	loss 1.4380 (2.5917)	grad_norm 3.1315 (2.8147)	mem 17417MB
[2023-02-02 20:52:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][1200/1251]	eta 0:00:29 lr 0.000027	time 0.6398 (0.5700)	loss 2.8993 (2.5907)	grad_norm 2.5019 (2.8163)	mem 17417MB
[2023-02-02 20:53:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [274/300][1250/1251]	eta 0:00:00 lr 0.000027	time 0.5560 (0.5699)	loss 2.5036 (2.5928)	grad_norm 2.6752 (2.8152)	mem 17417MB
[2023-02-02 20:53:20 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 274 training takes 0:11:53
[2023-02-02 20:53:20 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_274.pth saving......
[2023-02-02 20:53:22 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_274.pth saved !!!
[2023-02-02 20:53:23 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.885 (0.885)	Loss 0.6722 (0.6722)	Acc@1 84.082 (84.082)	Acc@5 96.973 (96.973)	Mem 17417MB
[2023-02-02 20:53:31 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.870 Acc@5 96.746
[2023-02-02 20:53:31 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-02 20:53:32 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.258 (1.258)	Loss 0.7577 (0.7577)	Acc@1 83.594 (83.594)	Acc@5 95.605 (95.605)	Mem 17417MB
[2023-02-02 20:53:40 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 84.028 Acc@5 96.802
[2023-02-02 20:53:40 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 20:53:40 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 20:53:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][0/1251]	eta 0:35:53 lr 0.000027	time 1.7217 (1.7217)	loss 2.5893 (2.5893)	grad_norm 3.5503 (3.5503)	mem 17417MB
[2023-02-02 20:54:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][50/1251]	eta 0:11:53 lr 0.000027	time 0.6282 (0.5941)	loss 2.7126 (2.6614)	grad_norm 2.5160 (2.8727)	mem 17417MB
[2023-02-02 20:54:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][100/1251]	eta 0:11:10 lr 0.000027	time 0.5492 (0.5824)	loss 2.5990 (2.6381)	grad_norm 2.6062 (2.8803)	mem 17417MB
[2023-02-02 20:55:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][150/1251]	eta 0:10:35 lr 0.000027	time 0.5567 (0.5769)	loss 2.7508 (2.6008)	grad_norm 3.0346 (2.8423)	mem 17417MB
[2023-02-02 20:55:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][200/1251]	eta 0:10:03 lr 0.000027	time 0.5586 (0.5746)	loss 2.6418 (2.5890)	grad_norm 2.9371 (2.8305)	mem 17417MB
[2023-02-02 20:56:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][250/1251]	eta 0:09:33 lr 0.000027	time 0.5673 (0.5730)	loss 2.8902 (2.5858)	grad_norm 3.1657 (2.8318)	mem 17417MB
[2023-02-02 20:56:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][300/1251]	eta 0:09:04 lr 0.000027	time 0.5510 (0.5727)	loss 2.6258 (2.5738)	grad_norm 2.8854 (2.8383)	mem 17417MB
[2023-02-02 20:57:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][350/1251]	eta 0:08:34 lr 0.000026	time 0.5544 (0.5715)	loss 2.2896 (2.5657)	grad_norm 2.6477 (2.8328)	mem 17417MB
[2023-02-02 20:57:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][400/1251]	eta 0:08:06 lr 0.000026	time 0.5630 (0.5717)	loss 2.6663 (2.5736)	grad_norm 2.3441 (2.8212)	mem 17417MB
[2023-02-02 20:57:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][450/1251]	eta 0:07:37 lr 0.000026	time 0.6221 (0.5711)	loss 3.5156 (2.5774)	grad_norm 2.8001 (2.8259)	mem 17417MB
[2023-02-02 20:58:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][500/1251]	eta 0:07:08 lr 0.000026	time 0.5609 (0.5709)	loss 1.9123 (2.5671)	grad_norm 3.0101 (2.8216)	mem 17417MB
[2023-02-02 20:58:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][550/1251]	eta 0:06:40 lr 0.000026	time 0.5604 (0.5707)	loss 2.8532 (2.5727)	grad_norm 2.4824 (2.8248)	mem 17417MB
[2023-02-02 20:59:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][600/1251]	eta 0:06:11 lr 0.000026	time 0.5499 (0.5709)	loss 2.4171 (2.5732)	grad_norm 2.6292 (2.8202)	mem 17417MB
[2023-02-02 20:59:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][650/1251]	eta 0:05:42 lr 0.000026	time 0.5536 (0.5705)	loss 2.8102 (2.5704)	grad_norm 2.5322 (2.8176)	mem 17417MB
[2023-02-02 21:00:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][700/1251]	eta 0:05:14 lr 0.000026	time 0.5574 (0.5706)	loss 1.5725 (2.5667)	grad_norm 2.6992 (2.8143)	mem 17417MB
[2023-02-02 21:00:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][750/1251]	eta 0:04:45 lr 0.000026	time 0.6185 (0.5704)	loss 1.9615 (2.5734)	grad_norm 2.5808 (2.8131)	mem 17417MB
[2023-02-02 21:01:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][800/1251]	eta 0:04:17 lr 0.000026	time 0.5557 (0.5705)	loss 1.7735 (2.5768)	grad_norm 2.9098 (2.8123)	mem 17417MB
[2023-02-02 21:01:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][850/1251]	eta 0:03:48 lr 0.000026	time 0.5488 (0.5703)	loss 2.7140 (2.5796)	grad_norm 3.8494 (2.8168)	mem 17417MB
[2023-02-02 21:02:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][900/1251]	eta 0:03:20 lr 0.000026	time 0.5639 (0.5703)	loss 2.8463 (2.5798)	grad_norm 3.0000 (2.8155)	mem 17417MB
[2023-02-02 21:02:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][950/1251]	eta 0:02:51 lr 0.000026	time 0.5514 (0.5701)	loss 1.9102 (2.5828)	grad_norm 2.4298 (2.8160)	mem 17417MB
[2023-02-02 21:03:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][1000/1251]	eta 0:02:23 lr 0.000026	time 0.5554 (0.5701)	loss 2.5555 (2.5823)	grad_norm 2.5716 (2.8166)	mem 17417MB
[2023-02-02 21:03:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][1050/1251]	eta 0:01:54 lr 0.000026	time 0.5554 (0.5700)	loss 2.3861 (2.5830)	grad_norm 2.6038 (2.8193)	mem 17417MB
[2023-02-02 21:04:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][1100/1251]	eta 0:01:26 lr 0.000026	time 0.5617 (0.5699)	loss 2.6952 (2.5887)	grad_norm 2.7761 (inf)	mem 17417MB
[2023-02-02 21:04:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][1150/1251]	eta 0:00:57 lr 0.000026	time 0.5575 (0.5699)	loss 1.9463 (2.5884)	grad_norm 2.7133 (inf)	mem 17417MB
[2023-02-02 21:05:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][1200/1251]	eta 0:00:29 lr 0.000026	time 0.5549 (0.5700)	loss 2.2828 (2.5914)	grad_norm 2.3524 (inf)	mem 17417MB
[2023-02-02 21:05:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [275/300][1250/1251]	eta 0:00:00 lr 0.000026	time 0.5500 (0.5699)	loss 2.7952 (2.5872)	grad_norm 3.0153 (inf)	mem 17417MB
[2023-02-02 21:05:33 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 275 training takes 0:11:53
[2023-02-02 21:05:33 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_275.pth saving......
[2023-02-02 21:05:35 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_275.pth saved !!!
[2023-02-02 21:05:36 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.907 (0.907)	Loss 0.7659 (0.7659)	Acc@1 82.520 (82.520)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-02 21:05:44 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.828 Acc@5 96.714
[2023-02-02 21:05:44 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.8%
[2023-02-02 21:05:45 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.234 (1.234)	Loss 0.6998 (0.6998)	Acc@1 83.594 (83.594)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-02 21:05:53 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 84.008 Acc@5 96.798
[2023-02-02 21:05:53 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 21:05:53 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 21:05:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][0/1251]	eta 0:35:58 lr 0.000026	time 1.7251 (1.7251)	loss 3.0931 (3.0931)	grad_norm 2.4589 (2.4589)	mem 17417MB
[2023-02-02 21:06:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][50/1251]	eta 0:11:54 lr 0.000025	time 0.6372 (0.5950)	loss 2.8964 (2.6037)	grad_norm 2.4944 (2.7646)	mem 17417MB
[2023-02-02 21:06:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][100/1251]	eta 0:11:11 lr 0.000025	time 0.6399 (0.5832)	loss 3.1747 (2.5884)	grad_norm 2.5692 (2.7691)	mem 17417MB
[2023-02-02 21:07:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][150/1251]	eta 0:10:36 lr 0.000025	time 0.5518 (0.5781)	loss 1.9355 (2.5812)	grad_norm 3.5869 (2.7915)	mem 17417MB
[2023-02-02 21:07:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][200/1251]	eta 0:10:04 lr 0.000025	time 0.5740 (0.5756)	loss 3.3279 (2.5991)	grad_norm 2.4122 (2.8058)	mem 17417MB
[2023-02-02 21:08:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][250/1251]	eta 0:09:34 lr 0.000025	time 0.6317 (0.5743)	loss 1.9941 (2.6065)	grad_norm 3.0138 (2.7961)	mem 17417MB
[2023-02-02 21:08:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][300/1251]	eta 0:09:05 lr 0.000025	time 0.5508 (0.5732)	loss 2.6720 (2.5916)	grad_norm 2.9198 (2.8085)	mem 17417MB
[2023-02-02 21:09:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][350/1251]	eta 0:08:36 lr 0.000025	time 0.5528 (0.5729)	loss 2.9086 (2.6136)	grad_norm 2.9128 (2.8142)	mem 17417MB
[2023-02-02 21:09:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][400/1251]	eta 0:08:07 lr 0.000025	time 0.5526 (0.5725)	loss 2.8592 (2.6032)	grad_norm 2.7678 (2.8292)	mem 17417MB
[2023-02-02 21:10:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][450/1251]	eta 0:07:38 lr 0.000025	time 0.5546 (0.5724)	loss 2.7564 (2.6083)	grad_norm 2.5348 (2.8260)	mem 17417MB
[2023-02-02 21:10:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][500/1251]	eta 0:07:09 lr 0.000025	time 0.5514 (0.5719)	loss 2.5269 (2.6017)	grad_norm 2.8343 (2.8286)	mem 17417MB
[2023-02-02 21:11:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][550/1251]	eta 0:06:40 lr 0.000025	time 0.5588 (0.5716)	loss 2.4802 (2.6001)	grad_norm 2.9101 (2.8233)	mem 17417MB
[2023-02-02 21:11:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][600/1251]	eta 0:06:12 lr 0.000025	time 0.5599 (0.5716)	loss 2.7582 (2.6038)	grad_norm 2.9293 (2.8296)	mem 17417MB
[2023-02-02 21:12:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][650/1251]	eta 0:05:43 lr 0.000025	time 0.5610 (0.5714)	loss 2.8770 (2.5963)	grad_norm 2.9371 (2.8315)	mem 17417MB
[2023-02-02 21:12:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][700/1251]	eta 0:05:14 lr 0.000025	time 0.5525 (0.5715)	loss 1.9619 (2.5981)	grad_norm 2.7051 (2.8292)	mem 17417MB
[2023-02-02 21:13:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][750/1251]	eta 0:04:46 lr 0.000025	time 0.5578 (0.5713)	loss 2.6640 (2.6025)	grad_norm 2.6003 (2.8284)	mem 17417MB
[2023-02-02 21:13:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][800/1251]	eta 0:04:17 lr 0.000025	time 0.5495 (0.5714)	loss 1.7412 (2.6037)	grad_norm 2.9108 (2.8341)	mem 17417MB
[2023-02-02 21:13:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][850/1251]	eta 0:03:49 lr 0.000025	time 0.5573 (0.5712)	loss 2.9040 (2.6033)	grad_norm 3.3592 (2.8383)	mem 17417MB
[2023-02-02 21:14:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][900/1251]	eta 0:03:20 lr 0.000025	time 0.5533 (0.5713)	loss 2.9402 (2.6073)	grad_norm 2.7543 (2.8339)	mem 17417MB
[2023-02-02 21:14:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][950/1251]	eta 0:02:51 lr 0.000025	time 0.5537 (0.5710)	loss 2.8587 (2.6024)	grad_norm 2.8946 (inf)	mem 17417MB
[2023-02-02 21:15:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][1000/1251]	eta 0:02:23 lr 0.000025	time 0.5631 (0.5711)	loss 1.6897 (2.6024)	grad_norm 2.6468 (inf)	mem 17417MB
[2023-02-02 21:15:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][1050/1251]	eta 0:01:54 lr 0.000024	time 0.5528 (0.5709)	loss 3.2236 (2.6027)	grad_norm 2.7899 (inf)	mem 17417MB
[2023-02-02 21:16:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][1100/1251]	eta 0:01:26 lr 0.000024	time 0.6201 (0.5709)	loss 2.8490 (2.6048)	grad_norm 3.2676 (inf)	mem 17417MB
[2023-02-02 21:16:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][1150/1251]	eta 0:00:57 lr 0.000024	time 0.5558 (0.5708)	loss 2.5050 (2.6042)	grad_norm 2.4619 (inf)	mem 17417MB
[2023-02-02 21:17:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][1200/1251]	eta 0:00:29 lr 0.000024	time 0.5614 (0.5707)	loss 2.6973 (2.6022)	grad_norm 3.1997 (inf)	mem 17417MB
[2023-02-02 21:17:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [276/300][1250/1251]	eta 0:00:00 lr 0.000024	time 0.5484 (0.5707)	loss 1.8623 (2.6003)	grad_norm 2.5462 (inf)	mem 17417MB
[2023-02-02 21:17:47 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 276 training takes 0:11:54
[2023-02-02 21:17:47 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_276.pth saving......
[2023-02-02 21:17:49 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_276.pth saved !!!
[2023-02-02 21:17:50 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.935 (0.935)	Loss 0.7024 (0.7024)	Acc@1 84.082 (84.082)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-02 21:17:58 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.946 Acc@5 96.720
[2023-02-02 21:17:58 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-02 21:17:59 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.531 (1.531)	Loss 0.6923 (0.6923)	Acc@1 83.789 (83.789)	Acc@5 97.461 (97.461)	Mem 17417MB
[2023-02-02 21:18:07 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 84.000 Acc@5 96.802
[2023-02-02 21:18:07 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 21:18:07 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 21:18:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][0/1251]	eta 0:36:27 lr 0.000024	time 1.7486 (1.7486)	loss 2.1179 (2.1179)	grad_norm 2.3293 (2.3293)	mem 17417MB
[2023-02-02 21:18:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][50/1251]	eta 0:11:54 lr 0.000024	time 0.5599 (0.5952)	loss 2.7703 (2.5328)	grad_norm 3.3248 (2.9194)	mem 17417MB
[2023-02-02 21:19:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][100/1251]	eta 0:11:09 lr 0.000024	time 0.6249 (0.5821)	loss 2.7273 (2.5804)	grad_norm 3.1056 (2.8415)	mem 17417MB
[2023-02-02 21:19:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][150/1251]	eta 0:10:36 lr 0.000024	time 0.5557 (0.5781)	loss 1.9801 (2.5748)	grad_norm 2.7819 (2.8194)	mem 17417MB
[2023-02-02 21:20:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][200/1251]	eta 0:10:04 lr 0.000024	time 0.5555 (0.5748)	loss 1.7646 (2.5494)	grad_norm 3.2404 (2.8292)	mem 17417MB
[2023-02-02 21:20:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][250/1251]	eta 0:09:34 lr 0.000024	time 0.5526 (0.5735)	loss 2.6207 (2.5638)	grad_norm 2.8638 (2.8328)	mem 17417MB
[2023-02-02 21:21:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][300/1251]	eta 0:09:04 lr 0.000024	time 0.5543 (0.5729)	loss 2.4873 (2.5651)	grad_norm 2.8082 (2.8253)	mem 17417MB
[2023-02-02 21:21:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][350/1251]	eta 0:08:35 lr 0.000024	time 0.5524 (0.5722)	loss 2.7427 (2.5739)	grad_norm 2.9730 (2.8264)	mem 17417MB
[2023-02-02 21:21:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][400/1251]	eta 0:08:06 lr 0.000024	time 0.5628 (0.5718)	loss 2.8900 (2.5827)	grad_norm 2.6285 (2.8217)	mem 17417MB
[2023-02-02 21:22:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][450/1251]	eta 0:07:37 lr 0.000024	time 0.5500 (0.5711)	loss 2.8132 (2.5798)	grad_norm 2.7149 (2.8188)	mem 17417MB
[2023-02-02 21:22:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][500/1251]	eta 0:07:08 lr 0.000024	time 0.5525 (0.5708)	loss 2.2011 (2.5870)	grad_norm 2.4554 (2.8208)	mem 17417MB
[2023-02-02 21:23:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][550/1251]	eta 0:06:39 lr 0.000024	time 0.5541 (0.5706)	loss 2.5882 (2.5857)	grad_norm 2.8544 (2.8186)	mem 17417MB
[2023-02-02 21:23:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][600/1251]	eta 0:06:11 lr 0.000024	time 0.5511 (0.5705)	loss 2.4330 (2.5882)	grad_norm 2.4532 (2.8139)	mem 17417MB
[2023-02-02 21:24:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][650/1251]	eta 0:05:42 lr 0.000024	time 0.5537 (0.5702)	loss 2.2887 (2.5854)	grad_norm 2.7714 (2.8141)	mem 17417MB
[2023-02-02 21:24:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][700/1251]	eta 0:05:14 lr 0.000024	time 0.5590 (0.5703)	loss 2.7024 (2.5913)	grad_norm 2.9584 (2.8179)	mem 17417MB
[2023-02-02 21:25:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][750/1251]	eta 0:04:45 lr 0.000024	time 0.5636 (0.5700)	loss 2.8312 (2.5945)	grad_norm 2.6252 (2.8226)	mem 17417MB
[2023-02-02 21:25:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][800/1251]	eta 0:04:17 lr 0.000024	time 0.6155 (0.5700)	loss 2.9719 (2.5955)	grad_norm 3.3862 (2.8283)	mem 17417MB
[2023-02-02 21:26:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][850/1251]	eta 0:03:48 lr 0.000023	time 0.5563 (0.5699)	loss 2.6561 (2.5957)	grad_norm 2.5553 (2.8316)	mem 17417MB
[2023-02-02 21:26:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][900/1251]	eta 0:03:20 lr 0.000023	time 0.6264 (0.5698)	loss 2.4274 (2.5975)	grad_norm 2.6471 (2.8309)	mem 17417MB
[2023-02-02 21:27:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][950/1251]	eta 0:02:51 lr 0.000023	time 0.5551 (0.5698)	loss 2.8364 (2.5936)	grad_norm 2.4500 (2.8303)	mem 17417MB
[2023-02-02 21:27:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][1000/1251]	eta 0:02:22 lr 0.000023	time 0.6132 (0.5697)	loss 2.6889 (2.5902)	grad_norm 2.9336 (2.8303)	mem 17417MB
[2023-02-02 21:28:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][1050/1251]	eta 0:01:54 lr 0.000023	time 0.5562 (0.5697)	loss 2.8887 (2.5850)	grad_norm 2.6542 (2.8287)	mem 17417MB
[2023-02-02 21:28:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][1100/1251]	eta 0:01:26 lr 0.000023	time 0.5596 (0.5697)	loss 2.2310 (2.5873)	grad_norm 2.9807 (2.8292)	mem 17417MB
[2023-02-02 21:29:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][1150/1251]	eta 0:00:57 lr 0.000023	time 0.5555 (0.5695)	loss 3.0491 (2.5862)	grad_norm 2.9343 (2.8297)	mem 17417MB
[2023-02-02 21:29:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][1200/1251]	eta 0:00:29 lr 0.000023	time 0.6445 (0.5697)	loss 1.8564 (2.5851)	grad_norm 3.0216 (2.8279)	mem 17417MB
[2023-02-02 21:30:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [277/300][1250/1251]	eta 0:00:00 lr 0.000023	time 0.5470 (0.5695)	loss 2.7051 (2.5880)	grad_norm 3.4097 (2.8282)	mem 17417MB
[2023-02-02 21:30:00 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 277 training takes 0:11:52
[2023-02-02 21:30:00 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_277.pth saving......
[2023-02-02 21:30:02 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_277.pth saved !!!
[2023-02-02 21:30:03 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.877 (0.877)	Loss 0.7074 (0.7074)	Acc@1 84.082 (84.082)	Acc@5 95.605 (95.605)	Mem 17417MB
[2023-02-02 21:30:11 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.906 Acc@5 96.710
[2023-02-02 21:30:11 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-02 21:30:12 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.268 (1.268)	Loss 0.6902 (0.6902)	Acc@1 84.082 (84.082)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-02 21:30:20 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.986 Acc@5 96.802
[2023-02-02 21:30:20 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 21:30:20 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 21:30:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][0/1251]	eta 0:34:23 lr 0.000023	time 1.6499 (1.6499)	loss 2.6505 (2.6505)	grad_norm 2.5648 (2.5648)	mem 17417MB
[2023-02-02 21:30:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][50/1251]	eta 0:11:49 lr 0.000023	time 0.5679 (0.5906)	loss 2.7076 (2.5512)	grad_norm 2.6721 (2.9324)	mem 17417MB
[2023-02-02 21:31:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][100/1251]	eta 0:11:09 lr 0.000023	time 0.5608 (0.5819)	loss 2.8482 (2.5815)	grad_norm 2.6894 (2.9227)	mem 17417MB
[2023-02-02 21:31:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][150/1251]	eta 0:10:36 lr 0.000023	time 0.5518 (0.5780)	loss 2.3872 (2.5861)	grad_norm 3.3645 (2.8974)	mem 17417MB
[2023-02-02 21:32:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][200/1251]	eta 0:10:05 lr 0.000023	time 0.5521 (0.5758)	loss 2.6058 (2.5840)	grad_norm 2.5805 (2.8914)	mem 17417MB
[2023-02-02 21:32:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][250/1251]	eta 0:09:35 lr 0.000023	time 0.5544 (0.5747)	loss 2.7624 (2.5881)	grad_norm 2.4990 (2.8932)	mem 17417MB
[2023-02-02 21:33:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][300/1251]	eta 0:09:05 lr 0.000023	time 0.5576 (0.5740)	loss 2.7573 (2.5813)	grad_norm 3.1689 (2.8708)	mem 17417MB
[2023-02-02 21:33:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][350/1251]	eta 0:08:36 lr 0.000023	time 0.5525 (0.5732)	loss 3.1034 (2.5958)	grad_norm 2.7456 (2.8738)	mem 17417MB
[2023-02-02 21:34:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][400/1251]	eta 0:08:07 lr 0.000023	time 0.5519 (0.5728)	loss 2.7171 (2.5924)	grad_norm 2.2879 (2.8725)	mem 17417MB
[2023-02-02 21:34:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][450/1251]	eta 0:07:38 lr 0.000023	time 0.5557 (0.5727)	loss 2.7968 (2.5890)	grad_norm 2.8330 (2.8718)	mem 17417MB
[2023-02-02 21:35:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][500/1251]	eta 0:07:09 lr 0.000023	time 0.6331 (0.5723)	loss 3.0180 (2.5951)	grad_norm 2.8359 (2.8706)	mem 17417MB
[2023-02-02 21:35:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][550/1251]	eta 0:06:40 lr 0.000023	time 0.6197 (0.5718)	loss 1.8612 (2.5863)	grad_norm 2.9977 (2.8736)	mem 17417MB
[2023-02-02 21:36:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][600/1251]	eta 0:06:12 lr 0.000023	time 0.5592 (0.5716)	loss 2.9448 (2.5908)	grad_norm 2.8346 (2.8688)	mem 17417MB
[2023-02-02 21:36:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][650/1251]	eta 0:05:43 lr 0.000022	time 0.5529 (0.5717)	loss 2.6226 (2.5893)	grad_norm 2.9230 (2.8733)	mem 17417MB
[2023-02-02 21:37:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][700/1251]	eta 0:05:14 lr 0.000022	time 0.5595 (0.5714)	loss 2.5932 (2.5868)	grad_norm 2.6452 (2.8697)	mem 17417MB
[2023-02-02 21:37:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][750/1251]	eta 0:04:46 lr 0.000022	time 0.5591 (0.5714)	loss 2.8288 (2.5803)	grad_norm 2.7048 (2.8632)	mem 17417MB
[2023-02-02 21:37:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][800/1251]	eta 0:04:17 lr 0.000022	time 0.5459 (0.5713)	loss 2.6187 (2.5857)	grad_norm 3.1102 (2.8619)	mem 17417MB
[2023-02-02 21:38:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][850/1251]	eta 0:03:49 lr 0.000022	time 0.5522 (0.5711)	loss 1.4732 (2.5894)	grad_norm 3.2564 (2.8661)	mem 17417MB
[2023-02-02 21:38:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][900/1251]	eta 0:03:20 lr 0.000022	time 0.5590 (0.5711)	loss 2.2549 (2.5932)	grad_norm 2.4895 (2.8621)	mem 17417MB
[2023-02-02 21:39:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][950/1251]	eta 0:02:51 lr 0.000022	time 0.5553 (0.5711)	loss 2.2517 (2.5961)	grad_norm 2.5204 (2.8577)	mem 17417MB
[2023-02-02 21:39:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][1000/1251]	eta 0:02:23 lr 0.000022	time 0.5610 (0.5710)	loss 2.9346 (2.5925)	grad_norm 2.4915 (2.8608)	mem 17417MB
[2023-02-02 21:40:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][1050/1251]	eta 0:01:54 lr 0.000022	time 0.5557 (0.5710)	loss 2.3694 (2.5911)	grad_norm 3.1819 (2.8607)	mem 17417MB
[2023-02-02 21:40:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][1100/1251]	eta 0:01:26 lr 0.000022	time 0.5554 (0.5708)	loss 2.4439 (2.5939)	grad_norm 2.7033 (2.8611)	mem 17417MB
[2023-02-02 21:41:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][1150/1251]	eta 0:00:57 lr 0.000022	time 0.5915 (0.5709)	loss 2.9336 (2.5953)	grad_norm 2.8254 (2.8576)	mem 17417MB
[2023-02-02 21:41:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][1200/1251]	eta 0:00:29 lr 0.000022	time 0.6288 (0.5707)	loss 2.1470 (2.5919)	grad_norm 2.7249 (2.8564)	mem 17417MB
[2023-02-02 21:42:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [278/300][1250/1251]	eta 0:00:00 lr 0.000022	time 0.5519 (0.5707)	loss 2.9178 (2.5943)	grad_norm 2.4245 (inf)	mem 17417MB
[2023-02-02 21:42:14 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 278 training takes 0:11:54
[2023-02-02 21:42:14 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_278.pth saving......
[2023-02-02 21:42:16 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_278.pth saved !!!
[2023-02-02 21:42:17 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.834 (0.834)	Loss 0.7264 (0.7264)	Acc@1 84.277 (84.277)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-02 21:42:25 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.908 Acc@5 96.718
[2023-02-02 21:42:25 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-02 21:42:26 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.190 (1.190)	Loss 0.7090 (0.7090)	Acc@1 82.129 (82.129)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 21:42:34 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.994 Acc@5 96.808
[2023-02-02 21:42:34 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 21:42:34 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 21:42:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][0/1251]	eta 0:33:23 lr 0.000022	time 1.6014 (1.6014)	loss 2.4039 (2.4039)	grad_norm 2.4151 (2.4151)	mem 17417MB
[2023-02-02 21:43:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][50/1251]	eta 0:11:58 lr 0.000022	time 0.5599 (0.5979)	loss 1.6701 (2.5481)	grad_norm 2.5855 (2.9212)	mem 17417MB
[2023-02-02 21:43:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][100/1251]	eta 0:11:11 lr 0.000022	time 0.6527 (0.5836)	loss 1.8427 (2.6009)	grad_norm 3.0023 (2.9193)	mem 17417MB
[2023-02-02 21:44:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][150/1251]	eta 0:10:36 lr 0.000022	time 0.5614 (0.5783)	loss 2.6909 (2.6010)	grad_norm 3.1044 (2.8986)	mem 17417MB
[2023-02-02 21:44:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][200/1251]	eta 0:10:04 lr 0.000022	time 0.5478 (0.5752)	loss 3.0879 (2.5943)	grad_norm 4.0060 (2.8783)	mem 17417MB
[2023-02-02 21:44:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][250/1251]	eta 0:09:35 lr 0.000022	time 0.5542 (0.5745)	loss 2.6367 (2.5725)	grad_norm 2.4164 (2.8796)	mem 17417MB
[2023-02-02 21:45:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][300/1251]	eta 0:09:05 lr 0.000022	time 0.5503 (0.5741)	loss 2.8721 (2.5820)	grad_norm 2.7353 (2.8811)	mem 17417MB
[2023-02-02 21:45:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][350/1251]	eta 0:08:36 lr 0.000022	time 0.5510 (0.5730)	loss 2.8885 (2.5793)	grad_norm 2.8316 (2.8968)	mem 17417MB
[2023-02-02 21:46:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][400/1251]	eta 0:08:07 lr 0.000022	time 0.5529 (0.5726)	loss 2.8529 (2.5817)	grad_norm 2.7409 (2.9000)	mem 17417MB
[2023-02-02 21:46:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][450/1251]	eta 0:07:38 lr 0.000022	time 0.5544 (0.5728)	loss 2.8596 (2.5829)	grad_norm 3.5575 (2.8955)	mem 17417MB
[2023-02-02 21:47:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][500/1251]	eta 0:07:09 lr 0.000021	time 0.5545 (0.5720)	loss 2.7526 (2.5733)	grad_norm 3.2615 (2.8948)	mem 17417MB
[2023-02-02 21:47:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][550/1251]	eta 0:06:40 lr 0.000021	time 0.5517 (0.5718)	loss 2.3463 (2.5771)	grad_norm 2.4735 (2.9101)	mem 17417MB
[2023-02-02 21:48:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][600/1251]	eta 0:06:12 lr 0.000021	time 0.5472 (0.5715)	loss 1.9948 (2.5840)	grad_norm 2.9011 (2.9030)	mem 17417MB
[2023-02-02 21:48:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][650/1251]	eta 0:05:43 lr 0.000021	time 0.5552 (0.5715)	loss 2.7932 (2.5896)	grad_norm 2.6191 (2.8926)	mem 17417MB
[2023-02-02 21:49:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][700/1251]	eta 0:05:14 lr 0.000021	time 0.5525 (0.5711)	loss 2.8049 (2.5935)	grad_norm 2.9729 (2.8894)	mem 17417MB
[2023-02-02 21:49:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][750/1251]	eta 0:04:46 lr 0.000021	time 0.5616 (0.5712)	loss 2.6803 (2.5900)	grad_norm 3.1730 (2.8829)	mem 17417MB
[2023-02-02 21:50:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][800/1251]	eta 0:04:17 lr 0.000021	time 0.5583 (0.5710)	loss 2.7931 (2.5903)	grad_norm 2.5484 (2.8770)	mem 17417MB
[2023-02-02 21:50:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][850/1251]	eta 0:03:49 lr 0.000021	time 0.5600 (0.5713)	loss 2.1764 (2.5906)	grad_norm 2.6325 (2.8735)	mem 17417MB
[2023-02-02 21:51:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][900/1251]	eta 0:03:20 lr 0.000021	time 0.5562 (0.5709)	loss 2.5093 (2.5922)	grad_norm 2.6784 (2.8719)	mem 17417MB
[2023-02-02 21:51:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][950/1251]	eta 0:02:51 lr 0.000021	time 0.5522 (0.5710)	loss 2.9355 (2.5920)	grad_norm 3.3968 (2.8725)	mem 17417MB
[2023-02-02 21:52:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][1000/1251]	eta 0:02:23 lr 0.000021	time 0.6191 (0.5710)	loss 2.4941 (2.5881)	grad_norm 2.9226 (2.8721)	mem 17417MB
[2023-02-02 21:52:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][1050/1251]	eta 0:01:54 lr 0.000021	time 0.5518 (0.5710)	loss 2.7996 (2.5899)	grad_norm 2.9348 (2.8758)	mem 17417MB
[2023-02-02 21:53:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][1100/1251]	eta 0:01:26 lr 0.000021	time 0.5569 (0.5710)	loss 2.3027 (2.5909)	grad_norm 2.6814 (2.8786)	mem 17417MB
[2023-02-02 21:53:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][1150/1251]	eta 0:00:57 lr 0.000021	time 0.5481 (0.5711)	loss 2.7457 (2.5871)	grad_norm 3.3500 (2.8793)	mem 17417MB
[2023-02-02 21:54:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][1200/1251]	eta 0:00:29 lr 0.000021	time 0.5652 (0.5709)	loss 2.8007 (2.5906)	grad_norm 2.6735 (2.8772)	mem 17417MB
[2023-02-02 21:54:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [279/300][1250/1251]	eta 0:00:00 lr 0.000021	time 0.6064 (0.5709)	loss 3.0048 (2.5910)	grad_norm 2.6073 (2.8753)	mem 17417MB
[2023-02-02 21:54:28 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 279 training takes 0:11:54
[2023-02-02 21:54:28 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_279.pth saving......
[2023-02-02 21:54:30 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_279.pth saved !!!
[2023-02-02 21:54:31 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.008 (1.008)	Loss 0.7114 (0.7114)	Acc@1 83.398 (83.398)	Acc@5 97.266 (97.266)	Mem 17417MB
[2023-02-02 21:54:39 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.864 Acc@5 96.752
[2023-02-02 21:54:39 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-02 21:54:40 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.198 (1.198)	Loss 0.7437 (0.7437)	Acc@1 83.008 (83.008)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-02 21:54:48 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.964 Acc@5 96.824
[2023-02-02 21:54:48 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 21:54:48 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 21:54:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][0/1251]	eta 0:34:51 lr 0.000021	time 1.6718 (1.6718)	loss 2.1468 (2.1468)	grad_norm 2.4462 (2.4462)	mem 17417MB
[2023-02-02 21:55:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][50/1251]	eta 0:11:48 lr 0.000021	time 0.6317 (0.5901)	loss 2.8369 (2.5681)	grad_norm 2.9820 (2.8830)	mem 17417MB
[2023-02-02 21:55:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][100/1251]	eta 0:11:09 lr 0.000021	time 0.6349 (0.5813)	loss 3.0414 (2.5629)	grad_norm 3.1693 (2.8624)	mem 17417MB
[2023-02-02 21:56:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][150/1251]	eta 0:10:34 lr 0.000021	time 0.5558 (0.5761)	loss 2.8567 (2.5620)	grad_norm 2.7818 (2.8668)	mem 17417MB
[2023-02-02 21:56:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][200/1251]	eta 0:10:03 lr 0.000021	time 0.5603 (0.5739)	loss 2.7031 (2.5673)	grad_norm 2.5747 (2.8622)	mem 17417MB
[2023-02-02 21:57:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][250/1251]	eta 0:09:33 lr 0.000021	time 0.5533 (0.5727)	loss 2.7550 (2.5706)	grad_norm 2.9267 (2.8685)	mem 17417MB
[2023-02-02 21:57:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][300/1251]	eta 0:09:04 lr 0.000021	time 0.5517 (0.5725)	loss 2.1713 (2.5710)	grad_norm 2.8313 (2.8727)	mem 17417MB
[2023-02-02 21:58:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][350/1251]	eta 0:08:34 lr 0.000021	time 0.5515 (0.5716)	loss 3.0746 (2.5843)	grad_norm 2.1328 (2.8595)	mem 17417MB
[2023-02-02 21:58:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][400/1251]	eta 0:08:06 lr 0.000020	time 0.5467 (0.5711)	loss 2.7384 (2.5844)	grad_norm 2.9767 (2.8564)	mem 17417MB
[2023-02-02 21:59:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][450/1251]	eta 0:07:37 lr 0.000020	time 0.5487 (0.5707)	loss 3.0585 (2.5786)	grad_norm 3.3479 (2.8538)	mem 17417MB
[2023-02-02 21:59:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][500/1251]	eta 0:07:08 lr 0.000020	time 0.5545 (0.5708)	loss 2.7635 (2.5741)	grad_norm 2.7193 (2.8484)	mem 17417MB
[2023-02-02 22:00:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][550/1251]	eta 0:06:39 lr 0.000020	time 0.5533 (0.5706)	loss 2.5658 (2.5755)	grad_norm 3.1159 (2.8524)	mem 17417MB
[2023-02-02 22:00:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][600/1251]	eta 0:06:11 lr 0.000020	time 0.5605 (0.5705)	loss 2.7296 (2.5811)	grad_norm 2.5796 (2.8547)	mem 17417MB
[2023-02-02 22:01:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][650/1251]	eta 0:05:42 lr 0.000020	time 0.5544 (0.5704)	loss 1.5639 (2.5764)	grad_norm 3.4234 (2.8693)	mem 17417MB
[2023-02-02 22:01:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][700/1251]	eta 0:05:14 lr 0.000020	time 0.5539 (0.5702)	loss 2.6615 (2.5766)	grad_norm 2.6885 (2.8633)	mem 17417MB
[2023-02-02 22:01:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][750/1251]	eta 0:04:45 lr 0.000020	time 0.5535 (0.5702)	loss 2.1033 (2.5739)	grad_norm 2.6743 (2.8624)	mem 17417MB
[2023-02-02 22:02:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][800/1251]	eta 0:04:17 lr 0.000020	time 0.5565 (0.5701)	loss 2.6154 (2.5710)	grad_norm 2.6275 (2.8619)	mem 17417MB
[2023-02-02 22:02:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][850/1251]	eta 0:03:48 lr 0.000020	time 0.5565 (0.5699)	loss 2.9793 (2.5790)	grad_norm 2.9790 (2.8706)	mem 17417MB
[2023-02-02 22:03:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][900/1251]	eta 0:03:20 lr 0.000020	time 0.6406 (0.5700)	loss 2.0556 (2.5775)	grad_norm 3.0311 (2.8681)	mem 17417MB
[2023-02-02 22:03:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][950/1251]	eta 0:02:51 lr 0.000020	time 0.5610 (0.5696)	loss 2.4100 (2.5773)	grad_norm 2.7383 (2.8671)	mem 17417MB
[2023-02-02 22:04:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][1000/1251]	eta 0:02:22 lr 0.000020	time 0.5516 (0.5697)	loss 2.8282 (2.5791)	grad_norm 2.5255 (inf)	mem 17417MB
[2023-02-02 22:04:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][1050/1251]	eta 0:01:54 lr 0.000020	time 0.5484 (0.5698)	loss 2.8540 (2.5806)	grad_norm 2.8111 (inf)	mem 17417MB
[2023-02-02 22:05:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][1100/1251]	eta 0:01:26 lr 0.000020	time 0.6391 (0.5699)	loss 2.7665 (2.5802)	grad_norm 2.5081 (inf)	mem 17417MB
[2023-02-02 22:05:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][1150/1251]	eta 0:00:57 lr 0.000020	time 0.5485 (0.5697)	loss 3.0112 (2.5809)	grad_norm 3.1932 (inf)	mem 17417MB
[2023-02-02 22:06:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][1200/1251]	eta 0:00:29 lr 0.000020	time 0.6235 (0.5697)	loss 2.4628 (2.5809)	grad_norm 3.2267 (inf)	mem 17417MB
[2023-02-02 22:06:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [280/300][1250/1251]	eta 0:00:00 lr 0.000020	time 0.5494 (0.5696)	loss 1.9315 (2.5825)	grad_norm 2.6633 (inf)	mem 17417MB
[2023-02-02 22:06:41 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 280 training takes 0:11:52
[2023-02-02 22:06:41 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_280.pth saving......
[2023-02-02 22:06:43 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_280.pth saved !!!
[2023-02-02 22:06:44 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.882 (0.882)	Loss 0.6862 (0.6862)	Acc@1 84.375 (84.375)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-02 22:06:52 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.842 Acc@5 96.746
[2023-02-02 22:06:52 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.8%
[2023-02-02 22:06:53 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.233 (1.233)	Loss 0.7274 (0.7274)	Acc@1 83.594 (83.594)	Acc@5 96.582 (96.582)	Mem 17417MB
[2023-02-02 22:07:01 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.944 Acc@5 96.816
[2023-02-02 22:07:01 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 22:07:01 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 22:07:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][0/1251]	eta 0:35:15 lr 0.000020	time 1.6908 (1.6908)	loss 2.7894 (2.7894)	grad_norm 2.7756 (2.7756)	mem 17417MB
[2023-02-02 22:07:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][50/1251]	eta 0:11:57 lr 0.000020	time 0.5552 (0.5976)	loss 2.7392 (2.5146)	grad_norm 2.4872 (2.8446)	mem 17417MB
[2023-02-02 22:08:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][100/1251]	eta 0:11:12 lr 0.000020	time 0.5488 (0.5840)	loss 2.6798 (2.5945)	grad_norm 2.9902 (2.8858)	mem 17417MB
[2023-02-02 22:08:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][150/1251]	eta 0:10:37 lr 0.000020	time 0.5557 (0.5791)	loss 2.5880 (2.5981)	grad_norm 2.8132 (2.8605)	mem 17417MB
[2023-02-02 22:08:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][200/1251]	eta 0:10:06 lr 0.000020	time 0.5528 (0.5772)	loss 2.8044 (2.5962)	grad_norm 3.0362 (2.8551)	mem 17417MB
[2023-02-02 22:09:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][250/1251]	eta 0:09:36 lr 0.000020	time 0.5507 (0.5759)	loss 2.7317 (2.5883)	grad_norm 3.0136 (2.8598)	mem 17417MB
[2023-02-02 22:09:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][300/1251]	eta 0:09:06 lr 0.000020	time 0.6165 (0.5746)	loss 2.4430 (2.5763)	grad_norm 2.6352 (2.8755)	mem 17417MB
[2023-02-02 22:10:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][350/1251]	eta 0:08:37 lr 0.000019	time 0.5533 (0.5741)	loss 2.8002 (2.5827)	grad_norm 2.8245 (2.8818)	mem 17417MB
[2023-02-02 22:10:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][400/1251]	eta 0:08:08 lr 0.000019	time 0.5531 (0.5736)	loss 2.9540 (2.5757)	grad_norm 2.8260 (2.8745)	mem 17417MB
[2023-02-02 22:11:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][450/1251]	eta 0:07:39 lr 0.000019	time 0.5543 (0.5732)	loss 2.1168 (2.5661)	grad_norm 2.8604 (2.8870)	mem 17417MB
[2023-02-02 22:11:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][500/1251]	eta 0:07:10 lr 0.000019	time 0.5527 (0.5726)	loss 2.5031 (2.5634)	grad_norm 3.1300 (2.8838)	mem 17417MB
[2023-02-02 22:12:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][550/1251]	eta 0:06:41 lr 0.000019	time 0.5543 (0.5725)	loss 2.8916 (2.5580)	grad_norm 3.1654 (2.8929)	mem 17417MB
[2023-02-02 22:12:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][600/1251]	eta 0:06:12 lr 0.000019	time 0.5543 (0.5726)	loss 3.1798 (2.5570)	grad_norm 2.5197 (2.8931)	mem 17417MB
[2023-02-02 22:13:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][650/1251]	eta 0:05:43 lr 0.000019	time 0.5558 (0.5723)	loss 1.9475 (2.5555)	grad_norm 2.9725 (2.8879)	mem 17417MB
[2023-02-02 22:13:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][700/1251]	eta 0:05:15 lr 0.000019	time 0.5528 (0.5720)	loss 2.9458 (2.5552)	grad_norm 3.2922 (2.8847)	mem 17417MB
[2023-02-02 22:14:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][750/1251]	eta 0:04:46 lr 0.000019	time 0.5557 (0.5720)	loss 2.4864 (2.5610)	grad_norm 3.0155 (2.8867)	mem 17417MB
[2023-02-02 22:14:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][800/1251]	eta 0:04:17 lr 0.000019	time 0.5527 (0.5718)	loss 2.7305 (2.5661)	grad_norm 2.9592 (2.8827)	mem 17417MB
[2023-02-02 22:15:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][850/1251]	eta 0:03:49 lr 0.000019	time 0.5513 (0.5716)	loss 2.5681 (2.5639)	grad_norm 2.4883 (2.8791)	mem 17417MB
[2023-02-02 22:15:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][900/1251]	eta 0:03:20 lr 0.000019	time 0.6277 (0.5715)	loss 1.6932 (2.5628)	grad_norm 2.9862 (2.8798)	mem 17417MB
[2023-02-02 22:16:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][950/1251]	eta 0:02:51 lr 0.000019	time 0.5527 (0.5713)	loss 2.8068 (2.5651)	grad_norm 3.4463 (2.8842)	mem 17417MB
[2023-02-02 22:16:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][1000/1251]	eta 0:02:23 lr 0.000019	time 0.5586 (0.5713)	loss 3.1848 (2.5655)	grad_norm 4.0691 (2.8854)	mem 17417MB
[2023-02-02 22:17:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][1050/1251]	eta 0:01:54 lr 0.000019	time 0.5535 (0.5711)	loss 2.7953 (2.5661)	grad_norm 3.0165 (2.8861)	mem 17417MB
[2023-02-02 22:17:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][1100/1251]	eta 0:01:26 lr 0.000019	time 0.6301 (0.5711)	loss 2.0619 (2.5668)	grad_norm 2.5026 (2.8855)	mem 17417MB
[2023-02-02 22:17:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][1150/1251]	eta 0:00:57 lr 0.000019	time 0.5623 (0.5711)	loss 2.8638 (2.5696)	grad_norm 2.8920 (2.8853)	mem 17417MB
[2023-02-02 22:18:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][1200/1251]	eta 0:00:29 lr 0.000019	time 0.5576 (0.5709)	loss 1.9128 (2.5678)	grad_norm 2.5168 (2.8829)	mem 17417MB
[2023-02-02 22:18:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [281/300][1250/1251]	eta 0:00:00 lr 0.000019	time 0.5485 (0.5709)	loss 3.1075 (2.5683)	grad_norm 3.0149 (2.8827)	mem 17417MB
[2023-02-02 22:18:55 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 281 training takes 0:11:54
[2023-02-02 22:18:56 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_281.pth saving......
[2023-02-02 22:18:57 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_281.pth saved !!!
[2023-02-02 22:18:58 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.831 (0.831)	Loss 0.7681 (0.7681)	Acc@1 82.422 (82.422)	Acc@5 96.484 (96.484)	Mem 17417MB
[2023-02-02 22:19:06 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.856 Acc@5 96.798
[2023-02-02 22:19:06 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-02 22:19:07 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.261 (1.261)	Loss 0.6469 (0.6469)	Acc@1 85.840 (85.840)	Acc@5 97.266 (97.266)	Mem 17417MB
[2023-02-02 22:19:15 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.950 Acc@5 96.818
[2023-02-02 22:19:15 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 22:19:15 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 22:19:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][0/1251]	eta 0:37:58 lr 0.000019	time 1.8212 (1.8212)	loss 2.6789 (2.6789)	grad_norm 2.7564 (2.7564)	mem 17417MB
[2023-02-02 22:19:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][50/1251]	eta 0:11:58 lr 0.000019	time 0.5630 (0.5985)	loss 2.3868 (2.5560)	grad_norm 3.1123 (2.9471)	mem 17417MB
[2023-02-02 22:20:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][100/1251]	eta 0:11:11 lr 0.000019	time 0.5671 (0.5830)	loss 2.8303 (2.5581)	grad_norm 2.5741 (2.9162)	mem 17417MB
[2023-02-02 22:20:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][150/1251]	eta 0:10:37 lr 0.000019	time 0.5603 (0.5790)	loss 2.4348 (2.5636)	grad_norm 3.6165 (2.9056)	mem 17417MB
[2023-02-02 22:21:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][200/1251]	eta 0:10:05 lr 0.000019	time 0.5587 (0.5763)	loss 2.1021 (2.5527)	grad_norm 2.7696 (2.9062)	mem 17417MB
[2023-02-02 22:21:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][250/1251]	eta 0:09:35 lr 0.000019	time 0.5597 (0.5749)	loss 2.8291 (2.5535)	grad_norm 2.7517 (2.8892)	mem 17417MB
[2023-02-02 22:22:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][300/1251]	eta 0:09:05 lr 0.000019	time 0.6230 (0.5736)	loss 2.7816 (2.5473)	grad_norm 2.6472 (2.8907)	mem 17417MB
[2023-02-02 22:22:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][350/1251]	eta 0:08:36 lr 0.000018	time 0.5559 (0.5729)	loss 2.5793 (2.5611)	grad_norm 2.5745 (2.8876)	mem 17417MB
[2023-02-02 22:23:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][400/1251]	eta 0:08:06 lr 0.000018	time 0.5553 (0.5719)	loss 2.9969 (2.5536)	grad_norm 2.7494 (2.8896)	mem 17417MB
[2023-02-02 22:23:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][450/1251]	eta 0:07:37 lr 0.000018	time 0.5521 (0.5716)	loss 2.7930 (2.5529)	grad_norm 2.7025 (2.8885)	mem 17417MB
[2023-02-02 22:24:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][500/1251]	eta 0:07:09 lr 0.000018	time 0.5508 (0.5714)	loss 2.6473 (2.5591)	grad_norm 3.0151 (2.8904)	mem 17417MB
[2023-02-02 22:24:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][550/1251]	eta 0:06:40 lr 0.000018	time 0.5577 (0.5713)	loss 2.0682 (2.5541)	grad_norm 2.4359 (2.9012)	mem 17417MB
[2023-02-02 22:24:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][600/1251]	eta 0:06:11 lr 0.000018	time 0.5526 (0.5710)	loss 2.6237 (2.5571)	grad_norm 3.1670 (2.8971)	mem 17417MB
[2023-02-02 22:25:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][650/1251]	eta 0:05:43 lr 0.000018	time 0.5545 (0.5710)	loss 2.7724 (2.5501)	grad_norm 3.0160 (2.8985)	mem 17417MB
[2023-02-02 22:25:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][700/1251]	eta 0:05:14 lr 0.000018	time 0.5559 (0.5705)	loss 3.0523 (2.5512)	grad_norm 2.7928 (2.9063)	mem 17417MB
[2023-02-02 22:26:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][750/1251]	eta 0:04:45 lr 0.000018	time 0.5523 (0.5704)	loss 3.2081 (2.5555)	grad_norm 2.6270 (2.9077)	mem 17417MB
[2023-02-02 22:26:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][800/1251]	eta 0:04:17 lr 0.000018	time 0.5552 (0.5701)	loss 2.5000 (2.5554)	grad_norm 2.8001 (2.9084)	mem 17417MB
[2023-02-02 22:27:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][850/1251]	eta 0:03:48 lr 0.000018	time 0.5560 (0.5701)	loss 2.7110 (2.5591)	grad_norm 2.3504 (2.9073)	mem 17417MB
[2023-02-02 22:27:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][900/1251]	eta 0:03:20 lr 0.000018	time 0.5511 (0.5701)	loss 2.8118 (2.5607)	grad_norm 2.6789 (2.9038)	mem 17417MB
[2023-02-02 22:28:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][950/1251]	eta 0:02:51 lr 0.000018	time 0.5553 (0.5700)	loss 2.7174 (2.5596)	grad_norm 2.9403 (2.9011)	mem 17417MB
[2023-02-02 22:28:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][1000/1251]	eta 0:02:23 lr 0.000018	time 0.5508 (0.5701)	loss 2.1007 (2.5596)	grad_norm 2.6115 (2.8965)	mem 17417MB
[2023-02-02 22:29:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][1050/1251]	eta 0:01:54 lr 0.000018	time 0.5594 (0.5701)	loss 2.7479 (2.5593)	grad_norm 2.6477 (2.8982)	mem 17417MB
[2023-02-02 22:29:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][1100/1251]	eta 0:01:26 lr 0.000018	time 0.6218 (0.5701)	loss 2.7032 (2.5604)	grad_norm 2.8597 (2.8955)	mem 17417MB
[2023-02-02 22:30:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][1150/1251]	eta 0:00:57 lr 0.000018	time 0.6268 (0.5700)	loss 2.9567 (2.5626)	grad_norm 2.6268 (2.8995)	mem 17417MB
[2023-02-02 22:30:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][1200/1251]	eta 0:00:29 lr 0.000018	time 0.5611 (0.5698)	loss 2.2718 (2.5653)	grad_norm 2.9234 (2.9014)	mem 17417MB
[2023-02-02 22:31:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [282/300][1250/1251]	eta 0:00:00 lr 0.000018	time 0.5479 (0.5699)	loss 2.5460 (2.5636)	grad_norm 2.4286 (2.9050)	mem 17417MB
[2023-02-02 22:31:08 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 282 training takes 0:11:53
[2023-02-02 22:31:08 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_282.pth saving......
[2023-02-02 22:31:10 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_282.pth saved !!!
[2023-02-02 22:31:11 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.873 (0.873)	Loss 0.7505 (0.7505)	Acc@1 82.910 (82.910)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-02 22:31:19 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.900 Acc@5 96.758
[2023-02-02 22:31:19 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-02 22:31:20 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.471 (1.471)	Loss 0.6227 (0.6227)	Acc@1 85.547 (85.547)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-02 22:31:28 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.954 Acc@5 96.816
[2023-02-02 22:31:28 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 22:31:28 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 22:31:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][0/1251]	eta 0:33:49 lr 0.000018	time 1.6223 (1.6223)	loss 1.7894 (1.7894)	grad_norm 2.2165 (2.2165)	mem 17417MB
[2023-02-02 22:31:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][50/1251]	eta 0:11:48 lr 0.000018	time 0.5575 (0.5897)	loss 1.9370 (2.5315)	grad_norm 2.8669 (2.8979)	mem 17417MB
[2023-02-02 22:32:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][100/1251]	eta 0:11:08 lr 0.000018	time 0.6496 (0.5810)	loss 1.7262 (2.5346)	grad_norm 2.3491 (2.9764)	mem 17417MB
[2023-02-02 22:32:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][150/1251]	eta 0:10:34 lr 0.000018	time 0.5544 (0.5767)	loss 1.6598 (2.5119)	grad_norm 2.7189 (2.9448)	mem 17417MB
[2023-02-02 22:33:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][200/1251]	eta 0:10:04 lr 0.000018	time 0.6120 (0.5755)	loss 3.1622 (2.5450)	grad_norm 3.5520 (2.9223)	mem 17417MB
[2023-02-02 22:33:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][250/1251]	eta 0:09:34 lr 0.000018	time 0.6046 (0.5736)	loss 1.6144 (2.5454)	grad_norm 2.7895 (2.9311)	mem 17417MB
[2023-02-02 22:34:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][300/1251]	eta 0:09:04 lr 0.000018	time 0.5612 (0.5729)	loss 2.5733 (2.5618)	grad_norm 3.0161 (2.9257)	mem 17417MB
[2023-02-02 22:34:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][350/1251]	eta 0:08:35 lr 0.000018	time 0.5537 (0.5723)	loss 2.0704 (2.5654)	grad_norm 2.8726 (2.9207)	mem 17417MB
[2023-02-02 22:35:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][400/1251]	eta 0:08:06 lr 0.000018	time 0.5592 (0.5721)	loss 2.7527 (2.5628)	grad_norm 3.4968 (2.9298)	mem 17417MB
[2023-02-02 22:35:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][450/1251]	eta 0:07:37 lr 0.000017	time 0.5604 (0.5717)	loss 2.6224 (2.5636)	grad_norm 3.0377 (2.9388)	mem 17417MB
[2023-02-02 22:36:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][500/1251]	eta 0:07:09 lr 0.000017	time 0.6240 (0.5716)	loss 2.7840 (2.5592)	grad_norm 2.5468 (2.9406)	mem 17417MB
[2023-02-02 22:36:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][550/1251]	eta 0:06:40 lr 0.000017	time 0.5620 (0.5715)	loss 2.6755 (2.5619)	grad_norm 2.6284 (2.9349)	mem 17417MB
[2023-02-02 22:37:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][600/1251]	eta 0:06:12 lr 0.000017	time 0.6098 (0.5718)	loss 2.7256 (2.5637)	grad_norm 3.1269 (2.9324)	mem 17417MB
[2023-02-02 22:37:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][650/1251]	eta 0:05:43 lr 0.000017	time 0.5555 (0.5717)	loss 2.8675 (2.5646)	grad_norm 2.4519 (2.9348)	mem 17417MB
[2023-02-02 22:38:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][700/1251]	eta 0:05:14 lr 0.000017	time 0.5554 (0.5714)	loss 2.1941 (2.5618)	grad_norm 2.5260 (2.9378)	mem 17417MB
[2023-02-02 22:38:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][750/1251]	eta 0:04:46 lr 0.000017	time 0.5491 (0.5714)	loss 1.7766 (2.5704)	grad_norm 2.7327 (2.9336)	mem 17417MB
[2023-02-02 22:39:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][800/1251]	eta 0:04:17 lr 0.000017	time 0.5595 (0.5711)	loss 2.7066 (2.5714)	grad_norm 3.5403 (2.9302)	mem 17417MB
[2023-02-02 22:39:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][850/1251]	eta 0:03:49 lr 0.000017	time 0.6134 (0.5711)	loss 2.0503 (2.5665)	grad_norm 2.8432 (2.9241)	mem 17417MB
[2023-02-02 22:40:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][900/1251]	eta 0:03:20 lr 0.000017	time 0.6215 (0.5710)	loss 3.0240 (2.5706)	grad_norm 2.7997 (2.9179)	mem 17417MB
[2023-02-02 22:40:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][950/1251]	eta 0:02:51 lr 0.000017	time 0.5514 (0.5709)	loss 2.4251 (2.5672)	grad_norm 2.5769 (2.9179)	mem 17417MB
[2023-02-02 22:41:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][1000/1251]	eta 0:02:23 lr 0.000017	time 0.6223 (0.5710)	loss 2.3511 (2.5667)	grad_norm 2.8511 (2.9167)	mem 17417MB
[2023-02-02 22:41:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][1050/1251]	eta 0:01:54 lr 0.000017	time 0.5574 (0.5709)	loss 2.5523 (2.5687)	grad_norm 2.8765 (2.9167)	mem 17417MB
[2023-02-02 22:41:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][1100/1251]	eta 0:01:26 lr 0.000017	time 0.5542 (0.5708)	loss 1.8677 (2.5660)	grad_norm 2.5350 (2.9125)	mem 17417MB
[2023-02-02 22:42:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][1150/1251]	eta 0:00:57 lr 0.000017	time 0.5604 (0.5709)	loss 2.7946 (2.5675)	grad_norm 3.0762 (2.9137)	mem 17417MB
[2023-02-02 22:42:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][1200/1251]	eta 0:00:29 lr 0.000017	time 0.5578 (0.5708)	loss 2.9942 (2.5665)	grad_norm 2.6760 (2.9139)	mem 17417MB
[2023-02-02 22:43:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [283/300][1250/1251]	eta 0:00:00 lr 0.000017	time 0.5499 (0.5708)	loss 2.2395 (2.5684)	grad_norm 2.7565 (2.9167)	mem 17417MB
[2023-02-02 22:43:23 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 283 training takes 0:11:54
[2023-02-02 22:43:23 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_283.pth saving......
[2023-02-02 22:43:25 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_283.pth saved !!!
[2023-02-02 22:43:25 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.858 (0.858)	Loss 0.6710 (0.6710)	Acc@1 84.863 (84.863)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-02 22:43:33 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.882 Acc@5 96.716
[2023-02-02 22:43:33 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-02 22:43:35 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.393 (1.393)	Loss 0.6745 (0.6745)	Acc@1 84.180 (84.180)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-02 22:43:42 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.946 Acc@5 96.816
[2023-02-02 22:43:42 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 22:43:42 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 22:43:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][0/1251]	eta 0:34:38 lr 0.000017	time 1.6615 (1.6615)	loss 3.1335 (3.1335)	grad_norm 2.4866 (2.4866)	mem 17417MB
[2023-02-02 22:44:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][50/1251]	eta 0:11:55 lr 0.000017	time 0.5559 (0.5955)	loss 2.0923 (2.5277)	grad_norm 2.7419 (inf)	mem 17417MB
[2023-02-02 22:44:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][100/1251]	eta 0:11:10 lr 0.000017	time 0.6255 (0.5828)	loss 2.7147 (2.5572)	grad_norm 2.6483 (inf)	mem 17417MB
[2023-02-02 22:45:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][150/1251]	eta 0:10:37 lr 0.000017	time 0.5559 (0.5787)	loss 2.8685 (2.5674)	grad_norm 2.9515 (inf)	mem 17417MB
[2023-02-02 22:45:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][200/1251]	eta 0:10:05 lr 0.000017	time 0.5582 (0.5760)	loss 2.0082 (2.5767)	grad_norm 2.9939 (inf)	mem 17417MB
[2023-02-02 22:46:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][250/1251]	eta 0:09:35 lr 0.000017	time 0.5502 (0.5745)	loss 2.9658 (2.5539)	grad_norm 2.9583 (inf)	mem 17417MB
[2023-02-02 22:46:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][300/1251]	eta 0:09:05 lr 0.000017	time 0.5547 (0.5737)	loss 2.3803 (2.5600)	grad_norm 3.0385 (inf)	mem 17417MB
[2023-02-02 22:47:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][350/1251]	eta 0:08:36 lr 0.000017	time 0.5507 (0.5731)	loss 2.7893 (2.5528)	grad_norm 3.1679 (inf)	mem 17417MB
[2023-02-02 22:47:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][400/1251]	eta 0:08:07 lr 0.000017	time 0.5780 (0.5725)	loss 1.8419 (2.5507)	grad_norm 2.6288 (inf)	mem 17417MB
[2023-02-02 22:48:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][450/1251]	eta 0:07:38 lr 0.000017	time 0.6079 (0.5720)	loss 2.7561 (2.5579)	grad_norm 3.3189 (inf)	mem 17417MB
[2023-02-02 22:48:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][500/1251]	eta 0:07:09 lr 0.000017	time 0.6226 (0.5716)	loss 1.9824 (2.5581)	grad_norm 2.6404 (inf)	mem 17417MB
[2023-02-02 22:48:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][550/1251]	eta 0:06:40 lr 0.000017	time 0.5498 (0.5714)	loss 2.2062 (2.5683)	grad_norm 3.2932 (inf)	mem 17417MB
[2023-02-02 22:49:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][600/1251]	eta 0:06:12 lr 0.000017	time 0.5540 (0.5717)	loss 2.4544 (2.5669)	grad_norm 2.9473 (inf)	mem 17417MB
[2023-02-02 22:49:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][650/1251]	eta 0:05:43 lr 0.000016	time 0.5548 (0.5713)	loss 1.7859 (2.5646)	grad_norm 2.4604 (inf)	mem 17417MB
[2023-02-02 22:50:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][700/1251]	eta 0:05:14 lr 0.000016	time 0.5477 (0.5714)	loss 2.3268 (2.5685)	grad_norm 2.6782 (inf)	mem 17417MB
[2023-02-02 22:50:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][750/1251]	eta 0:04:46 lr 0.000016	time 0.5567 (0.5711)	loss 2.5668 (2.5705)	grad_norm 3.4137 (inf)	mem 17417MB
[2023-02-02 22:51:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][800/1251]	eta 0:04:17 lr 0.000016	time 0.5653 (0.5713)	loss 1.9053 (2.5631)	grad_norm 2.7779 (inf)	mem 17417MB
[2023-02-02 22:51:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][850/1251]	eta 0:03:48 lr 0.000016	time 0.5525 (0.5711)	loss 2.7229 (2.5683)	grad_norm 3.4422 (inf)	mem 17417MB
[2023-02-02 22:52:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][900/1251]	eta 0:03:20 lr 0.000016	time 0.6384 (0.5710)	loss 2.8415 (2.5706)	grad_norm 2.6087 (inf)	mem 17417MB
[2023-02-02 22:52:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][950/1251]	eta 0:02:51 lr 0.000016	time 0.5532 (0.5709)	loss 3.0063 (2.5734)	grad_norm 2.8560 (inf)	mem 17417MB
[2023-02-02 22:53:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][1000/1251]	eta 0:02:23 lr 0.000016	time 0.5568 (0.5709)	loss 2.7646 (2.5728)	grad_norm 2.7369 (inf)	mem 17417MB
[2023-02-02 22:53:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][1050/1251]	eta 0:01:54 lr 0.000016	time 0.5573 (0.5706)	loss 2.0353 (2.5713)	grad_norm 2.7656 (inf)	mem 17417MB
[2023-02-02 22:54:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][1100/1251]	eta 0:01:26 lr 0.000016	time 0.5531 (0.5706)	loss 3.0146 (2.5729)	grad_norm 2.7253 (inf)	mem 17417MB
[2023-02-02 22:54:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][1150/1251]	eta 0:00:57 lr 0.000016	time 0.5547 (0.5706)	loss 2.8327 (2.5708)	grad_norm 2.7086 (inf)	mem 17417MB
[2023-02-02 22:55:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][1200/1251]	eta 0:00:29 lr 0.000016	time 0.5523 (0.5704)	loss 2.7353 (2.5722)	grad_norm 2.5744 (inf)	mem 17417MB
[2023-02-02 22:55:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [284/300][1250/1251]	eta 0:00:00 lr 0.000016	time 0.6381 (0.5704)	loss 3.0796 (2.5674)	grad_norm 3.3645 (inf)	mem 17417MB
[2023-02-02 22:55:36 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 284 training takes 0:11:53
[2023-02-02 22:55:36 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_284.pth saving......
[2023-02-02 22:55:38 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_284.pth saved !!!
[2023-02-02 22:55:39 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.867 (0.867)	Loss 0.6318 (0.6318)	Acc@1 85.938 (85.938)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-02 22:55:47 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.804 Acc@5 96.710
[2023-02-02 22:55:47 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.8%
[2023-02-02 22:55:48 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.227 (1.227)	Loss 0.6051 (0.6051)	Acc@1 86.328 (86.328)	Acc@5 97.363 (97.363)	Mem 17417MB
[2023-02-02 22:55:56 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.942 Acc@5 96.806
[2023-02-02 22:55:56 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 22:55:56 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 22:55:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][0/1251]	eta 0:36:51 lr 0.000016	time 1.7678 (1.7678)	loss 2.5863 (2.5863)	grad_norm 3.2679 (3.2679)	mem 17417MB
[2023-02-02 22:56:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][50/1251]	eta 0:11:58 lr 0.000016	time 0.5532 (0.5986)	loss 2.5512 (2.5778)	grad_norm 3.2333 (2.9368)	mem 17417MB
[2023-02-02 22:56:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][100/1251]	eta 0:11:10 lr 0.000016	time 0.5544 (0.5828)	loss 2.7093 (2.5665)	grad_norm 3.2358 (2.8894)	mem 17417MB
[2023-02-02 22:57:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][150/1251]	eta 0:10:37 lr 0.000016	time 0.5616 (0.5787)	loss 2.9050 (2.5582)	grad_norm 3.1154 (2.9316)	mem 17417MB
[2023-02-02 22:57:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][200/1251]	eta 0:10:05 lr 0.000016	time 0.5530 (0.5759)	loss 2.2622 (2.5521)	grad_norm 2.8918 (2.9332)	mem 17417MB
[2023-02-02 22:58:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][250/1251]	eta 0:09:35 lr 0.000016	time 0.6260 (0.5750)	loss 2.0106 (2.5562)	grad_norm 2.6360 (2.9213)	mem 17417MB
[2023-02-02 22:58:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][300/1251]	eta 0:09:05 lr 0.000016	time 0.5526 (0.5732)	loss 1.7577 (2.5521)	grad_norm 2.5481 (2.9292)	mem 17417MB
[2023-02-02 22:59:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][350/1251]	eta 0:08:35 lr 0.000016	time 0.5540 (0.5724)	loss 2.8997 (2.5683)	grad_norm 2.8604 (2.9228)	mem 17417MB
[2023-02-02 22:59:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][400/1251]	eta 0:08:06 lr 0.000016	time 0.5516 (0.5723)	loss 2.2991 (2.5720)	grad_norm 2.9896 (2.9190)	mem 17417MB
[2023-02-02 23:00:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][450/1251]	eta 0:07:38 lr 0.000016	time 0.6154 (0.5719)	loss 2.8842 (2.5607)	grad_norm 3.1548 (2.9345)	mem 17417MB
[2023-02-02 23:00:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][500/1251]	eta 0:07:09 lr 0.000016	time 0.5575 (0.5715)	loss 2.5318 (2.5566)	grad_norm 2.4862 (2.9248)	mem 17417MB
[2023-02-02 23:01:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][550/1251]	eta 0:06:40 lr 0.000016	time 0.5593 (0.5710)	loss 2.6838 (2.5602)	grad_norm 3.0076 (2.9267)	mem 17417MB
[2023-02-02 23:01:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][600/1251]	eta 0:06:11 lr 0.000016	time 0.5533 (0.5711)	loss 2.8940 (2.5558)	grad_norm 2.5341 (2.9270)	mem 17417MB
[2023-02-02 23:02:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][650/1251]	eta 0:05:43 lr 0.000016	time 0.5532 (0.5709)	loss 2.8838 (2.5565)	grad_norm 3.3573 (2.9284)	mem 17417MB
[2023-02-02 23:02:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][700/1251]	eta 0:05:14 lr 0.000016	time 0.5554 (0.5708)	loss 3.4366 (2.5579)	grad_norm 2.5643 (2.9234)	mem 17417MB
[2023-02-02 23:03:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][750/1251]	eta 0:04:45 lr 0.000016	time 0.5538 (0.5708)	loss 3.0527 (2.5644)	grad_norm 3.0507 (2.9210)	mem 17417MB
[2023-02-02 23:03:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][800/1251]	eta 0:04:17 lr 0.000016	time 0.6201 (0.5706)	loss 2.7320 (2.5713)	grad_norm 2.9513 (2.9219)	mem 17417MB
[2023-02-02 23:04:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][850/1251]	eta 0:03:48 lr 0.000016	time 0.5575 (0.5705)	loss 3.1861 (2.5696)	grad_norm 3.1875 (nan)	mem 17417MB
[2023-02-02 23:04:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][900/1251]	eta 0:03:20 lr 0.000016	time 0.5501 (0.5706)	loss 2.5942 (2.5673)	grad_norm 2.7693 (nan)	mem 17417MB
[2023-02-02 23:04:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][950/1251]	eta 0:02:51 lr 0.000015	time 0.5596 (0.5706)	loss 1.7222 (2.5700)	grad_norm 3.0261 (nan)	mem 17417MB
[2023-02-02 23:05:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][1000/1251]	eta 0:02:23 lr 0.000015	time 0.5571 (0.5707)	loss 1.9773 (2.5724)	grad_norm 3.1773 (nan)	mem 17417MB
[2023-02-02 23:05:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][1050/1251]	eta 0:01:54 lr 0.000015	time 0.5561 (0.5705)	loss 2.6215 (2.5742)	grad_norm 3.7379 (nan)	mem 17417MB
[2023-02-02 23:06:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][1100/1251]	eta 0:01:26 lr 0.000015	time 0.6313 (0.5705)	loss 1.5809 (2.5760)	grad_norm 3.1586 (nan)	mem 17417MB
[2023-02-02 23:06:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][1150/1251]	eta 0:00:57 lr 0.000015	time 0.5568 (0.5703)	loss 2.8247 (2.5731)	grad_norm 2.9361 (nan)	mem 17417MB
[2023-02-02 23:07:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][1200/1251]	eta 0:00:29 lr 0.000015	time 0.6142 (0.5702)	loss 3.1296 (2.5759)	grad_norm 3.0914 (nan)	mem 17417MB
[2023-02-02 23:07:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [285/300][1250/1251]	eta 0:00:00 lr 0.000015	time 0.6211 (0.5701)	loss 2.3677 (2.5755)	grad_norm 3.3151 (nan)	mem 17417MB
[2023-02-02 23:07:49 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 285 training takes 0:11:53
[2023-02-02 23:07:50 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_285.pth saving......
[2023-02-02 23:07:51 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_285.pth saved !!!
[2023-02-02 23:07:52 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.871 (0.871)	Loss 0.6623 (0.6623)	Acc@1 83.398 (83.398)	Acc@5 97.461 (97.461)	Mem 17417MB
[2023-02-02 23:08:00 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.850 Acc@5 96.704
[2023-02-02 23:08:00 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-02 23:08:01 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.288 (1.288)	Loss 0.7057 (0.7057)	Acc@1 84.180 (84.180)	Acc@5 95.996 (95.996)	Mem 17417MB
[2023-02-02 23:08:09 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.938 Acc@5 96.802
[2023-02-02 23:08:09 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 23:08:09 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 23:08:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][0/1251]	eta 0:34:40 lr 0.000015	time 1.6634 (1.6634)	loss 2.7056 (2.7056)	grad_norm 2.8884 (2.8884)	mem 17417MB
[2023-02-02 23:08:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][50/1251]	eta 0:11:54 lr 0.000015	time 0.6486 (0.5949)	loss 2.1678 (2.5686)	grad_norm 2.9218 (2.9103)	mem 17417MB
[2023-02-02 23:09:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][100/1251]	eta 0:11:08 lr 0.000015	time 0.5572 (0.5810)	loss 2.2892 (2.5776)	grad_norm 2.7550 (2.8946)	mem 17417MB
[2023-02-02 23:09:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][150/1251]	eta 0:10:36 lr 0.000015	time 0.5627 (0.5777)	loss 2.9267 (2.5808)	grad_norm 3.1170 (2.9168)	mem 17417MB
[2023-02-02 23:10:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][200/1251]	eta 0:10:04 lr 0.000015	time 0.5522 (0.5755)	loss 2.8570 (2.5785)	grad_norm 3.3234 (2.9091)	mem 17417MB
[2023-02-02 23:10:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][250/1251]	eta 0:09:34 lr 0.000015	time 0.6166 (0.5742)	loss 2.8214 (2.5865)	grad_norm 2.5242 (2.9191)	mem 17417MB
[2023-02-02 23:11:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][300/1251]	eta 0:09:05 lr 0.000015	time 0.6063 (0.5737)	loss 2.8173 (2.5808)	grad_norm 2.7367 (2.9342)	mem 17417MB
[2023-02-02 23:11:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][350/1251]	eta 0:08:35 lr 0.000015	time 0.5637 (0.5725)	loss 1.9378 (2.5712)	grad_norm 2.9485 (2.9414)	mem 17417MB
[2023-02-02 23:11:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][400/1251]	eta 0:08:07 lr 0.000015	time 0.5581 (0.5724)	loss 2.6886 (2.5719)	grad_norm 2.6680 (2.9422)	mem 17417MB
[2023-02-02 23:12:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][450/1251]	eta 0:07:38 lr 0.000015	time 0.5520 (0.5719)	loss 3.2149 (2.5719)	grad_norm 3.2094 (2.9363)	mem 17417MB
[2023-02-02 23:12:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][500/1251]	eta 0:07:09 lr 0.000015	time 0.5637 (0.5715)	loss 2.6499 (2.5750)	grad_norm 2.8719 (2.9259)	mem 17417MB
[2023-02-02 23:13:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][550/1251]	eta 0:06:40 lr 0.000015	time 0.5653 (0.5712)	loss 3.1577 (2.5771)	grad_norm 2.6553 (2.9278)	mem 17417MB
[2023-02-02 23:13:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][600/1251]	eta 0:06:11 lr 0.000015	time 0.5597 (0.5711)	loss 2.6005 (2.5789)	grad_norm 2.9024 (2.9252)	mem 17417MB
[2023-02-02 23:14:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][650/1251]	eta 0:05:43 lr 0.000015	time 0.5550 (0.5710)	loss 2.9003 (2.5820)	grad_norm 3.2204 (2.9206)	mem 17417MB
[2023-02-02 23:14:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][700/1251]	eta 0:05:14 lr 0.000015	time 0.5575 (0.5708)	loss 2.4544 (2.5780)	grad_norm 3.7244 (2.9155)	mem 17417MB
[2023-02-02 23:15:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][750/1251]	eta 0:04:45 lr 0.000015	time 0.5619 (0.5707)	loss 2.6301 (2.5822)	grad_norm 3.6461 (2.9185)	mem 17417MB
[2023-02-02 23:15:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][800/1251]	eta 0:04:17 lr 0.000015	time 0.6175 (0.5707)	loss 2.1414 (2.5841)	grad_norm 2.7677 (2.9207)	mem 17417MB
[2023-02-02 23:16:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][850/1251]	eta 0:03:48 lr 0.000015	time 0.5522 (0.5706)	loss 2.4931 (2.5834)	grad_norm 3.1982 (2.9244)	mem 17417MB
[2023-02-02 23:16:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][900/1251]	eta 0:03:20 lr 0.000015	time 0.5509 (0.5705)	loss 2.9551 (2.5907)	grad_norm 2.5135 (2.9201)	mem 17417MB
[2023-02-02 23:17:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][950/1251]	eta 0:02:51 lr 0.000015	time 0.5523 (0.5705)	loss 3.0641 (2.5877)	grad_norm 2.6193 (2.9164)	mem 17417MB
[2023-02-02 23:17:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][1000/1251]	eta 0:02:23 lr 0.000015	time 0.5535 (0.5706)	loss 2.5886 (2.5862)	grad_norm 2.7193 (2.9139)	mem 17417MB
[2023-02-02 23:18:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][1050/1251]	eta 0:01:54 lr 0.000015	time 0.5573 (0.5705)	loss 1.7890 (2.5869)	grad_norm 2.5396 (2.9141)	mem 17417MB
[2023-02-02 23:18:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][1100/1251]	eta 0:01:26 lr 0.000015	time 0.5553 (0.5705)	loss 1.8898 (2.5860)	grad_norm 3.2151 (2.9148)	mem 17417MB
[2023-02-02 23:19:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][1150/1251]	eta 0:00:57 lr 0.000015	time 0.5619 (0.5703)	loss 2.2457 (2.5842)	grad_norm 3.0858 (2.9182)	mem 17417MB
[2023-02-02 23:19:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][1200/1251]	eta 0:00:29 lr 0.000015	time 0.5522 (0.5704)	loss 2.7137 (2.5827)	grad_norm 3.3060 (2.9218)	mem 17417MB
[2023-02-02 23:20:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [286/300][1250/1251]	eta 0:00:00 lr 0.000015	time 0.5477 (0.5703)	loss 3.1052 (2.5829)	grad_norm 3.8464 (2.9250)	mem 17417MB
[2023-02-02 23:20:03 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 286 training takes 0:11:53
[2023-02-02 23:20:03 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_286.pth saving......
[2023-02-02 23:20:05 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_286.pth saved !!!
[2023-02-02 23:20:06 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.891 (0.891)	Loss 0.6752 (0.6752)	Acc@1 83.594 (83.594)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-02 23:20:14 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.930 Acc@5 96.760
[2023-02-02 23:20:14 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-02 23:20:15 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.574 (1.574)	Loss 0.7090 (0.7090)	Acc@1 84.277 (84.277)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-02 23:20:23 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.932 Acc@5 96.796
[2023-02-02 23:20:23 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 23:20:23 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 23:20:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][0/1251]	eta 0:36:08 lr 0.000015	time 1.7337 (1.7337)	loss 2.1282 (2.1282)	grad_norm 2.4692 (2.4692)	mem 17417MB
[2023-02-02 23:20:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][50/1251]	eta 0:11:51 lr 0.000015	time 0.6354 (0.5923)	loss 2.8055 (2.6761)	grad_norm 3.6016 (2.9700)	mem 17417MB
[2023-02-02 23:21:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][100/1251]	eta 0:11:10 lr 0.000015	time 0.6366 (0.5824)	loss 2.9317 (2.5789)	grad_norm 4.0957 (2.9529)	mem 17417MB
[2023-02-02 23:21:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][150/1251]	eta 0:10:34 lr 0.000014	time 0.5521 (0.5766)	loss 2.3691 (2.5633)	grad_norm 2.4954 (2.9347)	mem 17417MB
[2023-02-02 23:22:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][200/1251]	eta 0:10:04 lr 0.000014	time 0.5501 (0.5753)	loss 2.8734 (2.5787)	grad_norm 2.8347 (2.9527)	mem 17417MB
[2023-02-02 23:22:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][250/1251]	eta 0:09:32 lr 0.000014	time 0.5569 (0.5721)	loss 2.7403 (2.5779)	grad_norm 3.8178 (2.9644)	mem 17417MB
[2023-02-02 23:23:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][300/1251]	eta 0:09:03 lr 0.000014	time 0.5669 (0.5718)	loss 2.9626 (2.5745)	grad_norm 3.5196 (2.9754)	mem 17417MB
[2023-02-02 23:23:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][350/1251]	eta 0:08:34 lr 0.000014	time 0.5563 (0.5710)	loss 2.9200 (2.5749)	grad_norm 3.1878 (2.9722)	mem 17417MB
[2023-02-02 23:24:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][400/1251]	eta 0:08:05 lr 0.000014	time 0.5502 (0.5710)	loss 2.4392 (2.5837)	grad_norm 3.1496 (2.9698)	mem 17417MB
[2023-02-02 23:24:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][450/1251]	eta 0:07:37 lr 0.000014	time 0.5522 (0.5707)	loss 2.4793 (2.5877)	grad_norm 3.5164 (inf)	mem 17417MB
[2023-02-02 23:25:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][500/1251]	eta 0:07:08 lr 0.000014	time 0.6108 (0.5705)	loss 2.9656 (2.5960)	grad_norm 2.5323 (inf)	mem 17417MB
[2023-02-02 23:25:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][550/1251]	eta 0:06:39 lr 0.000014	time 0.5520 (0.5702)	loss 2.7446 (2.5991)	grad_norm 3.0776 (inf)	mem 17417MB
[2023-02-02 23:26:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][600/1251]	eta 0:06:11 lr 0.000014	time 0.5548 (0.5705)	loss 2.4202 (2.5972)	grad_norm 2.5293 (inf)	mem 17417MB
[2023-02-02 23:26:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][650/1251]	eta 0:05:42 lr 0.000014	time 0.5614 (0.5700)	loss 2.6503 (2.5928)	grad_norm 2.6354 (inf)	mem 17417MB
[2023-02-02 23:27:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][700/1251]	eta 0:05:14 lr 0.000014	time 0.5536 (0.5701)	loss 2.6369 (2.5982)	grad_norm 3.2959 (inf)	mem 17417MB
[2023-02-02 23:27:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][750/1251]	eta 0:04:45 lr 0.000014	time 0.5602 (0.5699)	loss 3.0185 (2.5967)	grad_norm 3.0535 (inf)	mem 17417MB
[2023-02-02 23:28:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][800/1251]	eta 0:04:17 lr 0.000014	time 0.5467 (0.5700)	loss 2.8017 (2.5984)	grad_norm 3.0921 (inf)	mem 17417MB
[2023-02-02 23:28:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][850/1251]	eta 0:03:48 lr 0.000014	time 0.5526 (0.5700)	loss 2.5492 (2.5888)	grad_norm 2.6031 (inf)	mem 17417MB
[2023-02-02 23:28:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][900/1251]	eta 0:03:20 lr 0.000014	time 0.5558 (0.5699)	loss 2.6417 (2.5871)	grad_norm 2.6950 (inf)	mem 17417MB
[2023-02-02 23:29:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][950/1251]	eta 0:02:51 lr 0.000014	time 0.5614 (0.5696)	loss 2.1549 (2.5871)	grad_norm 2.8744 (inf)	mem 17417MB
[2023-02-02 23:29:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][1000/1251]	eta 0:02:22 lr 0.000014	time 0.5536 (0.5697)	loss 2.7441 (2.5815)	grad_norm 2.9921 (inf)	mem 17417MB
[2023-02-02 23:30:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][1050/1251]	eta 0:01:54 lr 0.000014	time 0.5686 (0.5693)	loss 2.7702 (2.5778)	grad_norm 2.9756 (inf)	mem 17417MB
[2023-02-02 23:30:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][1100/1251]	eta 0:01:25 lr 0.000014	time 0.6313 (0.5694)	loss 2.6721 (2.5746)	grad_norm 2.7310 (inf)	mem 17417MB
[2023-02-02 23:31:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][1150/1251]	eta 0:00:57 lr 0.000014	time 0.5529 (0.5694)	loss 2.8713 (2.5759)	grad_norm 2.6799 (inf)	mem 17417MB
[2023-02-02 23:31:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][1200/1251]	eta 0:00:29 lr 0.000014	time 0.5508 (0.5693)	loss 2.0738 (2.5790)	grad_norm 2.7367 (inf)	mem 17417MB
[2023-02-02 23:32:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [287/300][1250/1251]	eta 0:00:00 lr 0.000014	time 0.5518 (0.5694)	loss 2.5952 (2.5800)	grad_norm 3.4591 (inf)	mem 17417MB
[2023-02-02 23:32:16 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 287 training takes 0:11:52
[2023-02-02 23:32:16 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_287.pth saving......
[2023-02-02 23:32:18 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_287.pth saved !!!
[2023-02-02 23:32:19 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.847 (0.847)	Loss 0.6924 (0.6924)	Acc@1 84.277 (84.277)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-02 23:32:26 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.870 Acc@5 96.754
[2023-02-02 23:32:26 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-02 23:32:28 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.158 (1.158)	Loss 0.7450 (0.7450)	Acc@1 83.496 (83.496)	Acc@5 95.215 (95.215)	Mem 17417MB
[2023-02-02 23:32:36 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.948 Acc@5 96.790
[2023-02-02 23:32:36 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 23:32:36 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 23:32:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][0/1251]	eta 0:33:48 lr 0.000014	time 1.6216 (1.6216)	loss 2.1665 (2.1665)	grad_norm 2.8129 (2.8129)	mem 17417MB
[2023-02-02 23:33:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][50/1251]	eta 0:11:52 lr 0.000014	time 0.5567 (0.5936)	loss 2.4697 (2.5318)	grad_norm 3.0916 (2.9401)	mem 17417MB
[2023-02-02 23:33:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][100/1251]	eta 0:11:09 lr 0.000014	time 0.5507 (0.5818)	loss 2.2624 (2.5370)	grad_norm 2.7084 (2.9214)	mem 17417MB
[2023-02-02 23:34:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][150/1251]	eta 0:10:35 lr 0.000014	time 0.5478 (0.5772)	loss 2.9966 (2.5681)	grad_norm 2.6967 (2.9257)	mem 17417MB
[2023-02-02 23:34:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][200/1251]	eta 0:10:03 lr 0.000014	time 0.5563 (0.5740)	loss 2.7091 (2.5536)	grad_norm 3.2051 (2.9253)	mem 17417MB
[2023-02-02 23:34:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][250/1251]	eta 0:09:33 lr 0.000014	time 0.5620 (0.5727)	loss 2.9159 (2.5675)	grad_norm 2.7391 (2.9252)	mem 17417MB
[2023-02-02 23:35:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][300/1251]	eta 0:09:04 lr 0.000014	time 0.5561 (0.5723)	loss 2.4906 (2.5551)	grad_norm 2.9849 (2.9126)	mem 17417MB
[2023-02-02 23:35:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][350/1251]	eta 0:08:35 lr 0.000014	time 0.5638 (0.5718)	loss 2.7565 (2.5513)	grad_norm 2.8996 (2.9128)	mem 17417MB
[2023-02-02 23:36:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][400/1251]	eta 0:08:06 lr 0.000014	time 0.5627 (0.5713)	loss 2.8074 (2.5508)	grad_norm 2.5620 (2.9350)	mem 17417MB
[2023-02-02 23:36:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][450/1251]	eta 0:07:37 lr 0.000014	time 0.5632 (0.5711)	loss 2.7798 (2.5593)	grad_norm 2.8377 (2.9381)	mem 17417MB
[2023-02-02 23:37:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][500/1251]	eta 0:07:08 lr 0.000014	time 0.5555 (0.5707)	loss 1.7701 (2.5536)	grad_norm 2.8542 (2.9375)	mem 17417MB
[2023-02-02 23:37:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][550/1251]	eta 0:06:39 lr 0.000014	time 0.5589 (0.5706)	loss 3.1928 (2.5563)	grad_norm 2.6230 (2.9366)	mem 17417MB
[2023-02-02 23:38:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][600/1251]	eta 0:06:11 lr 0.000014	time 0.5916 (0.5706)	loss 2.8674 (2.5620)	grad_norm 2.8410 (2.9320)	mem 17417MB
[2023-02-02 23:38:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][650/1251]	eta 0:05:42 lr 0.000014	time 0.5492 (0.5705)	loss 2.2986 (2.5692)	grad_norm 3.8015 (2.9359)	mem 17417MB
[2023-02-02 23:39:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][700/1251]	eta 0:05:14 lr 0.000014	time 0.5616 (0.5705)	loss 3.0237 (2.5656)	grad_norm 2.3472 (2.9377)	mem 17417MB
[2023-02-02 23:39:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][750/1251]	eta 0:04:45 lr 0.000014	time 0.5563 (0.5700)	loss 2.5812 (2.5667)	grad_norm 3.2497 (2.9409)	mem 17417MB
[2023-02-02 23:40:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][800/1251]	eta 0:04:17 lr 0.000013	time 0.5533 (0.5700)	loss 1.7734 (2.5673)	grad_norm 2.6583 (2.9394)	mem 17417MB
[2023-02-02 23:40:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][850/1251]	eta 0:03:48 lr 0.000013	time 0.5479 (0.5698)	loss 2.1207 (2.5679)	grad_norm 2.8443 (2.9384)	mem 17417MB
[2023-02-02 23:41:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][900/1251]	eta 0:03:20 lr 0.000013	time 0.6116 (0.5699)	loss 2.6201 (2.5727)	grad_norm 3.3889 (2.9379)	mem 17417MB
[2023-02-02 23:41:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][950/1251]	eta 0:02:51 lr 0.000013	time 0.5689 (0.5697)	loss 2.9848 (2.5755)	grad_norm 3.1072 (2.9413)	mem 17417MB
[2023-02-02 23:42:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][1000/1251]	eta 0:02:23 lr 0.000013	time 0.6093 (0.5698)	loss 2.2630 (2.5665)	grad_norm 3.0430 (2.9375)	mem 17417MB
[2023-02-02 23:42:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][1050/1251]	eta 0:01:54 lr 0.000013	time 0.5497 (0.5696)	loss 2.0284 (2.5654)	grad_norm 2.7400 (2.9378)	mem 17417MB
[2023-02-02 23:43:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][1100/1251]	eta 0:01:26 lr 0.000013	time 0.6220 (0.5697)	loss 2.6878 (2.5686)	grad_norm 3.3018 (2.9404)	mem 17417MB
[2023-02-02 23:43:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][1150/1251]	eta 0:00:57 lr 0.000013	time 0.5539 (0.5696)	loss 1.7106 (2.5644)	grad_norm 2.7966 (inf)	mem 17417MB
[2023-02-02 23:44:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][1200/1251]	eta 0:00:29 lr 0.000013	time 0.6335 (0.5696)	loss 2.2656 (2.5654)	grad_norm 2.8700 (inf)	mem 17417MB
[2023-02-02 23:44:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [288/300][1250/1251]	eta 0:00:00 lr 0.000013	time 0.5489 (0.5697)	loss 2.3773 (2.5663)	grad_norm 2.8324 (inf)	mem 17417MB
[2023-02-02 23:44:28 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 288 training takes 0:11:52
[2023-02-02 23:44:29 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_288.pth saving......
[2023-02-02 23:44:30 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_288.pth saved !!!
[2023-02-02 23:44:31 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.852 (0.852)	Loss 0.7803 (0.7803)	Acc@1 83.301 (83.301)	Acc@5 96.191 (96.191)	Mem 17417MB
[2023-02-02 23:44:39 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.944 Acc@5 96.708
[2023-02-02 23:44:39 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-02 23:44:40 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.183 (1.183)	Loss 0.6624 (0.6624)	Acc@1 84.961 (84.961)	Acc@5 96.973 (96.973)	Mem 17417MB
[2023-02-02 23:44:48 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.948 Acc@5 96.786
[2023-02-02 23:44:48 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-02 23:44:48 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 23:44:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][0/1251]	eta 0:36:46 lr 0.000013	time 1.7639 (1.7639)	loss 2.4495 (2.4495)	grad_norm 3.1114 (3.1114)	mem 17417MB
[2023-02-02 23:45:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][50/1251]	eta 0:11:53 lr 0.000013	time 0.5543 (0.5937)	loss 2.0923 (2.4594)	grad_norm 2.9263 (2.8887)	mem 17417MB
[2023-02-02 23:45:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][100/1251]	eta 0:11:11 lr 0.000013	time 0.5596 (0.5838)	loss 2.0780 (2.4915)	grad_norm 2.7479 (2.9032)	mem 17417MB
[2023-02-02 23:46:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][150/1251]	eta 0:10:37 lr 0.000013	time 0.5567 (0.5790)	loss 2.7251 (2.5133)	grad_norm 2.4844 (2.9556)	mem 17417MB
[2023-02-02 23:46:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][200/1251]	eta 0:10:05 lr 0.000013	time 0.5583 (0.5760)	loss 1.9017 (2.5235)	grad_norm 3.2334 (2.9354)	mem 17417MB
[2023-02-02 23:47:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][250/1251]	eta 0:09:35 lr 0.000013	time 0.6264 (0.5751)	loss 2.2170 (2.5531)	grad_norm 3.0251 (2.9101)	mem 17417MB
[2023-02-02 23:47:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][300/1251]	eta 0:09:05 lr 0.000013	time 0.5831 (0.5738)	loss 2.5394 (2.5556)	grad_norm 2.4853 (2.9164)	mem 17417MB
[2023-02-02 23:48:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][350/1251]	eta 0:08:35 lr 0.000013	time 0.5726 (0.5726)	loss 2.6176 (2.5482)	grad_norm 2.4342 (2.9091)	mem 17417MB
[2023-02-02 23:48:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][400/1251]	eta 0:08:06 lr 0.000013	time 0.5500 (0.5722)	loss 2.6786 (2.5452)	grad_norm 2.6063 (2.9180)	mem 17417MB
[2023-02-02 23:49:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][450/1251]	eta 0:07:37 lr 0.000013	time 0.5527 (0.5717)	loss 1.7338 (2.5388)	grad_norm 2.8501 (2.9393)	mem 17417MB
[2023-02-02 23:49:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][500/1251]	eta 0:07:09 lr 0.000013	time 0.5558 (0.5715)	loss 2.8171 (2.5416)	grad_norm 3.1464 (2.9361)	mem 17417MB
[2023-02-02 23:50:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][550/1251]	eta 0:06:40 lr 0.000013	time 0.5559 (0.5713)	loss 2.5810 (2.5478)	grad_norm 3.2363 (2.9382)	mem 17417MB
[2023-02-02 23:50:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][600/1251]	eta 0:06:11 lr 0.000013	time 0.5503 (0.5707)	loss 2.7153 (2.5515)	grad_norm 2.5333 (2.9375)	mem 17417MB
[2023-02-02 23:51:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][650/1251]	eta 0:05:43 lr 0.000013	time 0.5688 (0.5709)	loss 2.6428 (2.5467)	grad_norm 2.9401 (2.9376)	mem 17417MB
[2023-02-02 23:51:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][700/1251]	eta 0:05:14 lr 0.000013	time 0.5535 (0.5705)	loss 2.8937 (2.5473)	grad_norm 2.7369 (2.9322)	mem 17417MB
[2023-02-02 23:51:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][750/1251]	eta 0:04:45 lr 0.000013	time 0.5567 (0.5702)	loss 2.7155 (2.5487)	grad_norm 2.8966 (2.9344)	mem 17417MB
[2023-02-02 23:52:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][800/1251]	eta 0:04:17 lr 0.000013	time 0.5497 (0.5700)	loss 3.0060 (2.5509)	grad_norm 2.5296 (2.9323)	mem 17417MB
[2023-02-02 23:52:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][850/1251]	eta 0:03:48 lr 0.000013	time 0.5560 (0.5698)	loss 2.4215 (2.5508)	grad_norm 2.8398 (2.9357)	mem 17417MB
[2023-02-02 23:53:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][900/1251]	eta 0:03:20 lr 0.000013	time 0.5527 (0.5698)	loss 2.0721 (2.5539)	grad_norm 2.8279 (2.9418)	mem 17417MB
[2023-02-02 23:53:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][950/1251]	eta 0:02:51 lr 0.000013	time 0.5629 (0.5698)	loss 2.5335 (2.5603)	grad_norm 3.0045 (2.9389)	mem 17417MB
[2023-02-02 23:54:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][1000/1251]	eta 0:02:22 lr 0.000013	time 0.5535 (0.5695)	loss 2.7116 (2.5596)	grad_norm 2.6105 (2.9375)	mem 17417MB
[2023-02-02 23:54:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][1050/1251]	eta 0:01:54 lr 0.000013	time 0.5542 (0.5697)	loss 2.3575 (2.5608)	grad_norm 2.6640 (2.9376)	mem 17417MB
[2023-02-02 23:55:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][1100/1251]	eta 0:01:26 lr 0.000013	time 0.5597 (0.5696)	loss 2.3308 (2.5597)	grad_norm 2.8477 (2.9381)	mem 17417MB
[2023-02-02 23:55:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][1150/1251]	eta 0:00:57 lr 0.000013	time 0.5671 (0.5696)	loss 1.8304 (2.5565)	grad_norm 3.2510 (2.9366)	mem 17417MB
[2023-02-02 23:56:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][1200/1251]	eta 0:00:29 lr 0.000013	time 0.5518 (0.5695)	loss 2.6923 (2.5579)	grad_norm 2.7798 (2.9376)	mem 17417MB
[2023-02-02 23:56:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [289/300][1250/1251]	eta 0:00:00 lr 0.000013	time 0.5489 (0.5695)	loss 2.8006 (2.5583)	grad_norm 2.7501 (2.9387)	mem 17417MB
[2023-02-02 23:56:41 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 289 training takes 0:11:52
[2023-02-02 23:56:41 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_289.pth saving......
[2023-02-02 23:56:43 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_289.pth saved !!!
[2023-02-02 23:56:44 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.883 (0.883)	Loss 0.6950 (0.6950)	Acc@1 83.789 (83.789)	Acc@5 97.461 (97.461)	Mem 17417MB
[2023-02-02 23:56:52 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.900 Acc@5 96.768
[2023-02-02 23:56:52 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-02 23:56:53 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.226 (1.226)	Loss 0.6605 (0.6605)	Acc@1 85.059 (85.059)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-02 23:57:01 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.968 Acc@5 96.782
[2023-02-02 23:57:01 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-02 23:57:01 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-02 23:57:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][0/1251]	eta 0:35:42 lr 0.000013	time 1.7122 (1.7122)	loss 2.7156 (2.7156)	grad_norm 3.2755 (3.2755)	mem 17417MB
[2023-02-02 23:57:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][50/1251]	eta 0:11:50 lr 0.000013	time 0.5522 (0.5919)	loss 2.1954 (2.5907)	grad_norm 3.2377 (2.9406)	mem 17417MB
[2023-02-02 23:58:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][100/1251]	eta 0:11:08 lr 0.000013	time 0.6310 (0.5805)	loss 1.8810 (2.5658)	grad_norm 3.0874 (2.9533)	mem 17417MB
[2023-02-02 23:58:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][150/1251]	eta 0:10:34 lr 0.000013	time 0.5598 (0.5761)	loss 3.0715 (2.5711)	grad_norm 2.6733 (2.9366)	mem 17417MB
[2023-02-02 23:58:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][200/1251]	eta 0:10:03 lr 0.000013	time 0.5541 (0.5746)	loss 1.5001 (2.5766)	grad_norm 2.7811 (2.9166)	mem 17417MB
[2023-02-02 23:59:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][250/1251]	eta 0:09:33 lr 0.000013	time 0.5560 (0.5732)	loss 2.8520 (2.5589)	grad_norm 2.8935 (2.9151)	mem 17417MB
[2023-02-02 23:59:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][300/1251]	eta 0:09:04 lr 0.000013	time 0.5813 (0.5724)	loss 2.1680 (2.5533)	grad_norm 2.7516 (2.9183)	mem 17417MB
[2023-02-03 00:00:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][350/1251]	eta 0:08:35 lr 0.000013	time 0.5538 (0.5718)	loss 2.6549 (2.5627)	grad_norm 2.9284 (2.9236)	mem 17417MB
[2023-02-03 00:00:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][400/1251]	eta 0:08:06 lr 0.000013	time 0.5533 (0.5711)	loss 1.8007 (2.5630)	grad_norm 3.1226 (2.9406)	mem 17417MB
[2023-02-03 00:01:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][450/1251]	eta 0:07:37 lr 0.000013	time 0.5550 (0.5709)	loss 3.1724 (2.5679)	grad_norm 2.9203 (2.9441)	mem 17417MB
[2023-02-03 00:01:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][500/1251]	eta 0:07:08 lr 0.000012	time 0.5564 (0.5703)	loss 2.6595 (2.5640)	grad_norm 3.2189 (2.9455)	mem 17417MB
[2023-02-03 00:02:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][550/1251]	eta 0:06:39 lr 0.000012	time 0.5565 (0.5700)	loss 2.7929 (2.5616)	grad_norm 3.3203 (2.9475)	mem 17417MB
[2023-02-03 00:02:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][600/1251]	eta 0:06:11 lr 0.000012	time 0.5600 (0.5700)	loss 2.9466 (2.5709)	grad_norm 2.5944 (2.9515)	mem 17417MB
[2023-02-03 00:03:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][650/1251]	eta 0:05:42 lr 0.000012	time 0.5497 (0.5698)	loss 2.8711 (2.5688)	grad_norm 3.3618 (2.9585)	mem 17417MB
[2023-02-03 00:03:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][700/1251]	eta 0:05:13 lr 0.000012	time 0.5584 (0.5696)	loss 2.1801 (2.5687)	grad_norm 2.6939 (2.9517)	mem 17417MB
[2023-02-03 00:04:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][750/1251]	eta 0:04:45 lr 0.000012	time 0.5581 (0.5695)	loss 2.1136 (2.5656)	grad_norm 2.6851 (2.9517)	mem 17417MB
[2023-02-03 00:04:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][800/1251]	eta 0:04:16 lr 0.000012	time 0.5615 (0.5693)	loss 2.8191 (2.5634)	grad_norm 2.8109 (2.9531)	mem 17417MB
[2023-02-03 00:05:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][850/1251]	eta 0:03:48 lr 0.000012	time 0.5585 (0.5696)	loss 3.1651 (2.5662)	grad_norm 3.1093 (2.9561)	mem 17417MB
[2023-02-03 00:05:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][900/1251]	eta 0:03:19 lr 0.000012	time 0.5524 (0.5693)	loss 3.2003 (2.5625)	grad_norm 2.8452 (2.9544)	mem 17417MB
[2023-02-03 00:06:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][950/1251]	eta 0:02:51 lr 0.000012	time 0.5558 (0.5694)	loss 2.0462 (2.5637)	grad_norm 2.5744 (2.9529)	mem 17417MB
[2023-02-03 00:06:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][1000/1251]	eta 0:02:22 lr 0.000012	time 0.5612 (0.5694)	loss 2.8311 (2.5622)	grad_norm 2.6109 (2.9473)	mem 17417MB
[2023-02-03 00:06:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][1050/1251]	eta 0:01:54 lr 0.000012	time 0.5653 (0.5695)	loss 2.7860 (2.5607)	grad_norm 2.8103 (2.9461)	mem 17417MB
[2023-02-03 00:07:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][1100/1251]	eta 0:01:25 lr 0.000012	time 0.5519 (0.5694)	loss 2.3005 (2.5597)	grad_norm 2.5938 (2.9466)	mem 17417MB
[2023-02-03 00:07:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][1150/1251]	eta 0:00:57 lr 0.000012	time 0.5536 (0.5695)	loss 2.3923 (2.5577)	grad_norm 3.1929 (2.9449)	mem 17417MB
[2023-02-03 00:08:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][1200/1251]	eta 0:00:29 lr 0.000012	time 0.5590 (0.5692)	loss 2.1624 (2.5545)	grad_norm 3.0134 (2.9497)	mem 17417MB
[2023-02-03 00:08:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [290/300][1250/1251]	eta 0:00:00 lr 0.000012	time 0.5498 (0.5692)	loss 3.2072 (2.5552)	grad_norm 3.3485 (2.9503)	mem 17417MB
[2023-02-03 00:08:53 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 290 training takes 0:11:52
[2023-02-03 00:08:53 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_290.pth saving......
[2023-02-03 00:08:55 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_290.pth saved !!!
[2023-02-03 00:08:56 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.955 (0.955)	Loss 0.6435 (0.6435)	Acc@1 85.840 (85.840)	Acc@5 96.973 (96.973)	Mem 17417MB
[2023-02-03 00:09:04 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.880 Acc@5 96.706
[2023-02-03 00:09:04 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-03 00:09:05 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.183 (1.183)	Loss 0.7450 (0.7450)	Acc@1 83.887 (83.887)	Acc@5 96.484 (96.484)	Mem 17417MB
[2023-02-03 00:09:13 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.966 Acc@5 96.784
[2023-02-03 00:09:13 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-03 00:09:13 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-03 00:09:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][0/1251]	eta 0:35:02 lr 0.000012	time 1.6805 (1.6805)	loss 2.6054 (2.6054)	grad_norm 3.0068 (3.0068)	mem 17417MB
[2023-02-03 00:09:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][50/1251]	eta 0:11:52 lr 0.000012	time 0.5529 (0.5933)	loss 2.2852 (2.5321)	grad_norm 4.0824 (3.0157)	mem 17417MB
[2023-02-03 00:10:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][100/1251]	eta 0:11:10 lr 0.000012	time 0.5625 (0.5824)	loss 2.3365 (2.5435)	grad_norm 3.0202 (3.0423)	mem 17417MB
[2023-02-03 00:10:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][150/1251]	eta 0:10:35 lr 0.000012	time 0.5566 (0.5771)	loss 3.0378 (2.5583)	grad_norm 3.1242 (3.0124)	mem 17417MB
[2023-02-03 00:11:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][200/1251]	eta 0:10:04 lr 0.000012	time 0.5684 (0.5755)	loss 2.6144 (2.5635)	grad_norm 3.6877 (2.9933)	mem 17417MB
[2023-02-03 00:11:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][250/1251]	eta 0:09:34 lr 0.000012	time 0.5541 (0.5743)	loss 2.3567 (2.5826)	grad_norm 2.6232 (3.0010)	mem 17417MB
[2023-02-03 00:12:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][300/1251]	eta 0:09:04 lr 0.000012	time 0.5533 (0.5728)	loss 1.8506 (2.5816)	grad_norm 3.1904 (2.9913)	mem 17417MB
[2023-02-03 00:12:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][350/1251]	eta 0:08:35 lr 0.000012	time 0.5514 (0.5723)	loss 2.3546 (2.5613)	grad_norm 4.1528 (2.9933)	mem 17417MB
[2023-02-03 00:13:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][400/1251]	eta 0:08:06 lr 0.000012	time 0.5533 (0.5713)	loss 3.1256 (2.5633)	grad_norm 2.8941 (2.9795)	mem 17417MB
[2023-02-03 00:13:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][450/1251]	eta 0:07:37 lr 0.000012	time 0.5499 (0.5710)	loss 2.5606 (2.5618)	grad_norm 2.4970 (2.9822)	mem 17417MB
[2023-02-03 00:13:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][500/1251]	eta 0:07:08 lr 0.000012	time 0.5586 (0.5709)	loss 2.9631 (2.5600)	grad_norm 2.5650 (2.9724)	mem 17417MB
[2023-02-03 00:14:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][550/1251]	eta 0:06:39 lr 0.000012	time 0.5540 (0.5706)	loss 2.8134 (2.5526)	grad_norm 2.2953 (2.9665)	mem 17417MB
[2023-02-03 00:14:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][600/1251]	eta 0:06:11 lr 0.000012	time 0.5525 (0.5705)	loss 1.6288 (2.5474)	grad_norm 2.9483 (2.9717)	mem 17417MB
[2023-02-03 00:15:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][650/1251]	eta 0:05:42 lr 0.000012	time 0.5564 (0.5705)	loss 2.5241 (2.5444)	grad_norm 2.9116 (2.9728)	mem 17417MB
[2023-02-03 00:15:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][700/1251]	eta 0:05:14 lr 0.000012	time 0.5617 (0.5700)	loss 2.8166 (2.5503)	grad_norm 2.7068 (2.9672)	mem 17417MB
[2023-02-03 00:16:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][750/1251]	eta 0:04:45 lr 0.000012	time 0.5551 (0.5699)	loss 2.9214 (2.5519)	grad_norm 2.9830 (2.9720)	mem 17417MB
[2023-02-03 00:16:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][800/1251]	eta 0:04:17 lr 0.000012	time 0.5604 (0.5699)	loss 2.1070 (2.5548)	grad_norm 2.9792 (2.9715)	mem 17417MB
[2023-02-03 00:17:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][850/1251]	eta 0:03:48 lr 0.000012	time 0.5638 (0.5699)	loss 2.1701 (2.5557)	grad_norm 3.6581 (2.9674)	mem 17417MB
[2023-02-03 00:17:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][900/1251]	eta 0:03:20 lr 0.000012	time 0.6356 (0.5700)	loss 2.4818 (2.5608)	grad_norm 3.3743 (2.9670)	mem 17417MB
[2023-02-03 00:18:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][950/1251]	eta 0:02:51 lr 0.000012	time 0.5590 (0.5697)	loss 3.1654 (2.5637)	grad_norm 3.7259 (2.9657)	mem 17417MB
[2023-02-03 00:18:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][1000/1251]	eta 0:02:22 lr 0.000012	time 0.5507 (0.5697)	loss 2.8808 (2.5636)	grad_norm 3.8520 (2.9636)	mem 17417MB
[2023-02-03 00:19:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][1050/1251]	eta 0:01:54 lr 0.000012	time 0.5483 (0.5697)	loss 3.0181 (2.5688)	grad_norm 2.6533 (2.9603)	mem 17417MB
[2023-02-03 00:19:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][1100/1251]	eta 0:01:26 lr 0.000012	time 0.5497 (0.5697)	loss 2.2059 (2.5681)	grad_norm 3.0054 (2.9614)	mem 17417MB
[2023-02-03 00:20:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][1150/1251]	eta 0:00:57 lr 0.000012	time 0.5536 (0.5698)	loss 2.6912 (2.5679)	grad_norm 3.1847 (2.9601)	mem 17417MB
[2023-02-03 00:20:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][1200/1251]	eta 0:00:29 lr 0.000012	time 0.6174 (0.5697)	loss 3.0011 (2.5676)	grad_norm 2.9495 (2.9619)	mem 17417MB
[2023-02-03 00:21:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [291/300][1250/1251]	eta 0:00:00 lr 0.000012	time 0.5503 (0.5696)	loss 2.7433 (2.5675)	grad_norm 2.8035 (2.9634)	mem 17417MB
[2023-02-03 00:21:06 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 291 training takes 0:11:52
[2023-02-03 00:21:06 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_291.pth saving......
[2023-02-03 00:21:08 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_291.pth saved !!!
[2023-02-03 00:21:09 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.872 (0.872)	Loss 0.7191 (0.7191)	Acc@1 83.496 (83.496)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-03 00:21:16 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.810 Acc@5 96.718
[2023-02-03 00:21:16 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.8%
[2023-02-03 00:21:18 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.358 (1.358)	Loss 0.6996 (0.6996)	Acc@1 83.984 (83.984)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-03 00:21:26 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.952 Acc@5 96.782
[2023-02-03 00:21:26 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-03 00:21:26 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-03 00:21:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][0/1251]	eta 0:34:40 lr 0.000012	time 1.6631 (1.6631)	loss 2.8194 (2.8194)	grad_norm 3.0839 (3.0839)	mem 17417MB
[2023-02-03 00:21:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][50/1251]	eta 0:11:46 lr 0.000012	time 0.5486 (0.5884)	loss 2.6981 (2.5534)	grad_norm 2.8876 (2.9748)	mem 17417MB
[2023-02-03 00:22:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][100/1251]	eta 0:11:06 lr 0.000012	time 0.5569 (0.5789)	loss 3.0188 (2.6069)	grad_norm 2.9305 (2.9842)	mem 17417MB
[2023-02-03 00:22:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][150/1251]	eta 0:10:32 lr 0.000012	time 0.5547 (0.5744)	loss 2.6389 (2.6219)	grad_norm 2.5807 (2.9864)	mem 17417MB
[2023-02-03 00:23:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][200/1251]	eta 0:10:02 lr 0.000012	time 0.5618 (0.5731)	loss 2.6632 (2.6092)	grad_norm 3.1974 (inf)	mem 17417MB
[2023-02-03 00:23:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][250/1251]	eta 0:09:33 lr 0.000012	time 0.5538 (0.5726)	loss 3.1248 (2.6032)	grad_norm 2.8208 (inf)	mem 17417MB
[2023-02-03 00:24:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][300/1251]	eta 0:09:03 lr 0.000012	time 0.6448 (0.5716)	loss 2.8702 (2.6043)	grad_norm 2.7469 (inf)	mem 17417MB
[2023-02-03 00:24:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][350/1251]	eta 0:08:34 lr 0.000012	time 0.5621 (0.5707)	loss 3.3221 (2.5892)	grad_norm 2.5340 (inf)	mem 17417MB
[2023-02-03 00:25:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][400/1251]	eta 0:08:04 lr 0.000012	time 0.5579 (0.5698)	loss 2.6471 (2.5930)	grad_norm 2.5027 (inf)	mem 17417MB
[2023-02-03 00:25:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][450/1251]	eta 0:07:36 lr 0.000012	time 0.5548 (0.5696)	loss 2.6577 (2.6046)	grad_norm 3.0099 (inf)	mem 17417MB
[2023-02-03 00:26:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][500/1251]	eta 0:07:07 lr 0.000012	time 0.5594 (0.5691)	loss 2.8329 (2.6074)	grad_norm 2.7126 (inf)	mem 17417MB
[2023-02-03 00:26:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][550/1251]	eta 0:06:38 lr 0.000012	time 0.5534 (0.5692)	loss 2.5290 (2.6095)	grad_norm 2.5107 (inf)	mem 17417MB
[2023-02-03 00:27:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][600/1251]	eta 0:06:10 lr 0.000012	time 0.5511 (0.5690)	loss 2.4777 (2.6044)	grad_norm 2.8560 (inf)	mem 17417MB
[2023-02-03 00:27:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][650/1251]	eta 0:05:41 lr 0.000012	time 0.5577 (0.5688)	loss 2.3636 (2.5954)	grad_norm 3.0688 (inf)	mem 17417MB
[2023-02-03 00:28:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][700/1251]	eta 0:05:13 lr 0.000012	time 0.5561 (0.5686)	loss 2.8385 (2.5869)	grad_norm 3.2070 (inf)	mem 17417MB
[2023-02-03 00:28:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][750/1251]	eta 0:04:44 lr 0.000011	time 0.5590 (0.5686)	loss 1.8876 (2.5817)	grad_norm 2.7644 (inf)	mem 17417MB
[2023-02-03 00:29:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][800/1251]	eta 0:04:16 lr 0.000011	time 0.5509 (0.5686)	loss 2.5595 (2.5747)	grad_norm 2.6779 (inf)	mem 17417MB
[2023-02-03 00:29:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][850/1251]	eta 0:03:47 lr 0.000011	time 0.5690 (0.5684)	loss 2.9845 (2.5742)	grad_norm 3.2957 (inf)	mem 17417MB
[2023-02-03 00:29:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][900/1251]	eta 0:03:19 lr 0.000011	time 0.5539 (0.5683)	loss 2.9774 (2.5742)	grad_norm 2.9565 (nan)	mem 17417MB
[2023-02-03 00:30:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][950/1251]	eta 0:02:51 lr 0.000011	time 0.5502 (0.5682)	loss 2.6506 (2.5685)	grad_norm 2.7107 (nan)	mem 17417MB
[2023-02-03 00:30:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][1000/1251]	eta 0:02:22 lr 0.000011	time 0.5538 (0.5681)	loss 2.7968 (2.5664)	grad_norm 2.8334 (nan)	mem 17417MB
[2023-02-03 00:31:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][1050/1251]	eta 0:01:54 lr 0.000011	time 0.5526 (0.5681)	loss 1.9243 (2.5630)	grad_norm 3.6481 (nan)	mem 17417MB
[2023-02-03 00:31:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][1100/1251]	eta 0:01:25 lr 0.000011	time 0.6209 (0.5681)	loss 3.0601 (2.5604)	grad_norm 3.0235 (nan)	mem 17417MB
[2023-02-03 00:32:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][1150/1251]	eta 0:00:57 lr 0.000011	time 0.5607 (0.5680)	loss 2.8422 (2.5619)	grad_norm 3.8214 (nan)	mem 17417MB
[2023-02-03 00:32:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][1200/1251]	eta 0:00:28 lr 0.000011	time 0.6282 (0.5681)	loss 2.5923 (2.5595)	grad_norm 2.5075 (nan)	mem 17417MB
[2023-02-03 00:33:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [292/300][1250/1251]	eta 0:00:00 lr 0.000011	time 0.5506 (0.5680)	loss 2.2223 (2.5612)	grad_norm 3.6543 (nan)	mem 17417MB
[2023-02-03 00:33:17 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 292 training takes 0:11:50
[2023-02-03 00:33:17 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_292.pth saving......
[2023-02-03 00:33:19 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_292.pth saved !!!
[2023-02-03 00:33:19 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.836 (0.836)	Loss 0.7144 (0.7144)	Acc@1 83.398 (83.398)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-03 00:33:27 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.884 Acc@5 96.724
[2023-02-03 00:33:27 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-03 00:33:29 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.231 (1.231)	Loss 0.6747 (0.6747)	Acc@1 84.277 (84.277)	Acc@5 97.266 (97.266)	Mem 17417MB
[2023-02-03 00:33:37 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.962 Acc@5 96.784
[2023-02-03 00:33:37 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 84.0%
[2023-02-03 00:33:37 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-03 00:33:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][0/1251]	eta 0:37:49 lr 0.000011	time 1.8145 (1.8145)	loss 2.7640 (2.7640)	grad_norm 2.9558 (2.9558)	mem 17417MB
[2023-02-03 00:34:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][50/1251]	eta 0:11:49 lr 0.000011	time 0.5544 (0.5909)	loss 2.4097 (2.5504)	grad_norm 2.5336 (3.0542)	mem 17417MB
[2023-02-03 00:34:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][100/1251]	eta 0:11:09 lr 0.000011	time 0.6398 (0.5815)	loss 2.8217 (2.5571)	grad_norm 2.9458 (3.0051)	mem 17417MB
[2023-02-03 00:35:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][150/1251]	eta 0:10:34 lr 0.000011	time 0.5529 (0.5762)	loss 2.3288 (2.5437)	grad_norm 2.9395 (3.0147)	mem 17417MB
[2023-02-03 00:35:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][200/1251]	eta 0:10:03 lr 0.000011	time 0.5482 (0.5740)	loss 2.7039 (2.5189)	grad_norm 3.0129 (2.9968)	mem 17417MB
[2023-02-03 00:36:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][250/1251]	eta 0:09:33 lr 0.000011	time 0.5583 (0.5727)	loss 2.8369 (2.5271)	grad_norm 4.0323 (3.0043)	mem 17417MB
[2023-02-03 00:36:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][300/1251]	eta 0:09:03 lr 0.000011	time 0.5572 (0.5714)	loss 2.8256 (2.5415)	grad_norm 2.8836 (2.9879)	mem 17417MB
[2023-02-03 00:36:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][350/1251]	eta 0:08:34 lr 0.000011	time 0.5618 (0.5709)	loss 2.8911 (2.5620)	grad_norm 2.7968 (2.9967)	mem 17417MB
[2023-02-03 00:37:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][400/1251]	eta 0:08:05 lr 0.000011	time 0.5599 (0.5702)	loss 2.5817 (2.5697)	grad_norm 2.8749 (2.9992)	mem 17417MB
[2023-02-03 00:37:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][450/1251]	eta 0:07:36 lr 0.000011	time 0.5574 (0.5703)	loss 3.0893 (2.5732)	grad_norm 3.0390 (3.0041)	mem 17417MB
[2023-02-03 00:38:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][500/1251]	eta 0:07:07 lr 0.000011	time 0.5546 (0.5698)	loss 2.9414 (2.5716)	grad_norm 2.7433 (3.0049)	mem 17417MB
[2023-02-03 00:38:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][550/1251]	eta 0:06:39 lr 0.000011	time 0.6387 (0.5700)	loss 2.5052 (2.5692)	grad_norm 2.7028 (3.0123)	mem 17417MB
[2023-02-03 00:39:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][600/1251]	eta 0:06:10 lr 0.000011	time 0.5618 (0.5697)	loss 3.1800 (2.5735)	grad_norm 3.4004 (3.0134)	mem 17417MB
[2023-02-03 00:39:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][650/1251]	eta 0:05:42 lr 0.000011	time 0.5681 (0.5697)	loss 2.2394 (2.5671)	grad_norm 2.8255 (3.0091)	mem 17417MB
[2023-02-03 00:40:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][700/1251]	eta 0:05:13 lr 0.000011	time 0.5563 (0.5694)	loss 1.5366 (2.5675)	grad_norm 3.5785 (3.0065)	mem 17417MB
[2023-02-03 00:40:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][750/1251]	eta 0:04:45 lr 0.000011	time 0.5600 (0.5695)	loss 2.2732 (2.5634)	grad_norm 2.5497 (3.0055)	mem 17417MB
[2023-02-03 00:41:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][800/1251]	eta 0:04:16 lr 0.000011	time 0.5519 (0.5692)	loss 1.8870 (2.5616)	grad_norm 2.7579 (2.9983)	mem 17417MB
[2023-02-03 00:41:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][850/1251]	eta 0:03:48 lr 0.000011	time 0.6158 (0.5693)	loss 2.0898 (2.5610)	grad_norm 2.7497 (2.9959)	mem 17417MB
[2023-02-03 00:42:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][900/1251]	eta 0:03:19 lr 0.000011	time 0.5555 (0.5691)	loss 2.7345 (2.5598)	grad_norm 2.7908 (2.9946)	mem 17417MB
[2023-02-03 00:42:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][950/1251]	eta 0:02:51 lr 0.000011	time 0.5519 (0.5689)	loss 2.6639 (2.5627)	grad_norm 2.8138 (2.9901)	mem 17417MB
[2023-02-03 00:43:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][1000/1251]	eta 0:02:22 lr 0.000011	time 0.5504 (0.5689)	loss 1.4829 (2.5607)	grad_norm 2.9892 (2.9881)	mem 17417MB
[2023-02-03 00:43:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][1050/1251]	eta 0:01:54 lr 0.000011	time 0.5729 (0.5689)	loss 2.1921 (2.5556)	grad_norm 2.6336 (2.9837)	mem 17417MB
[2023-02-03 00:44:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][1100/1251]	eta 0:01:25 lr 0.000011	time 0.6312 (0.5689)	loss 2.6095 (2.5530)	grad_norm 2.8377 (2.9850)	mem 17417MB
[2023-02-03 00:44:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][1150/1251]	eta 0:00:57 lr 0.000011	time 0.6157 (0.5687)	loss 3.0520 (2.5517)	grad_norm 2.9135 (2.9847)	mem 17417MB
[2023-02-03 00:45:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][1200/1251]	eta 0:00:29 lr 0.000011	time 0.5567 (0.5687)	loss 2.7547 (2.5475)	grad_norm 3.2950 (2.9830)	mem 17417MB
[2023-02-03 00:45:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [293/300][1250/1251]	eta 0:00:00 lr 0.000011	time 0.5492 (0.5687)	loss 1.6736 (2.5442)	grad_norm 2.9189 (2.9877)	mem 17417MB
[2023-02-03 00:45:28 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 293 training takes 0:11:51
[2023-02-03 00:45:29 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_293.pth saving......
[2023-02-03 00:45:30 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_293.pth saved !!!
[2023-02-03 00:45:31 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.841 (0.841)	Loss 0.7124 (0.7124)	Acc@1 83.398 (83.398)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-03 00:45:39 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.900 Acc@5 96.732
[2023-02-03 00:45:39 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-03 00:45:41 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.297 (1.297)	Loss 0.7055 (0.7055)	Acc@1 84.277 (84.277)	Acc@5 96.680 (96.680)	Mem 17417MB
[2023-02-03 00:45:49 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.946 Acc@5 96.784
[2023-02-03 00:45:49 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-03 00:45:49 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-03 00:45:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][0/1251]	eta 0:35:19 lr 0.000011	time 1.6942 (1.6942)	loss 2.8032 (2.8032)	grad_norm 3.2144 (3.2144)	mem 17417MB
[2023-02-03 00:46:19 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][50/1251]	eta 0:11:46 lr 0.000011	time 0.5523 (0.5882)	loss 2.0510 (2.6607)	grad_norm 3.5457 (2.9176)	mem 17417MB
[2023-02-03 00:46:47 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][100/1251]	eta 0:11:05 lr 0.000011	time 0.5528 (0.5778)	loss 2.5552 (2.5861)	grad_norm 2.9406 (2.9415)	mem 17417MB
[2023-02-03 00:47:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][150/1251]	eta 0:10:32 lr 0.000011	time 0.5555 (0.5743)	loss 2.2741 (2.5634)	grad_norm 2.8247 (2.9646)	mem 17417MB
[2023-02-03 00:47:44 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][200/1251]	eta 0:10:01 lr 0.000011	time 0.5580 (0.5723)	loss 2.3501 (2.5718)	grad_norm 2.6167 (2.9883)	mem 17417MB
[2023-02-03 00:48:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][250/1251]	eta 0:09:32 lr 0.000011	time 0.5582 (0.5719)	loss 2.9215 (2.5461)	grad_norm 3.6284 (2.9999)	mem 17417MB
[2023-02-03 00:48:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][300/1251]	eta 0:09:02 lr 0.000011	time 0.5659 (0.5709)	loss 1.7600 (2.5508)	grad_norm 2.8169 (3.0119)	mem 17417MB
[2023-02-03 00:49:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][350/1251]	eta 0:08:33 lr 0.000011	time 0.5564 (0.5704)	loss 2.7802 (2.5585)	grad_norm 2.9366 (3.0144)	mem 17417MB
[2023-02-03 00:49:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][400/1251]	eta 0:08:05 lr 0.000011	time 0.5580 (0.5700)	loss 2.5629 (2.5498)	grad_norm 2.5777 (3.0054)	mem 17417MB
[2023-02-03 00:50:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][450/1251]	eta 0:07:36 lr 0.000011	time 0.6425 (0.5696)	loss 2.6036 (2.5485)	grad_norm 2.7702 (3.0097)	mem 17417MB
[2023-02-03 00:50:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][500/1251]	eta 0:07:07 lr 0.000011	time 0.5553 (0.5697)	loss 2.2852 (2.5430)	grad_norm 2.7292 (3.0048)	mem 17417MB
[2023-02-03 00:51:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][550/1251]	eta 0:06:39 lr 0.000011	time 0.5536 (0.5695)	loss 2.4998 (2.5485)	grad_norm 2.6767 (3.0100)	mem 17417MB
[2023-02-03 00:51:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][600/1251]	eta 0:06:10 lr 0.000011	time 0.5531 (0.5695)	loss 2.8458 (2.5416)	grad_norm 2.9792 (3.0087)	mem 17417MB
[2023-02-03 00:51:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][650/1251]	eta 0:05:42 lr 0.000011	time 0.5525 (0.5692)	loss 2.1259 (2.5414)	grad_norm 2.6091 (3.0137)	mem 17417MB
[2023-02-03 00:52:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][700/1251]	eta 0:05:13 lr 0.000011	time 0.5584 (0.5690)	loss 2.4169 (2.5445)	grad_norm 2.9059 (3.0220)	mem 17417MB
[2023-02-03 00:52:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][750/1251]	eta 0:04:44 lr 0.000011	time 0.5539 (0.5688)	loss 2.6020 (2.5445)	grad_norm 2.4283 (3.0179)	mem 17417MB
[2023-02-03 00:53:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][800/1251]	eta 0:04:16 lr 0.000011	time 0.5462 (0.5689)	loss 2.2237 (2.5431)	grad_norm 2.7646 (3.0168)	mem 17417MB
[2023-02-03 00:53:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][850/1251]	eta 0:03:48 lr 0.000011	time 0.6129 (0.5688)	loss 2.6099 (2.5483)	grad_norm 3.0588 (3.0170)	mem 17417MB
[2023-02-03 00:54:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][900/1251]	eta 0:03:19 lr 0.000011	time 0.5449 (0.5688)	loss 2.1578 (2.5454)	grad_norm 3.2325 (3.0187)	mem 17417MB
[2023-02-03 00:54:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][950/1251]	eta 0:02:51 lr 0.000011	time 0.5536 (0.5684)	loss 2.5966 (2.5477)	grad_norm 3.0222 (3.0241)	mem 17417MB
[2023-02-03 00:55:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][1000/1251]	eta 0:02:22 lr 0.000011	time 0.5524 (0.5685)	loss 1.6080 (2.5475)	grad_norm 2.8525 (3.0201)	mem 17417MB
[2023-02-03 00:55:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][1050/1251]	eta 0:01:54 lr 0.000011	time 0.5575 (0.5684)	loss 2.9003 (2.5479)	grad_norm 2.8164 (3.0198)	mem 17417MB
[2023-02-03 00:56:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][1100/1251]	eta 0:01:25 lr 0.000011	time 0.6263 (0.5684)	loss 2.8201 (2.5469)	grad_norm 2.5920 (3.0231)	mem 17417MB
[2023-02-03 00:56:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][1150/1251]	eta 0:00:57 lr 0.000011	time 0.6309 (0.5684)	loss 2.1620 (2.5435)	grad_norm 3.8186 (3.0218)	mem 17417MB
[2023-02-03 00:57:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][1200/1251]	eta 0:00:28 lr 0.000011	time 0.5531 (0.5683)	loss 2.8913 (2.5486)	grad_norm 2.6401 (3.0221)	mem 17417MB
[2023-02-03 00:57:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [294/300][1250/1251]	eta 0:00:00 lr 0.000011	time 0.5487 (0.5683)	loss 2.7497 (2.5500)	grad_norm 3.1385 (3.0215)	mem 17417MB
[2023-02-03 00:57:40 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 294 training takes 0:11:51
[2023-02-03 00:57:40 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_294.pth saving......
[2023-02-03 00:57:41 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_294.pth saved !!!
[2023-02-03 00:57:42 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.853 (0.853)	Loss 0.6427 (0.6427)	Acc@1 85.547 (85.547)	Acc@5 96.582 (96.582)	Mem 17417MB
[2023-02-03 00:57:50 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.926 Acc@5 96.730
[2023-02-03 00:57:50 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-03 00:57:52 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.283 (1.283)	Loss 0.6740 (0.6740)	Acc@1 84.570 (84.570)	Acc@5 97.363 (97.363)	Mem 17417MB
[2023-02-03 00:58:00 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.940 Acc@5 96.780
[2023-02-03 00:58:00 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-03 00:58:00 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-03 00:58:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][0/1251]	eta 0:34:25 lr 0.000011	time 1.6511 (1.6511)	loss 1.9535 (1.9535)	grad_norm 2.8310 (2.8310)	mem 17417MB
[2023-02-03 00:58:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][50/1251]	eta 0:11:49 lr 0.000011	time 0.5564 (0.5908)	loss 2.6390 (2.5556)	grad_norm 2.9671 (3.0093)	mem 17417MB
[2023-02-03 00:58:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][100/1251]	eta 0:11:06 lr 0.000011	time 0.6112 (0.5791)	loss 2.4515 (2.5368)	grad_norm 3.9074 (3.0007)	mem 17417MB
[2023-02-03 00:59:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][150/1251]	eta 0:10:33 lr 0.000011	time 0.5534 (0.5752)	loss 2.8981 (2.5705)	grad_norm 3.9782 (2.9998)	mem 17417MB
[2023-02-03 00:59:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][200/1251]	eta 0:10:02 lr 0.000011	time 0.5475 (0.5734)	loss 2.7646 (2.5808)	grad_norm 2.5900 (2.9966)	mem 17417MB
[2023-02-03 01:00:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][250/1251]	eta 0:09:32 lr 0.000011	time 0.6398 (0.5723)	loss 1.4186 (2.5494)	grad_norm 2.8968 (3.0317)	mem 17417MB
[2023-02-03 01:00:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][300/1251]	eta 0:09:03 lr 0.000011	time 0.5527 (0.5711)	loss 2.3392 (2.5678)	grad_norm 2.8911 (3.0193)	mem 17417MB
[2023-02-03 01:01:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][350/1251]	eta 0:08:34 lr 0.000011	time 0.5624 (0.5706)	loss 1.6854 (2.5707)	grad_norm 3.0909 (3.0295)	mem 17417MB
[2023-02-03 01:01:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][400/1251]	eta 0:08:05 lr 0.000011	time 0.5714 (0.5701)	loss 1.7844 (2.5530)	grad_norm 2.4609 (3.0290)	mem 17417MB
[2023-02-03 01:02:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][450/1251]	eta 0:07:36 lr 0.000011	time 0.5550 (0.5696)	loss 3.2135 (2.5531)	grad_norm 3.1744 (3.0221)	mem 17417MB
[2023-02-03 01:02:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][500/1251]	eta 0:07:07 lr 0.000011	time 0.6128 (0.5693)	loss 2.5910 (2.5501)	grad_norm 2.9090 (3.0234)	mem 17417MB
[2023-02-03 01:03:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][550/1251]	eta 0:06:38 lr 0.000011	time 0.5449 (0.5688)	loss 2.1398 (2.5591)	grad_norm 2.6191 (3.0169)	mem 17417MB
[2023-02-03 01:03:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][600/1251]	eta 0:06:10 lr 0.000011	time 0.5593 (0.5687)	loss 1.9340 (2.5536)	grad_norm 3.2636 (inf)	mem 17417MB
[2023-02-03 01:04:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][650/1251]	eta 0:05:41 lr 0.000011	time 0.5524 (0.5685)	loss 2.8648 (2.5548)	grad_norm 3.3672 (inf)	mem 17417MB
[2023-02-03 01:04:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][700/1251]	eta 0:05:13 lr 0.000011	time 0.5581 (0.5685)	loss 2.9375 (2.5534)	grad_norm 3.2580 (inf)	mem 17417MB
[2023-02-03 01:05:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][750/1251]	eta 0:04:44 lr 0.000011	time 0.5564 (0.5684)	loss 3.0867 (2.5520)	grad_norm 2.9054 (inf)	mem 17417MB
[2023-02-03 01:05:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][800/1251]	eta 0:04:16 lr 0.000011	time 0.5551 (0.5683)	loss 2.9073 (2.5511)	grad_norm 2.8070 (inf)	mem 17417MB
[2023-02-03 01:06:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][850/1251]	eta 0:03:47 lr 0.000011	time 0.6091 (0.5682)	loss 2.4737 (2.5486)	grad_norm 3.8747 (inf)	mem 17417MB
[2023-02-03 01:06:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][900/1251]	eta 0:03:19 lr 0.000010	time 0.6194 (0.5682)	loss 2.8448 (2.5517)	grad_norm 2.9014 (inf)	mem 17417MB
[2023-02-03 01:07:00 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][950/1251]	eta 0:02:50 lr 0.000010	time 0.5558 (0.5681)	loss 3.0190 (2.5501)	grad_norm 2.9126 (inf)	mem 17417MB
[2023-02-03 01:07:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][1000/1251]	eta 0:02:22 lr 0.000010	time 0.5490 (0.5681)	loss 2.6259 (2.5536)	grad_norm 2.8326 (inf)	mem 17417MB
[2023-02-03 01:07:57 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][1050/1251]	eta 0:01:54 lr 0.000010	time 0.6449 (0.5680)	loss 2.3370 (2.5543)	grad_norm 3.0507 (inf)	mem 17417MB
[2023-02-03 01:08:25 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][1100/1251]	eta 0:01:25 lr 0.000010	time 0.5548 (0.5680)	loss 2.8593 (2.5559)	grad_norm 2.8562 (inf)	mem 17417MB
[2023-02-03 01:08:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][1150/1251]	eta 0:00:57 lr 0.000010	time 0.5632 (0.5680)	loss 3.1100 (2.5564)	grad_norm 2.7704 (inf)	mem 17417MB
[2023-02-03 01:09:22 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][1200/1251]	eta 0:00:28 lr 0.000010	time 0.5574 (0.5680)	loss 2.2012 (2.5524)	grad_norm 2.8527 (inf)	mem 17417MB
[2023-02-03 01:09:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [295/300][1250/1251]	eta 0:00:00 lr 0.000010	time 0.5478 (0.5680)	loss 2.1369 (2.5528)	grad_norm 2.9272 (inf)	mem 17417MB
[2023-02-03 01:09:50 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 295 training takes 0:11:50
[2023-02-03 01:09:51 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_295.pth saving......
[2023-02-03 01:09:52 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_295.pth saved !!!
[2023-02-03 01:09:53 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.986 (0.986)	Loss 0.6193 (0.6193)	Acc@1 85.254 (85.254)	Acc@5 97.070 (97.070)	Mem 17417MB
[2023-02-03 01:10:01 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.906 Acc@5 96.716
[2023-02-03 01:10:01 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-03 01:10:02 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.271 (1.271)	Loss 0.7579 (0.7579)	Acc@1 82.812 (82.812)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-03 01:10:10 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.940 Acc@5 96.778
[2023-02-03 01:10:10 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-03 01:10:10 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-03 01:10:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][0/1251]	eta 0:34:46 lr 0.000010	time 1.6678 (1.6678)	loss 2.7751 (2.7751)	grad_norm 3.0516 (3.0516)	mem 17417MB
[2023-02-03 01:10:41 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][50/1251]	eta 0:11:56 lr 0.000010	time 0.6558 (0.5968)	loss 2.8104 (2.5986)	grad_norm 2.7788 (3.0171)	mem 17417MB
[2023-02-03 01:11:09 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][100/1251]	eta 0:11:08 lr 0.000010	time 0.6188 (0.5811)	loss 2.1480 (2.5458)	grad_norm 3.6696 (3.0275)	mem 17417MB
[2023-02-03 01:11:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][150/1251]	eta 0:10:36 lr 0.000010	time 0.5543 (0.5778)	loss 2.4746 (2.5368)	grad_norm 2.9144 (3.0546)	mem 17417MB
[2023-02-03 01:12:06 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][200/1251]	eta 0:10:04 lr 0.000010	time 0.5519 (0.5748)	loss 1.6345 (2.5390)	grad_norm 2.7270 (3.0423)	mem 17417MB
[2023-02-03 01:12:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][250/1251]	eta 0:09:34 lr 0.000010	time 0.5519 (0.5736)	loss 2.7127 (2.5529)	grad_norm 2.9727 (3.0452)	mem 17417MB
[2023-02-03 01:13:03 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][300/1251]	eta 0:09:04 lr 0.000010	time 0.5555 (0.5723)	loss 2.6166 (2.5643)	grad_norm 3.2778 (3.0377)	mem 17417MB
[2023-02-03 01:13:31 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][350/1251]	eta 0:08:34 lr 0.000010	time 0.5542 (0.5715)	loss 2.0559 (2.5507)	grad_norm 2.7564 (3.0304)	mem 17417MB
[2023-02-03 01:13:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][400/1251]	eta 0:08:06 lr 0.000010	time 0.5534 (0.5712)	loss 2.7076 (2.5522)	grad_norm 2.9311 (3.0424)	mem 17417MB
[2023-02-03 01:14:28 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][450/1251]	eta 0:07:37 lr 0.000010	time 0.6187 (0.5710)	loss 2.0373 (2.5501)	grad_norm 2.6243 (3.0406)	mem 17417MB
[2023-02-03 01:14:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][500/1251]	eta 0:07:08 lr 0.000010	time 0.6262 (0.5702)	loss 2.2659 (2.5558)	grad_norm 3.9877 (3.0434)	mem 17417MB
[2023-02-03 01:15:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][550/1251]	eta 0:06:39 lr 0.000010	time 0.5459 (0.5701)	loss 2.9377 (2.5491)	grad_norm 2.9498 (3.0388)	mem 17417MB
[2023-02-03 01:15:53 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][600/1251]	eta 0:06:11 lr 0.000010	time 0.5535 (0.5700)	loss 2.2709 (2.5475)	grad_norm 2.8923 (3.0337)	mem 17417MB
[2023-02-03 01:16:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][650/1251]	eta 0:05:42 lr 0.000010	time 0.5561 (0.5698)	loss 2.9551 (2.5560)	grad_norm 2.8371 (3.0292)	mem 17417MB
[2023-02-03 01:16:50 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][700/1251]	eta 0:05:13 lr 0.000010	time 0.5597 (0.5698)	loss 2.3246 (2.5440)	grad_norm 2.9030 (3.0221)	mem 17417MB
[2023-02-03 01:17:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][750/1251]	eta 0:04:45 lr 0.000010	time 0.6307 (0.5695)	loss 2.1933 (2.5422)	grad_norm 3.2484 (3.0234)	mem 17417MB
[2023-02-03 01:17:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][800/1251]	eta 0:04:16 lr 0.000010	time 0.5544 (0.5694)	loss 2.5035 (2.5465)	grad_norm 2.7993 (3.0218)	mem 17417MB
[2023-02-03 01:18:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][850/1251]	eta 0:03:48 lr 0.000010	time 0.5598 (0.5694)	loss 2.7767 (2.5401)	grad_norm 3.1341 (3.0219)	mem 17417MB
[2023-02-03 01:18:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][900/1251]	eta 0:03:19 lr 0.000010	time 0.6244 (0.5692)	loss 2.8601 (2.5401)	grad_norm 3.0987 (3.0271)	mem 17417MB
[2023-02-03 01:19:12 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][950/1251]	eta 0:02:51 lr 0.000010	time 0.5570 (0.5691)	loss 3.1460 (2.5438)	grad_norm 2.9339 (3.0324)	mem 17417MB
[2023-02-03 01:19:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][1000/1251]	eta 0:02:22 lr 0.000010	time 0.5564 (0.5690)	loss 3.0069 (2.5431)	grad_norm 2.4929 (3.0318)	mem 17417MB
[2023-02-03 01:20:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][1050/1251]	eta 0:01:54 lr 0.000010	time 0.5537 (0.5689)	loss 2.7035 (2.5427)	grad_norm 3.0048 (3.0372)	mem 17417MB
[2023-02-03 01:20:37 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][1100/1251]	eta 0:01:25 lr 0.000010	time 0.5564 (0.5689)	loss 1.7470 (2.5445)	grad_norm 2.9744 (3.0331)	mem 17417MB
[2023-02-03 01:21:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][1150/1251]	eta 0:00:57 lr 0.000010	time 0.5593 (0.5688)	loss 2.6592 (2.5388)	grad_norm 3.1652 (3.0322)	mem 17417MB
[2023-02-03 01:21:34 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][1200/1251]	eta 0:00:29 lr 0.000010	time 0.5522 (0.5690)	loss 2.1045 (2.5404)	grad_norm 3.0048 (3.0345)	mem 17417MB
[2023-02-03 01:22:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [296/300][1250/1251]	eta 0:00:00 lr 0.000010	time 0.5507 (0.5689)	loss 2.8849 (2.5436)	grad_norm 2.9893 (3.0356)	mem 17417MB
[2023-02-03 01:22:02 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 296 training takes 0:11:51
[2023-02-03 01:22:02 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_296.pth saving......
[2023-02-03 01:22:04 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_296.pth saved !!!
[2023-02-03 01:22:05 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.855 (0.855)	Loss 0.6824 (0.6824)	Acc@1 84.961 (84.961)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-03 01:22:13 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.882 Acc@5 96.728
[2023-02-03 01:22:13 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-03 01:22:14 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.214 (1.214)	Loss 0.7397 (0.7397)	Acc@1 83.594 (83.594)	Acc@5 96.973 (96.973)	Mem 17417MB
[2023-02-03 01:22:22 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.936 Acc@5 96.770
[2023-02-03 01:22:22 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-03 01:22:22 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-03 01:22:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][0/1251]	eta 0:38:48 lr 0.000010	time 1.8610 (1.8610)	loss 2.5971 (2.5971)	grad_norm 3.1860 (3.1860)	mem 17417MB
[2023-02-03 01:22:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][50/1251]	eta 0:11:50 lr 0.000010	time 0.5547 (0.5916)	loss 3.3578 (2.6815)	grad_norm 3.9063 (3.1982)	mem 17417MB
[2023-02-03 01:23:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][100/1251]	eta 0:11:09 lr 0.000010	time 0.5526 (0.5818)	loss 2.3887 (2.6607)	grad_norm 3.1822 (3.1556)	mem 17417MB
[2023-02-03 01:23:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][150/1251]	eta 0:10:34 lr 0.000010	time 0.5550 (0.5763)	loss 2.9658 (2.6355)	grad_norm 3.3106 (3.1321)	mem 17417MB
[2023-02-03 01:24:18 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][200/1251]	eta 0:10:03 lr 0.000010	time 0.5582 (0.5744)	loss 2.8091 (2.5974)	grad_norm 3.3572 (3.0995)	mem 17417MB
[2023-02-03 01:24:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][250/1251]	eta 0:09:33 lr 0.000010	time 0.5549 (0.5731)	loss 3.1272 (2.5701)	grad_norm 4.0734 (3.0964)	mem 17417MB
[2023-02-03 01:25:15 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][300/1251]	eta 0:09:04 lr 0.000010	time 0.5760 (0.5726)	loss 2.2068 (2.5654)	grad_norm 3.8355 (3.0829)	mem 17417MB
[2023-02-03 01:25:43 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][350/1251]	eta 0:08:34 lr 0.000010	time 0.5548 (0.5714)	loss 2.2115 (2.5650)	grad_norm 3.0431 (3.0742)	mem 17417MB
[2023-02-03 01:26:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][400/1251]	eta 0:08:06 lr 0.000010	time 0.5613 (0.5714)	loss 2.2446 (2.5601)	grad_norm 2.8710 (3.0770)	mem 17417MB
[2023-02-03 01:26:40 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][450/1251]	eta 0:07:37 lr 0.000010	time 0.6246 (0.5705)	loss 2.9986 (2.5695)	grad_norm 3.0230 (3.0659)	mem 17417MB
[2023-02-03 01:27:08 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][500/1251]	eta 0:07:08 lr 0.000010	time 0.5568 (0.5705)	loss 2.5292 (2.5627)	grad_norm 2.6315 (3.0685)	mem 17417MB
[2023-02-03 01:27:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][550/1251]	eta 0:06:39 lr 0.000010	time 0.5598 (0.5699)	loss 2.8806 (2.5655)	grad_norm 3.8955 (3.0677)	mem 17417MB
[2023-02-03 01:28:05 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][600/1251]	eta 0:06:11 lr 0.000010	time 0.5480 (0.5701)	loss 2.7640 (2.5638)	grad_norm 2.5093 (3.0600)	mem 17417MB
[2023-02-03 01:28:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][650/1251]	eta 0:05:42 lr 0.000010	time 0.5570 (0.5698)	loss 2.1789 (2.5594)	grad_norm 3.1137 (3.0567)	mem 17417MB
[2023-02-03 01:29:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][700/1251]	eta 0:05:14 lr 0.000010	time 0.5633 (0.5700)	loss 1.9631 (2.5575)	grad_norm 2.4721 (3.0629)	mem 17417MB
[2023-02-03 01:29:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][750/1251]	eta 0:04:45 lr 0.000010	time 0.5606 (0.5696)	loss 2.5936 (2.5602)	grad_norm 3.1179 (3.0626)	mem 17417MB
[2023-02-03 01:29:59 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][800/1251]	eta 0:04:16 lr 0.000010	time 0.6192 (0.5698)	loss 1.9605 (2.5586)	grad_norm 2.9471 (3.0553)	mem 17417MB
[2023-02-03 01:30:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][850/1251]	eta 0:03:48 lr 0.000010	time 0.5604 (0.5694)	loss 1.6399 (2.5464)	grad_norm 3.2860 (3.0566)	mem 17417MB
[2023-02-03 01:30:56 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][900/1251]	eta 0:03:19 lr 0.000010	time 0.5605 (0.5697)	loss 1.8288 (2.5435)	grad_norm 2.7214 (3.0507)	mem 17417MB
[2023-02-03 01:31:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][950/1251]	eta 0:02:51 lr 0.000010	time 0.5540 (0.5695)	loss 2.9190 (2.5461)	grad_norm 3.5007 (3.0473)	mem 17417MB
[2023-02-03 01:31:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][1000/1251]	eta 0:02:22 lr 0.000010	time 0.6414 (0.5695)	loss 1.6893 (2.5449)	grad_norm 3.2390 (3.0431)	mem 17417MB
[2023-02-03 01:32:21 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][1050/1251]	eta 0:01:54 lr 0.000010	time 0.5540 (0.5693)	loss 1.9686 (2.5447)	grad_norm 3.1824 (3.0402)	mem 17417MB
[2023-02-03 01:32:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][1100/1251]	eta 0:01:25 lr 0.000010	time 0.6338 (0.5692)	loss 2.6651 (2.5465)	grad_norm 3.0267 (3.0369)	mem 17417MB
[2023-02-03 01:33:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][1150/1251]	eta 0:00:57 lr 0.000010	time 0.5477 (0.5692)	loss 2.7902 (2.5435)	grad_norm 3.2221 (3.0337)	mem 17417MB
[2023-02-03 01:33:46 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][1200/1251]	eta 0:00:29 lr 0.000010	time 0.6499 (0.5690)	loss 2.8173 (2.5421)	grad_norm 2.8358 (3.0341)	mem 17417MB
[2023-02-03 01:34:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [297/300][1250/1251]	eta 0:00:00 lr 0.000010	time 0.5480 (0.5690)	loss 3.0130 (2.5411)	grad_norm 2.8549 (3.0359)	mem 17417MB
[2023-02-03 01:34:14 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 297 training takes 0:11:51
[2023-02-03 01:34:14 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_297.pth saving......
[2023-02-03 01:34:16 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_297.pth saved !!!
[2023-02-03 01:34:17 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.872 (0.872)	Loss 0.6039 (0.6039)	Acc@1 85.742 (85.742)	Acc@5 97.559 (97.559)	Mem 17417MB
[2023-02-03 01:34:25 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.934 Acc@5 96.726
[2023-02-03 01:34:25 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-03 01:34:26 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.346 (1.346)	Loss 0.7420 (0.7420)	Acc@1 82.520 (82.520)	Acc@5 96.387 (96.387)	Mem 17417MB
[2023-02-03 01:34:34 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.944 Acc@5 96.768
[2023-02-03 01:34:34 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-03 01:34:34 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-03 01:34:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][0/1251]	eta 0:35:08 lr 0.000010	time 1.6852 (1.6852)	loss 2.8043 (2.8043)	grad_norm 3.0767 (3.0767)	mem 17417MB
[2023-02-03 01:35:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][50/1251]	eta 0:11:54 lr 0.000010	time 0.5518 (0.5949)	loss 2.7125 (2.5704)	grad_norm 2.7531 (2.9613)	mem 17417MB
[2023-02-03 01:35:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][100/1251]	eta 0:11:10 lr 0.000010	time 0.5525 (0.5825)	loss 2.9212 (2.5306)	grad_norm 3.0721 (2.9972)	mem 17417MB
[2023-02-03 01:36:02 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][150/1251]	eta 0:10:37 lr 0.000010	time 0.5590 (0.5787)	loss 2.6054 (2.5344)	grad_norm 3.7851 (2.9996)	mem 17417MB
[2023-02-03 01:36:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][200/1251]	eta 0:10:04 lr 0.000010	time 0.5548 (0.5754)	loss 3.2212 (2.5551)	grad_norm 3.4059 (2.9927)	mem 17417MB
[2023-02-03 01:36:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][250/1251]	eta 0:09:34 lr 0.000010	time 0.5575 (0.5737)	loss 2.4092 (2.5426)	grad_norm 3.3209 (2.9869)	mem 17417MB
[2023-02-03 01:37:27 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][300/1251]	eta 0:09:05 lr 0.000010	time 0.5551 (0.5735)	loss 2.9595 (2.5582)	grad_norm 3.1816 (3.0168)	mem 17417MB
[2023-02-03 01:37:55 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][350/1251]	eta 0:08:35 lr 0.000010	time 0.5609 (0.5722)	loss 2.1437 (2.5642)	grad_norm 3.2145 (3.0347)	mem 17417MB
[2023-02-03 01:38:24 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][400/1251]	eta 0:08:06 lr 0.000010	time 0.6324 (0.5720)	loss 2.7882 (2.5722)	grad_norm 3.1985 (3.0356)	mem 17417MB
[2023-02-03 01:38:52 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][450/1251]	eta 0:07:37 lr 0.000010	time 0.6468 (0.5716)	loss 2.6765 (2.5673)	grad_norm 4.1502 (3.0474)	mem 17417MB
[2023-02-03 01:39:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][500/1251]	eta 0:07:08 lr 0.000010	time 0.5524 (0.5708)	loss 2.8710 (2.5541)	grad_norm 2.8857 (3.0386)	mem 17417MB
[2023-02-03 01:39:49 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][550/1251]	eta 0:06:40 lr 0.000010	time 0.5552 (0.5710)	loss 3.0321 (2.5468)	grad_norm 2.6549 (3.0527)	mem 17417MB
[2023-02-03 01:40:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][600/1251]	eta 0:06:11 lr 0.000010	time 0.5531 (0.5706)	loss 2.1566 (2.5451)	grad_norm 2.9926 (3.0661)	mem 17417MB
[2023-02-03 01:40:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][650/1251]	eta 0:05:42 lr 0.000010	time 0.5492 (0.5704)	loss 1.7049 (2.5414)	grad_norm 3.6919 (3.0643)	mem 17417MB
[2023-02-03 01:41:14 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][700/1251]	eta 0:05:14 lr 0.000010	time 0.5566 (0.5701)	loss 2.3866 (2.5343)	grad_norm 3.4896 (3.0586)	mem 17417MB
[2023-02-03 01:41:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][750/1251]	eta 0:04:45 lr 0.000010	time 0.5516 (0.5698)	loss 2.1917 (2.5362)	grad_norm 2.5834 (3.0557)	mem 17417MB
[2023-02-03 01:42:11 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][800/1251]	eta 0:04:16 lr 0.000010	time 0.6207 (0.5698)	loss 3.1847 (2.5379)	grad_norm 2.8850 (3.0553)	mem 17417MB
[2023-02-03 01:42:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][850/1251]	eta 0:03:48 lr 0.000010	time 0.5517 (0.5697)	loss 2.4107 (2.5326)	grad_norm 3.2140 (3.0501)	mem 17417MB
[2023-02-03 01:43:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][900/1251]	eta 0:03:19 lr 0.000010	time 0.5534 (0.5695)	loss 3.0048 (2.5311)	grad_norm 3.1798 (inf)	mem 17417MB
[2023-02-03 01:43:36 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][950/1251]	eta 0:02:51 lr 0.000010	time 0.5602 (0.5696)	loss 2.6060 (2.5316)	grad_norm 2.9546 (inf)	mem 17417MB
[2023-02-03 01:44:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][1000/1251]	eta 0:02:22 lr 0.000010	time 0.5539 (0.5694)	loss 2.2455 (2.5321)	grad_norm 2.5659 (inf)	mem 17417MB
[2023-02-03 01:44:33 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][1050/1251]	eta 0:01:54 lr 0.000010	time 0.5789 (0.5694)	loss 2.5560 (2.5314)	grad_norm 3.1479 (inf)	mem 17417MB
[2023-02-03 01:45:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][1100/1251]	eta 0:01:25 lr 0.000010	time 0.5491 (0.5695)	loss 2.9945 (2.5372)	grad_norm 2.6666 (inf)	mem 17417MB
[2023-02-03 01:45:30 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][1150/1251]	eta 0:00:57 lr 0.000010	time 0.5509 (0.5695)	loss 1.7222 (2.5350)	grad_norm 4.0220 (inf)	mem 17417MB
[2023-02-03 01:45:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][1200/1251]	eta 0:00:29 lr 0.000010	time 0.6273 (0.5695)	loss 3.0371 (2.5385)	grad_norm 3.2044 (inf)	mem 17417MB
[2023-02-03 01:46:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [298/300][1250/1251]	eta 0:00:00 lr 0.000010	time 0.6143 (0.5694)	loss 1.7914 (2.5393)	grad_norm 3.3908 (inf)	mem 17417MB
[2023-02-03 01:46:27 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 298 training takes 0:11:52
[2023-02-03 01:46:27 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_298.pth saving......
[2023-02-03 01:46:28 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_298.pth saved !!!
[2023-02-03 01:46:29 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.859 (0.859)	Loss 0.7180 (0.7180)	Acc@1 82.812 (82.812)	Acc@5 96.777 (96.777)	Mem 17417MB
[2023-02-03 01:46:37 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.934 Acc@5 96.728
[2023-02-03 01:46:37 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-03 01:46:38 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.172 (1.172)	Loss 0.7323 (0.7323)	Acc@1 83.594 (83.594)	Acc@5 96.094 (96.094)	Mem 17417MB
[2023-02-03 01:46:47 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.942 Acc@5 96.760
[2023-02-03 01:46:47 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-03 01:46:47 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-03 01:46:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][0/1251]	eta 0:33:15 lr 0.000010	time 1.5947 (1.5947)	loss 2.5872 (2.5872)	grad_norm 3.3222 (3.3222)	mem 17417MB
[2023-02-03 01:47:17 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][50/1251]	eta 0:11:43 lr 0.000010	time 0.5541 (0.5858)	loss 1.9638 (2.6450)	grad_norm 2.5705 (2.9957)	mem 17417MB
[2023-02-03 01:47:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][100/1251]	eta 0:11:06 lr 0.000010	time 0.6534 (0.5786)	loss 2.0577 (2.5931)	grad_norm 2.5869 (3.0291)	mem 17417MB
[2023-02-03 01:48:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][150/1251]	eta 0:10:32 lr 0.000010	time 0.5545 (0.5740)	loss 2.5236 (2.6130)	grad_norm 3.1495 (3.0749)	mem 17417MB
[2023-02-03 01:48:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][200/1251]	eta 0:10:02 lr 0.000010	time 0.5552 (0.5731)	loss 1.9125 (2.5673)	grad_norm 2.8933 (3.0575)	mem 17417MB
[2023-02-03 01:49:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][250/1251]	eta 0:09:32 lr 0.000010	time 0.5552 (0.5717)	loss 2.9878 (2.5604)	grad_norm 2.9541 (3.0587)	mem 17417MB
[2023-02-03 01:49:39 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][300/1251]	eta 0:09:03 lr 0.000010	time 0.5475 (0.5714)	loss 2.3595 (2.5445)	grad_norm 2.2348 (3.0516)	mem 17417MB
[2023-02-03 01:50:07 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][350/1251]	eta 0:08:34 lr 0.000010	time 0.5606 (0.5705)	loss 3.1637 (2.5461)	grad_norm 2.9464 (3.0515)	mem 17417MB
[2023-02-03 01:50:35 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][400/1251]	eta 0:08:05 lr 0.000010	time 0.5510 (0.5706)	loss 2.9070 (2.5524)	grad_norm 3.1099 (3.0509)	mem 17417MB
[2023-02-03 01:51:04 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][450/1251]	eta 0:07:36 lr 0.000010	time 0.5619 (0.5701)	loss 2.9189 (2.5455)	grad_norm 2.9961 (3.0482)	mem 17417MB
[2023-02-03 01:51:32 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][500/1251]	eta 0:07:08 lr 0.000010	time 0.5489 (0.5701)	loss 2.1605 (2.5390)	grad_norm 3.0106 (3.0512)	mem 17417MB
[2023-02-03 01:52:01 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][550/1251]	eta 0:06:39 lr 0.000010	time 0.5627 (0.5700)	loss 2.6208 (2.5401)	grad_norm 2.5976 (3.0499)	mem 17417MB
[2023-02-03 01:52:29 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][600/1251]	eta 0:06:11 lr 0.000010	time 0.5597 (0.5702)	loss 2.6804 (2.5477)	grad_norm 3.4463 (3.0533)	mem 17417MB
[2023-02-03 01:52:58 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][650/1251]	eta 0:05:42 lr 0.000010	time 0.5516 (0.5699)	loss 2.8990 (2.5479)	grad_norm 2.6225 (3.0553)	mem 17417MB
[2023-02-03 01:53:26 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][700/1251]	eta 0:05:13 lr 0.000010	time 0.5646 (0.5695)	loss 2.8302 (2.5466)	grad_norm 2.7519 (nan)	mem 17417MB
[2023-02-03 01:53:54 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][750/1251]	eta 0:04:45 lr 0.000010	time 0.6247 (0.5695)	loss 1.7810 (2.5449)	grad_norm 3.0925 (nan)	mem 17417MB
[2023-02-03 01:54:23 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][800/1251]	eta 0:04:16 lr 0.000010	time 0.5574 (0.5696)	loss 3.1425 (2.5449)	grad_norm 3.3983 (nan)	mem 17417MB
[2023-02-03 01:54:51 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][850/1251]	eta 0:03:48 lr 0.000010	time 0.5598 (0.5695)	loss 2.3936 (2.5457)	grad_norm 2.6499 (nan)	mem 17417MB
[2023-02-03 01:55:20 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][900/1251]	eta 0:03:19 lr 0.000010	time 0.5570 (0.5695)	loss 2.8255 (2.5459)	grad_norm 3.8667 (nan)	mem 17417MB
[2023-02-03 01:55:48 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][950/1251]	eta 0:02:51 lr 0.000010	time 0.5540 (0.5693)	loss 2.5086 (2.5436)	grad_norm 2.5366 (nan)	mem 17417MB
[2023-02-03 01:56:16 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][1000/1251]	eta 0:02:22 lr 0.000010	time 0.5575 (0.5693)	loss 2.5354 (2.5400)	grad_norm 2.5829 (nan)	mem 17417MB
[2023-02-03 01:56:45 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][1050/1251]	eta 0:01:54 lr 0.000010	time 0.5585 (0.5692)	loss 2.7024 (2.5418)	grad_norm 2.8427 (nan)	mem 17417MB
[2023-02-03 01:57:13 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][1100/1251]	eta 0:01:25 lr 0.000010	time 0.6258 (0.5691)	loss 2.8751 (2.5412)	grad_norm 2.3761 (nan)	mem 17417MB
[2023-02-03 01:57:42 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][1150/1251]	eta 0:00:57 lr 0.000010	time 0.5540 (0.5690)	loss 2.9086 (2.5427)	grad_norm 2.6410 (nan)	mem 17417MB
[2023-02-03 01:58:10 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][1200/1251]	eta 0:00:29 lr 0.000010	time 0.5628 (0.5690)	loss 1.9657 (2.5400)	grad_norm 2.8450 (nan)	mem 17417MB
[2023-02-03 01:58:38 QFormer_transformer_base_patch4_window7_224] (main.py 312): INFO Train: [299/300][1250/1251]	eta 0:00:00 lr 0.000010	time 0.5471 (0.5689)	loss 3.2074 (2.5441)	grad_norm 3.2523 (nan)	mem 17417MB
[2023-02-03 01:58:39 QFormer_transformer_base_patch4_window7_224] (main.py 320): INFO EPOCH 299 training takes 0:11:51
[2023-02-03 01:58:39 QFormer_transformer_base_patch4_window7_224] (utils.py 162): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_299.pth saving......
[2023-02-03 01:58:40 QFormer_transformer_base_patch4_window7_224] (utils.py 164): INFO output/QFormer_transformer_base_patch4_window7_224/1024-dpr55-coords_lambda5e-1/ckpt_epoch_299.pth saved !!!
[2023-02-03 01:58:41 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 0.848 (0.848)	Loss 0.7919 (0.7919)	Acc@1 81.836 (81.836)	Acc@5 96.289 (96.289)	Mem 17417MB
[2023-02-03 01:58:49 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.898 Acc@5 96.728
[2023-02-03 01:58:49 QFormer_transformer_base_patch4_window7_224] (main.py 211): INFO Accuracy of the network on the 50000 test images: 83.9%
[2023-02-03 01:58:50 QFormer_transformer_base_patch4_window7_224] (main.py 364): INFO Test: [0/49]	Time 1.210 (1.210)	Loss 0.6964 (0.6964)	Acc@1 83.594 (83.594)	Acc@5 96.582 (96.582)	Mem 17417MB
[2023-02-03 01:58:58 QFormer_transformer_base_patch4_window7_224] (main.py 371): INFO  * Acc@1 83.946 Acc@5 96.768
[2023-02-03 01:58:58 QFormer_transformer_base_patch4_window7_224] (main.py 224): INFO Accuracy of the ema network on the 50000 test images: 83.9%
[2023-02-03 01:58:58 QFormer_transformer_base_patch4_window7_224] (main.py 228): INFO Max accuracy: 84.08% at 268 epoch
[2023-02-03 01:58:58 QFormer_transformer_base_patch4_window7_224] (main.py 232): INFO Training time 2 days, 13:01:09
